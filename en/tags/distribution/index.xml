<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Distribution on </title>
    <link>https://chengjunwang.com/en/tags/distribution/index.xml</link>
    <description>Recent content in Distribution on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Cheng-Jun Wang</copyright>
    <atom:link href="/en/tags/distribution/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Fitting rank order distribution with R</title>
      <link>https://chengjunwang.com/en/post/en/2014-03-17-fit-power-law/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/en/post/en/2014-03-17-fit-power-law/</guid>
      <description>

&lt;p&gt;The long-tail distribution can be quantified in primarily &lt;a href=&#34;http://arxiv.org/pdf/cond-mat/0412004.pdf?origin=publication_detail&#34; target=&#34;_blank&#34;&gt;three ways, see Newman &amp;rsquo;s paper here&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Power law distribution&lt;/li&gt;
&lt;li&gt;Zipf distribution&lt;/li&gt;
&lt;li&gt;Pareto distribution&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here, I talk about the Zipf distribution which assesses the relationship between rank order and Frequency (probability).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Zipf&amp;rsquo;s law now refers more generally to frequency distributions of &amp;ldquo;rank data,&amp;rdquo; in which the relative frequency of the nth-ranked item is given by the Zeta distribution. from &lt;a href=&#34;http://en.wikipedia.org/wiki/Zipf&#39;s_law&#34; target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;dgbd&#34;&gt;DGBD&lt;/h2&gt;

&lt;p&gt;In Gustavo Martínez-Mekler et al&amp;rsquo;s &lt;a href=&#34;http://www.plosone.org/article/info%3adoi/10.1371/journal.pone.0004791&#34; target=&#34;_blank&#34;&gt;article&lt;/a&gt;, they proposed a discrete generalized beta distribution: $$f&amp;reg; = A(N+1-r)^b/r^a$$, where r is the rank, &lt;strong&gt;N&lt;/strong&gt; is maximum value, A the normalization constant and (a, b) two fitting exponents.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s interesting to find that &lt;a href=&#34;http://journals.aps.org/pre/pdf/10.1103/PhysRevE.84.026113&#34; target=&#34;_blank&#34;&gt;Wu and Zhang (2011)&lt;/a&gt; adopt the DGBD distribution to quantify the online social systems. Basically, they are interested in accelerating growth in human online behaviors.&lt;/p&gt;

&lt;p&gt;Deﬁning P as the number of active users in a day and T as the total activity generated by these users, they find a power law relationship between them $$T = P^\gamma$$. Given $$\gamma$$ larger than 1, there exists an accelerating growth phenomena in online systems (e.g., tagging, microblogging)&lt;/p&gt;

&lt;p&gt;They denote the activity of a user in one day with t&amp;reg;, in which r is the decreasing rank of the activity among all individual activities in the day. Thus the maximum value of r, $$r_{max}$$, equals population P. The DGBD model of individual activities is then&lt;/p&gt;

&lt;p&gt;$$t&amp;reg; = A(P+1−r)^b r^a (a &amp;gt; 0,b &amp;gt; 0)$$&lt;/p&gt;

&lt;p&gt;They introduced that a determines the activities of highly active users(corresponds to the exponent $$\alpha$$ in Zipf’s law), b determines the activities of the less active users. Using the DGBD, They can ﬁt the empirical curves with $$R^2$$ &amp;gt; 0.9.&lt;/p&gt;

&lt;p&gt;Here I start with an empirical dataset. The Tweet of Milan city in December 2013. Basically, we know the language of each tweet. Thus we have the frequency of each language.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;freq = c(1116, 2067, 137 ,  124, 643,  2042, 55  ,47186,  7504, 1488, 211,   1608,  3517 , 7  , 896  ,  378, 17 ,3098, 164977  ,  601 ,  196, 637, 149 , 44,2 ,  1801, 882   , 636,5184,  1851,  776 ,   343   , 851, 33  ,4011,   209,  715 ,  937 , 20,   6922, 2028 , 23,  3045 , 16 , 334,  31 ,  2)

lan = c(&amp;quot;af&amp;quot;,&amp;quot;ar&amp;quot;,&amp;quot;bg&amp;quot;,&amp;quot;cs&amp;quot;,&amp;quot;da&amp;quot;,&amp;quot;de&amp;quot;,&amp;quot;el&amp;quot;,&amp;quot;en&amp;quot;,&amp;quot;es&amp;quot;,&amp;quot;et&amp;quot;,&amp;quot;fa&amp;quot;,&amp;quot;fi&amp;quot;,&amp;quot;fr&amp;quot;,&amp;quot;he&amp;quot;,&amp;quot;hr&amp;quot;,&amp;quot;hu&amp;quot;,&amp;quot;id&amp;quot;,&amp;quot;it&amp;quot;,&amp;quot;ja&amp;quot;,&amp;quot;ko&amp;quot;,&amp;quot;lt&amp;quot;,&amp;quot;lv&amp;quot;,&amp;quot;mk&amp;quot;,&amp;quot;ne&amp;quot;,&amp;quot;nl&amp;quot;,&amp;quot;no&amp;quot;,&amp;quot;pl&amp;quot;,&amp;quot;pt&amp;quot;,&amp;quot;ro&amp;quot;,&amp;quot;ru&amp;quot;,&amp;quot;sk&amp;quot;,&amp;quot;sl&amp;quot;,&amp;quot;so&amp;quot;,&amp;quot;sq&amp;quot;,&amp;quot;sv&amp;quot;,&amp;quot;sw&amp;quot;,&amp;quot;th&amp;quot;,&amp;quot;tl&amp;quot;,&amp;quot;tr&amp;quot;,&amp;quot;uk&amp;quot;,&amp;quot;und&amp;quot;,&amp;quot;ur&amp;quot;,&amp;quot;vi&amp;quot;,&amp;quot;zh-cn&amp;quot;,&amp;quot;zh-tw&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus, we can calculate the decreasing rank for each language.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Rank = rank(-freq, ties.method = c(&amp;quot;first&amp;quot;) )
data = data.frame(lan, freq, Rank)
data$Probability = data$Freq/sum(data$Freq)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can write a simple function to fit the rank ordered data and capture the distribution.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;get_dgbd = function(freq){
  Rank = rank(-freq, ties.method = c(&amp;quot;first&amp;quot;) )
  p = freq/sum(as.numeric(freq))
  # get the log form
  log.f = log(freq)
  log.p = log(p)
  log.rank = log(Rank)
  log.inverse.rank = log(length(Rank)+1-Rank)

  # linear regression of zifp: for probability
  cozp=coef(lm(log.p~log.rank))
  zipf.p = function(x) exp(cozp[[1]] + cozp[2]*log(x))

  # linear regression of zifp: for frequency
  cozf=coef(lm(log.f~log.rank))
  zipf.f = function(x) exp(cozf[[1]] + cozf[2]*log(x))

  # linear regression of dgbd: for probability
  codp=coef(lm(log.p~log.inverse.rank + log.rank))
  dgbd.p = function(x) exp(codp[[1]]+ codp[[2]]*log(length(x)+1-x) + codp[[3]]*log(x))

  # linear regression of dgbd: for frequency
  codf=coef(lm(log.f~log.inverse.rank + log.rank))
  dgbd.f = function(x) exp(codf[[1]]+ codf[[2]]*log(length(x)+1-x) + codf[[3]]*log(x))
  return(c(zipf.p, zipf.f, dgbd.p, dgbd.f))
}

zipf.p = get_dgbd(data$Freq)[[1]]
zipf.f = get_dgbd(data$Freq)[[2]]
dgbd.p = get_dgbd(data$Freq)[[3]]
dgbd.f = get_dgbd(data$Freq)[[4]]


plot(freq~Rank,log=&amp;quot;xy&amp;quot;, xlab = &amp;quot;Rank (log)&amp;quot;, ylab = &amp;quot;Frequency (log)&amp;quot;, data = data)
curve(zipf.f, col=&amp;quot;red&amp;quot;, add = T, n = length(data$Rank))
curve(dgbd.f, col=&amp;quot;blue&amp;quot;, add = T, n = length(data$Rank))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remember to specify the length of values in &amp;lsquo;curve&amp;rsquo;. About its importance, check &lt;a href=&#34;http://stackoverflow.com/questions/22446006/why-is-curve-so-different-from-lines-and-points-in-r&#34; target=&#34;_blank&#34;&gt;this post&lt;/a&gt; on stackoverflow.&lt;/p&gt;

&lt;p&gt;Finally, we can plot it with ggplot2.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;require(ggplot2)
P = ggplot(data=data, aes(x=Rank, y=Freq, label = Var1)) + geom_point() +
  coord_trans(xtrans = &amp;quot;log10&amp;quot;, ytrans = &amp;quot;log10&amp;quot;)+
  stat_function(fun = dgbd.f, n = length(Rank), colour = &#39;red&#39;, size = 1)+
  geom_text(aes(label=Var1),hjust=1.5, vjust=0, angle = 45, size = 3)

png(file = &amp;quot;./language_rank_order_distribution2.png&amp;quot;,
    width=8, height=5,
    units=&amp;quot;in&amp;quot;, res=700)
P
dev.off()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm3.staticflickr.com/2725/13212714535_820edf5a12_z.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm3.staticflickr.com/2767/13213038184_4d8fb106d2_z.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-to-construct-your-model&#34;&gt;How to construct your model?&lt;/h2&gt;

&lt;p&gt;Using the DGBD model, we can fit the frequency-rank data almost perfectly. However, there are many other other forms of alternative equations. For example, there are Zipf-Manderbrot Model and &lt;a href=&#34;http://statweb.stanford.edu/~owen/courses/306a/ZipfAndGutenberg.pdf&#34; target=&#34;_blank&#34;&gt;its modifications&lt;/a&gt;, How to guarantee that which specific model is the right one? We need to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;learn more about the underlying mechanisms.&lt;/li&gt;
&lt;li&gt;observe the patterns of the data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the paper titled &lt;a href=&#34;http://www3.nd.edu/~networks/Publication%20Categories/03%20Journal%20Articles/Social%20Science/Modeling%20bursts_Phys.%20Rev.%20E%2073,%20036127%20(2006).pdf&#34; target=&#34;_blank&#34;&gt;Modeling bursts and heavy tails in human dynamics&lt;/a&gt;, Alexei Vázquez et al tried to propose two queuing models to explain the &lt;strong&gt;value&lt;/strong&gt; of scaling parameter in the temporal patterns of human behaviors. They capture the temporal patterns with two measurements: interevent time $$\tau$$ and waiting times $$\tau_{w}$$.&lt;/p&gt;

&lt;p&gt;The time between two consecutive events is called the interevent time, $$\tau$$; the waiting (or response) time, $$\tau_w$$, representing the amount of time a task waits on an individual’s priority list before being executed.&lt;/p&gt;

&lt;p&gt;Assuming that &lt;strong&gt;the tasks are executed independently from each other at a constant rate $$\lambda$$&lt;/strong&gt;, the time can be approximated by a Poisson process:&lt;/p&gt;

&lt;p&gt;$$p(\tau) = \lambda e^{-\lambda \tau}$$ .&lt;/p&gt;

&lt;p&gt;However, we know that in many human behaviors, the Poisson process fails to capture the burst phenomenon. The temporal patterns can be generally categorized into two classes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A. The $$\alpha$$= 1 universality class: Web browsing, email, and library datasets&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;B. The $$\alpha$$=&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; universality class: The correspondence of Einstein, Darwin, and Freud, which is characterized by &lt;strong&gt;a power law decay&lt;/strong&gt; combined with &lt;strong&gt;an exponential cutoff&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$$p(\tau)\simeq \tau^{-&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;} e^{-\tau / \tau_{0}}$$.&lt;/p&gt;

&lt;p&gt;in which $$\tau_0 = \frac{1}{\mu (1-\sqrt{\rho})}$$, and $$\rho = \lambda / \mu$$. Recall that $$\lambda$$ is the arrival rate of new task, and $$\mu$$ is the response rate , thus $$\rho$$ is the task/job/traffic intensity.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Subcritical regime: When $$\rho$$ &amp;lt; 1, there are fewer job, and more queuing space.&lt;/li&gt;
&lt;li&gt;Critical regime: When $$\rho$$ = 1, arrival rate equals response rate&lt;/li&gt;
&lt;li&gt;Supercritical regime: When $$\rho$$ &amp;gt; 1, there are more job, and less queuing space.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, they also find that the interevent time distribution between two consecutive transactions made by a stock broker. The distribution follows a power law with the exponential cutoff $$p(\tau)\simeq \tau^{-1.3} e^{-\tau / \tau_{0}}$$.&lt;/p&gt;

&lt;p&gt;####References&lt;/p&gt;

&lt;p&gt;Martínez-Mekler G, Martínez RA, del Río MB, Mansilla R, Miramontes P, et al. (2009) Universality of Rank-Ordering Distributions in the Arts and Sciences. PLoS ONE 4(3): e4791. doi:10.1371/journal.pone.0004791&lt;/p&gt;

&lt;p&gt;Wu L, Zhang J. (2011) Accelerating growth and size-dependent distribution of human online activities. PHYSICAL REVIEW E 84, 026113 (2011)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
