<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Weibo on Academic</title>
    <link>https://chengjunwang.com/en/tags/weibo/index.xml</link>
    <description>Recent content in Weibo on Academic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Cheng-Jun Wang</copyright>
    <atom:link href="/en/tags/weibo/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Scraping data from Sina Weibo using Python</title>
      <link>https://chengjunwang.com/en/post/en/2014-03-16-scraping-weibo-using-python/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/en/post/en/2014-03-16-scraping-weibo-using-python/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://weblab.com.cityu.edu.hk/blog/chengjun/files/2012/09/33.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;weibo-oauth2-0&#34;&gt;Weibo Oauth2.0&lt;/h3&gt;

&lt;p&gt;I would like to introduce you how to use python to scrape tweets from Sina Weibo in this post.&lt;/p&gt;

&lt;h4 id=&#34;automatically-get-authorization-by-oauth2-0&#34;&gt;Automatically get authorization by oauth2.0&lt;/h4&gt;

&lt;p&gt;First, following this webpage to set your app, especially to get the app key, app secret, and set the callback url.  See an &lt;a href=&#34;http://blog.laisky.us/2012/01/278/&#34; target=&#34;_blank&#34;&gt;introduction&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Second, following this &lt;a href=&#34;http://www.how2dns.com/blog/?p=538&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;, you can automatically get the code from the callback url.&lt;/p&gt;

&lt;p&gt;The following python script demonstrates how to automatically get authorization.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python
# -*- coding: utf8 -*-

from weibo import APIClient
import urllib2
import urllib
import sys
import time
from time import clock
import csv
import random

reload(sys)
sys.setdefaultencoding(&#39;utf-8&#39;)

&#39;&#39;&#39;Step 0 Login with OAuth2.0&#39;&#39;&#39;
if __name__ == &amp;quot;__main__&amp;quot;:
    APP_KEY = &#39;663...&#39; # app key
    APP_SECRET = &#39;2fc....&#39; # app secret
    CALLBACK_URL = &#39;https://api.weibo.com/oauth2/default.html&#39; # set callback url exactly like this!
    AUTH_URL = &#39;https://api.weibo.com/oauth2/authorize&#39;
    USERID = &#39;w...4&#39; # your weibo user id
    PASSWD = &#39;w....&#39; #your pw

    client = APIClient(app_key=APP_KEY, app_secret=APP_SECRET, redirect_uri=CALLBACK_URL)
    referer_url = client.get_authorize_url()
    print &amp;quot;referer url is : %s&amp;quot; % referer_url

    cookies = urllib2.HTTPCookieProcessor()
    opener = urllib2.build_opener(cookies)
    urllib2.install_opener(opener)

    postdata = {&amp;quot;client_id&amp;quot;: APP_KEY,
                &amp;quot;redirect_uri&amp;quot;: CALLBACK_URL,
                &amp;quot;userId&amp;quot;: USERID,
                &amp;quot;passwd&amp;quot;: PASSWD,
                &amp;quot;isLoginSina&amp;quot;: &amp;quot;0&amp;quot;,
                &amp;quot;action&amp;quot;: &amp;quot;submit&amp;quot;,
                &amp;quot;response_type&amp;quot;: &amp;quot;code&amp;quot;,
                }
    headers = {&amp;quot;User-Agent&amp;quot;: &amp;quot;Mozilla/5.0 (Windows NT 6.1; rv:11.0) Gecko/20100101 Firefox/11.0&amp;quot;,
                &amp;quot;Host&amp;quot;: &amp;quot;api.weibo.com&amp;quot;,
                &amp;quot;Referer&amp;quot;: referer_url
            }

    req  = urllib2.Request(
       url = AUTH_URL,
       data = urllib.urlencode(postdata),
       headers = headers
       )
    try:
        resp = urllib2.urlopen(req)
        print &amp;quot;callback url is : %s&amp;quot; % resp.geturl()
        code = resp.geturl()[-32:]
        print &amp;quot;code is : %s&amp;quot; %  code
    except Exception, e:
        print e

r = client.request_access_token(code)
access_token1 = r.access_token # The token return by sina
expires_in = r.expires_in

print &amp;quot;access_token=&amp;quot; ,access_token1
print &amp;quot;expires_in=&amp;quot; ,expires_in   # access_token lifetime by second. http://open.weibo.com/wiki/OAuth2/access_token

&amp;quot;&amp;quot;&amp;quot;save the access token&amp;quot;&amp;quot;&amp;quot;
client.set_access_token(access_token1, expires_in)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-the-number-of-retweets&#34;&gt;Get the number of retweets&lt;/h3&gt;

&lt;p&gt;Step 1. Assume that you have had a list of tweet ids, you want to get the number of repsots. Thus, you can have the distribution of the size of diffusion.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;&#39;&#39; Step 1 Get the number of reposts&#39;&#39;&#39;
&amp;quot;&amp;quot;&amp;quot;get the user ids&amp;quot;&amp;quot;&amp;quot;
dataReader = csv.reader(open(&#39;C:/Python27/weibo/sampledRtIds2.csv&#39;, &#39;r&#39;), delimiter=&#39;,&#39;, quotechar=&#39;|&#39;)
ids = []
for row in dataReader:
    ids.append(int(row[0]))  # modify the number to get the diffusers&#39; ids

file = open(&amp;quot;C:/Python27/weibo/repostsRT300000m2.csv&amp;quot;,&#39;wb&#39;) # save to csv file

start = clock()
print start

for seqNum in range(1500, 2999):
    id = ids[(0 + 100*seqNum) : (100+100*seqNum)]
    id = str(id).strip(&#39;[]&#39;).replace(&#39;L&#39;, &#39;&#39;)
    rate = client.get.account__rate_limit_status()
    sleep_time = rate.reset_time_in_seconds + 300
    remaining_ip_hits = rate.remaining_ip_hits
    remaining_user_hits = rate.remaining_user_hits
    if remaining_ip_hits &amp;gt;= 10 and remaining_user_hits &amp;gt;= 5:
        rtc = client.get.statuses__count(ids = id) # mid, 100
        for n in range(0, len(rtc)): # 0-99
            mid = rtc[n][&#39;id&#39;]
            reposts = rtc[n][&#39;reposts&#39;]
            comments = rtc[n][&#39;comments&#39;]
            attitudes = rtc[n][&#39;attitudes&#39;]
            timePass = clock()-start
            if round(timePass) % 10 == 0:
                print mid, reposts, len(rtc), &amp;quot;I have been working for %s seconds&amp;quot; % round(timePass)
            print &amp;gt;&amp;gt;file, &amp;quot;%s,%s,%s,%s&amp;quot; % (mid, reposts, comments, attitudes)
    elif remaining_ip_hits &amp;lt; 10 or remaining_user_hits &amp;lt; 5:
        print &amp;quot;Python will sleep %s seconds&amp;quot; % sleep_time
        time.sleep(sleep_time+60)

file.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-the-list-of-diffusers&#34;&gt;Get the list of diffusers&lt;/h3&gt;

&lt;p&gt;Step 2. If you want to step further and get the list of diffusers for a list of weibos. Thus, you will know how many reposts or retweets have been deleted by the website.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# &#39;&#39;&#39;Step 2 Get the diffusers&#39;&#39;&#39;
&amp;quot;&amp;quot;&amp;quot;read ids&amp;quot;&amp;quot;&amp;quot;
dataReader = csv.reader(open(&#39;C:/Python27/weibo/repostsSample3.csv&#39;, &#39;r&#39;), delimiter=&#39;,&#39;, quotechar=&#39;|&#39;)
ids = []
for row in dataReader:
    ids.append(int(row[1]))  # get the number to get the mid

addressForSavingData= &amp;quot;C:/Python27/weibo/diffsersSave.csv&amp;quot;
file = open(addressForSavingData,&#39;wb&#39;) # save to csv file

start = clock()
print start

lenid = len(ids) # lenid = 8 # test with the first two cases

for n in range(0, lenid+1):  # the 78 should be 77 here
    rate = client.get.account__rate_limit_status()
    sleep_time = rate.reset_time_in_seconds + 300
    remaining_ip_hits = rate.remaining_ip_hits
    remaining_user_hits = rate.remaining_user_hits
    if remaining_ip_hits &amp;gt;= 10 and remaining_user_hits &amp;gt;= 3:
        if reposts[n]%200 == 0:
            pages = reposts[n]/200
        else:
            pages = reposts[n]/200 + 1
        try:
            for pageNum in range(1, pages + 1):
                r = client.get.statuses__repost_timeline(id = ids[n], page = pageNum, count = 200)
                if len(r) == 0:
                    pass
                else:
                    m = int(len(r[&#39;reposts&#39;]))
                    for i in range(0, m):
                        &amp;quot;&amp;quot;&amp;quot;1.1 reposts&amp;quot;&amp;quot;&amp;quot;
                        mid = r[&#39;reposts&#39;][i].id
                        text = r[&#39;reposts&#39;][i].text.replace(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;)
                        created = r[&#39;reposts&#39;][i].created_at
                        &amp;quot;&amp;quot;&amp;quot;1.2 reposts.user&amp;quot;&amp;quot;&amp;quot;
                        user = r[&#39;reposts&#39;][i].user
                        user_id = user.id
                        user_name = user.name
                        user_province = user.province
                        user_city = user.city
                        user_gender = user.gender
                        user_url = user.url
                        user_followers = user.followers_count
                        user_bifollowers = user.bi_followers_count
                        user_friends = user.friends_count
                        user_statuses = user.statuses_count
                        user_created = user.created_at
                        user_verified = user.verified
                        &amp;quot;&amp;quot;&amp;quot;2.1 retweeted_status&amp;quot;&amp;quot;&amp;quot;
                        rts = r[&#39;reposts&#39;][i].retweeted_status
                        rts_mid = rts.id
                        rts_text = rts.text.replace(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;)
                        rts_created = rts.created_at
                        &amp;quot;&amp;quot;&amp;quot;2.2 retweeted_status.user&amp;quot;&amp;quot;&amp;quot;
                        rtsuser_id = rts.user.id
                        rtsuser_name = rts.user.name
                        rtsuser_province = rts.user.province
                        rtsuser_city = rts.user.city
                        rtsuser_gender = rts.user.gender
                        rtsuser_url = rts.user.url
                        rtsuser_followers = rts.user.followers_count
                        rtsuser_bifollowers = rts.user.bi_followers_count
                        rtsuser_friends = rts.user.friends_count
                        rtsuser_statuses = rts.user.statuses_count
                        rtsuser_created = rts.user.created_at
                        rtsuser_verified = rts.user.verified
                        timePass = clock()-start
                        if round(timePass) % 10 == 0:
                            print mid, rts_mid, &amp;quot;I have been working for %s seconds&amp;quot; % round(timePass)
                            time.sleep( random.randrange(3, 9, 1) )  # To avoid http error 504 gateway time-out
                        print &amp;gt;&amp;gt;file, &amp;quot;%s,&#39;%s&#39;,&#39;%s&#39;,%s,&#39;%s&#39;,%s,%s,%s,&#39;%s&#39;,%s,%s,%s,&#39;%s&#39;,%s,%s,&#39;%s&#39;,%s,&#39;%s&#39;,%s,%s,%s,&#39;%s&#39;,%s,%s,%s,%s,%s&amp;quot;  % (mid, created, text, # 3 # &amp;quot;%s,%s,|%s|,%s,|%s|,%s,%s,%s,|%s|,%s,%s,%s,%s,%s,%s,%s,%s,|%s|,%s,%s,%s,|%s|,%s,%s,%s,%s,%s&amp;quot; % (mid, created, text, # 3
                                            user_id, user_name, user_province, user_city, user_gender,  # 5 --&amp;gt; 5
                                            user_url, user_followers, user_friends, user_statuses, user_created, user_verified,  # rts_text, # 6 --&amp;gt; 9
                                            rts_mid, rts_created, # 2
                                            rtsuser_id, rtsuser_name, rtsuser_province, rtsuser_city, rtsuser_gender, # 5 --&amp;gt; 18
                                            rtsuser_url, rtsuser_followers, rtsuser_friends, rtsuser_statuses, rtsuser_created, rtsuser_verified)  # 6  --&amp;gt; 22
        except Exception, e:
            print &amp;gt;&amp;gt; sys.stderr, &#39;Encountered Exception:&#39;, e, ids[n]
            time.sleep(120)
            pass
    elif remaining_ip_hits &amp;lt; 10 or remaining_user_hits &amp;lt; 3:
        print &amp;quot;Python will sleep %s seconds&amp;quot; % sleep_time
        time.sleep(sleep_time+60)

file.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-the-following-relationships&#34;&gt;Get the following relationships&lt;/h3&gt;

&lt;p&gt;Step 3. Now, you may want to get the social graph for all the diffusers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;&#39;&#39;Step 3 Get the social graph&#39;&#39;&#39;
&amp;quot;&amp;quot;&amp;quot;read ids&amp;quot;&amp;quot;&amp;quot;
dataReader = csv.reader(open(&#39;C:/Python27/weibo/SocialGraphIdsForStepThree.csv&#39;, &#39;r&#39;), delimiter=&#39;,&#39;, quotechar=&#39;|&#39;)
ids = []
for row in dataReader:
    ids.append(int(row[0]))  # get the number to get the mid

ids = ids[188648:697060]

addressForSavingData= &amp;quot;C:/Python27/weibo/socialgraphSave142_2.csv&amp;quot;
file = open(addressForSavingData,&#39;wb&#39;) # save to csv file

addressForSavingError = &amp;quot;C:/Python27/weibo/socialgraphSaveError142_2.csv&amp;quot;
errorlog = open(addressForSavingError,&#39;w&#39;)
errorlog.close()

start = clock()
print start

for id in ids:
    try:
        rate = client.get.account__rate_limit_status()
        sleep_time = rate.reset_time_in_seconds + 300
        remaining_ip_hits = rate.remaining_ip_hits
        remaining_user_hits = rate.remaining_user_hits
        if remaining_ip_hits &amp;gt;= 10 and remaining_user_hits &amp;gt;= 3:
            cursor = -1
            fids=[]
            while cursor != 0:
                response = client.get.friendships__friends__ids(uid=id, count= 5000, cursor=cursor)  # the biggest count is 5000
                fids    += response.ids
                cursor = response.next_cursor # previousCursor = response.previous_cursor
                timePass = clock()-start
                if round(timePass) % 10 == 0:
                    print id, &amp;quot;I have been working for %s seconds&amp;quot; % round(timePass)
                    # time.sleep( 0.01 * random.randrange(0, 5, 1) )  # To avoid http error 504 gateway time-out
                if cursor == 0:
                    totalNum = response.total_number
                    for fid in fids:
                        print &amp;gt;&amp;gt;file, &amp;quot;%s,%s,%s&amp;quot;  % (id, fid, totalNum)
                    break
        elif remaining_ip_hits &amp;lt; 10 or remaining_user_hits &amp;lt; 3:
            print &amp;quot;Python will sleep %s seconds&amp;quot; % sleep_time
            time.sleep(sleep_time+60)
    except Exception, e:
        print &amp;gt;&amp;gt;sys.stderr, &#39;Encountered Exception:&#39;, e, id
        errorlog = open(addressForSavingError, &#39;a&#39;)
        print &amp;gt;&amp;gt;errorlog, &amp;quot;%s,%s&amp;quot;  % (id, e)
        errorlog.close()
        print &#39;When the error happens, the id is:&#39;, id
        time.sleep(60)
        pass

file.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-the-diffusion-network&#34;&gt;Get the diffusion network&lt;/h3&gt;

&lt;p&gt;Step 4. Given the collected data of retweets, we can get the diffusion path by parsing the text of weibo.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import re
import sys
from time import clock

reload(sys)
sys.setdefaultencoding(&#39;utf-8&#39;)

&#39;&#39;&#39;
Convert &amp;quot;Thu Aug 04 11:39:32 +0800 2011&amp;quot; to the ISO format: YYYY-MM-DD H:M:S
Refer to: http://stackoverflow.com/questions/15727510/using-python-regex-to-identify-retweeters-from-tweets-with-chinese-characters
&#39;&#39;&#39;

file = open(&amp;quot;D:/chengjun/New/repostsReSampleClean.csv&amp;quot;, &#39;r&#39;)
lines = file.readlines()

addressForSavingData= &amp;quot;D:/chengjun/New/diffusion_path6.csv&amp;quot;  
file = open(addressForSavingData,&#39;wb&#39;) # save to csv file

addressForSavingError = &amp;quot;D:/chengjun/New/Error.csv&amp;quot;  
errorlog = open(addressForSavingError,&#39;w&#39;)
errorlog.close

start = clock()  
print start

for line in lines:
    list = line.split(&#39;,&#39;)
    rtsmid = list[15].strip()  #rmid
    userName = list[5].strip().replace(&amp;quot;&#39;&amp;quot;, &amp;quot;&amp;quot;) # username
    submitterName = list[18].strip().replace(&amp;quot;&#39;&amp;quot;, &amp;quot;&amp;quot;)
    tweet = list[3].replace(&#39;,&#39;,&#39;&#39;)
    RTpattern = r&#39;&#39;&#39;//?@(\w+)&#39;&#39;&#39;
    rt = re.findall(RTpattern, tweet.decode(&amp;quot;utf-8&amp;quot;), re.UNICODE)
    if rt == None or len(rt)==0:
        target = userName
        source = submitterName
        print &amp;gt;&amp;gt;file, &amp;quot;%s,%s,%s&amp;quot;  % (rtsmid, source, target)
    elif rt != None and len(rt) != 0:
        rt.insert(0, userName) #
        for i in xrange(len(rt) - 1):
            target = rt[i].encode(&#39;utf-8&#39;)
            source = rt[i + 1].encode(&#39;utf-8&#39;)
            print &amp;gt;&amp;gt;file, &amp;quot;%s,%s,%s&amp;quot;  % (rtsmid, source, target)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The Rich-club on Sina Weibo</title>
      <link>https://chengjunwang.com/en/post/en/2014-03-14-weibo-landscape/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/en/post/en/2014-03-14-weibo-landscape/</guid>
      <description>

&lt;p&gt;This post is about the opinions tweeted &amp;amp; retweeted by the most influential users of Sina Weibo.&lt;/p&gt;

&lt;p&gt;About Sina Weibo, you can refer to the webpage of &lt;a href=&#34;http://en.wikipedia.org/wiki/Sina_Weibo#cite_note-3&#34; target=&#34;_blank&#34;&gt;wikipedia&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Sina Weibo (Chinese: 新浪微博; pinyin: Xīnlàng Wēibó; literally “Sina Microblog”) is a Chinese microblogging (weibo) website. Akin to a hybrid of Twitter and Facebook, it is one of the most popular sites in China, in use by well over 30% of Internet users, with a similar market penetration that Twitter has established in the USA. It was launched by SINA Corporation on 14 August 2009, and has more than 300 million registered users as of February 2012.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To study the news diffusion of Weibo Users, My collaborator Linwu and I had set up a research project of Weibo Landscape aiming at archiving the historical tweets of 800 verified weibo accounts (Rich club of Sina Weibo) before March 2012. Both the tweets created by them and the tweets retweeted by them are collected and indexed. So this archive can supply you the historical opinions reflected by these most influential users: including 400 media accounts+100 website accounts+ 100 government accounts +100 celebrities accounts+100 grass root accounts&lt;/p&gt;

&lt;p&gt;How does the media landscape look like?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://weblab.com.cityu.edu.hk/blog/chengjun/files/2012/04/landscape.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-opinions-of-the-rich-club&#34;&gt;The Opinions of the Rich Club&lt;/h3&gt;

&lt;p&gt;Understanding the rich club, see &lt;a href=&#34;http://chengjun.github.io/slides/strut/richclub/&#34; target=&#34;_blank&#34;&gt;my slides here&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the weighted rich-club effect tests whether a select group
of nodes share their strongest ties with each other in a
weighted network (Opsahl et al., 2008)&lt;/li&gt;
&lt;li&gt;80-20 rule  (Pareto, 1897)&lt;/li&gt;
&lt;li&gt;high degree nodes form many ties with each other
(Borgatti and Everett, 1999; Colizza et al., 2006; Newman, 2002)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://weblab.com.cityu.edu.hk/blog/chengjun/files/2012/04/core-and-periphery.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Although Sina Weibo is very densely connected, Individuals are separated from each other but closer to the celebrities. Thus the most influential users become the core of Sina Weibo, and they are followed by the common users. As the core of Sina Weibo, they have great influence on the information diffusion on the social media website.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;800 Influential Users (400 media accounts+100 website accounts+ 100-government accounts +100 celebrities accounts+100 grass root accounts) are identified by Sina Weibo.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The data were collected though user timeline api using Python.
The following relationship of the rich club reveals that they are closed connected (see the figure below).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://weblab.com.cityu.edu.hk/blog/chengjun/files/2012/04/social-network.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What is the relationship between rich club, random sample, and the unsampled majority in our data?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://chengjun.github.io/slides/strut/richclub/richclub_files/11148691843_63cd8203c3_o.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;How is the weighted rich-club effect in Sina Weibo?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://chengjun.github.io/slides/strut/richclub/richclub_files/11148617174_4347265242_o.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;have-a-try&#34;&gt;Have a try!&lt;/h3&gt;

&lt;p&gt;Unfortunately, this section does not work now. :&amp;lt;&lt;/p&gt;

&lt;p&gt;First, open the url: &lt;a href=&#34;http://weblab.com.cityu.edu.hk/demo/weibo.html&#34; target=&#34;_blank&#34;&gt;http://weblab.com.cityu.edu.hk/demo/weibo.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Second, input and query key words (e.g. 占领华尔街，艾未未，汶川地震，动车出轨， 日本地震) and click the search button to see the results. For example, you can query for Occupying Wall Street (占领华尔街), and you can find the items such as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;related 1-th-weibo:
mid:3365546399651413
score:-5.76427445942
uid:1893278624
link:source
time:Thu Oct 06 17:10:59 +0800 2011
content:【“占领华尔街”继续发酵 全美75所高校学生响应】“占领华尔街”抗议活动进入第19日，活动影响继续发酵，占领运动延伸至高校校园，最新发起的“占领高校”运动，号召全美高校学生5日下午加入上街游行的队伍。图为大批示威者在“占领华尔街”大本营——华尔街附近的祖科提公园Zuccotti Park集会。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have login Sina weibo, click the link of source, you can find the &lt;a href=&#34;http://www.weibo.com/1893278624/xrv9ZEuLX&#34; target=&#34;_blank&#34;&gt;original tweet&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;visualization-of-diffusion-path&#34;&gt;Visualization of diffusion path&lt;/h3&gt;

&lt;p&gt;Click the source of the top 1000 list of archive items, you can get the url of a given tweet, and then you can further visualize the diffusion path using the apps of Sina Weibo.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.doodod.com/doodod/home&#34; target=&#34;_blank&#34;&gt;doodod&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://newgraph.sinaapp.com/&#34; target=&#34;_blank&#34;&gt;newgraph&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, using the doodod, you can visualize the diffusion path following &lt;a href=&#34;http://www.doodod.com/doodod/chuanbo?weiboURL=http://weibo.com/1893278624/xrv9ZEuLX&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt;. The figure looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://weblab.com.cityu.edu.hk/blog/chengjun/files/2012/04/freshnew.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;######The Landscape of Information Diffusion on Sina Weibo：
Investigating the Rich-Club Effect&lt;/p&gt;

&lt;p&gt;This blog post is derived from my project of information diffusion on Sina Weibo. Based on the data of weibo landscape, we find that:&lt;/p&gt;

&lt;p&gt;Rich-club as a closely connected community in networks has important influences on the information flow within the online social system. We study the competing mechanisms underlying the information flows within and among different social groups inside the rich club of Sina Weibo. The results demonstrate that: first, there is relatively strong rich-club effect in both influential users and random sampled users; second, social selection, geographic proximity, and social influence have significant influence on the information flow within the rich-club for different social groups, and the impact of social influence is overwhelmingly strong. The implications help shed new light on our knowledge about the underlying mechanisms of information diffusion on the microblog.&lt;/p&gt;

&lt;p&gt;In the following post, I will introduce how to scrape data from Sina Weibo using Python.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
