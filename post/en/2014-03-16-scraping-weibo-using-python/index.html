<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Cheng-Jun Wang">

  
  
  
    
  
  <meta name="description" content="Weibo Oauth2.0 I would like to introduce you how to use python to scrape tweets from Sina Weibo in this post.
Automatically get authorization by oauth2.0 First, following this webpage to set your app, especially to get the app key, app secret, and set the callback url. See an introduction.
Second, following this link, you can automatically get the code from the callback url.
The following python script demonstrates how to automatically get authorization.">

  
  <link rel="alternate" hreflang="en-us" href="https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ChengJunWang">
  <meta property="twitter:creator" content="@ChengJunWang">
  
  <meta property="og:site_name" content="Cheng-Jun Wang">
  <meta property="og:url" content="https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/">
  <meta property="og:title" content="Scraping data from Sina Weibo using Python | Cheng-Jun Wang">
  <meta property="og:description" content="Weibo Oauth2.0 I would like to introduce you how to use python to scrape tweets from Sina Weibo in this post.
Automatically get authorization by oauth2.0 First, following this webpage to set your app, especially to get the app key, app secret, and set the callback url. See an introduction.
Second, following this link, you can automatically get the code from the callback url.
The following python script demonstrates how to automatically get authorization."><meta property="og:image" content="https://chengjunwang.com/img/headers/deer.webp">
  <meta property="twitter:image" content="https://chengjunwang.com/img/headers/deer.webp"><meta property="og:locale" content="en-us">
  
    
    
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/"
  },
  "headline": "Scraping data from Sina Weibo using Python",
  
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Cheng-Jun Wang"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Cheng-Jun Wang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://chengjunwang.com/img/icon-512.png"
    }
  },
  "description": "Weibo Oauth2.0 I would like to introduce you how to use python to scrape tweets from Sina Weibo in this post.\nAutomatically get authorization by oauth2.0 First, following this webpage to set your app, especially to get the app key, app secret, and set the callback url. See an introduction.\nSecond, following this link, you can automatically get the code from the callback url.\nThe following python script demonstrates how to automatically get authorization."
}
</script>

  

  


  


  





  <title>Scraping data from Sina Weibo using Python | Cheng-Jun Wang</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    
      <a class="navbar-brand" href="/">Cheng-Jun Wang</a>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>News</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/cv.pdf"><span>CV</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Scraping data from Sina Weibo using Python</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Jan 1, 0001
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      

<p><img src="http://weblab.com.cityu.edu.hk/blog/chengjun/files/2012/09/33.png" alt="" /></p>

<h3 id="weibo-oauth2-0">Weibo Oauth2.0</h3>

<p>I would like to introduce you how to use python to scrape tweets from Sina Weibo in this post.</p>

<h4 id="automatically-get-authorization-by-oauth2-0">Automatically get authorization by oauth2.0</h4>

<p>First, following this webpage to set your app, especially to get the app key, app secret, and set the callback url.  See an <a href="http://blog.laisky.us/2012/01/278/" target="_blank">introduction</a>.</p>

<p>Second, following this <a href="http://www.how2dns.com/blog/?p=538" target="_blank">link</a>, you can automatically get the code from the callback url.</p>

<p>The following python script demonstrates how to automatically get authorization.</p>

<pre><code>#!/usr/bin/env python
# -*- coding: utf8 -*-

from weibo import APIClient
import urllib2
import urllib
import sys
import time
from time import clock
import csv
import random

reload(sys)
sys.setdefaultencoding('utf-8')

'''Step 0 Login with OAuth2.0'''
if __name__ == &quot;__main__&quot;:
    APP_KEY = '663...' # app key
    APP_SECRET = '2fc....' # app secret
    CALLBACK_URL = 'https://api.weibo.com/oauth2/default.html' # set callback url exactly like this!
    AUTH_URL = 'https://api.weibo.com/oauth2/authorize'
    USERID = 'w...4' # your weibo user id
    PASSWD = 'w....' #your pw

    client = APIClient(app_key=APP_KEY, app_secret=APP_SECRET, redirect_uri=CALLBACK_URL)
    referer_url = client.get_authorize_url()
    print &quot;referer url is : %s&quot; % referer_url

    cookies = urllib2.HTTPCookieProcessor()
    opener = urllib2.build_opener(cookies)
    urllib2.install_opener(opener)

    postdata = {&quot;client_id&quot;: APP_KEY,
                &quot;redirect_uri&quot;: CALLBACK_URL,
                &quot;userId&quot;: USERID,
                &quot;passwd&quot;: PASSWD,
                &quot;isLoginSina&quot;: &quot;0&quot;,
                &quot;action&quot;: &quot;submit&quot;,
                &quot;response_type&quot;: &quot;code&quot;,
                }
    headers = {&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 6.1; rv:11.0) Gecko/20100101 Firefox/11.0&quot;,
                &quot;Host&quot;: &quot;api.weibo.com&quot;,
                &quot;Referer&quot;: referer_url
            }

    req  = urllib2.Request(
       url = AUTH_URL,
       data = urllib.urlencode(postdata),
       headers = headers
       )
    try:
        resp = urllib2.urlopen(req)
        print &quot;callback url is : %s&quot; % resp.geturl()
        code = resp.geturl()[-32:]
        print &quot;code is : %s&quot; %  code
    except Exception, e:
        print e

r = client.request_access_token(code)
access_token1 = r.access_token # The token return by sina
expires_in = r.expires_in

print &quot;access_token=&quot; ,access_token1
print &quot;expires_in=&quot; ,expires_in   # access_token lifetime by second. http://open.weibo.com/wiki/OAuth2/access_token

&quot;&quot;&quot;save the access token&quot;&quot;&quot;
client.set_access_token(access_token1, expires_in)
</code></pre>

<h3 id="get-the-number-of-retweets">Get the number of retweets</h3>

<p>Step 1. Assume that you have had a list of tweet ids, you want to get the number of repsots. Thus, you can have the distribution of the size of diffusion.</p>

<pre><code>''' Step 1 Get the number of reposts'''
&quot;&quot;&quot;get the user ids&quot;&quot;&quot;
dataReader = csv.reader(open('C:/Python27/weibo/sampledRtIds2.csv', 'r'), delimiter=',', quotechar='|')
ids = []
for row in dataReader:
    ids.append(int(row[0]))  # modify the number to get the diffusers' ids

file = open(&quot;C:/Python27/weibo/repostsRT300000m2.csv&quot;,'wb') # save to csv file

start = clock()
print start

for seqNum in range(1500, 2999):
    id = ids[(0 + 100*seqNum) : (100+100*seqNum)]
    id = str(id).strip('[]').replace('L', '')
    rate = client.get.account__rate_limit_status()
    sleep_time = rate.reset_time_in_seconds + 300
    remaining_ip_hits = rate.remaining_ip_hits
    remaining_user_hits = rate.remaining_user_hits
    if remaining_ip_hits &gt;= 10 and remaining_user_hits &gt;= 5:
        rtc = client.get.statuses__count(ids = id) # mid, 100
        for n in range(0, len(rtc)): # 0-99
            mid = rtc[n]['id']
            reposts = rtc[n]['reposts']
            comments = rtc[n]['comments']
            attitudes = rtc[n]['attitudes']
            timePass = clock()-start
            if round(timePass) % 10 == 0:
                print mid, reposts, len(rtc), &quot;I have been working for %s seconds&quot; % round(timePass)
            print &gt;&gt;file, &quot;%s,%s,%s,%s&quot; % (mid, reposts, comments, attitudes)
    elif remaining_ip_hits &lt; 10 or remaining_user_hits &lt; 5:
        print &quot;Python will sleep %s seconds&quot; % sleep_time
        time.sleep(sleep_time+60)

file.close()
</code></pre>

<h3 id="get-the-list-of-diffusers">Get the list of diffusers</h3>

<p>Step 2. If you want to step further and get the list of diffusers for a list of weibos. Thus, you will know how many reposts or retweets have been deleted by the website.</p>

<pre><code># '''Step 2 Get the diffusers'''
&quot;&quot;&quot;read ids&quot;&quot;&quot;
dataReader = csv.reader(open('C:/Python27/weibo/repostsSample3.csv', 'r'), delimiter=',', quotechar='|')
ids = []
for row in dataReader:
    ids.append(int(row[1]))  # get the number to get the mid

addressForSavingData= &quot;C:/Python27/weibo/diffsersSave.csv&quot;
file = open(addressForSavingData,'wb') # save to csv file

start = clock()
print start

lenid = len(ids) # lenid = 8 # test with the first two cases

for n in range(0, lenid+1):  # the 78 should be 77 here
    rate = client.get.account__rate_limit_status()
    sleep_time = rate.reset_time_in_seconds + 300
    remaining_ip_hits = rate.remaining_ip_hits
    remaining_user_hits = rate.remaining_user_hits
    if remaining_ip_hits &gt;= 10 and remaining_user_hits &gt;= 3:
        if reposts[n]%200 == 0:
            pages = reposts[n]/200
        else:
            pages = reposts[n]/200 + 1
        try:
            for pageNum in range(1, pages + 1):
                r = client.get.statuses__repost_timeline(id = ids[n], page = pageNum, count = 200)
                if len(r) == 0:
                    pass
                else:
                    m = int(len(r['reposts']))
                    for i in range(0, m):
                        &quot;&quot;&quot;1.1 reposts&quot;&quot;&quot;
                        mid = r['reposts'][i].id
                        text = r['reposts'][i].text.replace(&quot;,&quot;, &quot;&quot;)
                        created = r['reposts'][i].created_at
                        &quot;&quot;&quot;1.2 reposts.user&quot;&quot;&quot;
                        user = r['reposts'][i].user
                        user_id = user.id
                        user_name = user.name
                        user_province = user.province
                        user_city = user.city
                        user_gender = user.gender
                        user_url = user.url
                        user_followers = user.followers_count
                        user_bifollowers = user.bi_followers_count
                        user_friends = user.friends_count
                        user_statuses = user.statuses_count
                        user_created = user.created_at
                        user_verified = user.verified
                        &quot;&quot;&quot;2.1 retweeted_status&quot;&quot;&quot;
                        rts = r['reposts'][i].retweeted_status
                        rts_mid = rts.id
                        rts_text = rts.text.replace(&quot;,&quot;, &quot;&quot;)
                        rts_created = rts.created_at
                        &quot;&quot;&quot;2.2 retweeted_status.user&quot;&quot;&quot;
                        rtsuser_id = rts.user.id
                        rtsuser_name = rts.user.name
                        rtsuser_province = rts.user.province
                        rtsuser_city = rts.user.city
                        rtsuser_gender = rts.user.gender
                        rtsuser_url = rts.user.url
                        rtsuser_followers = rts.user.followers_count
                        rtsuser_bifollowers = rts.user.bi_followers_count
                        rtsuser_friends = rts.user.friends_count
                        rtsuser_statuses = rts.user.statuses_count
                        rtsuser_created = rts.user.created_at
                        rtsuser_verified = rts.user.verified
                        timePass = clock()-start
                        if round(timePass) % 10 == 0:
                            print mid, rts_mid, &quot;I have been working for %s seconds&quot; % round(timePass)
                            time.sleep( random.randrange(3, 9, 1) )  # To avoid http error 504 gateway time-out
                        print &gt;&gt;file, &quot;%s,'%s','%s',%s,'%s',%s,%s,%s,'%s',%s,%s,%s,'%s',%s,%s,'%s',%s,'%s',%s,%s,%s,'%s',%s,%s,%s,%s,%s&quot;  % (mid, created, text, # 3 # &quot;%s,%s,|%s|,%s,|%s|,%s,%s,%s,|%s|,%s,%s,%s,%s,%s,%s,%s,%s,|%s|,%s,%s,%s,|%s|,%s,%s,%s,%s,%s&quot; % (mid, created, text, # 3
                                            user_id, user_name, user_province, user_city, user_gender,  # 5 --&gt; 5
                                            user_url, user_followers, user_friends, user_statuses, user_created, user_verified,  # rts_text, # 6 --&gt; 9
                                            rts_mid, rts_created, # 2
                                            rtsuser_id, rtsuser_name, rtsuser_province, rtsuser_city, rtsuser_gender, # 5 --&gt; 18
                                            rtsuser_url, rtsuser_followers, rtsuser_friends, rtsuser_statuses, rtsuser_created, rtsuser_verified)  # 6  --&gt; 22
        except Exception, e:
            print &gt;&gt; sys.stderr, 'Encountered Exception:', e, ids[n]
            time.sleep(120)
            pass
    elif remaining_ip_hits &lt; 10 or remaining_user_hits &lt; 3:
        print &quot;Python will sleep %s seconds&quot; % sleep_time
        time.sleep(sleep_time+60)

file.close()
</code></pre>

<h3 id="get-the-following-relationships">Get the following relationships</h3>

<p>Step 3. Now, you may want to get the social graph for all the diffusers.</p>

<pre><code>'''Step 3 Get the social graph'''
&quot;&quot;&quot;read ids&quot;&quot;&quot;
dataReader = csv.reader(open('C:/Python27/weibo/SocialGraphIdsForStepThree.csv', 'r'), delimiter=',', quotechar='|')
ids = []
for row in dataReader:
    ids.append(int(row[0]))  # get the number to get the mid

ids = ids[188648:697060]

addressForSavingData= &quot;C:/Python27/weibo/socialgraphSave142_2.csv&quot;
file = open(addressForSavingData,'wb') # save to csv file

addressForSavingError = &quot;C:/Python27/weibo/socialgraphSaveError142_2.csv&quot;
errorlog = open(addressForSavingError,'w')
errorlog.close()

start = clock()
print start

for id in ids:
    try:
        rate = client.get.account__rate_limit_status()
        sleep_time = rate.reset_time_in_seconds + 300
        remaining_ip_hits = rate.remaining_ip_hits
        remaining_user_hits = rate.remaining_user_hits
        if remaining_ip_hits &gt;= 10 and remaining_user_hits &gt;= 3:
            cursor = -1
            fids=[]
            while cursor != 0:
                response = client.get.friendships__friends__ids(uid=id, count= 5000, cursor=cursor)  # the biggest count is 5000
                fids    += response.ids
                cursor = response.next_cursor # previousCursor = response.previous_cursor
                timePass = clock()-start
                if round(timePass) % 10 == 0:
                    print id, &quot;I have been working for %s seconds&quot; % round(timePass)
                    # time.sleep( 0.01 * random.randrange(0, 5, 1) )  # To avoid http error 504 gateway time-out
                if cursor == 0:
                    totalNum = response.total_number
                    for fid in fids:
                        print &gt;&gt;file, &quot;%s,%s,%s&quot;  % (id, fid, totalNum)
                    break
        elif remaining_ip_hits &lt; 10 or remaining_user_hits &lt; 3:
            print &quot;Python will sleep %s seconds&quot; % sleep_time
            time.sleep(sleep_time+60)
    except Exception, e:
        print &gt;&gt;sys.stderr, 'Encountered Exception:', e, id
        errorlog = open(addressForSavingError, 'a')
        print &gt;&gt;errorlog, &quot;%s,%s&quot;  % (id, e)
        errorlog.close()
        print 'When the error happens, the id is:', id
        time.sleep(60)
        pass

file.close()
</code></pre>

<h3 id="get-the-diffusion-network">Get the diffusion network</h3>

<p>Step 4. Given the collected data of retweets, we can get the diffusion path by parsing the text of weibo.</p>

<pre><code>import re
import sys
from time import clock

reload(sys)
sys.setdefaultencoding('utf-8')

'''
Convert &quot;Thu Aug 04 11:39:32 +0800 2011&quot; to the ISO format: YYYY-MM-DD H:M:S
Refer to: http://stackoverflow.com/questions/15727510/using-python-regex-to-identify-retweeters-from-tweets-with-chinese-characters
'''

file = open(&quot;D:/chengjun/New/repostsReSampleClean.csv&quot;, 'r')
lines = file.readlines()

addressForSavingData= &quot;D:/chengjun/New/diffusion_path6.csv&quot;  
file = open(addressForSavingData,'wb') # save to csv file

addressForSavingError = &quot;D:/chengjun/New/Error.csv&quot;  
errorlog = open(addressForSavingError,'w')
errorlog.close

start = clock()  
print start

for line in lines:
    list = line.split(',')
    rtsmid = list[15].strip()  #rmid
    userName = list[5].strip().replace(&quot;'&quot;, &quot;&quot;) # username
    submitterName = list[18].strip().replace(&quot;'&quot;, &quot;&quot;)
    tweet = list[3].replace(',','')
    RTpattern = r'''//?@(\w+)'''
    rt = re.findall(RTpattern, tweet.decode(&quot;utf-8&quot;), re.UNICODE)
    if rt == None or len(rt)==0:
        target = userName
        source = submitterName
        print &gt;&gt;file, &quot;%s,%s,%s&quot;  % (rtsmid, source, target)
    elif rt != None and len(rt) != 0:
        rt.insert(0, userName) #
        for i in xrange(len(rt) - 1):
            target = rt[i].encode('utf-8')
            source = rt[i + 1].encode('utf-8')
            print &gt;&gt;file, &quot;%s,%s,%s&quot;  % (rtsmid, source, target)
</code></pre>

    </div>

    







<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/&amp;text=Scraping%20data%20from%20Sina%20Weibo%20using%20Python" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/&amp;t=Scraping%20data%20from%20Sina%20Weibo%20using%20Python" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Scraping%20data%20from%20Sina%20Weibo%20using%20Python&amp;body=https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/&amp;title=Scraping%20data%20from%20Sina%20Weibo%20using%20Python" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Scraping%20data%20from%20Sina%20Weibo%20using%20Python%20https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/&amp;title=Scraping%20data%20from%20Sina%20Weibo%20using%20Python" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  






  
  
  
    
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hudd12f2352811943b67d6d42ef6240e45_28224_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://chengjunwang.com/">Cheng-Jun Wang</a></h5>
      <h6 class="card-subtitle">Associate Professor</h6>
      <p class="card-text">Cheng-Jun Wang is currently an associate  professor in the <a href="http://jc.nju.edu.cn" target="_blank">School of Journalism and Communication, Nanjing University</a>.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:%20wangchengjun@nju.edu.cn" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/ChengJunWang" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.uk/citations?user=nNdt_G8AAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/chengjun" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.researchgate.net/profile/Cheng_Jun_Wang" target="_blank" rel="noopener">
        <i class="fab fa-researchgate"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.douban.com/people/1558440/" target="_blank" rel="noopener">
        <i class="fab fa-douban"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









  
  



  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3d0750632391ba55d8fd99a18dab4a0d.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    All rights &copy; reserved 2019 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
