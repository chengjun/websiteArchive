<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.37.1" />
  <meta name="author" content="Cheng-Jun Wang">
  <meta name="description" content="Associate Professor">

  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  


  

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7cMerriweather%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://chengjunwang.com/index.xml" type="application/rss+xml" title="Cheng-Jun Wang">
  <link rel="feed" href="https://chengjunwang.com/index.xml" type="application/rss+xml" title="Cheng-Jun Wang">
  

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://chengjunwang.com/post/en/2012-04-23-scraping-newyork-times-with-python/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ChengJunWang">
  <meta property="twitter:creator" content="@ChengJunWang">
  
  <meta property="og:site_name" content="Cheng-Jun Wang">
  <meta property="og:url" content="https://chengjunwang.com/post/en/2012-04-23-scraping-newyork-times-with-python/">
  <meta property="og:title" content="Scraping New York Times &amp; The Guardian using Python | Cheng-Jun Wang">
  <meta property="og:description" content="">
  <meta property="og:locale" content="en-us">
  
  
  
  

  

  <title>Scraping New York Times &amp; The Guardian using Python | Cheng-Jun Wang</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Cheng-Jun Wang</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>News</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  


<div class="col-sm-2 col-sm-offset-1 doc-sidebar right">

	<div id="sidebar">
	<div class="sidebar-module">
		<div class="sidebar-toc">
			<h4 class="sidebar-heading">Table of Contents</h4>
			
			
		</div>
	</div>
	
	</div>

</div>



  <div class="article-container">
    <div class="article-inner">
      <h1 itemprop="name">Scraping New York Times &amp; The Guardian using Python</h1>

      

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="0001-01-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      0001-01-01
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    3 min read
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Scraping%20New%20York%20Times%20%26%20The%20Guardian%20using%20Python&amp;url=https%3a%2f%2fchengjunwang.com%2fpost%2fen%2f2012-04-23-scraping-newyork-times-with-python%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fchengjunwang.com%2fpost%2fen%2f2012-04-23-scraping-newyork-times-with-python%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fchengjunwang.com%2fpost%2fen%2f2012-04-23-scraping-newyork-times-with-python%2f&amp;title=Scraping%20New%20York%20Times%20%26%20The%20Guardian%20using%20Python"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fchengjunwang.com%2fpost%2fen%2f2012-04-23-scraping-newyork-times-with-python%2f&amp;title=Scraping%20New%20York%20Times%20%26%20The%20Guardian%20using%20Python"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Scraping%20New%20York%20Times%20%26%20The%20Guardian%20using%20Python&amp;body=https%3a%2f%2fchengjunwang.com%2fpost%2fen%2f2012-04-23-scraping-newyork-times-with-python%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


      <div class="article-style" itemprop="articleBody">
        <p>I have read the blog post about Scraping New York Times Articles with R. Itâ€™s great. I want to reproduce the work with python.
First, we should learn about nytimes article search api.</p>

<p><a href="http://developer.nytimes.com/docs/article_search_api/" target="_blank">http://developer.nytimes.com/docs/article_search_api/</a></p>

<p>Second, we need to register and get the key which will be used in python script.</p>

<p><a href="http://developer.nytimes.com/apps/register" target="_blank">http://developer.nytimes.com/apps/register</a></p>

<pre><code># !/usr/bin/env python
# -*- coding: UTF-8  -*-
# Scraping New York Times using python
# 20120421@ Canberra
# chengjun wang

import json
import urllib2

'''
About the api and the key, see the links above.
'''

'''step 1: input query information'''
apiUrl='http://api.nytimes.com/svc/search/v1/article?format=json'
query='query=occupy+wall+street'                            # set the query word here
apiDate='begin_date=20110901&amp;end_date=20120214'             # set the date here
fields='fields=body%2Curl%2Ctitle%2Cdate%2Cdes_facet%2Cdesk_facet%2Cbyline'
offset='offset=0'
key='api-key=c2c5b91680.......2811165'  # input your key here

'''step 2: get the number of offset/pages'''
link=[apiUrl, query, apiDate, fields, offset, key]
ReqUrl='&amp;'.join(link)
jstr = urllib2.urlopen(ReqUrl).read()  # t = jstr.strip('()')
ts = json.loads( jstr )
number=ts['total'] #  the number of queries  # query=ts['tokens'] # result=ts['results']
print number
seq=range(number/9)  # this is not a good way
print seq

'''step 3: crawl the data and dump into csv'''
import csv
addressForSavingData= &quot;D:/Research/Dropbox/tweets/wapor_assessing online opinion/News coverage of ows/nyt.csv&quot;
file = open(addressForSavingData,'wb') # save to csv file
for i in seq:
    nums=str(i)
    offsets=''.join(['offset=', nums]) # I made error here, and print is a good way to test
    links=[apiUrl, query, apiDate, fields, offsets, key]
    ReqUrls='&amp;'.join(links)
    print &quot;*_____________*&quot;, ReqUrls
    jstrs = urllib2.urlopen(ReqUrls).read()
    t = jstrs.strip('()')
    tss= json.loads( t )  # error no joson object
    result = tss['results']
    for ob in result:
        title=ob['title']  # body=ob['body']   # body,url,title,date,des_facet,desk_facet,byline
        print title
        url=ob['url']
        date=ob['date'] # desk_facet=ob['desk_facet']  # byline=ob['byline'] # some author names don't exist
        w = csv.writer(file,delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)
        w.writerow((date, title, url)) # write it out
file.close()
pass
</code></pre>

<p>see the result:</p>

<p><img src="http://weblab.com.cityu.edu.hk/blog/chengjun/files/2012/04/nyt1.png" alt="" /></p>

<p>Similarly, you can crawl the article data from The Guardian. See the link below.</p>

<p><a href="http://explorer.content.guardianapis.com/#/?format=json&amp;order-by=newest" target="_blank">http://explorer.content.guardianapis.com/#/?format=json&amp;order-by=newest</a></p>

<p>After you have registered you app and got the key, we can work on the python script.</p>

<pre><code># !/usr/bin/env python
# -*- coding: UTF-8 -*-
# Scraping The Guardian using Python
# 20120421@ Canberra
# chengjun wang

import json
import urllib2

'''

http://content.guardianapis.com/search?q=occupy+wall+street&amp;from-date=2011-09-01&amp;to-date=2012-02-14&amp;page=2

&amp;page-size=3&amp;format=json&amp;show-fields=all&amp;use-date=newspaper-edition&amp;api-key=m....g33gzq
'''

'''step 1: input query information'''
apiUrl='http://content.guardianapis.com/search?q=occupy+wall+street' # set the query word here
apiDate='from-date=2011-09-01&amp;to-date=2011-10-14'           # set the date here
apiPage='page=2'   # set the page
apiNum=10       # set the number of articles in one page
apiPageSize=''.join(['page-size=',str(apiNum)])
fields='format=json&amp;show-fields=all&amp;use-date=newspaper-edition'
key='api-key=mudfuj...g33gzq' # input your key here

'''step 2: get the number of offset/pages'''
link=[apiUrl, apiDate, apiPage, apiPageSize, fields, key]
ReqUrl='&amp;'.join(link)
jstr = urllib2.urlopen(ReqUrl).read() # t = jstr.strip('()')
ts = json.loads( jstr )
number=ts['response']['total'] # the number of queries # query=ts['tokens'] # result=ts['results']
print number
seq=range(number/(apiNum-1)) # this is not a good way
print seq

'''step 3: crawl the data and dump into csv'''
import csv
addressForSavingData= &quot;D:/Research/Dropbox/tweets/wapor_assessing online opinion/News coverage of ows/guardian.csv&quot;
file = open(addressForSavingData,'wb') # save to csv file
for i in seq:
    nums=str(i+1)
    apiPages=''.join(['page=', nums]) # I made error here, and print is a good way to test
    links= [apiUrl, apiDate, apiPages, apiPageSize, fields, key]
    ReqUrls='&amp;'.join(links)
    print &quot;*_____________*&quot;, ReqUrls
    jstrs = urllib2.urlopen(ReqUrls).read()
    t = jstrs.strip('()')
    tss= json.loads( t )
    result = tss['response']['results']
    for ob in result:
        title=ob['webTitle'].encode('utf-8') # body=ob['body']  # body,url,title,date,des_facet,desk_facet,byline
        print title
        section=ob[&quot;sectionName&quot;].encode('utf-8')
        url=ob['webUrl']
        date=ob['fields']['newspaperEditionDate'] # date=ob['webPublicationDate'] # byline=ob['fields']['byline']
        w = csv.writer(file,delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)
        w.writerow((date, title, section, url)) # write it out
file.close()
pass
</code></pre>

      </div>

      

    </div>
  </div>

</article>






<div class="article-container">
  

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2016 Cheng-Jun Wang &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

