[{"authors":["admin"],"categories":null,"content":"Cheng-Jun Wang is currently an associate professor in the School of Journalism and Communication, Nanjing University. He is the director of Computational Communication Collaboratory, and a research member of Web Mining Lab. His research on computational communication appears in both SSCI and SCI indexed journals, such as Internet Research, Cyberpsychology, Telematics and Informatics, Scientific Reports, PloS ONE, and Physica A. In 2014, He founded the website of computational communication. You can find his CV here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://chengjunwang.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Cheng-Jun Wang is currently an associate professor in the School of Journalism and Communication, Nanjing University. He is the director of Computational Communication Collaboratory, and a research member of Web Mining Lab. His research on computational communication appears in both SSCI and SCI indexed journals, such as Internet Research, Cyberpsychology, Telematics and Informatics, Scientific Reports, PloS ONE, and Physica A. In 2014, He founded the website of computational communication. You can find his CV here.","tags":null,"title":"Cheng-Jun Wang","type":"authors"},{"authors":null,"categories":null,"content":" 来回答一个问题：已经开放的数据当中，确诊人数最多的小区是哪一个？\n前文介绍了akshare的安装和简单使用，本文介绍使用akshare获取细化到每个小区的确诊人数数据。腾讯提供了一个公开的数据，可以供查询。为此，我们将使用到akshare的epidemic_area_detail接口。\n epidemic_area_detail() 细化到每个小区的确诊人数 需要遍历每个页面, 如非必要, 请勿运行 https://ncov.html5.qq.com/community?channelid=1\u0026amp;from=singlemessage\u0026amp;isappinstalled=0 :return: 全国每个小区的确诊人数 :rtype: pandas.DataFrame\n import akshare as ak epidemic_area_detail_df = ak.epidemic_area_detail() print(epidemic_area_detail_df)  一共1070, 要等待一会儿。\n下载完成后，我们可以看一下江苏的数据：\n先看一下每个小区的确诊人数：\nepidemic_area_detail_df['cnt_sum_certain'].unique()   array([\u0026lsquo;2\u0026rsquo;, \u0026lsquo;4\u0026rsquo;, \u0026lsquo;1\u0026rsquo;, \u0026lsquo;-1\u0026rsquo;, \u0026lsquo;3\u0026rsquo;, \u0026lsquo;5\u0026rsquo;, \u0026lsquo;7\u0026rsquo;, \u0026lsquo;10\u0026rsquo;, \u0026lsquo;6\u0026rsquo;, \u0026lsquo;8\u0026rsquo;, \u0026lsquo;9\u0026rsquo;, \u0026lsquo;12\u0026rsquo;, \u0026lsquo;14\u0026rsquo;, \u0026lsquo;19\u0026rsquo;, \u0026lsquo;13\u0026rsquo;, \u0026lsquo;11\u0026rsquo;, \u0026lsquo;256\u0026rsquo;, \u0026lsquo;119\u0026rsquo;, \u0026lsquo;31\u0026rsquo;, \u0026lsquo;15\u0026rsquo;, \u0026lsquo;22\u0026rsquo;, \u0026lsquo;16\u0026rsquo;, \u0026lsquo;39\u0026rsquo;, \u0026lsquo;17\u0026rsquo;, \u0026lsquo;23\u0026rsquo;], dtype=object)\n 发现：1. 数据是字符串格式；2.含有 ‘-1’，应该是不详。\nimport numpy as np vlist = [] for i in epidemic_area_detail_df['cnt_sum_certain']: if i != '-1': vlist.append(int(i)) else: vlist.append(np.nan) epidemic_area_detail_df['cnt_sum_certain'] = vlist  来看一下除掉人数不详的情况，本数据共有多少人确诊：\nnp.nansum(vlist) # 7229.0  确认人数最大值是多少？是哪一个小区？\nepidemic_area_detail_df[epidemic_area_detail_df['cnt_sum_certain']==np.nanmax(vlist)]  ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"04870b324b3c50ee8e328e6ab4890f0e","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/2019ncov%E7%A1%AE%E8%AF%8A%E4%BA%BA%E6%95%B0%E6%9C%80%E5%A4%9A%E7%9A%84%E5%B0%8F%E5%8C%BA%E6%98%AF%E5%93%AA%E4%B8%80%E4%B8%AA/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/2019ncov%E7%A1%AE%E8%AF%8A%E4%BA%BA%E6%95%B0%E6%9C%80%E5%A4%9A%E7%9A%84%E5%B0%8F%E5%8C%BA%E6%98%AF%E5%93%AA%E4%B8%80%E4%B8%AA/","section":"\u0008计算新闻","summary":"来回答一个问题：已经开放的数据当中，确诊人数最多的小区是哪一个？\n前文介绍了akshare的安装和简单使用，本文介绍使用akshare获取细化到每个小区的确诊人数数据。腾讯提供了一个公开的数据，可以供查询。为此，我们将使用到akshare的epidemic_area_detail接口。\n epidemic_area_detail() 细化到每个小区的确诊人数 需要遍历每个页面, 如非必要, 请勿运行 https://ncov.html5.qq.com/community?channelid=1\u0026amp;from=singlemessage\u0026amp;isappinstalled=0 :return: 全国每个小区的确诊人数 :rtype: pandas.DataFrame\n import akshare as ak epidemic_area_detail_df = ak.epidemic_area_detail() print(epidemic_area_detail_df)  一共1070, 要等待一会儿。\n下载完成后，我们可以看一下江苏的数据：\n先看一下每个小区的确诊人数：\nepidemic_area_detail_df['cnt_sum_certain'].unique()   array([\u0026lsquo;2\u0026rsquo;, \u0026lsquo;4\u0026rsquo;, \u0026lsquo;1\u0026rsquo;, \u0026lsquo;-1\u0026rsquo;, \u0026lsquo;3\u0026rsquo;, \u0026lsquo;5\u0026rsquo;, \u0026lsquo;7\u0026rsquo;, \u0026lsquo;10\u0026rsquo;, \u0026lsquo;6\u0026rsquo;, \u0026lsquo;8\u0026rsquo;, \u0026lsquo;9\u0026rsquo;, \u0026lsquo;12\u0026rsquo;, \u0026lsquo;14\u0026rsquo;, \u0026lsquo;19\u0026rsquo;, \u0026lsquo;13\u0026rsquo;, \u0026lsquo;11\u0026rsquo;, \u0026lsquo;256\u0026rsquo;, \u0026lsquo;119\u0026rsquo;, \u0026lsquo;31\u0026rsquo;, \u0026lsquo;15\u0026rsquo;, \u0026lsquo;22\u0026rsquo;, \u0026lsquo;16\u0026rsquo;, \u0026lsquo;39\u0026rsquo;, \u0026lsquo;17\u0026rsquo;, \u0026lsquo;23\u0026rsquo;], dtype=object)\n 发现：1. 数据是字符串格式；2.含有 ‘-1’，应该是不详。\nimport numpy as np vlist = [] for i in epidemic_area_detail_df['cnt_sum_certain']: if i !","tags":[""],"title":"2019确诊人数最多的小区是哪一个？","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  Causal Inference Book 来源：https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/\nMiguel Hernan \u0026amp; Jamie Robinshave written a book that provides a cohesive presentation of concepts of, and methods for, causal inference. Much of this material is currently scattered across journals in several disciplines or confined to technical articles. We expect that the book will be of interest to anyone interested in causal inference, e.g., epidemiologists, statisticians, psychologists, economists, sociologists, political scientists, computer scientists… The book is divided in 3 parts of increasing difficulty: causal inference without models, causal inference with models, and causal inference from complex longitudinal data.\n Hernán MA, Robins JM (2020). Causal Inference: What If. Boca Raton: Chapman \u0026amp; Hall/CRC.\n The components of the book can be accessed by clicking on the links below:\n The Causal Inference book (updated 21 February 2020) NHEFS data  In SAS, Stata, MS Excel, and CSV formats Codebook  Computer code  SAS by Roger Logan Stata by Eleanor Murray and Roger Logan R by Joy Shi and Sean McGrath. Rendered version by Tom Palmer. Python by James Fiedler Parametric g-formula software in R and SAS    Warning: At this stage, we may still revise and correct errors without documenting the changes. Please make sure you use the most updated version of the book posted here.\n ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"f2cc93e80ed10b779b50749e6e732116","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/causal-inferencewhat-if-%E7%94%B5%E5%AD%90%E4%B9%A6%E4%BB%A3%E7%A0%81%E6%95%B0%E6%8D%AE/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/causal-inferencewhat-if-%E7%94%B5%E5%AD%90%E4%B9%A6%E4%BB%A3%E7%A0%81%E6%95%B0%E6%8D%AE/","section":"\u0008计算新闻","summary":"Causal Inference Book 来源：https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/\nMiguel Hernan \u0026amp; Jamie Robinshave written a book that provides a cohesive presentation of concepts of, and methods for, causal inference. Much of this material is currently scattered across journals in several disciplines or confined to technical articles. We expect that the book will be of interest to anyone interested in causal inference, e.g., epidemiologists, statisticians, psychologists, economists, sociologists, political scientists, computer scientists… The book is divided in 3 parts of increasing difficulty: causal inference without models, causal inference with models, and causal inference from complex longitudinal data.","tags":[""],"title":"Causal Inference: 电子书、代码、数据","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  数据来源 不断更新当中：\n https://github.com/CSSEGISandData/COVID-19 https://github.com/data-journalism/WuHan2019nCov https://github.com/AaronWard/covid-19-analysis 澎湃 839-Studio  Noval-Coronavirus-763-Cases Novel-Coronavirus-Updates   可视化  http://vis.pku.edu.cn/ncov/home.html  538数据新闻项目  fivethirtyeight/data  ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"2c372825bc9d99cd8bee24ad5d8af5f5","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/covid-19%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90%E4%B8%8D%E6%96%AD%E6%95%B4%E7%90%86%E5%BD%93%E4%B8%AD/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/covid-19%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90%E4%B8%8D%E6%96%AD%E6%95%B4%E7%90%86%E5%BD%93%E4%B8%AD/","section":"\u0008计算新闻","summary":"  数据来源 不断更新当中：\n https://github.com/CSSEGISandData/COVID-19 https://github.com/data-journalism/WuHan2019nCov https://github.com/AaronWard/covid-19-analysis 澎湃 839-Studio  Noval-Coronavirus-763-Cases Novel-Coronavirus-Updates   可视化  http://vis.pku.edu.cn/ncov/home.html  538数据新闻项目  fivethirtyeight/data  ","tags":[""],"title":"Covid-19数据来源（更新当中）","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"   epidemic_hist_all() NCP细化到地市的细颗粒数据 https://github.com/norratek/Ncov2020HistoryData https://docs.google.com/spreadsheets/d/1JNQnFYJpR7PxQo5K5lwXTuE0F6jprhMXuy7DPnV9H90/edit#gid=0 :return: 返回每日的历史数据 :rtype: pandas.DataFrame\n import akshare as ak import pylab as plt plt.style.use('fivethirtyeight') epidemic_hist_all_df = ak.epidemic_hist_all()  提取江苏省的历史数据 epidemic_hist_all_df = epidemic_hist_all_df.sort_values(by='date') js = epidemic_hist_all_df[epidemic_hist_all_df['Province']=='江苏省'] js.head()  看一下南京市的数据 plt.figure(figsize=(12, 6), dpi = 200) i = '南京' df = js[js['City']==i] plt.plot(df['date'], df['Confirmed'], 'r-s', label = '累计确诊') plt.plot(df['date'], df['Cured'], 'g-o', label = '累计治愈') plt.title(i, fontsize =20) plt.legend() # plt.yscale('log') plt.xticks(rotation=60) plt.ylabel('数量', fontsize = 20) plt.show()  江苏所有地级市数据 cols = [ '#bd2309', '#bbb12d', '#1480fa', '#14fa2f', '#000000', '#faf214', '#2edfea', '#ea2ec4', '#ea2e40', '#cdcdcd', '#577a4d', '#2e46c0', '#f59422', '#219774', '#8086d9' ] plt.figure(figsize=(12, 6), dpi = 200) for k, i in enumerate(js['City'].unique()): df = js[js['City']==i] plt.plot(df['date'], df['Confirmed'], color= cols[k], marker='o', linestyle='-', label = i) plt.title('江苏省', fontsize =20) plt.legend() # plt.yscale('log') plt.xticks(rotation=60) plt.ylabel('累计确诊数量', fontsize = 20) plt.show()  ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"49c1014a91cee88de05bcf281215b837","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/2019ncov%E7%BB%86%E9%A2%97%E7%B2%92%E5%BA%A6%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/2019ncov%E7%BB%86%E9%A2%97%E7%B2%92%E5%BA%A6%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE/","section":"\u0008计算新闻","summary":" ","tags":[""],"title":"Covid-19细颗粒度历史数据","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  安装pygame 首先尝试： \u0026gt; pip install pygame -i http://pypi.douban.com/simple\n如果出错，尝试 \u0026gt; pip install pygame -i http://pypi.douban.com/simple \u0026ndash;trusted-host pypi.douban.com\n开始玩游戏！ https://www.pygame.org/\n python3 -m pygame.examples.aliens\n 想要学习更多东西？ Below are unofficial tutorials and guides. Anything with wrong install instructions is not allowed.\nGeneral Tutorials[](https://www.pygame.org/wiki/tutorials#General%20Tutorials \u0026laquo;Permalink to this definition\u0026raquo;)  Tutorials by DR0ID PyGame object oriented tutorials by przemo_li Thepythongamebook tutorial about Pygame  Pygame Tutorials on Specific Topics[](https://www.pygame.org/wiki/tutorials#Pygame%20Tutorials%20on%20Specific%20Topics \u0026laquo;Permalink to this definition\u0026raquo;)  Screencasts and tutorials at Scriptedfun, making an arkanoid type game A tutorial on making a top-down tile-based game PyGame Physics Youtube Tutorials by maaack YouTube series creating a top down racing game with Python 3  ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"36b1b137af75af858ced83705ffe4e54","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/pygame%E5%86%85%E7%BD%AE%E5%B0%8F%E6%B8%B8%E6%88%8F%E5%A4%96%E6%98%9F%E4%BA%BA/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/pygame%E5%86%85%E7%BD%AE%E5%B0%8F%E6%B8%B8%E6%88%8F%E5%A4%96%E6%98%9F%E4%BA%BA/","section":"\u0008计算新闻","summary":"  安装pygame 首先尝试： \u0026gt; pip install pygame -i http://pypi.douban.com/simple\n如果出错，尝试 \u0026gt; pip install pygame -i http://pypi.douban.com/simple \u0026ndash;trusted-host pypi.douban.com\n开始玩游戏！ https://www.pygame.org/\n python3 -m pygame.examples.aliens\n 想要学习更多东西？ Below are unofficial tutorials and guides. Anything with wrong install instructions is not allowed.\nGeneral Tutorials[](https://www.pygame.org/wiki/tutorials#General%20Tutorials \u0026laquo;Permalink to this definition\u0026raquo;)  Tutorials by DR0ID PyGame object oriented tutorials by przemo_li Thepythongamebook tutorial about Pygame  Pygame Tutorials on Specific Topics[](https://www.pygame.org/wiki/tutorials#Pygame%20Tutorials%20on%20Specific%20Topics \u0026laquo;Permalink to this definition\u0026raquo;)  Screencasts and tutorials at Scriptedfun, making an arkanoid type game A tutorial on making a top-down tile-based game PyGame Physics Youtube Tutorials by maaack YouTube series creating a top down racing game with Python 3  ","tags":[""],"title":"Pygame内置小游戏：外星人","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  来源： 麦田亲子悦读\n《石头汤》是凯迪克大奖得主琼·穆特代表作，2007年度全国十佳童书，全数百所知名小学、幼儿园指定必读书！作者琼•穆特以优美恬静的画风在美术及插画创作领域享有盛名，他运用华丽的水彩画，引领读者去深思故事背后的蕴涵。他把自己对禅宗和东方文化的热爱，融入到这个古老的巧计故事当中，以此弘扬慷慨好施的力量。这是一个来自欧洲的古老传说，被各个国家的作者演绎成不同的版本。中国版的《石头汤》作者是一个美国人，但他对中国文化和元素非常的了解，连绘本画风色调都是国画风格，完全符合中国人的审美。\n这也是一个奇怪的故事！ 石头也能用来煮汤吗？鸡可以煮汤，鸭可以煮汤，冬瓜火腿、番茄和鸡蛋都可以用来煮汤，但石头怎么能煮汤呢？\n如何摆脱困境？ 这个故事说的正是用石头煮汤，三个和尚阿福、阿禄、阿寿在旅行的路途中，边走边聊着猫的胡须、太阳的颜色和一个人怎样才能得到快乐。正说着，他们来到了一个村庄。这是一个历经了很多苦难的村庄，洪水、战争……村民们被折磨得苦不堪言，对世界再也没有信心，对生活丧失了热情，邻居之间彼此猜忌，缺乏信任，更别提陌生人了。这个村庄和石头汤之间产生了什么联系，又发生了什么故事呢？\n三个和尚来到村子里，并没有人迎接，反而家家户户门窗紧闭。\n行动和分享 三个和尚不疾不徐地在一块空地上捡柴火、生火，架起一口锅，开始煮石头汤。\n画面中一直有一位黄衣女孩在关注着和尚们的动向，终于她鼓起勇气去问和尚们在做什么了。和尚们说，他们要煮石头汤，可是这么小的锅，恐怕煮不出很多，于是小女孩自告奋勇地回家取锅。\n这个线索人物——黄衣女孩。黄色更像是一抹阳光，照进了每一个村民心中，驱散了大家心头的阴霾。也是这样一抹阳光，在推动着整个故事向前发展。\n小女孩的母亲很好奇她拿这么大的锅要做什么，小女孩回答：那三个和尚要用大锅来煮石头汤。此言一出，犹如一颗石子投入一池春水，惊起了水花。大家都很好奇，用石头怎么煮汤呢？\n 琼·穆特说，书中小女孩衣服的颜色是太阳的颜色。\n 怪不得，她看起来那么与众不同。在每个人都紧锁心门时，她没有一点犹豫和怀疑地去信任三个和尚，给了他们最多的帮助。是她带领着村民尝到了石头汤的甜美，品味到了分享带给人的满足。这份单纯美好特别珍贵。其实每个孩子都拥有纯净的心灵，大人所要做的，就是保护好他们内心的纯净。\n 第一枚多米诺骨牌被推倒了，蝴蝶效应随之发生。大家纷纷走出家门，围观三个和尚煮石头汤。\n 三个和尚一边搅动大锅里的水，一边自言自语到，上次我们煮这种材质的石头汤，还放了些盐和胡椒粉，可惜我们没带。于是，就有秀才从自己家里拿来这些调料，接下来不断地又村民从家里拿出食材加入到锅中，锅中的食材越来越多，香气弥散在空中。\n 当一个人付出时，就会有更多人愿意付出。\n 村民贡献着自己家的各种食材，一锅材料丰富的石头汤就煮好了，全体村民因着这一锅石头汤，还进行了久违的欢宴。欢宴结束之后，大家争先恐后地邀请三个和尚到自己家里来住。\n和尚感谢村民们的慷慨，而村民们则感谢三个和尚送给他们享用不尽的财富——分享使人更加富足。\n最后，三个和尚留下一句禅语“幸福就像做石头汤那样简单”。\n 如果你知道往哪里走 全世界都会为你让步 如果你知道自己需要什么 行动起来 展示你的作品 大声呐喊 全世界都会愿意帮助你。\n ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"4872cd6b914cbf22a8023c0763a3c0e1","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E7%9F%B3%E5%A4%B4%E6%B1%A4/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E7%9F%B3%E5%A4%B4%E6%B1%A4/","section":"\u0008计算新闻","summary":" ","tags":[""],"title":"《石头汤》","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  数据来源：http://www.policyuncertainty.com/scmp_monthly.html\nimport akshare as ak epu_index_df = ak.article_epu_index(index=\u0026quot;China\u0026quot;) # 注意单词第一个字母大写 epu_index_df.head()  文献  Baker, Scott, Nicholas Bloom and Steven J. Davis, \u0026laquo;Measuring Economic Policy Uncertainty,\u0026raquo; Quarterly Journal of Economics, November 2016, Vol 131, Issue 4   We develop a new index of economic policy uncertainty (EPU) based on newspaper coverage frequency. Several types of evidence—including human readings of 12,000 newspaper articles—indicate that our index proxies for movements in policy-related economic uncertainty. Our U.S. index spikes near tight presidential elections, Gulf Wars I and II, the 9\u0026frasl;11 attacks, the failure of Lehman Brothers, the 2011 debt ceiling dispute, and other major battles over fiscal policy. Using firm-level data, we find that policy uncertainty is associated with greater stock price volatility and reduced investment and employment in policy-sensitive sectors like defense, health care, finance, and infrastructure construction. At the macro level, innovations in policy uncertainty foreshadow declines in investment, output, and employment in the United States and, in a panel vector autoregressive setting, for 12 major economies. Extending our U.S. index back to 1900, EPU rose dramatically in the 1930s (from late 1931) and has drifted upward since the 1960s.\n  Baker, Scott, Nicholas Bloom, Steven J. Davis, and Xiaoxi Wang, 2013. \u0026laquo;Economic Policy Uncertainty in China,\u0026raquo; unpublished paper, University of Chicago  ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"af1f34bec816fd50c4e87d6bcdbaa46b","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%B8%AD%E5%9B%BD%E7%9A%84%E7%BB%8F%E6%B5%8E%E6%94%BF%E7%AD%96%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%95%B0%E6%8D%AE/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%B8%AD%E5%9B%BD%E7%9A%84%E7%BB%8F%E6%B5%8E%E6%94%BF%E7%AD%96%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%95%B0%E6%8D%AE/","section":"\u0008计算新闻","summary":"数据来源：http://www.policyuncertainty.com/scmp_monthly.html\nimport akshare as ak epu_index_df = ak.article_epu_index(index=\u0026quot;China\u0026quot;) # 注意单词第一个字母大写 epu_index_df.head()  文献  Baker, Scott, Nicholas Bloom and Steven J. Davis, \u0026laquo;Measuring Economic Policy Uncertainty,\u0026raquo; Quarterly Journal of Economics, November 2016, Vol 131, Issue 4   We develop a new index of economic policy uncertainty (EPU) based on newspaper coverage frequency. Several types of evidence—including human readings of 12,000 newspaper articles—indicate that our index proxies for movements in policy-related economic uncertainty.","tags":[""],"title":"中国经济政策不确定性数据","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":" 导语：量化模型显示，当媒体的报道量增加十倍，传染病的感染数将会减少33.5％。 \u0026gt; Understanding the effect of media on disease spread can help improve epidemic forecasting and uncover preventive measures to slow the spread of disease. Most previously introduced models have approximated media effect through disease incidence, making media influence dependent on the size of epidemic. We propose an alternative approach, which relies on real data about disease coverage in the news, allowing us to model low incidence/high interest diseases, such as SARS, Ebola or H1N1. We introduce a network-based model, in which disease is transmitted through local interactions between individuals and the probability of transmission is affected by media coverage. We assume that media attention increases self-protection (e.g. hand washing and compliance with social distancing), which, in turn, decreases disease model. We apply the model to the case of H1N1 transmission in Mexico City in 2009 and show how media influence—measured by the time series of the weekly count of news articles published on the outbreak—helps to explain the observed transmission dynamics. We show that incorporating the media attention based on the observed media coverage of the outbreak better estimates the disease dynamics from what would be predicted by using media function that approximate the media impact using the number of cases and rate of spread. Finally, we apply the model to a typical influenza season in Washington, DC and estimate how the transmission pattern would have changed given different levels of media coverage.\nLouis Kim ,Shannon M. Fast, Natasha Markuzon. Incorporating media data into a model of infectious disease transmission. PloS ONE. February 4, 2019. https://doi.org/10.1371/journal.pone.0197646\n华盛顿大学的Louis Kim教授和Shannon M. Fast, Natasha Markuzon几位科学家做过一个有意思的研究，观察媒体报道的数量与疾病传播数量之间的关系。这其中的原理在于，疾病的传播是在动态的社会活动中发生的，所以个人行动对传播有着重要的影响。媒体报道多了，大家的防范意识增强了，疾病的传播速度就会减缓。Louis Kim教授等的模型显示，当媒体的报道量增加十倍，此类疾病的感染数减少33.5％。因此，媒体可能是预防疾病传播的一个有效手段。\n建立研究模型\nLouis Kim教授等建立了一个疾病传播模型，并在该模型中加入了对媒体报道的量化，展现媒体报道数量和传染病例数量之间的关系。该模型分为两部分，第一部分量化疾病传播概率，第二部分量化媒体的影响力。\n（1）量化疾病传播概率\nLouis Kim教授等使用了易感-感染-康复（SIR）模型来展现疾病传播的概率。SIR模型专门模拟个人直接相互感染的情况，而非通过诸如蚊子之类的疾病媒介相互感染的情况。SIR对三种状态之间的人员流动进行建模：易感（S），感染（I）和康复（R）。这些变量代表每组中的人数。每个人在时间t的状态都由X表示。在时间t，受感染的个体以概率p（t）感染他身边的易感个体i和j。因此，如果\n则：\n 感染后，个体在T（R）时间段后恢复。因此，如果  并且 则:\n如果考虑到疫苗的作用，并在疫苗在注射后要等d时间才生效。设η为疫苗效力。 然后，如果易感人i在时间t接种了疫苗，则： （2）量化媒体报道的影响力\n这个研究假设媒体对疫情的关注会增加民众的自我保护行为，例如洗手，使用口罩和遵守社交隔离，从而减少疾病传播。具体来说，将时间t的每次接触传播概率定义为上述提到的疾病传播概率p（0）和媒体函数g的乘积： 其中Mt是在时间t发布的新闻报道的数量；α是由媒体对传染概率带来的影响；λ指最近媒体宣传信息的权重。媒体函数g，会随着新闻文章数量的增加而减小，这意味着当最近有许多关于该疾病的文章发表时，疾病的传播速度会减慢。 这其中的θ为新闻文章数量的指数加权移动平均值，假设发表的文章会继续影响当前行为，但影响程度会随着时间而降低。令θt为新闻文章数量的指数加权移动平均值，参数λ∈（0，1]，代表最近和之前报道数量的权重：\n墨西哥城案例和华盛顿特区案例\nLouis Kim教授等使用了两个实际案例，并把其中真实的媒体报道数据纳入了的疾病传播的模型。Louis Kim教授等发现，在疾病传播模型中，加入媒体报道数量的变量后，模型呈现出的结果和现实十分贴近。这两个案例分别是2009年墨西哥H1N1病毒的爆发，以及2014-2015年华盛顿特区2014-2015年的流感季。\n（1）墨西哥城案例\n2009年，墨西哥城爆发了两次H1N1流感。第一次是在4月中旬开始的。爆发规模较小，并通过社交隔离和公共宣传活动，迅速得到了控制。第二次爆发始于8月，传播范围比第一次爆发更为广泛。春季疫情的爆发引起了媒体的强烈关注，而秋季疫情的报道则相对较少。由于在春季和秋季爆发之间，H1N1病毒的感染力以及墨西哥城的社会结构，都不会发生很大的变化，因此需要通过媒体报道的差异来解释传染规模之间的差异。在该模型中，Louis Kim教授等使用上述提到的模型对春季和秋季疫情的爆发进行了模拟。H1N1的每周流感病例数的数据由墨西哥社会保障研究所提供。因为H1N1疫苗要到2009年11月下旬才面世，无法对墨西哥的疾病传播产生重大影响，所以在此分析中未考虑疫苗的接种。互联网生物监视公司HealthMap收集了在线发布的、专门提到了墨西哥城的H1N1流感爆发的文章。Louis Kim教授等发现在墨西哥城爆发的春季H1N1疫情引起了媒体的强烈兴趣。在6月1日之前，HealthMap收集了815篇突发新闻文章，从4月22日到6月1日，每天约有20篇文章。而秋季疫情中的文章数量则少很多。在9月17日至12月6日之间，HealthMap收集了66篇已发表的文章，每天少于1篇文章。可以看出，春季爆发期间由于媒体的覆盖激增，使得民众采取的保护措施，从而减缓疾病传播的速度。相比之下，秋季疫情几乎没有受到抑制，没有引起媒体的广泛关注。Louis Kim教授等使用上述加入了媒体报道变量的模型，模拟墨西哥城春季、秋季疫情的发病人数，发现模型对真实情况模拟的非常贴近，加权平均绝对误差为1243例。下图中红线是模型做出的每周病例数，黑线是真实的病例数。二者有着很好的重叠。 （2）华盛顿特区案例\n华盛顿特区2014-2015年曾爆发严重的流感疫情，美国每10万人中有51.4人因流感住院。Louis Kim教授等使用了和墨西哥城案例相似的研究方法，2014-2015年流感季节每周新的A型流感住院病例数可以从华盛顿特区卫生部获得。疫情的媒体覆盖面有限。每周的新闻文章数量在流感季节的高峰期达到顶峰，截至2015年1月1日当周收集了25篇文章。Louis Kim教授等将模型模拟出的病例数与华盛顿特区2014-2015年流感季的真实病例数进行了对比，发现加权平均绝对误差为2818例。华盛顿特区的案例表明，由于发表的新闻报道数量很少，因此媒体在2014-2015年华盛顿特区的流感季节对行为的影响有限。但是如果在模拟中，把每周新闻数量增加十倍时，媒体就会发挥更大的作用，传染病例数会减少33.5％。左图中红线是模型做出的每周病例数，黑线是真实的病例数。二者的重叠度一般，因为媒体报道的数量比较小。右图中的红线是实际的媒体报道数量，绿线是无媒体的作用，蓝线是把媒体报道数量增加十倍。右图模型显示，当媒体报道数量增加十倍时，传染病例数会减少33.5％。\nLouis Kim教授等的研究表明，一方面，可以使用媒体报道的数量来模拟预测传染病的案例数，模型的准确度会随着媒体报道数量的增加而增加。另一方面，媒体报道对疫情覆盖的增加会减缓疾病的传播。\n","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"9fc24c9f5553ce6ad8df09fb8cf1caca","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BB%BF%E7%9C%9F%E6%A8%A1%E5%9E%8B%E8%A1%A8%E6%98%8E%E5%AA%92%E4%BD%93%E6%8A%A5%E9%81%93%E5%8F%AF%E8%83%BD%E9%99%8D%E4%BD%8E%E7%96%AB%E6%83%85%E4%BC%A0%E6%92%AD/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BB%BF%E7%9C%9F%E6%A8%A1%E5%9E%8B%E8%A1%A8%E6%98%8E%E5%AA%92%E4%BD%93%E6%8A%A5%E9%81%93%E5%8F%AF%E8%83%BD%E9%99%8D%E4%BD%8E%E7%96%AB%E6%83%85%E4%BC%A0%E6%92%AD/","section":"\u0008计算新闻","summary":" ","tags":[""],"title":"仿真模型表明媒体报道可以遏制传染病扩散","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  AkShare  AkShare 是基于 Python 的开源金融数据接口库, 目的是实现对股票, 期货, 期权, 基金, 外汇, 债券, 指数, 数字货币等金融产品的基本面数据、实时和历史行情数据、衍生数据从数据采集, 数据清洗, 到数据落地的一套开源工具, 满足金融数据科学家, 数据科学爱好者在金融数据获取方面的需求.\n AkShare 的特点是获取的是相对权威的金融数据网站公布的原始数据, 广大数据科学家可以利用原始数据进行各数据源之间的交叉验证, 进而再加工, 从而得出科学的结论.\n针对新型冠状病毒肺炎疫情，akshare开发了事件接口，链接如下：\nhttps://akshare.readthedocs.io/zh_CN/latest/data/event/event.html\n安装 pip install akshare --upgrade  对于国内用户anaconda使用者，推荐使用以下方法：\npip install akshare -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com --user --upgrade  使用 import akshare as ak import pylab as plt import pandas as pd import seaborn as sns # 提取数据 df_index4 = ak.weibo_index(word=\u0026quot;武汉\u0026quot;, time_type=\u0026quot;3month\u0026quot;) df_index6 = ak.weibo_index(word=\u0026quot;CDC\u0026quot;, time_type=\u0026quot;3month\u0026quot;) df_index7 = ak.weibo_index(word=\u0026quot;钟南山\u0026quot;, time_type=\u0026quot;3month\u0026quot;) df_index5 = ak.weibo_index(word=\u0026quot;疫情\u0026quot;, time_type=\u0026quot;3month\u0026quot;)  然后，使用matplotlib进行可视化。\nplt.figure(figsize=(12, 6), dpi = 200) plt.style.use('fivethirtyeight') plt.plot(df_index4.index, df_index4, label = '武汉', alpha = 0.5) plt.plot(df_index5.index, df_index5, label = '疫情', alpha = 0.5) plt.plot(df_index6.index, df_index6, label = 'CDC', alpha = 0.5) plt.plot(df_index7.index, df_index7, label = '钟南山', alpha = 0.5) plt.legend() plt.yscale('log') plt.xticks(rotation=60) plt.ylabel('微博指数', fontsize = 20) plt.show()  练习 绘制下图：\n","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"96c11c5421a172bdc47432a9bcdee50f","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8akshare%E5%88%86%E6%9E%902019ncov%E7%96%AB%E6%83%85%E5%BE%AE%E5%8D%9A%E6%8C%87%E6%95%B0/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8akshare%E5%88%86%E6%9E%902019ncov%E7%96%AB%E6%83%85%E5%BE%AE%E5%8D%9A%E6%8C%87%E6%95%B0/","section":"\u0008计算新闻","summary":"AkShare  AkShare 是基于 Python 的开源金融数据接口库, 目的是实现对股票, 期货, 期权, 基金, 外汇, 债券, 指数, 数字货币等金融产品的基本面数据、实时和历史行情数据、衍生数据从数据采集, 数据清洗, 到数据落地的一套开源工具, 满足金融数据科学家, 数据科学爱好者在金融数据获取方面的需求.\n AkShare 的特点是获取的是相对权威的金融数据网站公布的原始数据, 广大数据科学家可以利用原始数据进行各数据源之间的交叉验证, 进而再加工, 从而得出科学的结论.\n针对新型冠状病毒肺炎疫情，akshare开发了事件接口，链接如下：\nhttps://akshare.readthedocs.io/zh_CN/latest/data/event/event.html\n安装 pip install akshare --upgrade  对于国内用户anaconda使用者，推荐使用以下方法：\npip install akshare -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com --user --upgrade  使用 import akshare as ak import pylab as plt import pandas as pd import seaborn as sns # 提取数据 df_index4 = ak.weibo_index(word=\u0026quot;武汉\u0026quot;, time_type=\u0026quot;3month\u0026quot;) df_index6 = ak.weibo_index(word=\u0026quot;CDC\u0026quot;, time_type=\u0026quot;3month\u0026quot;) df_index7 = ak.","tags":[""],"title":"使用akshare分析covid19微博指数","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"   Doraemon：本文尝试使用python对经典传染病模型进行实现，因传染病模型研究属于传染病动力学研究方向，不是本人的工作范围，因此，本人只是将模型中的微分方程，用Python进行实现，想起到抛砖引玉的效果。来源： https://zhuanlan.zhihu.com/p/104091330\n SI模型 import scipy.integrate as spi import numpy as np import matplotlib.pyplot as plt # N为人群总数 N = 10000 # β为传染率系数 beta = 0.25 # gamma为恢复率系数 gamma = 0 # I_0为感染者的初始人数 I_0 = 1 # S_0为易感者的初始人数 S_0 = N - I_0 # T为传播时间 T = 150 # INI为初始状态下的数组 INI = (S_0,I_0) def funcSI(inivalue,_): Y = np.zeros(2) X = inivalue # 易感个体变化 Y[0] = - (beta * X[0] * X[1]) / N + gamma * X[1] # 感染个体变化 Y[1] = (beta * X[0] * X[1]) / N - gamma * X[1] return Y T_range = np.arange(0,T + 1) RES = spi.odeint(funcSI,INI,T_range) plt.plot(RES[:,0],color = 'darkblue',label = 'Susceptible',marker = '.') plt.plot(RES[:,1],color = 'red',label = 'Infection',marker = '.') plt.title('SI Model') plt.legend() plt.xlabel('Day') plt.ylabel('Number') plt.show()  SIS模型 import scipy.integrate as spi import numpy as np import matplotlib.pyplot as plt # N为人群总数 N = 10000 # β为传染率系数 beta = 0.25 # gamma为恢复率系数 gamma = 0.05 # I_0为感染者的初始人数 I_0 = 1 # S_0为易感者的初始人数 S_0 = N - I_0 # T为传播时间 T = 150 # INI为初始状态下的数组 INI = (S_0,I_0) def funcSIS(inivalue,_): Y = np.zeros(2) X = inivalue # 易感个体变化 Y[0] = - (beta * X[0]) / N * X[1] + gamma * X[1] # 感染个体变化 Y[1] = (beta * X[0] * X[1]) / N - gamma * X[1] return Y T_range = np.arange(0,T + 1) RES = spi.odeint(funcSIS,INI,T_range) plt.plot(RES[:,0],color = 'darkblue',label = 'Susceptible',marker = '.') plt.plot(RES[:,1],color = 'red',label = 'Infection',marker = '.') plt.title('SIS Model') plt.legend() plt.xlabel('Day') plt.ylabel('Number') plt.show()  SIR模型 import scipy.integrate as spi import numpy as np import matplotlib.pyplot as plt # N为人群总数 N = 10000 # β为传染率系数 beta = 0.25 # gamma为恢复率系数 gamma = 0.05 # I_0为感染者的初始人数 I_0 = 1 # R_0为治愈者的初始人数 R_0 = 0 # S_0为易感者的初始人数 S_0 = N - I_0 - R_0 # T为传播时间 T = 150 # INI为初始状态下的数组 INI = (S_0,I_0,R_0) def funcSIR(inivalue,_): Y = np.zeros(3) X = inivalue # 易感个体变化 Y[0] = - (beta * X[0] * X[1]) / N # 感染个体变化 Y[1] = (beta * X[0] * X[1]) / N - gamma * X[1] # 治愈个体变化 Y[2] = gamma * X[1] return Y T_range = np.arange(0,T + 1) RES = spi.odeint(funcSIR,INI,T_range) plt.plot(RES[:,0],color = 'darkblue',label = 'Susceptible',marker = '.') plt.plot(RES[:,1],color = 'red',label = 'Infection',marker = '.') plt.plot(RES[:,2],color = 'green',label = 'Recovery',marker = '.') plt.title('SIR Model') plt.legend() plt.xlabel('Day') plt.ylabel('Number') plt.show()  SEIR模型 import scipy.integrate as spi import numpy as np import pylab as plt # N为人群总数 N = 10000 # β为传染率系数 beta = 0.6 # gamma为恢复率系数 gamma = 0.1 # Te为疾病潜伏期 Te = 14 # I_0为感染者的初始人数 I_0 = 1 # E_0为潜伏者的初始人数 E_0 = 0 # R_0为治愈者的初始人数 R_0 = 0 # S_0为易感者的初始人数 S_0 = N - I_0 - E_0 - R_0 # T为传播时间 T = 150 # INI为初始状态下的数组 INI = (S_0,E_0,I_0,R_0)  def funcSEIR(inivalue,_): Y = np.zeros(4) X = inivalue # 易感个体变化 Y[0] = - (beta * X[0] * X[2]) / N # 潜伏个体变化 Y[1] = (beta * X[0] * X[2]) / N - X[1] / Te # 感染个体变化 Y[2] = X[1] / Te - gamma * X[2] # 治愈个体变化 Y[3] = gamma * X[2] return Y T_range = np.arange(0,T + 1) RES = spi.odeint(funcSEIR,INI,T_range)  plt.plot(RES[:,0],color = 'darkblue',label = 'Susceptible',marker = '.') plt.plot(RES[:,1],color = 'orange',label = 'Exposed',marker = '.') plt.plot(RES[:,2],color = 'red',label = 'Infection',marker = '.') plt.plot(RES[:,3],color = 'green',label = 'Recovery',marker = '.') plt.title('SEIR Model') plt.legend() plt.xlabel('Day') plt.ylabel('Number') plt.show()  SEIRS模型 import scipy.integrate as spi import numpy as np import matplotlib.pyplot as plt # N为人群总数 N = 10000 # β为传染率系数 beta = 0.6 # gamma为恢复率系数 gamma = 0.1 # Ts为抗体持续时间 Ts = 7 # Te为疾病潜伏期 Te = 14 # I_0为感染者的初始人数 I_0 = 1 # E_0为潜伏者的初始人数 E_0 = 0 # R_0为治愈者的初始人数 R_0 = 0 # S_0为易感者的初始人数 S_0 = N - I_0 - E_0 - R_0 # T为传播时间 T = 150 # INI为初始状态下的数组 INI = (S_0,E_0,I_0,R_0) def funcSEIRS(inivalue,_): Y = np.zeros(4) X = inivalue # 易感个体变化 Y[0] = - (beta * X[0] * X[2]) / N + X[3] / Ts # 潜伏个体变化 Y[1] = (beta * X[0] * X[2]) / N - X[1] / Te # 感染个体变化 Y[2] = X[1] / Te - gamma * X[2] # 治愈个体变化 Y[3] = gamma * X[2] - X[3] / Ts return Y T_range = np.arange(0,T + 1) RES = spi.odeint(funcSEIRS,INI,T_range) plt.plot(RES[:,0],color = 'darkblue',label = 'Susceptible',marker = '.') plt.plot(RES[:,1],color = 'orange',label = 'Exposed',marker = '.') plt.plot(RES[:,2],color = 'red',label = 'Infection',marker = '.') plt.plot(RES[:,3],color = 'green',label = 'Recovery',marker = '.') plt.title('SEIRS Model') plt.legend() plt.xlabel('Day') plt.ylabel('Number') plt.show()  推荐大家阅读Albert-Laszlo Barabasi的书Network Science，大家可以在如下网站直接阅读传染病模型这一章：http://barabasi.com/networksciencebook/chapter/10#contact-networks。有两个Hypothesis：1,Compartmentalization; 2, Homogenous Mixing。具体看教材。默认条件：1, closed population; 2, no births; 3, no deaths; 4, no migrations.\n","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"e80720f1cc6ba9a211af3abfbee27306","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8python%E6%A8%A1%E6%8B%9F%E4%BC%A0%E6%9F%93%E7%97%85%E6%A8%A1%E5%9E%8B/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8python%E6%A8%A1%E6%8B%9F%E4%BC%A0%E6%9F%93%E7%97%85%E6%A8%A1%E5%9E%8B/","section":"\u0008计算新闻","summary":"Doraemon：本文尝试使用python对经典传染病模型进行实现，因传染病模型研究属于传染病动力学研究方向，不是本人的工作范围，因此，本人只是将模型中的微分方程，用Python进行实现，想起到抛砖引玉的效果。来源： https://zhuanlan.zhihu.com/p/104091330\n SI模型 import scipy.integrate as spi import numpy as np import matplotlib.pyplot as plt # N为人群总数 N = 10000 # β为传染率系数 beta = 0.25 # gamma为恢复率系数 gamma = 0 # I_0为感染者的初始人数 I_0 = 1 # S_0为易感者的初始人数 S_0 = N - I_0 # T为传播时间 T = 150 # INI为初始状态下的数组 INI = (S_0,I_0) def funcSI(inivalue,_): Y = np.zeros(2) X = inivalue # 易感个体变化 Y[0] = - (beta * X[0] * X[1]) / N + gamma * X[1] # 感染个体变化 Y[1] = (beta * X[0] * X[1]) / N - gamma * X[1] return Y T_range = np.","tags":[""],"title":"使用python模拟传染病模型","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  安装pygame 首先尝试： \u0026gt; pip install pygame -i http://pypi.douban.com/simple\n如果出错，尝试 \u0026gt; pip install pygame -i http://pypi.douban.com/simple \u0026ndash;trusted-host pypi.douban.com\n下载游戏代码 https://github.com/computational-class/aircraftbattle\n推荐使用Github Desktop下载到本机，例如我放在/github/aircraftbattle文件夹当中。\n运行游戏 在terminal当中打开游戏所在文件夹（注意：根据你的本地文件所在位置）\n cd github/aircraftbattle\n 运行aircraftbattle.py\n python aircraftbattle.py\n Enjoy your game! 想要理解背后的代码 https://www.bilibili.com/video/av14184325?p=461\n#导入模块 import pygame import random from pygame.locals import * from os import path #######################################基本参数配置####################################### #获取图片库和声音库路径 img_dir = path.join(path.dirname(__file__),'pic') sound_folder = path.join(path.dirname(__file__),'sounds') #定义游戏窗口、玩家血量条尺寸，游戏运行速度、炮火持续时间等参数 WIDTH = 480 HEIGHT = 600 FPS = 60 POWERUP_TIME = 5000 BAR_LENGTH = 100 BAR_HEIGHT = 10 #定义白、黑、红、绿、蓝、黄的RGB参数 WHITE = (255, 255, 255) BLACK = (0, 0, 0) RED = (255, 0, 0) GREEN = (0, 255, 0) BLUE = (0, 0, 255) YELLOW = (255, 255, 0) #初始化pygame模块，创建游戏窗口、游戏窗口命名、创建跟踪时间对象 pygame.init() pygame.mixer.init() #初始化音效 screen = pygame.display.set_mode((WIDTH,HEIGHT)) pygame.display.set_caption(\u0026quot;Aircraft Battle\u0026quot;) clock = pygame.time.Clock() #定义文本字体 font_name = pygame.font.match_font('arial') #######################################加载图片####################################### #加载游戏进行中背景图片 background = pygame.image.load(path.join(img_dir,'starfield.png')).convert() background = pygame.transform.scale(background,(WIDTH,1536)) height = -936 #加载玩家图片 player_img = pygame.image.load(path.join(img_dir,'player.png')).convert() player_mini_img = pygame.transform.scale(player_img,(25, 19)) player_mini_img.set_colorkey(BLACK) #加载玩家炮弹、导弹图片 bullet_img = pygame.image.load(path.join(img_dir,'bullet.png')).convert() missile_img = pygame.image.load(path.join(img_dir,'missile.png')).convert_alpha() #加载敌机炮弹图片 enemies_bullet_img = pygame.image.load(path.join(img_dir,'enemies_bullet.png')).convert() #加载盾牌、闪电图片 powerup_images = {} powerup_images['shield'] = pygame.image.load(path.join(img_dir, 'shield.png')).convert() powerup_images['gun'] = pygame.image.load(path.join(img_dir, 'bolt.png')).convert() #加载敌机和火山石图片 enemies_images = [] lava_images = [] #敌机 enemies_list = [ 'enemies1.png', 'enemies2.png', 'enemies3.png' ] #火山石 lava_list = [ 'lava_med.png', 'lava_small1.png', 'lava_small2.png', 'lava_tiny.png' ] for image in enemies_list: enemies_img = pygame.image.load(path.join(img_dir,image)).convert() enemies_img = pygame.transform.scale(enemies_img,(80, 60)) enemies_images.append(enemies_img) for image in lava_list: lava_images.append(pygame.image.load(path.join(img_dir,image)).convert()) #加载爆炸图片 explosion_anim = {} explosion_anim['lg'] = [] explosion_anim['sm'] = [] explosion_anim['player'] = [] for i in range(9): #敌机、火山石爆炸 filename = 'regularExplosion0{}.png'.format(i) img = pygame.image.load(path.join(img_dir,filename)).convert() img.set_colorkey(BLACK) #大爆炸 img_lg = pygame.transform.scale(img,(75,75)) explosion_anim['lg'].append(img_lg) #小爆炸 img_sm = pygame.transform.scale(img,(32,32)) explosion_anim['sm'].append(img_sm) #玩家爆炸 filename = 'sonicExplosion0{}.png'.format(i) img = pygame.image.load(path.join(img_dir,filename)).convert() img.set_colorkey(BLACK) explosion_anim['player'].append(img) #######################################加载声音####################################### #加载炮弹、导弹发射声音 shooting_sound = pygame.mixer.Sound(path.join(sound_folder,'pew.wav')) missile_sound = pygame.mixer.Sound(path.join(sound_folder,'rocket.ogg')) #加载敌机、火山石爆炸声音 expl_sounds = [] for sound in ['expl3.wav', 'expl6.wav']: expl_sounds.append(pygame.mixer.Sound(path.join(sound_folder,sound))) #调低音量 pygame.mixer.music.set_volume(0.2) #加载玩家爆炸声音 player_die_sound = pygame.mixer.Sound(path.join(sound_folder,'rumble1.ogg')) #######################################函数区####################################### #游戏初始界面和准备开始界面函数 def main_menu(): global screen #加载游戏初始界面背景音乐 menu_song = pygame.mixer.music.load(path.join(sound_folder,\u0026quot;menu.ogg\u0026quot;)) #循环播放 pygame.mixer.music.play(-1) #加载游戏初始界面背景图片 title = pygame.image.load(path.join(img_dir,\u0026quot;main.png\u0026quot;)).convert() title = pygame.transform.scale(title,(WIDTH, HEIGHT),screen) screen.blit(title,(0,0)) pygame.display.update() #检测玩家操作事件 while True: ev = pygame.event.poll() if ev.type == pygame.KEYDOWN: if ev.key == pygame.K_RETURN: break elif ev.type == pygame.QUIT: pygame.quit() quit() else: draw_text(screen, \u0026quot;Press [ENTER] To Begin\u0026quot;, 30, WIDTH/2, HEIGHT/2) draw_text(screen, \u0026quot;[A] ← [S] ↓ [D] → [W] ↑\u0026quot;, 30, WIDTH/2, 2*HEIGHT/3) draw_text(screen, \u0026quot;[Space] fire\u0026quot;, 30, WIDTH/2, 3*HEIGHT/4) pygame.display.update() #加载准备声音 ready = pygame.mixer.Sound(path.join(sound_folder,'getready.ogg')) ready.play() #加载准备开始界面背景颜色和文本 screen.fill(BLACK) draw_text(screen, \u0026quot;GET READY!\u0026quot;, 40, WIDTH/2, HEIGHT/3) pygame.display.update() #设置文本属性函数 def draw_text(surf,text,size,x,y): #定义文本参数 font = pygame.font.Font(font_name,size) text_surface = font.render(text,True,WHITE) text_rect = text_surface.get_rect() text_rect.midtop = (x,y) surf.blit(text_surface,text_rect) #设置玩家血量条属性函数 def draw_shield_bar(surf,x,y,pct): pct = max(pct,0) fill = (pct/100)*BAR_LENGTH outline_rect = pygame.Rect(x,y,BAR_LENGTH,BAR_HEIGHT) fill_rect = pygame.Rect(x,y,fill,BAR_HEIGHT) pygame.draw.rect(surf,GREEN,fill_rect) pygame.draw.rect(surf,WHITE,outline_rect,2) #设置玩家生命数量属性函数 def draw_lives(surf,x,y,lives,img): for i in range(lives): img_rect = img.get_rect() img_rect.x = x+30*i img_rect.y = y surf.blit(img,img_rect) #添加敌机函数 def newmob(): mob_element = Mob() all_sprites.add(mob_element) mobs.add(mob_element) #添加火山石函数 def newlava(): lava_element = Lava() all_sprites.add(lava_element) lavas.add(lava_element) #######################################类区####################################### class Explosion(pygame.sprite.Sprite): '''创建爆炸类''' def __init__(self,center,size): pygame.sprite.Sprite.__init__(self) self.size = size self.image = explosion_anim[self.size][0] self.rect = self.image.get_rect() self.rect.center = center self.frame = 0 self.last_update = pygame.time.get_ticks() self.frame_rate = 75 def update(self): now = pygame.time.get_ticks() if now - self.last_update \u0026gt; self.frame_rate: self.last_update = now self.frame += 1 if self.frame == len(explosion_anim[self.size]): self.kill() else: center = self.rect.center self.image = explosion_anim[self.size][self.frame] self.rect = self.image.get_rect() self.rect.center = center class Player(pygame.sprite.Sprite): '''创建玩家类''' def __init__(self): pygame.sprite.Sprite.__init__(self) self.image = pygame.transform.scale(player_img,(50, 38)) self.image.set_colorkey(BLACK) self.rect = self.image.get_rect() self.radius = 20 self.rect.centerx = WIDTH/2 self.rect.bottom = HEIGHT-10 self.speedx = 0 self.speedy = 0 self.shield = 100 self.shoot_delay = 250 self.last_shot = pygame.time.get_ticks() self.lives = 3 self.hidden = False self.hide_timer = pygame.time.get_ticks() self.power = 1 self.power_timer = pygame.time.get_ticks() def update(self): if self.power \u0026gt;= 2 and pygame.time.get_ticks() - self.power_time \u0026gt; POWERUP_TIME: self.power -= 1 self.power_time = pygame.time.get_ticks() if self.hidden and pygame.time.get_ticks() - self.hide_timer \u0026gt; 1000: self.hidden = False self.rect.centerx = WIDTH/2 self.rect.bottom = HEIGHT-30 self.speedx = 0 self.speedy = 0 #方向控制：A控制左、D控制右、W控制上、S控制下、A+W控制左上、A+S控制左下、D+W控制右上、D+S控制右下 keystate = pygame.key.get_pressed() if keystate[K_a]: self.speedx = -5 if keystate[K_d]: self.speedx = 5 if keystate[K_w]: self.speedy = -5 if keystate[K_s]: self.speedy = 5 #发射控制：空格 if keystate[pygame.K_SPACE]: self.shoot() #设置玩家移动边界 if self.rect.right \u0026gt; WIDTH: self.rect.right = WIDTH if self.rect.left \u0026lt; 0: self.rect.left = 0 if self.rect.top \u0026lt; 10: self.rect.top = 10 if self.rect.bottom \u0026gt; HEIGHT-10: self.rect.bottom = HEIGHT-10 self.rect.x += self.speedx self.rect.y += self.speedy def shoot(self): now = pygame.time.get_ticks() if now-self.last_shot \u0026gt; self.shoot_delay: self.last_shot = now #单火力 if self.power == 1: bullet = Bullet(self.rect.centerx, self.rect.top) all_sprites.add(bullet) bullets.add(bullet) shooting_sound.play() #双火力 if self.power == 2: bullet1 = Bullet(self.rect.left, self.rect.centery) bullet2 = Bullet(self.rect.right, self.rect.centery) all_sprites.add(bullet1) all_sprites.add(bullet2) bullets.add(bullet1) bullets.add(bullet2) shooting_sound.play() #三火力 if self.power \u0026gt;= 3: bullet1 = Bullet(self.rect.left, self.rect.centery) bullet2 = Bullet(self.rect.right, self.rect.centery) missile1 = Missile(self.rect.centerx, self.rect.top) # 导弹 all_sprites.add(bullet1) all_sprites.add(bullet2) all_sprites.add(missile1) bullets.add(bullet1) bullets.add(bullet2) bullets.add(missile1) shooting_sound.play() missile_sound.play() def powerup(self): self.power += 1 self.power_time = pygame.time.get_ticks() def hide(self): self.hidden = True self.hide_timer = pygame.time.get_ticks() self.rect.center = (WIDTH/2, HEIGHT+200) class Mob(pygame.sprite.Sprite): '''创建敌机类''' def __init__(self): pygame.sprite.Sprite.__init__(self) self.image_orig = random.choice(enemies_images) self.image_orig.set_colorkey(BLACK) self.image = self.image_orig.copy() self.rect = self.image.get_rect() self.radius = int(self.rect.width*.90/2) self.rect.x = random.randrange(0, WIDTH-self.rect.width) self.rect.y = random.randrange(-150,-100) self.speedy = random.randrange(5,10) self.speedx = random.randrange(-3,3) self.shoot_delay = 1000 self.last_shot = pygame.time.get_ticks() def update(self): self.rect.x += self.speedx self.rect.y += self.speedy if random.randrange(10) \u0026gt;= 6: self.enemies_shoot() if (self.rect.top \u0026gt; HEIGHT+10) or (self.rect.left \u0026lt; -25) or (self.rect.right \u0026gt; WIDTH+20): self.rect.x = random.randrange(0,WIDTH-self.rect.width) self.rect.y = random.randrange(-100,-40) self.speedy = random.randrange(1,8) def enemies_shoot(self): now = pygame.time.get_ticks() if now-self.last_shot \u0026gt; self.shoot_delay: self.last_shot = now enemies_bullet = EnemiesBullet(self.rect.centerx, self.rect.bottom) all_sprites.add(enemies_bullet) enemies_bullets.add(enemies_bullet) shooting_sound.play() class Lava(pygame.sprite.Sprite): '''创建火山石类''' def __init__(self): pygame.sprite.Sprite.__init__(self) self.image_orig = random.choice(lava_images) self.image_orig.set_colorkey(BLACK) self.image = self.image_orig.copy() self.rect = self.image.get_rect() self.radius = int(self.rect.width*.90/2) self.rect.x = random.randrange(0, WIDTH-self.rect.width) self.rect.y = random.randrange(-150,-100) self.speedy = random.randrange(5,10) self.speedx = random.randrange(-3,3) self.rotation = 0 self.rotation_speed = random.randrange(-8, 8) self.last_update = pygame.time.get_ticks() #添加火山石旋转效果 def rotate(self): time_now = pygame.time.get_ticks() if time_now-self.last_update \u0026gt; 50: self.last_update = time_now self.rotation = (self.rotation+self.rotation_speed)%360 new_image = pygame.transform.rotate(self.image_orig,self.rotation) old_center = self.rect.center self.image = new_image self.rect = self.image.get_rect() self.rect.center = old_center def update(self): self.rotate() self.rect.x += self.speedx self.rect.y += self.speedy if (self.rect.top \u0026gt; HEIGHT+10) or (self.rect.left \u0026lt; -25) or (self.rect.right \u0026gt; WIDTH+20): self.rect.x = random.randrange(0,WIDTH-self.rect.width) self.rect.y = random.randrange(-100,-40) self.speedy = random.randrange(1,8) class Bullet(pygame.sprite.Sprite): '''创建玩家炮弹类''' def __init__(self, x, y): pygame.sprite.Sprite.__init__(self) self.image = bullet_img self.image.set_colorkey(BLACK) self.rect = self.image.get_rect() self.rect.bottom = y self.rect.centerx = x self.speedy = -10 def update(self): self.rect.y += self.speedy if self.rect.bottom \u0026lt; 0: self.kill() class EnemiesBullet(pygame.sprite.Sprite): '''创建敌机炮弹类''' def __init__(self, x, y): pygame.sprite.Sprite.__init__(self) self.image = enemies_bullet_img self.image.set_colorkey(BLACK) self.rect = self.image.get_rect() self.rect.top = y self.rect.centerx = x self.speedy = 10 def update(self): self.rect.y += self.speedy if self.rect.top \u0026gt; 600: self.kill() class Missile(pygame.sprite.Sprite): '''创建导弹类''' def __init__(self, x, y): pygame.sprite.Sprite.__init__(self) self.image = missile_img self.image.set_colorkey(BLACK) self.rect = self.image.get_rect() self.rect.bottom = y self.rect.centerx = x self.speedy = -10 def update(self): self.rect.y += self.speedy if self.rect.bottom \u0026lt; 0: self.kill() class Pow(pygame.sprite.Sprite): '''创建补给类''' def __init__(self, center): pygame.sprite.Sprite.__init__(self) self.type = random.choice(['shield', 'gun']) self.image = powerup_images[self.type] self.image.set_colorkey(BLACK) self.rect = self.image.get_rect() self.rect.center = center self.speedy = 4 def update(self): self.rect.y += self.speedy if self.rect.top \u0026gt; HEIGHT: self.kill() #######################################主循环####################################### #定义游戏开始界面标识 running = True menu_display = True while running: if menu_display: main_menu() pygame.time.wait(3000) pygame.mixer.music.stop() pygame.mixer.music.load(path.join(sound_folder,'tgfcoder-FrozenJam-SeamlessLoop.ogg')) pygame.mixer.music.play(-1) menu_display = False all_sprites = pygame.sprite.Group() player = Player() all_sprites.add(player) mobs = pygame.sprite.Group() for i in range(4): newmob() lavas = pygame.sprite.Group() for i in range(4): newlava() bullets = pygame.sprite.Group() enemies_bullets = pygame.sprite.Group() powerups = pygame.sprite.Group() score = 0 clock.tick(FPS) for event in pygame.event.get(): if event.type == pygame.QUIT: running = False if event.type == pygame.KEYDOWN: if event.key == pygame.K_ESCAPE: running = False all_sprites.update() #敌机与玩家炮弹碰撞检测 hits = pygame.sprite.groupcollide(mobs,bullets,True,True) for hit in hits: score += 50-hit.radius random.choice(expl_sounds).play() expl = Explosion(hit.rect.center,'lg') all_sprites.add(expl) if random.random() \u0026gt; 0.9: pow = Pow(hit.rect.center) all_sprites.add(pow) powerups.add(pow) newmob() #火山石与玩家炮弹碰撞检测 hits = pygame.sprite.groupcollide(lavas,bullets,True,True) for hit in hits: score += 50-hit.radius random.choice(expl_sounds).play() expl = Explosion(hit.rect.center,'lg') all_sprites.add(expl) if random.random() \u0026gt; 0.9: pow = Pow(hit.rect.center) all_sprites.add(pow) powerups.add(pow) newlava() #玩家与敌机碰撞检测 hits = pygame.sprite.spritecollide(player,mobs,True,pygame.sprite.collide_circle) for hit in hits: player.shield -= hit.radius*2 expl = Explosion(hit.rect.center,'sm') all_sprites.add(expl) newmob() if player.shield \u0026lt;= 0: player_die_sound.play() death_explosion = Explosion(player.rect.center,'player') all_sprites.add(death_explosion) player.hide() player.lives -= 1 player.shield = 100 #玩家与火山石碰撞检测 hits = pygame.sprite.spritecollide(player,lavas,True,pygame.sprite.collide_circle) for hit in hits: player.shield -= hit.radius*2 expl = Explosion(hit.rect.center,'sm') all_sprites.add(expl) newlava() if player.shield \u0026lt;= 0: player_die_sound.play() death_explosion = Explosion(player.rect.center,'player') all_sprites.add(death_explosion) player.hide() player.lives -= 1 player.shield = 100 #玩家与敌机炮弹碰撞检测 hits = pygame.sprite.spritecollide(player,enemies_bullets,True,pygame.sprite.collide_circle) for hit in hits: player.shield -= hit.radius*2 expl = Explosion(hit.rect.center,'sm') all_sprites.add(expl) if player.shield \u0026lt;= 0: player_die_sound.play() death_explosion = Explosion(player.rect.center,'player') all_sprites.add(death_explosion) player.hide() player.lives -= 1 player.shield = 100 #玩家与补给碰撞检测 hits = pygame.sprite.spritecollide(player,powerups,True) for hit in hits: if hit.type == 'shield': player.shield += random.randrange(10,30) if player.shield \u0026gt;= 100: player.shield = 100 if hit.type == 'gun': player.powerup() if player.lives == 0 and not death_explosion.alive(): pygame.time.wait(1000) screen.fill(BLACK) draw_text(screen, \u0026quot;Game Over\u0026quot;, 40, WIDTH/2, HEIGHT/3) pygame.display.update() pygame.time.wait(3000) menu_display = True #背景画卷向下滚动 screen.fill(BLACK) screen.blit(background,(0,height)) height += 2 if height \u0026gt;= -168: height = -936 all_sprites.draw(screen) draw_text(screen,str(score),18,WIDTH/2,10) draw_shield_bar(screen,5,5,player.shield) draw_lives(screen,WIDTH-100,5,player.lives,player_mini_img) pygame.display.flip() pygame.quit()  ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"b391a745068298f23f34c73767c3288a","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8python%E7%8E%A9%E9%A3%9E%E6%9C%BA%E5%A4%A7%E6%88%98%E6%B8%B8%E6%88%8F/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8python%E7%8E%A9%E9%A3%9E%E6%9C%BA%E5%A4%A7%E6%88%98%E6%B8%B8%E6%88%8F/","section":"\u0008计算新闻","summary":"安装pygame 首先尝试： \u0026gt; pip install pygame -i http://pypi.douban.com/simple\n如果出错，尝试 \u0026gt; pip install pygame -i http://pypi.douban.com/simple \u0026ndash;trusted-host pypi.douban.com\n下载游戏代码 https://github.com/computational-class/aircraftbattle\n推荐使用Github Desktop下载到本机，例如我放在/github/aircraftbattle文件夹当中。\n运行游戏 在terminal当中打开游戏所在文件夹（注意：根据你的本地文件所在位置）\n cd github/aircraftbattle\n 运行aircraftbattle.py\n python aircraftbattle.py\n Enjoy your game! 想要理解背后的代码 https://www.bilibili.com/video/av14184325?p=461\n#导入模块 import pygame import random from pygame.locals import * from os import path #######################################基本参数配置####################################### #获取图片库和声音库路径 img_dir = path.join(path.dirname(__file__),'pic') sound_folder = path.join(path.dirname(__file__),'sounds') #定义游戏窗口、玩家血量条尺寸，游戏运行速度、炮火持续时间等参数 WIDTH = 480 HEIGHT = 600 FPS = 60 POWERUP_TIME = 5000 BAR_LENGTH = 100 BAR_HEIGHT = 10 #定义白、黑、红、绿、蓝、黄的RGB参数 WHITE = (255, 255, 255) BLACK = (0, 0, 0) RED = (255, 0, 0) GREEN = (0, 255, 0) BLUE = (0, 0, 255) YELLOW = (255, 255, 0) #初始化pygame模块，创建游戏窗口、游戏窗口命名、创建跟踪时间对象 pygame.","tags":[""],"title":"使用python玩飞机大战游戏","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  百度指数是以百度海量网民行为数据为基础的数据分享平台。在这里,你可以研究关键词搜索趋势、洞察网民兴趣和需求、监测舆情动向、定位受众特征。\n我以“疫情”和“口罩”两个关键词来看新冠疫情的公众关注情况。\nhttp://index.baidu.com/v2/main/index.html#/trend/%E7%96%AB%E6%83%85?words=%E7%96%AB%E6%83%85,%E5%8F%A3%E7%BD%A9\n趋势研究 地点选择“江苏”\n简单的百度指数，也可以借助于akshare爬取。按照akshare指数数据抓取部分的介绍，百度指数分为三部分，分别是搜索指数、资讯指数、媒体指数。具体可以操作如下：\nimport akshare as ak cookie = \u0026quot;此处输入您在网页端登录百度指数后的 cookie 数据\u0026quot; index_df1 = ak.baidu_search_index(word=\u0026quot;螺纹钢\u0026quot;, start_date='2010-12-27', end_date='2019-12-01', cookie=cookie) index_df2 = ak.baidu_info_index(word=\u0026quot;螺纹钢\u0026quot;, start_date='2017-07-03', end_date='2019-12-01', cookie=cookie) index_df3 = ak.baidu_media_index(word=\u0026quot;螺纹钢\u0026quot;, start_date='2010-12-27', end_date='2019-12-01', cookie=cookie)  想要了解更多？ - akshare百度指数部分实现方式 - 云爬虫技术研究笔记\n需求图谱 人群画像 点击地图，查看江苏的情况\n阅读文献  Shuanglong Li, Yunsong Chen, Guangye He. Mapping Public Concerns About Class Immobility in China.Social Indicators Research (2019) 144:745–765. https://doi.org/10.1007/s11205-019-02075-2 Ginsberg et al. (2009) “Detecting influenza epidemics using search engine query data”, Nature, http://dx.doi.org/10.1038/nature07634 Lazer et al (2014) “The Parable of Google Flu: Traps in Big Data Analysis.” Science. http://dx.doi.org/10.1126/science.1248506 Yang et al (2015) “Accurate estimation of influenza epidemics using Google search data via ARGO”, PNAS, http://dx.doi.org/10.1073/pnas.1515373112 Lampos et al 2015 “Advances in nowcasting influenza-like illness rates using search query logs” Scientific Reports, http://dx.doi.org/10.1038/srep12760  练习 搜索一下散装江苏和苏大强是如何成名的？\nwords=疫情,口罩,散装江苏,苏大强,江苏\n问题 请搜索城市级别的数据，回答江苏的哪一个城市更关注散装江苏？哪一个城市最关注苏大强？\n","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"721ce04896ec12a75c8d85e61e45f6b4","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8%E7%99%BE%E5%BA%A6%E6%8C%87%E6%95%B0%E4%BA%86%E8%A7%A3%E5%88%86%E7%9C%81%E5%92%8C%E5%9F%8E%E5%B8%82%E7%9A%84%E7%A4%BE%E4%BC%9A%E4%BA%8B%E4%BB%B6/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E4%BD%BF%E7%94%A8%E7%99%BE%E5%BA%A6%E6%8C%87%E6%95%B0%E4%BA%86%E8%A7%A3%E5%88%86%E7%9C%81%E5%92%8C%E5%9F%8E%E5%B8%82%E7%9A%84%E7%A4%BE%E4%BC%9A%E4%BA%8B%E4%BB%B6/","section":"\u0008计算新闻","summary":" ","tags":[""],"title":"使用百度指数了解\u0008社会事件","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":" 已有 24688 次阅读 2020-1-24 08:44 |系统分类:科研笔记\n有人已经注意到了海外研究团队基于现有公开数据对武汉当地感染武汉肺炎的实际人数进行估计。目前影响比较大，大家讨论比较多的分析报告主要有两个来源：\n 一是Alessandro Vespignani教授领衔的西北大学研究组的系列报告[1]， 二是以一个帝国理工的日本妹子（Natsuko Imai博士）为第一作者的系列报告[2]。为了方便，后文称为帝国理工报告和西北大学报告。Estimating the potential total number of novel Coronavirus in Wuhan City, China  两个报告采用的数据都是公开报道的武汉出境人员被确诊感染2019-nCoV的记录，但使用的方法有所不同。但是两个报告的结论惊人一致。 1. 帝国理工报告认为武汉全市在2020年1月18日左右差不多开始出现症状的2019-nCoV实际感染人数约为4000人，不确定性是1000-9700（通过参数敏感性分析得到的）； 2. 西北大学报告认为武汉全市在2020年1月20日左右2019-nCoV实际感染人数约为4050人，95%置信区间为1700-7950。估计这两天随着越南等地新确诊病例的出现，武汉感染人数的估计值还会上升。\n两个系列报告所使用的数据其实否非常简单（他们暂未获得或者暂未使用国内传播的数据，可能是因为传播路径太复杂），就是经由国际航班出境，且在境外被确诊的2019-nCoV感染人数。但两者使用的方法不太一样。下面我尽可能用科普的方法介绍两种方法的基本思路，并分析现有方法存在的缺陷。\n帝国理工报告的方法非常简单。Imai团队列出了一个简单的关系：\n 境外确诊的病人数 = 武汉总感染人数 * 武汉人每天坐飞机出境的概率 * 可以供武汉感染者出境且在境外才被发现的时间窗口长度（天数）。\n 只需要更新海外确诊病人数量，就可以估计武汉的实际病人数量。感兴趣的同学可以试一下：自己动手估计一下\noversea_num = range(100) wuhan_num = [19000000*i/(10*3301) for i in oversea_range] plt.plot(oversea_num, wuhan_num, color = 'darkblue', marker = '.') plt.title('帝国理工估计方法') plt.xlabel('海外确诊数') plt.ylabel('武汉实际患病人数') plt.show()  其中，可以供武汉感染者出境且在境外才被发现的时间窗口长度（天数）就是染病潜伏未出现症状的时期（Imai等人认为是5-6天，是用的SARS[3]和MERS[4]的结果）以及出现症状到医院确诊的时期（Imai等人认为是4-5天，这个时合理的，因为防控早期，感冒发热不影响出境，大家也不当回事儿），大约为10天。武汉人每天做飞机出境的概率就用武汉每天国际航班出境人数除以武汉国际机场覆盖的人口数。\nImai小组用武汉总人口（含流动人口）1900万作为武汉国际机场能够覆盖的人口数（有那么多人如果出国会选择从武汉国际机场出去），武汉国际机场出境游客平均每天3301人，截止1月21日下午4点，境外确诊病例7例（泰国3，日本1，韩国1，台湾1，美国1）。如果记武汉总人数为N，就有了一个显然的关系\n7=N*10*3301/19000000， 得到 N = (19000000*7)/(10*3301)=4029\n可以解出N=4029——这就是4000这个约数的来源。\n西北大学小组的方法要复杂得多，一般而言，这个方法也更为有效和精确。他们已经在过去的研究中 - 构建了一个全球人口分布以及不同区域之间流动性和可导致感染的接触强度的一个大型数据库 - 其中全球被分为3300个区域，任意两个区域之间的流动性数据都有，人口数据主要来源于一个国际合作项目（按0.25*0.25经纬度，大约25km*25km把世界划分成若干区域，估计这个区域的人口数）[5]。 - 这套数据加上他们成熟的传染病模型已经成功用于很多真实疾病传播早期的态势感知和发展预测，效果很好。其中整体的计算框架和方法可以参考文献[6]。\n就目前这个2019-nCoV武汉感染人数估计的问题，他们把*境外已经确诊的人数*作为证据D，*武汉待估计的感染人数*为N，则可应用贝叶斯定理：\n$$P(N)P(D|N)=P(D)P(N|D)$$\n我们要估计的就是P(N|D)，既给定境外确诊人数，武汉感染人数大概多少（证据D被认为是确定的，例如1月18日D为3个人感染，1月21日D为7个人感染）。\nVespignani小组对N进行抽样，做大量实验（模型中先假设武汉已经有了多少感染人数，再看P(D|N)的值，抽样时N从给定的P(N)里面按概率取）。\n 尽管帝国理工报告和西北大学报告所使用的方法不同，但是得到的结论是惊人一致的！\n 这两个报告存在的共同问题就是数据样本太小，因此估计的不确定区间特别大。因为样本特别小，还有可能存在系统性误差，例如可能喜欢吃野味的人更喜欢出境游。\n从方法细节来讲，帝国理工小组因为没有自己的全球疾病接触紧密度数据库，所以用平均出境人数，而没有具体到去泰国、去日本、去美国等等地方的人数，会存在偏差。西北大学的数据更新不太及时，不一定能够抓住春节前中国游客出行的一些阵发特性。\n 有没有更好的数据呢？有，已有更好数据，还在协调汇总。 是否可以通过国内的感染情况做更精确的估计呢？可以。 有没有人在做呢？有，不止一个团队。 大约什么结果呢？现在不好说。 帝国理工和西北大学报告的结果有没有参考价值呢？有！  虽然我不懂也没有看到病毒学方面的详细报导，但是我个人感觉2019-nCoV致病能力低于SARS——病的进程较缓慢，严重程度较低，致死率较低，但传播能力超过了SARS——有更长的无症状和轻微症状时期，且接触传染能力（各种接触方式和接触强度下被感染的概率）和基本再生数（R0，疾病爆发初期平均一个人能够感染的人数）应该不会低于SARS。对于病毒而言，这是进化了，不是弱化了，因为它们如果有知，应该目的不是杀死人而是传染更多的人。\n我的建议是我们大家平时要戴口罩、勤洗手、少出门、不聚会，遇到疑似问题要及时报告。\n必须要把这次武汉肺炎看作一次比SARS还厉害的对手来对付[7]。\n如果我们应对不充分，武汉肺炎将成为肆虐神州大地几十年甚至更长时间的常规性传染病，我们的下一代、再下一代、再再下一代都会一次次感染这个病。\n[1] M. Chinazzi, et al., Series Reports Entitled “Preliminary assessment of the International Spreading Risk Associated with the 2019 novel Coronavirus (2019-nCoV) outbreak in Wuhan City”.\n[2] N. Imai, et al., Series Reports Entitled “Estimating the potential total number of novel Coronavirus in Wuhan City, China”.\n[3] C. A. Donnelly, et al., Epidemiological determinants of spreading of causal agent of severe acute respiratory syndrome in Hong Kong, Lancet 361 (2003) 1761-1766.\n[4] S. Cauchemez, et al., Middle Esat respiratory syndrome coronavirus, Lancet Infect. Dis. 14 (2014) 50-56.\n[5] The Gridded Population Project, see database from the website: sedac.ciesin.columbia.edu.\n[6] D. Balcan, et al., Modeling the spreading of infectious diseases, Journal of Computational Science 1 (2010) 132-145.\n[7] Editorials, Stop the Wuhan coronavirus, Nature 577 (2020) 450.\n本文来自周涛科学网博客。链接地址：http://blog.sciencenet.cn/blog-3075-1215424.html\n","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"fbf630f9f4dcf4e70fa19b882ce19c87","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E5%B8%9D%E5%9B%BD%E7%90%86%E5%B7%A5%E5%92%8C%E8%A5%BF%E5%8C%97%E5%A4%A7%E5%AD%A6%E7%9A%84%E6%A8%A1%E5%9E%8B/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E5%B8%9D%E5%9B%BD%E7%90%86%E5%B7%A5%E5%92%8C%E8%A5%BF%E5%8C%97%E5%A4%A7%E5%AD%A6%E7%9A%84%E6%A8%A1%E5%9E%8B/","section":"\u0008计算新闻","summary":" ","tags":[""],"title":"帝国理工和西北大学估算武汉实际感染人数的模型","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  import akshare as ak import pylab as plt import numpy as np plt.style.use('fivethirtyeight') epidemic_hist_all_df = ak.epidemic_hist_all() df = ak.epidemic_163(indicator=\u0026quot;历史\u0026quot;) df.head()  获取每日新增数量\nalist = df['confirm'].tolist() daily_conf = [] for k, i in enumerate(alist): if k == 0: daily_conf.append(i) if k \u0026gt; 0: daily_conf.append(i - alist[k-1]) df['confirm_daily'] = daily_conf  获取微博指数数据\ndf_index = ak.weibo_index(word=\u0026quot;疫情\u0026quot;, time_type=\u0026quot;3month\u0026quot;) df_index.head()  合并数据\ndat = df_index.merge(df, how='inner', left_index = True, right_index = True ) dat.head()  plt.figure(figsize=(12, 6), dpi = 200) plt.plot(dat.index, dat['confirm_daily'], label = '每日新增确诊数量') plt.plot(dat.index, dat['疫情']/10000, label = '“疫情”微博指数/10000') #plt.yscale('log') plt.legend(fontsize = 20) plt.show()  画一下二者的散点图\nplt.plot(dat['疫情'], dat['confirm_daily'], 'ro') plt.xscale('log') plt.yscale('log') plt.xlabel('“疫情”微博指数/10000', fontsize = 20) plt.ylabel('每日新增确诊数量', fontsize = 20) plt.show()  算一下相关\nnp.corrcoef(dat['疫情'], dat['confirm_daily']) # 0.2384777  思考 🤔 如果没有2月12日的数据剧增会怎样？\n","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"6c5131f53c438c8747b13eb15d67367a","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E5%BE%AE%E5%8D%9A%E8%AE%A8%E8%AE%BA%E5%92%8C2019ncov%E7%96%AB%E6%83%85%E6%9C%89%E5%A4%9A%E5%A4%A7%E5%85%B3%E7%B3%BB/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E5%BE%AE%E5%8D%9A%E8%AE%A8%E8%AE%BA%E5%92%8C2019ncov%E7%96%AB%E6%83%85%E6%9C%89%E5%A4%9A%E5%A4%A7%E5%85%B3%E7%B3%BB/","section":"\u0008计算新闻","summary":"import akshare as ak import pylab as plt import numpy as np plt.style.use('fivethirtyeight') epidemic_hist_all_df = ak.epidemic_hist_all() df = ak.epidemic_163(indicator=\u0026quot;历史\u0026quot;) df.head()  获取每日新增数量\nalist = df['confirm'].tolist() daily_conf = [] for k, i in enumerate(alist): if k == 0: daily_conf.append(i) if k \u0026gt; 0: daily_conf.append(i - alist[k-1]) df['confirm_daily'] = daily_conf  获取微博指数数据\ndf_index = ak.weibo_index(word=\u0026quot;疫情\u0026quot;, time_type=\u0026quot;3month\u0026quot;) df_index.head()  合并数据\ndat = df_index.merge(df, how='inner', left_index = True, right_index = True ) dat.","tags":[""],"title":"微博讨论与covid19疫情的\u0008关联","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  问题 RQ: 舆论事件热度对新冠肺炎新增确诊数量有影响吗？\n数据 我们使用知微事见的数据来理解这一研究问题。 知微事见,专注于热点事件、企业危机事件、营销事件的研究与分析。当事件符合下列标准之一时，将被收录至知微事见事件库中：1.在短时间内达到高传播量的事件；2.在长期内都保持一定传播量的事件；3.在网络社交媒体中引起热议的事件。\n 1.什么是事件影响力指数？事件影响力指数（Event Influence Index，EII）是基于全网的社交媒体和网络媒体数据，用来刻画单一事件在互联网上的传播效果的权威指标。指数的计算数据来自全网的社交媒体和网络媒体数据。事件影响力指数是根据事件在社交媒体（以微博、微信为主）和网络媒体上的传播效果进行加和，加和后的事件影响力再通过归一化运算得到范围在0 ~ 100之间的事件影响力指数。\n 可以看到新冠肺炎依然占据舆论热点。\n我们使用的数据来自针对新冠肺炎事件脉络的梳理：http://xgml.zhiweidata.net/?from=floating#/\n数据读取和可视化 import pylab as plt import pandas as pd import seaborn as sns import json j = json.load(open('zhiwei_line.json')) df = pd.DataFrame(j) df.tail()  查看一下数据基本类型：\ndf.info()  RangeIndex: 52 entries, 0 to 51 Data columns (total 5 columns): # Column Non-Null Count Dtype\n0 time 52 non-null object 1 voice 52 non-null object 2 heat 52 non-null object 3 case 52 non-null object 4 allCase 52 non-null object dtypes: object(5) memory usage: 2.2+ KB\n结果发现都是object，未能被正确识别。\n# 将object转化为数值型的类型 df['heat'] = [float(i) for i in df['heat']] df['case'] = [int(i) for i in df['case']]  双y坐标轴可视化 # 双y坐标轴可视化 fig = plt.figure(figsize=(12,6),dpi = 200) plt.style.use('fivethirtyeight') ax1=fig.add_subplot(111) ax1.plot(df['time'], df['heat'], 'r-s') ax1.set_ylabel('舆论热度', fontsize = 16) ax1.tick_params(axis='x', rotation=60) ax1.legend(('舆论热度',),loc='upper left') ax2=ax1.twinx() ax2.plot(df['time'], df['case'], 'g-o') ax2.set_ylabel('新增确诊', fontsize = 16) ax2.legend(('新增确诊',),loc='upper right') plt.show()  格兰杰检验 接下来进行格兰杰因果检验。\nThe Null hypothesis for grangercausalitytests.\nH0: the time series in the second column, x2, does NOT Granger cause the time series in the first column, x1.\n Grange causality means that past values of x2 have a statistically significant effect on the current value of x1, taking past values of x1 into account as regressors. We reject the null hypothesis that x2 does not Granger cause x1 if the pvalues are below a desired size of the test.\n import statsmodels.api as sm from statsmodels.tsa.stattools import grangercausalitytests import numpy as np data = df[21:][['case','heat' ]].pct_change().dropna() data.plot();  gc_res = grangercausalitytests(data,4)  Granger Causality number of lags (no zero) 1 ssr based F test: F=0.0800 , p=0.7796 , df_denom=26, df_num=1 ssr based chi2 test: chi2=0.0892 , p=0.7652 , df=1 likelihood ratio test: chi2=0.0891 , p=0.7653 , df=1 parameter F test: F=0.0800 , p=0.7796 , df_denom=26, df_num=1\nGranger Causality number of lags (no zero) 2 ssr based F test: F=7.5340 , p=0.0030 , df_denom=23, df_num=2 ssr based chi2 test: chi2=18.3436 , p=0.0001 , df=2 likelihood ratio test: chi2=14.1086 , p=0.0009 , df=2 parameter F test: F=7.5340 , p=0.0030 , df_denom=23, df_num=2\nGranger Causality number of lags (no zero) 3 ssr based F test: F=13.4029 , p=0.0001 , df_denom=20, df_num=3 ssr based chi2 test: chi2=54.2818 , p=0.0000 , df=3 likelihood ratio test: chi2=29.7563 , p=0.0000 , df=3 parameter F test: F=13.4029 , p=0.0001 , df_denom=20, df_num=3\nGranger Causality number of lags (no zero) 4 ssr based F test: F=8.8419 , p=0.0005 , df_denom=17, df_num=4 ssr based chi2 test: chi2=54.0915 , p=0.0000 , df=4 likelihood ratio test: chi2=29.2519 , p=0.0000 , df=4 parameter F test: F=8.8419 , p=0.0005 , df_denom=17, df_num=4\n结论 舆论热度可以显著地导致新冠肺炎的确诊数量。\n练习 请使用格兰杰检验看一下反过来的问题：RQ2: 新冠肺炎确诊数量是否可以导致舆论热度？\n思考 🤔 Question: 这是伪相关吗？为什么？不了解伪相关，看这几个例子🌰 http://www.tylervigen.com/spurious-correlations\n延伸  Bertram Scheufele, Alexander Haas, Hans-Bernd Brosius （2011）Mirror or Molder? A Study of Media Coverage, Stock Prices, and Trading Volumes in Germany. Journal of Communication, Volume 61, Issue 1, February 2011, Pages 48–70. PDF   This article investigates the short‐term relationship between media coverage, stock prices, and trading volumes of eight listed German companies. A content analysis of news reports about the selected companies and a secondary analysis of the daily changes in closing prices and the trading volumes of these companies were combined in a time‐series design. After ARIMA‐modeling each of them, the results suggest that media coverage rather reflects than shapes the development at stock exchanges from a short‐term perspective (2 months). There were almost no hints for a widespread media effect, that is, an impact on so many investors that it will result in a measurable change in stock prices or trading volumes. Finally, theoretical and methodological consequences for exploring widespread media effects are discussed.\n ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"d2bae549f836217342de157d3900daef","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E8%88%86%E8%AE%BA%E4%BA%8B%E4%BB%B6%E7%83%AD%E5%BA%A6%E5%AF%B9%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E%E6%96%B0%E5%A2%9E%E7%A1%AE%E8%AF%8A%E6%95%B0%E9%87%8F%E6%9C%89%E5%BD%B1%E5%93%8D%E5%90%97/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E8%88%86%E8%AE%BA%E4%BA%8B%E4%BB%B6%E7%83%AD%E5%BA%A6%E5%AF%B9%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E%E6%96%B0%E5%A2%9E%E7%A1%AE%E8%AF%8A%E6%95%B0%E9%87%8F%E6%9C%89%E5%BD%B1%E5%93%8D%E5%90%97/","section":"\u0008计算新闻","summary":" ","tags":[""],"title":"舆论热点预测疫情感染？","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":"  这是南京大学《数据新闻》班级的作品展示，很多东西是半成品，欢迎提意见！\n 苏格拉底说：了解你自己！\n 疫情如火  2019年底，围绕武汉市为核心爆发了新型冠状病毒肺炎疫情。 2020年1月20日，国家卫健委高级别专家组组长、中国工程院院士、呼吸病学专家钟南山说“肯定‘人传人’。” 来源：财新网 陈宝成    钟南山表示，判断依据就是目前的资料。他在接受央视《新闻一加一》采访时也举例称，在广东有两个病例没有去过武汉，但他们的家人去了武汉，回到家里，这两个家庭都有人染上了新型冠状病毒。经过基因病毒的检测，是一致的。因此“现在可以说，肯定有人传人现象。”\n  武汉封城\n   自2020年1月23日10时起，全市城市公交、地铁、轮渡、长途客运暂停运营；无特殊原因，市民不要离开武汉，机场、火车站离汉通道暂时关闭。恢复时间另行通告。更多信息\n  返程复工  数据来源 不断更新当中：\n 澎湃 839-Studio\n Noval-Coronavirus-763-Cases Novel-Coronavirus-Updates  fivethirtyeight/data\n  为什么选择简书？ 1. Markdown的支持 import pandas ad pd print('hello world')  2. 数学公式 $$E = MC^2$$\n3. 直接粘贴图片 更重要的是：同学们觉得知乎账号太隐私了，不适合分享个人做的东西！Orz 为师震惊了。\n学生分组 武汉加油 ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"34f7159f13ad1a835893c50c7f6481d2","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB%E5%9C%A8%E8%A1%8C%E5%8A%A8/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB%E5%9C%A8%E8%A1%8C%E5%8A%A8/","section":"\u0008计算新闻","summary":"  这是南京大学《数据新闻》班级的作品展示，很多东西是半成品，欢迎提意见！\n 苏格拉底说：了解你自己！\n 疫情如火  2019年底，围绕武汉市为核心爆发了新型冠状病毒肺炎疫情。 2020年1月20日，国家卫健委高级别专家组组长、中国工程院院士、呼吸病学专家钟南山说“肯定‘人传人’。” 来源：财新网 陈宝成    钟南山表示，判断依据就是目前的资料。他在接受央视《新闻一加一》采访时也举例称，在广东有两个病例没有去过武汉，但他们的家人去了武汉，回到家里，这两个家庭都有人染上了新型冠状病毒。经过基因病毒的检测，是一致的。因此“现在可以说，肯定有人传人现象。”\n  武汉封城\n   自2020年1月23日10时起，全市城市公交、地铁、轮渡、长途客运暂停运营；无特殊原因，市民不要离开武汉，机场、火车站离汉通道暂时关闭。恢复时间另行通告。更多信息\n  返程复工  数据来源 不断更新当中：\n 澎湃 839-Studio\n Noval-Coronavirus-763-Cases Novel-Coronavirus-Updates  fivethirtyeight/data\n  为什么选择简书？ 1. Markdown的支持 import pandas ad pd print('hello world')  2. 数学公式 $$E = MC^2$$\n3. 直接粘贴图片 更重要的是：同学们觉得知乎账号太隐私了，不适合分享个人做的东西！Orz 为师震惊了。\n学生分组 武汉加油 ","tags":[""],"title":"计算新闻在行动","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":" http://h5.oeeee.com/h5/v20/nCovTimeline/\n","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581552000,"objectID":"55aeaf6f33b822a9a78bd7943587b963","permalink":"https://chengjunwang.com/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E8%AE%B0%E7%96%AB%E4%B8%80%E4%B8%AA%E5%BE%88%E6%A3%92%E7%9A%84%E6%95%B0%E6%8D%AE%E6%96%B0%E9%97%BB%E4%BD%9C%E5%93%81/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/%E8%AE%A1%E7%AE%97%E6%96%B0%E9%97%BB/%E8%AE%B0%E7%96%AB%E4%B8%80%E4%B8%AA%E5%BE%88%E6%A3%92%E7%9A%84%E6%95%B0%E6%8D%AE%E6%96%B0%E9%97%BB%E4%BD%9C%E5%93%81/","section":"\u0008计算新闻","summary":"http://h5.oeeee.com/h5/v20/nCovTimeline/","tags":[""],"title":"记疫：一个数据新闻作品","type":"\u0008计算新闻"},{"authors":null,"categories":null,"content":" 王成军，传播学博士，现为南京大学新闻传播学院副教授，计算传播学实验中心主任。他的研究兴趣主要集中于采用计算社会科学的研究方法分析人类传播问题，具体包括信息扩散、注意力流动、未来就业。其论文发表在SSCI/SCI索引的期刊, 如Scientific Reports, PloS ONE, Physica A, Cyberpsychology和Telematics and Informatics。\n联系方式  南京大学新闻传播学院, 计算传播学实验中心. 中国\u0008江苏省南京市栖霞区仙林大道163号南京大学（仙林校区）新闻传播学院450 (210023). 电子邮箱: wangchj04 at gmail.com ORCID: 0000-0002-9507-2888  教育经历  2010\u0026frasl;09-2014/10，香港城市大学，媒体与传播系，博士 2008\u0026frasl;09-2010/06，北京大学，新闻与传播学院，硕士 2004\u0026frasl;09-2008/06，兰州大学，新闻与传播学院，学士  工作经历  2019\u0026frasl;01-现在，南京大学新闻传播学院计算传播学实验中心，主任 2018\u0026frasl;07-现在，中国新闻史学会计算传播学研究委员会，秘书长 2017\u0026frasl;12-现在， 南京大学新闻传播学院，副教授 2014\u0026frasl;11-2017/12，南京大学新闻传播学院，助理研究员 2015\u0026frasl;03-2019/01，南京大学新闻传播学院计算传播学实验中心，副主任 2010/9月-现在，香港城市大学互联网挖掘实验室，研究成员  研究项目  中国博士后科学基金面上项目（第57批),2015M571722, 找回失落的参考群体：对“沉默的螺旋”进行多主体建模，2015/01-2018\u0026frasl;01, 5万元，主持 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015/07-2018\u0026frasl;12, 20万元，主持 互联网上的集体注意力流研究，国家自然科学基金（常规面上项目），61673070，2017/01-2020\u0026frasl;12,￥655200, 参与  期刊论文 * 代表通讯作者\n Xu H, Zhang Z, Wu L*, Wang C.J. * (2019) The Cinderella Complex: Word embeddings reveal gender stereotypes in movies and books. PLoS ONE 14(11): e0225385. doi:10.1371/journal.pone.0225385 Wang, C.J. * , Zhu, J.J.H.(2019) Jumping onto the Bandwagon of Collective Gatekeepers: Testing the Bandwagon Effect of Information Diffusion on Social News Website, Telematics and Informatics. 41:34-45, doi:10.1016/j.tele.2019.03.001 Wang, C.J., Wu, L*, Zhang, J., Janssen, M. (2016) The Collective Direction of Attention Diffusion. Scientific Reports. 6: 34059. doi:10.1038/srep34059 Wu, L., Wang, C.J. * (2016) Tracing the Attention of Moving Citizens. Scientific Reports. 6, 33103. doi: 10.1038/srep33103 Wang, C.J., Wu, L.*(2016) The Scaling of Attention Networks. Physica A: Statistical Mechanics and its Applications.448:196–204, doi: 10.1016/j.physa.2015.12.081 Chandra, Y.*, Jiang, C.L., Wang, C.J. (2016) Mining Social Entrepreneurship Strategies Using Topic Modeling, PLOS ONE, 11(3):e0151342, doi: 10.1371/journal.pone.0151342 Jiang, C.L*, Yang, M, Wang, C.J. (2017) Self-Disclosure to Parents in Emerging Adulthood: Examining the Roles of Perceived Parental Responsiveness and Separation-Individuation. Journal of Social and Personal Relationships. 34(4): 425-445. doi: 10.1177 /0265407516640603 Wang, C.J. *, Wang, P.P, Zhu, J.J.H (2013). Discussing Occupy Wall Street on Twitter: Longitudinal network analysis of equality, emotion, and stability of public discussion. Cyberpsychology, Behavior, and Social Networking, 16(9): 679-685. doi:10.1089/cyber.2012.0409. [SSCI, Ranking 4\u0026frasl;72 in Communication by 5-year IF]. 王成军，党明辉，杜骏飞 (2019) 找回失落的参考群体:对沉默的螺旋理论的边界条件的考察. 新闻大学. 156:13-29. （入选人大复印资料新闻与传播2019年第8期） 王成军 (2017).计算社会科学视野下的新闻学研究：挑战与机遇. 新闻大学, 4:26-32. （入选人大复印资料新闻与传播2017年第10期） 杜骏飞, 曲飞帆, 王成军（2016）2015年中国新闻传播学论著评析. 新闻与传播研究，12:108-119. 张晓雨,王成军 *(2016)数据可视化报道在数据新闻中的实践——以《卫报》和财新网为例.中国网络传播研究.(01):283-308. 陈志聪,秦强,王成军 *(2016)作为社会动员过程的互联网众筹公益——以腾讯乐捐为例.中国网络传播研究.(01):173-190. 王成军 (2016) 大数据计算与《纸牌屋》生成. 传媒评论. 5:63-66. 王成军 (2016) 计算传播学的起源、概念与应用. 编辑学刊,3:59-64. 王成军（2015）计算传播学: 作为计算社会科学的传播学.中国网络传播研究,8:193-208. 王成军（2015）“今日头条”的技术逻辑: 网络爬虫+矩阵筛选.传媒评论,10:34-37. 祝建华,彭泰权,梁海,王成军,秦洁,陈鹤鑫 (2014) 计算社会科学在新闻传播研究中的应用. 科研信息化技术与应用. 5 (2), 3-13 王成军,刘德寰,杨旭 (2011) 从自我实现到群体互动——“人肉搜索”的动机、态度和行为研究,中国传媒报告，10(02):63-73. 王成军,刘德寰 (2011) 移動的時尚: 追求時尚與手機互聯網的使用，香港《传媒透视》, (07):12-15. 王成军,张昕之 (2011) “众说纷纭”抑或“一言九鼎”？——以卡扎菲官邸攻陷事件在新浪微博上的信息扩散为例，香港《传媒透视》, (09):12-13.  会议论文  Zhi-Cong Chen, Lingfei Wu, Naipeng Chao, Cheng-Jun Wang * (2018) The Poor Read for Entertainment and the Rich Read for Education: Poverty, Fragmentation, and Knowledge Homogeneity. Poster to be presented at The 4th Annual International Conference on Computational Social Science (ic2s2), July 12–15, 2018. Evanston, Illinois, United States. Hui-Min Xu, Zhi-Cong Chen, Cheng-Jun Wang * (2018) Social Classes Shapes Our Trajectories in Both Online and Offline Space. Paper To be presented at The 4th Annual International Conference on Computational Social Science (ic2s2), July 12–15, 2018. Evanston, Illinois, United States. Wang, C.J. (2017) networkdiffusion: Simulating and Visualizing Network Diffusion Using R. The 10th China R Conference. Beijing, May 20-21. Slides. Wang, C.J. Zhang, X. (2017) Analyzing Mobile Phone Data With Network Science. The 67th Annual Conference of International Communication Association (ICA), San Diego, USA, May 27, 2017. Wang, C.J. (2015). Information diffusion on Microblogs: Testing the threshold hypothesis of interpersonal effects. Conference on Complex System (CCS\u0026rsquo;15), Tempe, Arizona, USA. Sep 28-Oct 2. Wang, C.J., Chen, H.X., Zhang, X.(2015) The Landscape of Information Diffusion on Sina Weibo: Investigating the Rich-Club Effect. Paper to be presented to the 65th Annual Conference of International Communication Association (ICA), San Juan, Puerto Rico, 21-25 May 2015. Lingfei Wu, Jiang Zhang, Marco Janssen, Cheng-Jun Wang, Min Zhao (2014). Attention Balls. The 6th International Conference on Social Informatics. Barcelona, 10-13 November 2014. Wang, C.J. (2014). The Origin of Bursts in Public Attention: The Temporality Hypothesis for the Diffusion of YouTube Videos. Paper to be presented to the 64th Annual Conference of International Communication Association (ICA), Seattle, Washington, USA. May 22-26. Wang, C.J, Chen, H.X (2013). Social selection or social influence: Network analysis of information flow within the Rich-club of Sina Weibo. Paper to be presented to the annual conference of International Association for Media and Communication Research (IAMCR), Dublin, Ireland, June 25-29. Wang, C.J, Liu, J. (2013). Looking for the signposts on the web: Clickstream analysis of the flow of public attention. Paper to be presented to the 63rd Annual Conference of International Communication Association (ICA), London, UK, June 17-21. Wang, P.P, Wang, C.J (2013). Rational information sharing or emotional expression in the online discussion: How does leadership spark conversations and trigger feedbacks. Paper to be presented to the 63rd Annual Conference of International Communication Association (ICA), London, UK, June 17-21. Wang, C.J. (2012). The origin of Bursts in public attention: Peak fraction, popularity, diffusion channels, and categories of YouTube videos. Paper presented at Honours Symposium for Asian Ph.D Students in Communication Research, Seoul, Korea, Oct 27-28. Wang, C.J., Wang, P.P (2012). Discussing Occupying Wall Street on Twitter: Longitudinal network analysis of equality, emotion, and stability. Paper to be presented to the 65th Annual Conference of World Association for Public Opinion Research (WAPOR), Hong Kong, June 14-16. Wang, C.J., Peng, T.Q (2012). Evaluating public discussion of Occupying Wall Street on Twitter: Linking Twitter streams with search quires, opinion polls, media coverage, and stock market index. Paper to be presented to the 65th Annual Conference of World Association for Public Opinion Research (WAPOR), Hong Kong, June 14-16. Wang, C.J. (2012). Jumping over the network threshold: How widespread could news diffuse on news sharing websites? Paper to be presented to the 62nd Annual Conference of International Communication Association (ICA), Phonix, Arizona, May 24-28. Wang, C.J., Wang, P.P (2012). Does the unkown information matter for online daters. Paper to be presented to the 62nd Annual Conference of International Communication Association (ICA), Phonix, Arizona, May 24-28. Wu, L.F., Wang,C.J. (2011). Heterogeneity and allometric growth of human collaborative tagging behavior. Poster session presented at The 7th Chinese Conference of Complex Networks (CCCN’11), Chengdu, China, October 21-24. Wang, C.J.(2011).The emergence of spiral of silence from individual behaviors: Agent-based modeling of the spiral of silence. Paper presented at The 64th Annual Conference of the World Association for Public Opinion Research (WAPOR), Amsterdam, The Netherlands, September 21-23. Wang, C.J.(2011).Surfing mobile Internet motivated by fashion attentiveness: An empirical study of China mobile Internet use. Paper presented at International Telecommunications Society Asia-Pacific Regional Conference (ITS), Taibei, Taiwan, June 26-29.  工作坊  王成军 (2019) \u0008社会科学家的机器学习.2019年计算传播学年会工作坊，中山大学，中国广州.12月7日。视频\u0008链接 Wang, C.J.(2014) Web Data Analysis. City University of Hong Kong, Department of Media and Communication. The Web Mining Workshop. 4.22-4.25 Wang, C.J.(2013) The Way to Computational Communication (通往计算传播学之路). Department of Journalism and Communication, Shenzhen University. Jan 4th. Wang, C.J.(2012) Jumping over Network Threshold: News Diffusion on News Sharing Website. The seminar of IR and Friends. Commonwealth Scientific and Industrial Research Organisation (CSIRO), Australia National University, Canberra. May 14.  图书、\u0008翻译和述评  \u0008张伦、王成军、许小可（2018）《计算传播学导论》. 北京：北京师范大学出版社. 王成军、吴令飞 (2017) 空间约束的人类行为. 胡泳、王俊秀（编）《连接之后: 公共空间重建与权力再分配》.北京:人民邮电出版社. pp. 262-271 许小可、胡海波、张伦、王成军 （2015）《社交网络上的计算传播学》. 北京：高等教育出版社. 王薇、王成军、王颖、刘璟 （翻译）(2013). 《社会网络分析：方法与实践》. 北京：机械工业出版社. 王成军 (2012, Aug 17). 爆发：人类行为在时间尺度上的特征. 中国科学报, 06. 王成军 (2012, Jul 03). 人类 90%的行为是可以预测的. 中国图书商报, 1857.  教学  数据科学Python编程基础 数据新闻 大数据挖掘与分析  社会服务 作为\u0008匿名审稿人为以下期刊评审论文：\n International Journal of Public Opinion Research (IJPOR) Computers in Human Behavior (CHB) Journal of the Association for Information Science and Technology (JASIST) Communication Methods and Measures (CMM) The Annual Conference of International Communication Association (ICA). 《新闻与传播研究》 《新闻大学》  我参加的学术组织包括：\n Complex System Society (CSS) International Communication Association (ICA) World Association of Public Opinion Research (WAPOR) International Telecommunications Society (ITS)  软件开发  flownetwork, 一个分析流网络的Python包. iching,一个实现易经的蓍草卜卦方法的Python包. networkdiffusion, 一个可视化和模拟网络信息扩散的R包 scholarNetwork,一个抓取和可视化谷歌学术（Google Scholars）合作者网络的Python包.  可视化项目  中国新闻地图 全球恐怖袭击  ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"2c74b1f46070d4512e5990b4e61b9c01","permalink":"https://chengjunwang.com/zh/cv/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/zh/cv/","section":"zh","summary":"王成军，传播学博士，现为南京大学新闻传播学院副教授，计算传播学实验中心主任。他的研究兴趣主要集中于采用计算社会科学的研究方法分析人类传播问题，具体包括信息扩散、注意力流动、未来就业。其论文发表在SSCI/SCI索引的期刊, 如Scientific Reports, PloS ONE, Physica A, Cyberpsychology和Telematics and Informatics。\n联系方式  南京大学新闻传播学院, 计算传播学实验中心. 中国\u0008江苏省南京市栖霞区仙林大道163号南京大学（仙林校区）新闻传播学院450 (210023). 电子邮箱: wangchj04 at gmail.com ORCID: 0000-0002-9507-2888  教育经历  2010\u0026frasl;09-2014/10，香港城市大学，媒体与传播系，博士 2008\u0026frasl;09-2010/06，北京大学，新闻与传播学院，硕士 2004\u0026frasl;09-2008/06，兰州大学，新闻与传播学院，学士  工作经历  2019\u0026frasl;01-现在，南京大学新闻传播学院计算传播学实验中心，主任 2018\u0026frasl;07-现在，中国新闻史学会计算传播学研究委员会，秘书长 2017\u0026frasl;12-现在， 南京大学新闻传播学院，副教授 2014\u0026frasl;11-2017/12，南京大学新闻传播学院，助理研究员 2015\u0026frasl;03-2019/01，南京大学新闻传播学院计算传播学实验中心，副主任 2010/9月-现在，香港城市大学互联网挖掘实验室，研究成员  研究项目  中国博士后科学基金面上项目（第57批),2015M571722, 找回失落的参考群体：对“沉默的螺旋”进行多主体建模，2015/01-2018\u0026frasl;01, 5万元，主持 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015/07-2018\u0026frasl;12, 20万元，主持 互联网上的集体注意力流研究，国家自然科学基金（常规面上项目），61673070，2017/01-2020\u0026frasl;12,￥655200, 参与  期刊论文 * 代表通讯作者\n Xu H, Zhang Z, Wu L*, Wang C.J. * (2019) The Cinderella Complex: Word embeddings reveal gender stereotypes in movies and books.","tags":null,"title":"王成军","type":"zh"},{"authors":["Huimin Xu","Zhang Zhang","Lingfei Wu","*Cheng-Jun Wang*"],"categories":null,"content":" Citation  Xu H, Zhang Z, Wu L*, Wang C.J. * (2019) The Cinderella Complex: Word embeddings reveal gender stereotypes in movies and books. PLoS ONE 14(11): e0225385. doi:10.1371/journal.pone.0225385\n You can also find the manuscript of arXiv from this link https://arxiv.org/pdf/1811.04599.pdf.\nData Availability The data underlying the results presented in the study are available from IMDB website (www.imdb.com), IMSDB website (www.imsdb.com), and the Gutenberg Project (www.gutenberg.org). All the code and processed data are available from https://github.com/xuhuimin2017/storyshape/\nClaims The rich literature on gender stereotypes points out the assumptions to explore in identifying and quantifying stereotypical narrative structures, including\n 1) The emotional dependency of females on males. Men and women have different social imagines. Men are agentic, and women are communal [19,29,30]; men are active, whereas women are passive; men give, and women take in relationships [29–31]. These biased images of men and women lead to biased expectations in their relationships. Those who consider women less competent would tend to believe that they are fragile and sensitive and need to be protected by men [19,32]. Following this literature, we propose to test the emotional dependency of females on males [33]; 2) Men act and women appear. The English novelist John Berger [34] used this quote to describe the male-female dichotomy. Considering the stereotypical role and traits of men, one would imagine men are more likely than women to be described using verbs; 3) Social endorsement of gender stereotypes. The social and cultural roots of gender stereotypes form social force against stereotype disconfirmation from people, action, or ideas [19]. In this sense, the stories that approve gender stereotypes will gain social approval themselves, whereas the stories against stereotypes will be ignored and disapproved. Our study will test this assumption by connecting the frame of stories with their social acceptance.   We firstly construct a vector representing the dimension of happy versus unhappy from pre-trained word vectors using Google News data [17]. The distance from this vector to other word vectors represents the “happiness score” of the corresponding words. The average of “happiness scores” over the timeline of stories quantifies their shape. Moreover, by controlling the window size to analyze only the words surrounding specific names, we can track the “happiness scores” of different characters. Using these techniques, we find that in the movie synopsis of Cinderella, the happiness of Ella (Cinderella) depends on Kit (Prince) but not vice versa. This finding supports the “Cinderella complex” [18], a narrative structure enhancing the stereotypical incompetence of women. Applying our analysis to 6,087 movie synopses, 1,109 movie scripts, and 7,226 books, we observe the vast existence of this narrative structure. Our review of the words surrounding characters unpack their stereotypical life packages; the lives of males are adventure-oriented, whereas the lives of females are romantic-relationship oriented. Finally, we reveal the social endorsement of gender stereotypes by identifying the association between the strength of gender stereotypes in movie synopses and the IMDB ratings to the analyzed movies.\n Fig 1. The Cinderella complex. a, Visualizing the sentiment landscape of the movie synopsis of Cinderella as a skyline (a black outline is added to enhance the “skyline”metaphor visually). We show sentences in a vertical schema, colored by their “happiness score”—green for happy and red for unhappy and the transparency represents the scale of the scores. Filled squares (orange for Ella and blue for Kit) indicate the co-occurrence of Ella (Cinderella) and Kit (the Prince) in the same sentence. Hollow squares indicate where only one character appears: b, The happiness curves of Ella (orange) and Kit (blue). The grey dotted lines marks the sentences in which they co-occur, corresponding to the filled squares in Panel a. We fit the increase or decrease in happiness scores across successive co-occurrences with OLS regression (see Methods for more information). Thick lines show the estimates of regression.\nOur analysis of the words surrounding female and male characters shows that the lives of males are adventure-oriented, whereas the lives of females are romantic-relationship oriented. Finally, we demonstrate the social endorsement of gender stereotypes by showing that gender-stereotypical movies are voted more frequently and rated higher.\n","date":1573689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573689600,"objectID":"9739232b80ea6a06bb801be882d4fd7b","permalink":"https://chengjunwang.com/publication/storytelling/","publishdate":"2019-11-14T00:00:00Z","relpermalink":"/publication/storytelling/","section":"publication","summary":"Using the word embedding techniques, we reveal the constructed emotional dependency of female characters on male characters in stories. We call this narrative structure “Cinderella complex,” which assumes that women depend on men in the pursuit of a happy, fulfilling life. Our analysis covers a substantial portion of narratives that shape the modern collective memory, including 7,226 books, 6,087 movie synopses, and 1,109 movie scripts. The “Cinderella complex” is observed to exist widely across periods and contexts, reminding how gender stereotypes are deeply rooted in our society.","tags":null,"title":"The Cinderella complex: Word embeddings reveal gender stereotypes in movies and books","type":"publication"},{"authors":null,"categories":null,"content":"\u0008word统计字数，加上空格为16万字。\n1． 版面字数 ﹦ 电脑统计字数×1.2＋图片折合版面字数；\n16*1.2 = 19.2\n","date":1573473600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573473600,"objectID":"33dde229c4b2e04495237ce72691622c","permalink":"https://chengjunwang.com/note/2019-11-16-diffusion-book/","publishdate":"2019-11-11T12:00:00Z","relpermalink":"/note/2019-11-16-diffusion-book/","section":"note","summary":" ","tags":["专著","出版社"],"title":"《跨越网络的门槛》图书出版计划","type":"note"},{"authors":null,"categories":null,"content":"YouTube Playlist for the 2019 Summer Institute in Computational Social Science\n本课程需要各组同学帮助完成一个视频下载任务，这个视频列表是Matthew J. Salganik 2019年的一个暑期课程，https://compsocialscience.github.io/summer-institute/2019/ ， Salganik还非常热心地写了一本开源书叫Bit By Bit: Social Research in the Digital Age https://www.bitbybitbook.com/ 。这个视频播放列表涵盖了暑期课的基本内容，简明地介绍了计算社会科学的基础知识，与我们的这门课程紧密相关。我们的课程侧重于编程操作，对于研究设计和背后的思考介绍的不够充分，Salganik的工作是一个很好的补充。\n可惜这个课程发布在youtube上，国内无法看到。我自己下载速度太慢，按照Salganik的idea，这种工作适合于采用mass collaboration来完成，因此我厚着脸皮给大家分配这个任务。\n   Thumbnail Title Duration Quality Format Download      1  SICSS 2019 \u0026ndash; Introduction to computational social science 00:37:39 720P mp4 Download   2  SICSS 2019 \u0026ndash; Why SICSS? 00:25:31 720P mp4 Download   3  SICSS 2019 \u0026ndash; Ethics: A principles based approach 00:55:27 720P mp4 Download   4  SICSS 2019 \u0026ndash; Ethical challenges 00:30:59 720P mp4 Download   5  SICSS 2019 \u0026ndash; Day 1 group exercise 00:04:10 720P mp4 Download   6  SICSS 2019 \u0026ndash; What is digital trace data? 00:08:48 360P mp4 Download   7  SICSS 2019 \u0026ndash; Strengths and weakness of digital trace data 00:43:22 360P mp4 Download   8  SICSS 2019 \u0026ndash; Screen scraping 00:39:04 360P mp4 Download   9  SICSS 2019 \u0026ndash; Application programming interfaces 01:03:46 720P mp4 Download   10  SICSS 2019 \u0026ndash; Building apps and bots for social science research 00:25:25 360P mp4 Download   11  SICSS 2019 \u0026ndash; Beth Noveck 01:28:21 720P mp4 Download   12  SICSS 2019 \u0026ndash; History of quantitative text analysis 00:09:37 360P mp4 Download   13  SICSS 2019 \u0026ndash; Basic text analysis with grep 00:44:09 360P mp4 Download   14  SICSS 2019 \u0026ndash; Topic models 01:05:19 360P mp4 Download   15  SICSS 2019 \u0026ndash; Dictionary-based text analysis 00:23:28 360P mp4 Download   16  SICSS 2019 \u0026ndash; Text networks 00:19:32 360P mp4 Download   17  SICSS 2019 \u0026ndash; Survey research in the digital age 00:31:19 360P mp4 Download   18  SICSS 2019 \u0026ndash; Probability and non probability sampling 00:42:25 360P mp4 Download   19  SICSS 2019 \u0026ndash; Computer administered interviews and wiki surveys 00:34:13 360P mp4 Download   20  SICSS 2019 \u0026ndash; Combining surveys and big data 00:17:42 360P mp4 Download   21  SICSS 2019 \u0026ndash; Day 4 group exercise 00:22:48 360P mp4 Download   22  SICSS 2019 \u0026ndash; Justin Grimmer 01:20:34 360P mp4 Download   23  SICSS 2019 \u0026ndash; Mass collaboration 00:41:09 360P mp4 Download   24  SICSS 2019 \u0026ndash; The Fragile Families Challenge 00:55:11 360P mp4 Download   25  SICSS 2019 \u0026ndash; Participating in the Fragile Families Challenge 00:38:59 360P mp4 Download   26  SICSS 2019 \u0026ndash; Annie Liang 01:33:58 360P mp4 Download   27  SICSS 2019 \u0026ndash; What, why, and which experiments? 00:10:48 360P mp4 Download   28  SICSS 2019 \u0026ndash; Moving beyond simple experiments 00:27:11 360P mp4 Download   29  SICSS 2019 \u0026ndash; Four strategies for making experiments happen 00:12:30 360P mp4 Download   30  SICSS 2019 \u0026ndash; Zero variable cost data 00:40:16 360P mp4 Download   31  SICSS 2019 \u0026ndash; Abdullah Almaatouq 01:05:56 360P mp4 Download   32  SICSS 2019 \u0026ndash; Eric Schwartz 01:16:09 720P mp4 Download   33  SICSS 2019 \u0026ndash; Chris Wiggins 01:23:17 360P mp4 Download   34  SICSS 2019 \u0026ndash; Jobs in Computational Social Science 01:32:40 720P mp4 Download    iTubeGo Video Downloader\n下载视频任务\nhttps://chengjunwang.com/post/en/2019-11-09-css-videos/\n点击download即可下载\n MF1911080 张嘉婵 MF1911082 张路路 MF1911083 张婷婷 MG1911001 陈帅彤  视频1-3\n 徐璐瑶 MG1911035 任洁 MF1911052 吴琪琦MF1911065 郭心仪MG1911017  视频 4-6\n MF1911002 安秋阳 MF1911066 吴秋恩 MF1911064 吴莉  视频7-9\n 郑梦欣MF1911090 赵雨瑶MF1911089 周详 MF1911094  视频10-12\n 林彦妍 MF1911038 林鸿MF1911036 蔺彦旭MF1911039  视频 13-15\n 兀梦婕 MF1911068 吴晓俊 MF1911067 周恩培 MF1911091 视频 16-18\n 刘艺MF1911042 秦浛嫣MF1911051 卢冰雪MF1911045 罗阳奇MG1911009\n  视频 19-21\n 韩柳柳 MF1911021 赵楠 MF1911088 张翼 MF1911086 视频 22-24\n 杨凡 MF1911072 杨璧全MF1911071 夏雨欣 MF1911069 视频 25-27\n 李媛媛 MG1911021 卢林艳MG1911024 张馨文MF1911084 卢功靖MG1911007 视频 28-30\n MF1911081 张洁 MF1911095 周震洋 赵启南 MG1811037\n  视频 31-32\n MF1911023 季谦 MF1911070 谢志宏 MF1911018 顾觐皓 MF1911034 李源  视频 33-34\n","date":1573171200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573171200,"objectID":"a5fb43bdd9365cde42f5b6f01ae10ed2","permalink":"https://chengjunwang.com/post/en/2019-11-09-css-videos/","publishdate":"2019-11-08T00:00:00Z","relpermalink":"/post/en/2019-11-09-css-videos/","section":"post","summary":"YouTube Playlist for the 2019 Summer Institute in Computational Social Science\n","tags":["\u0008CSS"],"title":"YouTube Playlist for the 2019 Summer Institute in Computational Social Science","type":"post"},{"authors":["Wang, C.J"],"categories":null,"content":"My ebook Elements of Computational Communication (In Chinese 《计算传播基础讲义》） is now available online, enjoy! https://chengjunwang.com/mybook. It is based on two related master courses:\n https://github.com/computational-class/bigdata https://github.com/computational-class/cjc  ","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"13ea820b0f9ea95a84977e7c5d40f107","permalink":"https://chengjunwang.com/publication/ccbook/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/ccbook/","section":"publication","summary":"My ebook Elements of Computational Communication (In Chinese 《计算传播基础讲义》）is now [available online](http://chengjunwang.com/mybook/), enjoy! ","tags":null,"title":"Elements of Computational Communication","type":"publication"},{"authors":null,"categories":null,"content":"   Journal Data Filtered By: Selected JCR Year: 2018 Selected Editions: SSCI Selected Categories: \u0026lsquo;COMMUNICATION\u0026rsquo; Selected Category Scheme: WoS         Rank Full Journal Title Total Cites Journal Impact Factor Eigenfactor Score   1 Journal of Computer-Mediated Communication 4,671 4.896 0.005040   2 NEW MEDIA \u0026amp; SOCIETY 5,972 4.800 0.009920   3 POLITICAL COMMUNICATION 2,464 4.339 0.004020   4 Information Communication \u0026amp; Society 3,911 4.124 0.007910   5 JOURNAL OF COMMUNICATION 7,883 3.753 0.007950   6 HUMAN COMMUNICATION RESEARCH 3,463 3.534 0.002480   7 JOURNAL OF ADVERTISING 4,143 3.518 0.002410   8 COMMUNICATION THEORY 2,440 3.395 0.002440   9 Comunicar 1,367 3.338 0.000760   10 PUBLIC OPINION QUARTERLY 6,139 3.310 0.005130   11 COMMUNICATION RESEARCH 4,400 3.087 0.004410   12 International Journal of Press-Politics 946 3.000 0.002190   13 PUBLIC UNDERSTANDING OF SCIENCE 2,704 2.754 0.003630   14 MEDIA PSYCHOLOGY 1,626 2.736 0.001780   15 Journalism 2,068 2.691 0.003390   16 Digital Journalism 1,066 2.679 0.003090   17 Environmental Communication-A Journal of Nature and Culture 884 2.469 0.001320   18 COMMUNICATION MONOGRAPHS 2,770 2.365 0.001510   19 Mobile Media \u0026amp; Communication 347 2.333 0.001280   20 Communication Methods and Measures 714 2.306 0.000960   21 SCIENCE COMMUNICATION 1,254 2.302 0.001890   22 International Journal of Advertising 1,653 2.234 0.001410   23 Journalism Studies 2,226 2.233 0.003220   24 Mass Communication and Society 1,431 2.189 0.001920   25 Journal of Public Relations Research 1,447 2.125 0.001110   26 Journalism Practice 1,461 2.124 0.002740   27 Feminist Media Studies 1,103 2.042 0.002380   28 JOURNALISM \u0026amp; MASS COMMUNICATION QUARTERLY 2,045 2.030 0.002110   29 EUROPEAN JOURNAL OF COMMUNICATION 1,283 2.015 0.001920   30 TELECOMMUNICATIONS POLICY 1,801 2.000 0.002070   31 JOURNAL OF ADVERTISING RESEARCH 2,741 1.969 0.001130   32 RESEARCH ON LANGUAGE AND SOCIAL INTERACTION 1,324 1.956 0.001680   33 Policy and Internet 468 1.927 0.001200   34 JOURNAL OF BROADCASTING \u0026amp; ELECTRONIC MEDIA 2,230 1.917 0.001890   35 MEDIA CULTURE \u0026amp; SOCIETY 2,290 1.886 0.003330   36 HEALTH COMMUNICATION 3,135 1.846 0.005480   37 JOURNAL OF HEALTH COMMUNICATION 4,290 1.773 0.007670   38 DISCOURSE STUDIES 1,337 1.678 0.001510   38 JOURNAL OF SOCIAL AND PERSONAL RELATIONSHIPS 3,550 1.678 0.003050   40 PUBLIC RELATIONS REVIEW 3,512 1.616 0.002290   41 Convergence-The International Journal of Research into New Media Technologies 651 1.607 0.000960   42 Games and Culture 714 1.574 0.000580   43 Journal of Media Psychology-Theories Methods and Applications 410 1.514 0.000760   44 Profesional de la Informacion 878 1.505 0.000790   45 INTERNATIONAL JOURNAL OF PUBLIC OPINION RESEARCH 1,295 1.484 0.002200   46 Journal of Children and Media 451 1.388 0.001100   47 Argumentation 583 1.300 0.000400   48 International Journal of Business Communication 100 1.293 0.000260   49 LANGUAGE \u0026amp; COMMUNICATION 1,179 1.292 0.001390   50 CRITICAL STUDIES IN MEDIA COMMUNICATION 645 1.267 0.000930   51 Television \u0026amp; New Media 617 1.245 0.001070   52 DISCOURSE \u0026amp; SOCIETY 1,910 1.237 0.001470   53 Communication \u0026amp; Sport 304 1.220 0.000690   54 WRITTEN COMMUNICATION 960 1.219 0.000630   55 INTERNATIONAL JOURNAL OF CONFLICT MANAGEMENT 899 1.196 0.000530   56 Management Communication Quarterly 1,311 1.193 0.000980   57 Interaction Studies 419 1.150 0.000420   58 IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION 562 1.143 0.000540   59 Asian Journal of Communication 554 1.097 0.000840   60 PERSONAL RELATIONSHIPS 2,231 1.096 0.001740   61 International Journal of Communication 2,401 1.069 0.006520   62 Chinese Journal of Communication 228 1.064 0.000470   63 JOURNAL OF APPLIED COMMUNICATION RESEARCH 1,054 1.033 0.000870   64 JOURNAL OF LANGUAGE AND SOCIAL PSYCHOLOGY 1,448 1.014 0.001460   65 Critical Discourse Studies 479 0.984 0.000880   66 Discourse \u0026amp; Communication 437 0.983 0.000740   67 Journal of Media Ethics 330 0.967 0.000280   68 Rhetoric Society Quarterly 373 0.956 0.000230   69 Communication and Critical-Cultural Studies 353 0.953 0.000670   70 International Communication Gazette 696 0.944 0.000880   71 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION 369 0.900 0.000400   72 JAVNOST-THE PUBLIC 334 0.860 0.000540   73 Discourse Context \u0026amp; Media 286 0.815 0.000640   74 Visual Communication 455 0.767 0.000550   75 QUARTERLY JOURNAL OF SPEECH 996 0.758 0.000410   76 Translator 455 0.744 0.000450   77 Media International Australia 445 0.713 0.000660   78 Communications-European Journal of Communication Research 470 0.707 0.000490   79 Social Semiotics 550 0.704 0.000920   80 TECHNICAL COMMUNICATION 433 0.657 0.000180   81 Communication Culture \u0026amp; Critique 324 0.653 0.000700   82 NARRATIVE INQUIRY 496 0.514 0.000300   83 Continuum-Journal of Media \u0026amp; Cultural Studies 712 0.486 0.000840   84 JOURNAL OF MEDIA ECONOMICS 242 0.417 0.000230   85 Text \u0026amp; Talk 451 0.400 0.000670   86 African Journalism Studies 36 0.347 0.000160   87 Journal of African Media Studies 85 0.309 0.000210   88 Tijdschrift voor Communicatiewetenschap 45 0.086 0.000070    ","date":1562803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562803200,"objectID":"13758622f61dab7eb1159e50b7bbffbe","permalink":"https://chengjunwang.com/post/en/2019-07-11-jcr/","publishdate":"2019-07-11T00:00:00Z","relpermalink":"/post/en/2019-07-11-jcr/","section":"post","summary":"Journal   Data Filtered By:  Selected JCR Year:   2018 Selected Editions: SSCI Selected Categories: 'COMMUNICATION' Selected   Category Scheme: WoS.\n","tags":["JCR"],"title":"Journal Citation Report 2019 for Communication Journals","type":"post"},{"authors":["Cheng-Jun Wang*","Jonathan J.H. Zhu"],"categories":null,"content":" Jumping onto the Bandwagon of Collective Gatekeepers: Testing the Bandwagon Effect of Information Diffusion on Social News Website\nCheng-Jun Wang $ ^{a,b}$ * , Jonathan J.H. Zhu ${^b}$\n$^a$ Computational Communication Collaboratory, School of Journalism and Communication, Nanjing University, Nanjing, China\n$^b$ Web Mining Lab, Department of Media and Communication, City University of Hong Kong, Hong Kong, China\nKeywords Information Diffusion; Collective Gatekeeping; Interpersonal Effects; Bandwagon Effects; Threshold Model\nThe results demonstrate that the bandwagon of collective gatekeepers is the primary driver for online news diffusion. Interestingly, the bandwagon effect of collective gatekeeping is moderated by the strength of interpersonal effects. The theoretical generalizations of this research contribute to our understanding about the impact of collective gatekeeping on information diffusion.\nHighlights  Drawing on threshold models to capture the interpersonal effects and collective gatekeeping, we test our hypothesis with two novel datasets of information diffusion on social media. The findings demonstrate that both bandwagon effect and interpersonal effect play important roles in collective gatekeeping on social media. The bandwagon of collective gatekeepers is the primary driver for online news diffusion The bandwagon effect of collective gatekeeping is moderated by the strength of interpersonal effects.  Telematics and Informatics\n Received at Editorial Office 2 Jul 2018 Article 3rd revised 19 Feb 2019 Article accepted for publication 3 Mar 2019  Please cite this article as:\n Wang, C-J. * , Zhu, J.J.H.(2019) Jumping onto the Bandwagon of Collective Gatekeepers: Testing the Bandwagon Effect of Information Diffusion on Social News Website, Telematics and Informatics. 41:34-45, doi: https://doi.org/10.1016/j.tele.2019.03.001\n ","date":1551622856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551622856,"objectID":"acca80ba3f25b4490dc98d044960de5b","permalink":"https://chengjunwang.com/publication/bandwagon/","publishdate":"2019-03-03T22:20:56+08:00","relpermalink":"/publication/bandwagon/","section":"publication","summary":"Based on collaborative information filtering and information aggregation services, the social news website carries out a collective gatekeeping function, supplying an empirical ground to test the bandwagon effect on information diffusion. Modeling the interpersonal effect and bandwagon effect in collective gatekeeping with threshold models, we confirm the bandwagon effect of collective gatekeeping on news diffusion with two novel datasets. ","tags":null,"title":"Jumping onto the Bandwagon of Collective Gatekeepers: Testing the Bandwagon Effect of Information Diffusion on Social News Website","type":"publication"},{"authors":null,"categories":null,"content":" 2019年来了，农历新年过去了，今天是情人节。米粒马上四岁，米果也快要满两岁了。再过两年，\u0008牛年一到，我也要36岁了。岁月太可怕了，总以为自己还有很多时间，却似乎一转眼就要40岁了。\n今天一早，我搭晓青公司的车去驾校，晓青去合肥出差。\n鲜花折纸 很漂亮的月季花折纸,简单易学,看了就会的手工DIY花朵\n我和米粒搜索了半天，这个方法最为简单。\n 但是\u0008，因为没有粉红色的纸，我们首先用水墨的颜料将白色便签纸染成粉红。 要严格按照上图的步骤来，前三步最关键。否则，容易把花朵🌺剪成两半！ 然后，按照图纸一番折腾，终于得到如下图的一朵粉红色的小花。  \u0008学开车 另外，晓青强行给我在手机app上预约了三天的驾驶科目三的课程。今天谷峰驾校第一天开课，我一早8点就找到了教练。结果，驾校开会从8：30到10点多。然后，就开始练习。\n科目三考试内容\nDay 1 2月14日\n 首先，上车  从车前方走过  练习打方向盘\n 向左打到底1.5圈   然后，练习启动和停车四步骤。\n 比如，启动的顺序是：  \u0008一踩脚刹 二挂前进挡D1 三打转向灯 四松手刹 （*注意：颠倒三、四步车会前溜，因为手刹挡不住动力系统*） 最后\u0008，松脚刹，踩油门前进。  停车与之相反：  一拉手刹 二停转向灯 三挂停车挡 四松脚刹   直行\n 目视前方30米处 在不影响驾驶的情况下，\u0008观察左、\u0008右后视镜 根据路的弯度，非常轻微转动方向盘  变线\n \u0008首先，打转向灯 其次，后视镜观察\u0008，确保可以转向 如果可以转向，三秒后轻打方向盘（非常小角度）转向 转向后，扶正方向盘  右转\n \u0008确保车子在右转向\u0008道 \u0008看到倒数第二个减速标志，轻踩刹车 看到倒数最后一个减速标志，刹车停住 左顾右盼：左右转头，观察人行横道 观察红绿灯，允许转向时才可以转 根据转向角度，打方向盘，随时调整 只有当\u0008车子方向正了之后，才完全回正方向盘  （左）掉头\n 减速 车头偏向中间\u0008花坛 当肩膀与路中间花坛平行时，继续前进3-4米 向左打死方向盘 脚放刹车 左顾右盼 \u0008\u0008掉头后，只有当\u0008车子方向正了之后，才完全回正方向盘   轻点刹车\n 手刹\n   手刹的专业称呼是辅助制动器，采用钢丝拉线连接到后制动蹄上，以对车子进行制动。手刹对于小型汽车来说，有的是在变速箱后，与传动轴连接的地方有一个制动盘，类似盘式制动器的（当然也有鼓式的），然后通过钢索，将拉力传动到那，从而实现驻车制动。拉动手刹后，它利用一个液压辅缸，推动车下边的液压总缸运动，然后带动气阀，（之所以这么设计，是为了驾驶室不听到那些空气的声音），然后气阀动作之后，制动传动轴。\n ","date":1550016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550016000,"objectID":"913bb0aecaa07b45a00a4b61181d73b5","permalink":"https://chengjunwang.com/zh/cn/2019-02-14-lovers-day.zh/","publishdate":"2019-02-13T00:00:00Z","relpermalink":"/zh/cn/2019-02-14-lovers-day.zh/","section":"zh","summary":"2019年来了，农历新年过去了。米粒马上四岁，米果也快要满两岁了。再过两年，\u0008牛年一到，我也要36岁了。岁月太可怕了，总以为自己还有很多时间，却似乎一转眼就要40岁了。今天是情人节，晓青出差，我去驾校。\n","tags":["news"],"title":"学折纸、学开车","type":"zh"},{"authors":["王成军"],"categories":null,"content":"[Abstract] The purpose of this study is threefold: first, to bring reference groups back into the framework of spiral of silence (SOS) by proposing an integrated framework of dual opinion climate; second, to investigate the boundary conditions of SOS; third, to identify the characteristics of SOS in terms of spatial variation and temporal evolution. Modeling SOS with agent-based models, the findings suggest that there is no guarantee of SOS with reference groups being brought back; the stable existence of SOS is contingent upon the comparative strength of mass media over reference groups; SOS is size-dependent upon reference groups and the population; the growth rate of SOS decreases over time. Thus, this research presents an extension of the SOS theory.\n[Key Words] spiral of silence; agent-based model; reference group; size-dependent; computational communication research\n引用: 王成军，党明辉，杜骏飞 (2019) 找回失落的参考群体:对沉默的螺旋理论的边界条件的考察. 新闻大学. 156:13-29. http://mall.cnki.net/magazine/Article/XWDX201904005.htm （入选人大复印资料新闻与传播2019年第8期）\n","date":1546313629,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546313629,"objectID":"9502404df7ac9cb53c9284d3bf70b034","permalink":"https://chengjunwang.com/publication/abm-sos/","publishdate":"2019-01-01T11:33:49+08:00","relpermalink":"/publication/abm-sos/","section":"publication","summary":"本文以双重意见气候作为研究沉默的螺旋理论的框架，采用多主体建模的方法，将参考群体重新引入对沉默的螺旋的研究当中，重新考察了沉默的螺旋理论的边界条件，并分析了沉默的螺旋在不同的区域和时间中的差异。研究发现：在引进参考群体的情况下不能确保沉默的螺旋必然出现；沉默的螺旋效果是否能够稳定地出现要视大众媒体对其参考群体的影响力大小而定；沉默的螺旋效果的大小依赖于参考群体规模以及社区总人口规模，其演化受个体的空间分布的影响，而其增长率随着时间递减。","tags":null,"title":"找回失落的参考群体：对沉默的螺旋理论的边界条件的考察","type":"publication"},{"authors":null,"categories":null,"content":"第三届中国系统科学大会拟于2019年5月18-19日在湖南长沙举行。大会由上海系统科学研究院主办,国防科技大学承办,中国科学院数学与系统科学研究院系统科学研究所、北京师范大学系统科学学院、北京交通大学交通系统科学与工程研究院、中国船舶工业系统工程研究院、中国系统工程学会、中国自动化学会控制理论专业委员会等单位协办。旨在为系统科学及其相关领域的国内外专家学者提供一个学术交流平台，促进相关学科的交流、发展和融合，促进新方向、新领域的产生。会议将采取大会报告、专题研讨、会前专题讲座、分组报告等形式进行交流。 http://iss.amss.cas.cn/cssc2019/zwtz/\n 2019系统科学大会邀请组组织者，请提交一个不超过500字的邀请组申请书，并附拟邀请报告人的姓名、单位、联系信息等。每个邀请组须由8-10位报告人组成。详情参见：http://cms.amss.ac.cn。\n 人类和疾病的传播行为之所以难以理解主要的原因在于其中卷入了海量的异质性的个体及其相互之间的互动，而复杂系统和网络科学为理解人类\u0008\u0008信息扩散和疾病传播提供了丰富的理论视角。人类的存在无往不在各种复杂系统当中，包括但不限于社会系统、经济系统、通信系统、交通系统、生态系统等。基于数字媒体等方式可以从复杂系统当中收集的海量数据，而大数据技术和人工智能的发展则为理解各种传播现象提供了丰富的计算方法。面对纷繁复杂的重要问题，收集大规模数据，采用计算机科学的算法挖掘和分析背后的模式，采用数据科学、系统科学的视角构建模型则为我们理解模式背后的机制提供了更多的可能性。\n狭义的计算传播是指数据驱动的、借助于可算方法所进行的传播过程，而分析计算传播现象的研究领域就是计算传播学。计算传播学主要关注人类传播行为可计算的基础问题，以传播网络分析、传播文本挖掘、数据科学等作为主要的分析工具，大规模地收集并分析人类和疾病传播行为背后的模式或法则，并分析模式背后的生成机制以及基本原理。为了更好地理解疾病扩散、假新闻的传播等计算传播问题，我们提议在系统科学年会中组织计算传播分论坛，邀请相关领域的研究者对（包括但不限于）以下研究领域进行探讨：\n 复杂系统当中的传播现象的计算基础是什么？其本身是否可以计算？是否可预测？ 计算传播如何推动大问题、大理论、大数据的融合？如何帮助我们理解复杂的人类群体行为？ 计算方法在计算传播研究中的应用。 计算传播的实践或者商业价值  ","date":1544054400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544054400,"objectID":"dc3413efd7f58b20eebd46b2f540006d","permalink":"https://chengjunwang.com/zh/cn/2018-12-07-ccr-panel.zh/","publishdate":"2018-12-06T00:00:00Z","relpermalink":"/zh/cn/2018-12-07-ccr-panel.zh/","section":"zh","summary":"人类和疾病的传播行为之所以难以理解主要的原因在于其中卷入了海量的异质性的个体及其相互之间的互动，而复杂系统和网络科学为理解人类\u0008\u0008信息扩散和疾病传播提供了丰富的理论视角。\n","tags":["news"],"title":"2019系统科学大会的计算传播学Panel","type":"zh"},{"authors":["张伦","王成军","许小可"],"categories":null,"content":" 《计算传播学导论》\n 作者: 张伦 / 王成军 / 许小可 出版社: 北京师范大学出版社 出版年: 2018-9 页数: 239 装帧: 平装 ISBN: 9787303241200   新书发布！[号外] 11月20号入库发货！《计算传播学导论》终于在当当预售了，（点下面传媒学术网公号里的链接或者直接在当当搜索“计算传播学”）～ 通过预售链接购买（有折扣哦！)。本书里总结了我们这几年在相关课程或讲习班的主要教学经验。还有很多不完善的地方，教学相长，不断改进吧。\n \u0026laquo;Introduction to Computational Communication\u0026raquo; (In Chinese 计算传播学导论) now available on dangdang.com for pre-order! http://product.dangdang.com/25581097.html\nWith the development of digital media, data-driven journalism, computational advertising, and media recommendation systems become a worldwide trend. At the same time, machine learning, as well as data science have made a big leap forward. Put together, all of these factors discussed above speed up the tide of computational communication research.\n二十一世纪是计算社会科学的时代。1998年邓肯·瓦茨关于小世界网络的模型和1999年阿尔伯特·巴拉巴西关于幂律和无标度网络的研究复兴了网络科学。一石激起千层浪，在学术领域产生了深远的影响。对于万维网上的人类行为的研究也形成了一个子领域，被称之为万维网科学(Web Science)；伴随着社交媒体等数字媒体的发展，社会网络分析开始受到前所未有的重视，社交网络上的信息流动网络研究也引起广泛的兴趣；与此同时，机器学习和数据科学取得了突飞猛进的发展，进一步加速了计算化的浪潮；在新闻传播产业当中，数据驱动的新闻生产、计算广告和媒体推荐系统开始成为席卷世界的潮流。面对海量的互联网数据、持续困扰人类的重大社会问题、崭新的理论视角、诱人的物理学模型，在世界大战中发展起来的新闻传播学研究会走向什么地方？这构成了困扰我们的时代问题，而计算传播学正是试图回应这一时代叩问的一种尝试。在大数据和人工智能时代，未来的计算社会科学家更需要训练问题意识、培养计算思维、增强数据挖掘和分析的能力，而这正是本书写作的一个重要目的。\n计算传播学将传播学研究置于数据和计算方法的坚固基础上。数据作为一种新的石油，解放了社会科学家对于理论的过度依赖。随着数字媒体的发展，人类社会积累的人类传播行为数据的规模日趋庞大，详尽地记录了社会发展和人类互动的各种细节。运用这些生动的人类传播行为数据，可以从更细的颗粒度、更大的样本规模上让我们捕捉社会的发展。毫无疑问，对于数据的挖掘依赖于人类的计算能力的提高，依赖于跨学科的研究方法和研究视角。我们人类传播行为的基因恰恰隐藏在互动性当中，但这种人类传播行为的互动性本身也使得传播过程充满了复杂性。网络科学为捕捉到纷繁复杂的人类互动提供了一个很好的视角。从数据出发，借助于计算方法和好的理论视角，就可以更好地刻画人类传播行为的模式和法则。\n目标读者  致力于进行“计算社会科学” 研究的本科生与研究生 准备开设《计算传播学》或《计算社会科学》课程的青年教师 对于定量传播学研究有基本了解 对于Python、R等软件仅初步了解 致力于日后进入相关数据科学领域工作的学生  本书特色  强调跨学科合作 （传播学、网络科学、计算机科学） 引用大量发表于Science、Nature、Proceedings of National Sciences (PNAS) 等国际顶级期刊的论文 附加主要Python程序代码  书籍网站 Slides和Code见：https://github.com/computational-class/ccrbook\n Python代码\n 教案 案例  导教班及教学研讨会  2019年 培训对象：利用本书作为核心教材的青年教师  如何购买？  上市时间：10月中下旬 售价：49.8元 京东、当当、亚马逊、卓越 （上市新书发布期间有一定折扣）  ","date":1539734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539734400,"objectID":"a72a742e3c6fb1fa98008f5ab9a63704","permalink":"https://chengjunwang.com/publication/ccr-book/","publishdate":"2018-10-17T00:00:00Z","relpermalink":"/publication/ccr-book/","section":"publication","summary":"Introduction to Computational Communication (In Chinese 计算传播学导论) now available on [dangdang.com for pre-order!](http://product.dangdang.com/25581097.html) ","tags":null,"title":"计算传播学导论","type":"publication"},{"authors":null,"categories":null,"content":"人总是要在一个房子里度过，不管是冰房子、石头房子、草房子、泥房子。一个房子是一个私有的领地，你在里面，便感觉自己自己可以安心地干点什么。但是现实生活却让人不断望而却步，因为房子太贵了。这么说，也是矫情。现在谁买不起个房子啊，中国人是三代人一起买房子。钱凑一下总是会有的。但是这中有一个限度。\n我赶的时间不好，赶上了中国经济的一个潜在的危机，GDP的增速降到7了，随之制造业不行了，股市不行了，于是被限购的房子解锁了。现在的人面对一个房子，所想的不是居住，而是投资。所以，这房价就可能有泡沫了，以为连住在玄武湖边上的大妈都花20万投资房地产了。不过，贵点还是有人买。\n车 南京市车管所 - 电话:025-96122, - 传真:025-84429309。 - 地址:南京市玄武区东方城68号。 - 邮编:210042\n二手车落户需要开车去吗？需要，因为要拍照，办理行驶证。行驶证和驾驶证不同：行驶证是车辆具备行驶的资质；驾驶证是自然人具有开车的资质。\n2018年10月12日下午终于完成了二手车落户，找了一个搭讪的私人中介，加上上车牌总共550元。李树开车，带上我和尹迪，先去九乡河东路加油站加油490元，然后开往车管所。去了之后，车管所的人没好气地告诉我二手车落户要去\u0008大公二手车交易市场（后来，黄牛告诉我是因为车管所没有空间了，大公是一个私人的公司）。\u0008非常恶劣的服务态度。\n从车管所大厅出门就有一个姓魏的中年女子（黄牛）搭讪，非常娴熟地问话，一口价450元。然后要拓印发动机编号，\u0008因为别克车的位置不容易拓印，未果。\n到了大公二手车交易市场，先上四楼调了档案，然后下楼排队，检察人员非常粗略的看了一下发动机，并未认真拓印。继续办理，保险的变更缺少一个签单，问了张超后找到，继续办理并随机抽取了车号苏A*67P7M。还拿到了车子的行驶证和登记证。旁边的人说：哪有什么好号码，677挺好。想到七上八下，我就觉得顺上上也不错。\u0008\n从大公回到车管所，搞环保（不知道是什么，反正2019年可以车子可以直接年检了）、上车牌，结果，车子上牌又要了100元。\n从车管所回来路上，王新说可以转保险，我微信发给张超\u0008我的身份证、行驶证和登记证的照片，直接联系保险公司办理了保险转移。\n回来仙林校区，继续把车开进学校行政北楼地下停车库，要记得去学校保卫处交表格。\n终于在临时牌照失效的前一天办理完成。\n车有了，驾照还没有！\n九曲花苑 每天走1000米到仙林翠谷公交站（地图）\n周转房申请 在oa系统里申请了周转房，房地产管理处 回复说：\n 不同意 副教授的正式批文还未下达 请完成副教授入职手续后申请 人资处 2017-07-14 09:17:50\n 中南山锦花城 交通配套：\n项目目前虽然距离现有的2号线南大仙林校区站2公里，但是距离2017年年初即将通车的4号线东流站仅1.2公里，并且还有未来规划中的8、9、16号线，未来的周边地铁交通会极为方便，此外项目周边公路网未来也是比较发达，规划的四横（玄武大道、仙林大道、沪宁高速、宁杭高速）三纵（绕城高速、长深高速、宁杭高速）主干道格局更是在保护生态的前提下发展的，板块自身的MRT、有轨电车、公共自行车、接驳公交也在紧锣密鼓的建设当中，可以说未来中南山锦花城的交通会比较发达方便，完全能够满足业主的出行需求。\n学区配套：\n在项目北侧南大、南师大等百年名校云集，人文学习氛围可以说是非常浓厚的，距离著名的南京外国语学校约2.5km，目前项目除了在和南外洽谈分校之外，还在和台湾康桥国际学校联系，争取能够引入双语国际学校，另外青龙地铁小镇片区未来将打造2所中学、4所初中、12所小学、15所幼儿园，可以说未来该地区的教育资源是完全能够为业主解决孩子学习的后顾之忧的，甚至有人预测青龙板块未来会成为仙林又一个著名的学区房板块。\n2017年4月16日，我和老爸去看了中南山锦花城的洋房，120平米要2.76万一平，340万的总价格，因为南京市限购，只要有贷款记录就要首付5成（170万！每月还贷8500元），感觉完全没有办法承受。而如果想要首付3成的话（102万，每月还贷12000元），就要真离婚或者假离婚（让银行查不到）由暮白来买这个房子。  宝华双创示范园 南京大学·句容创新创业示范园正式签约。2016年7月19日下午，南京大学·句容创新创业示范园合作协议签约仪式在句容举行。南京大学校长陈骏、镇江市委书记夏锦文、句容市委书记许文等领导出席签约仪式并讲话。\n地点:恒大雅苑马路对面的濠锋星钻和春天里的后面。\n2017-02-24 蓝鲸大学发布文件，成立句容双创示范园建设领导小组，2017-03-13 蓝鲸大学发布关于修订《南京大学专职科研系列岗位聘用办法》的通知，其中明确了专职科研人员不享受公费医疗、住房分配、住房补贴、租金补贴。想想过去半年里宝华房价一平米涨价了7000元人民币，个中意味令人咋舌。\n17160\u0026frasl;69332 = 0.24750475970691743万，即2475元一平米的低价，房价约为5000元一平米。\n最近一件烦人的事情是小县城句容居然限购了，六个月，外来家庭只能购买一套房子。学校对于是否给专职科研分房似乎已经达成了一致意见，专职科研不一定能转正，因而不具有购房资格。\n2017年10月3日，开始动工平地。\n宝华镇科技创城与南大项目。 梁书记担任第一指挥长，杨镇长任总指挥，谭镇长任常务副指挥长，涉及到的其他领导作为副指挥长参与其中，相关部门作为成员单位。指挥部下设南大国家级“双创”基地、中科大中科院研究生基地、苏宁大数据中心等四个项目服务部，其中南大“双创”基地作为一号项目集全镇之力推进。南大项目确保10月底完成土方平整，11月举行开园仪式； 信息来源\n重磅！国家级南大双创园开工，宝华成长三角创业中心\n80-170 平米商品房2004套、预留地下车库车位\n第一期 项目共9栋1242户：\n 4栋18层 1栋28层 3栋30层 1栋32层  共160亩，容积率2.5，建筑密度25%，绿化率30%\n 临近春天里的校区北侧为15、18层住宅（底部为配套\u0008商业） 中部为18层 东西两侧为28-32层。  2019年10月24日，学校发布了雍园的出售方案，也就是南京大学句容人才公寓出售方案。\n一个简单的计算：\n 一个车位平均8-10平米，35平方米，可以够停3到4辆车。 另外，根据句容的政策，车位是没有产权的 一般家庭不需要这么多车，多数一辆车就够了，也很少有捆绑销售车位的。 按照140平米的户型计算：(140*0.7 + 30)/140 = 0.9142 雍园的价格实际高达9千1百多； 按照120平米的户型计算：(120*0.7 + 30)/120 = 0.95 价格更高达9千5百多； 临近的春天里（靠近仙林东路）http://nj.sell.house365.com/community_id281324#xqjgzs 均价才9635元。 春天里马路对面的恒大雅苑（精装修、配套超市、电影院、健身中心）http://nj.sell.house365.com/community_id10007238#xqjgzs 均价10820元。 雍园的地理位置不如春天里（距离仙林东路更远、距离恒大的超市和电影院更远、距离公交站更远） 作为人才住宅，南京大学句容人才公寓的定价太高了。 更何况还有10年服务、八年限售等限制。 建议学校降低销售价格。  更令人担忧的是近两年以来，南京一直房价在涨，但南京周边都在跌。宝华新城作为郊野地区，无论江苏、南京、镇江、句容、宝华都没有实质性的规划，后面发展前景堪忧。如果房地产如2017年底那样火应该没有问题，现在宝华房地产的预期处于低谷当中。年轻老师唯一寄希望的就是南大自己的发展, 南大如果还是甩锅的思路，就难讲了。现在学校也是骑虎难下，成本太高了. 从这个行情上来看，确实是有点鸡肋的感觉。\n雍园的房子坑青年老师的一个地方在于:没有买过房子的人\u0008因此丧失\u0008\u0008首套房资格，并且无法使用南京住房公积金贷款。“南京市首套房首付比例:公积金20%,首套房首付比例一般最低为30%以上,贷款70%,原则上银行只贷给万位数或者是最低千位数的整数,零头要放进首付款里的,所以一般实际上的首付款比例都是超过30%的! ”有贷款\u0008没还清或首套无贷款，在南京买房5成首付；\u0008首套房贷款没还清8成首付。异地买房子不能使用南京住房公积金。反之，首套房假设房款为300万，只要筹够300*0.3 = 90万，就可以在南京首付买房，使用公积金办理贷款。南京的房子一直很稳定，周边还在降价。\n总房源 1200套\n 预留人才用房 350套 本次可点购房源 850套  A户型 137-140m² 580套 B户型 111-126m² 270\u0008套   A户型(两梯三户)\n A1 +50 A2 -100 A3 +50  B户型(两梯六户)\n B1 +50 B2 +70 B3 -120  九曲花苑 我一直住在迈皋桥这边，对仙林不熟悉。一直也没有鼓足勇气去看房子，更不想去买房子。仿佛安于现状。听了周围的老师的建议和家里人的话，开始去经天路看房子，先看了仙林湖旁的两家：金地湖城、新城香悦澜山。没有好的楼层，价格在17000左右，12月后，暮白到南京，再去看的时候就已经到了19000左右。如是这般，便买不起了。\n九曲花苑百度地图\n宝华镇政府沿着玉兰路向北直走就是。\n于是，开始在镇江句容宝华镇周围看仙林大道上的房子，泰达青筑、恒大雅苑，看了几家。后来看到天正的房子后，觉得户型不错，价格也便宜，就决定出手了。于是周末电话老爸从老家过来，周一开会，同事又介绍了仙林翠谷的九曲花苑的房子。\n*九曲花街*是美国加州洛杉矶的有名景观。九曲花苑是六层高的洋房，介乎别墅（3）和小高层（14）之间，得房率不是高层可以比的。于是，当天就决定预付3万，第二天，12月30日，周三去学院办理了工作证明后，下午就办理了农行的贷款73万，买了2栋401东边户。基本不会遮光，三面通透。感觉很好，就是远两公里。到南大仙林校区10公里。\n房子是四室两厅，一厨一卫，比较宽敞。东边户，早上和中午、下午的阳光都很好。\n美的电风扇安装 To-do List 需要完成房屋的设计工作 就近租房，以方便装修 8月1日交房，验房。检查线路 墙面、地板、灯、煤气 家具、厨具、洁具、热水 窗帘 4300元 空调、冰箱 网络  2017年10月11日安装了三台美的空调，215元架子+管子费用。\n 苏宁提供200元一台为期3年的质保。 另外两个需要打孔  海尔 冰箱 BCD-340WDPG 官网link \n沿着地板打孔到空调间会打到楼下的空调间！解决方案是在正面直接打一个孔。如上图所示。\n 美的空调 3599*4 + 9399 = 23795  美的Midea制冷王KFR-72LW/BP3DN8Y-YB300(B1) https://product.suning.com/0070170933/616864904.html\n 大3匹变频智能WiFi 圆柱立式柜机一级能效 美的空调大三匹制冷王变频柜机，适合48平以内的房间使用 高效压缩机，快速制冷制热，手机智能wife遥控\n  3599美的-淘宝链接\n Midea/美的 KFR-35GW/BP3DN1Y-PC200(B1)\n CCC证书编号: 2016010703897753 上市时间: 2016-8 产地: 中国大陆 内机包装尺寸: 960x390x290mm 内机堆码层数极限: 12层 内机尺寸: 880x295x195mm 内机毛重: 13.5kg 制冷功率: 860W 制冷量: 3500W 制热功率: 1160W 制热量: 4400W 外机包装尺寸: 910x420x630mm 外机堆码层数极限: 6层 外机尺寸: 807x328x555mm 外机毛重: 36kg 室内机噪音: 18dB 室外机噪音: 38dB 智能类型: 其他智能 电辅加热功率: 1050W 空调品牌: Midea/美的 美的空调型号: KFR-35GW/BP3DN1Y-PC200(B1) 空调面板颜色: 陶瓷白 空调类型: 壁挂式 冷暖类型: 冷暖电辅 空调功率: 大1.5匹 适用面积: 11m^2 (含)-20m^2 (含) 工作方式: 变频 能效等级: 一级  松下冰箱 3990 淘宝链接\n     容积      冷冻室容积 90L   冷藏室容积 177L   最大容积 313L   尺寸规格    净重 74kg   包装尺寸 647x699x2010mm   宽×深(厚)×高 606x639x1900mm   毛重 81kg   基本参数    上市时间 2015-10   冰箱冰柜品牌 Panasonic/松下   松下冰箱型号 NR-C31PX3-NL   智能类型 不支持智能   冰箱冷柜机型 冷藏冷冻冰箱   制冷方式 风冷   箱门结构 三门式   面板类型 VCM覆膜板   能效等级 一级   颜色分类 典雅金   制冷控制系统 电脑温控   技术参数    噪声 37dB   耗电量 0.7Kwh/24h    收房、装修进度 7月31日，拿到了房子的钥匙。装修还有漫漫长路。感觉非常的有压力。米粒妈妈带着米粒去西安和宝鸡住了一个月，从2016年十一开始装修。找了安徽人老王家的装修公司，包轻工，从水电开始，木工进入，之后油漆。期间做了地暖、瓷砖、橱柜、门套、灯具、窗户。\n这之间首先为了房屋的设计折腾了很久，把入户花园旁边的步入式衣帽间改成了一个独立的小房间。爸爸发挥了自己垒墙的专业技能，将米粒的房间和这个门口小房间改造得很漂亮。\n比较坎坷的一次斗智斗勇的事情是和地面找平的人的纠纷，对方谎称用了很多水泥。爸爸数了水泥袋子数量证实对方说假话。我最终站在爸爸一方同对方电话斗争。\n折腾到2016年12月29日开始做厨房和卫生间的吊顶，预约了30日做抽油烟机\n硬装收尾 橱柜 卧室木地板 洗手间推拉门 坐便器 洗手台3个 木匠打厨房吊柜 鞋柜和衣柜门板 厨房推拉门 纱窗  家具 芝华仕高力国际家居港，房东是在迈皋桥那边买的家具，暮白在那里买的公司家具。地址见百度地图。\n两个大床 1.8*2.0 沙发 电视桌 餐桌 1.5 + 6*椅子 沙发桌  2017年2月19日在恒大旁边的欢乐购家具城里的一家小店里预定了以上家具(总价13100元)。\n看了房东家里的家具，还是挺不错的的，除了不喜欢她选的真皮沙发。上淘宝看了源氏木语的家具比较简单。\n衣柜的移门比较难选，波浪纹的移门，上面是对开的小门。\n装修设计 需求：\n 办公区域 两个小孩的卧室，两个主卧室 一个客厅  主要矛盾是大客厅和办公区域的矛盾\n现在的思路是保留东北两个小房间的封闭性，分别装窗户和门。在小孩三岁后 住在小房间。\n如何兼容客厅和办公？\n希望有一个这样的书架 设计的架构是这样的：\n浴霸 2019年10月份，原来安装的两台浴霸都坏掉了。米粒爷爷去宝华的市场上一个oppo小店里看了一下，推荐了一个叫做本科的浴霸，\u0008一台就要1200多。功能还很一般。我查了一下，隐约觉得\u0008卖家在忽悠人。我周六和爸一起去看了下，坚定了这个认识。\n\u0008回来后果断从\u0008欧普官网订购了多功能智能风暖浴霸 三合一嵌入式集成吊顶卫生间暖风机 F135，选择了款式:C★旗舰款F135-Y★大功率可调温 免接线(遥控开关)。\n2016租房 8月14日与晓青去句容看了仙林悦城与恒大雅苑的房子。很多都是新的房子拿出来出租，多数没有好的家具。看了恒大雅苑四栋23楼的一个140平米的房子，三室两厅两卫。但是除了简单的硬装修之外，完全没有家具家电。最后决定每月两千租这个房子，我自己配家电，主要是两个空调+一个冰箱。带过去晓青的冰箱和电视。\n房东配两床+两衣柜+餐厅饭桌+六把椅子+客厅电视桌+茶几桌+四把小椅子+卧室窗帘。签约费500+租金每月两千，租期一年，预付押金1000。结果这个二逼房东糊弄人，重新找一个吧。\n关于宝华镇 宝华镇位于镇江市西郊、句容市西北部，西距南京23公里，紧邻南京仙林大学城，东至镇江市区35公里。南至南京禄口机场30公里，北至长江龙潭港6公里，312国道、沪宁铁路穿境而过。宝华得名于境内佛教“律宗第一名山”宝华山，宝华山国家森林公园属国家AAAA级风景区，内有享誉东南亚佛教名寺——宝华山隆昌寺。交通便捷，区位优越，资源丰富。\n百度百科 http://baike.baidu.com/subview/939271/9832164.htm\n教育 南外幼儿园仙林分校  四季金辉东南  宝华小学  宝华花园旁  交通 102路宝华专线 宝华到句容客运公司 首末班 ：06:20-17:35 全程票价：7 元 1 . 宝华 2 . 龙潭 3 . 东阳 4 . 孟塘 5 . 下鲍亭 6 . 朝阳 7 . 乌龟桥 8 . 汤山 9 . 新塘 10 . 黄梅 11 . 客运公司\n仙林湖地铁站 四号线已经通车，但是仙林湖地铁站却比想象中要远。从仙林湖站到鼓楼需要40分钟。可以坐2号线在金马路转4号线到鼓楼。\n玉兰路-仙林东路-仙林大道-经天路地铁站。s5地铁线会有一站经过宝华，但是距离仙林大道较远，需要经过宝华大道。预计2020年前完成。\n南京地铁15号线：经天路——保税物流中心未列入十三五规划。不要被忽悠了！\n详见：发展改革委关于南京城市轨道交通第二期建设规划调整方案（2016～2021年）的批复 \n附件：南京市城市轨道交通第二期建设规划调整方案（2016～2021年）示意图\n2号线东延到宝华 市政府办公厅关于贯彻落实宁镇扬同城化发展规划的通知 宁政办发〔2017〕149号\n 25．加快仙林—宝华科学城建设。整合仙林大学城和宝华片区，着力推进国家科学城建设，打造全国科技创新高地、区域智慧谷和东部宜居城。仙林大学城重点推进商务中心区建设，大力发展高等教育、科技研发以及文化创意产业，培育和壮大国家级科研机构、研发中心、工程中心和实验室等，强化基础研究和应用能力。加快推进南京地铁2号线和城市公交向宝华延伸。加快推进道路规划建设衔接，贯通桂山路、江嵊路等主次干道，疏通仙林大道。（牵头单位：栖霞区政府、仙林大学城管委会）\n26．加快龙潭—下蜀滨江港城建设。以临港经济和新城建设为重点，建设长江区域性航运物流中心核心区、临港先进制造业集聚区和现代化新城。推进交通基础设施衔接成网和市政公用设施共建共享。加快轨道15号线与沪宁城际铁路宝华站衔接，建设下龙公路，推进龙潭港四期和六期集装箱码头以及联检锚地建设，规划建设龙潭疏港公路和铁路。（牵头单位：栖霞区政府、南京经济技术开发区管委会）\n 公交车  159： 太少，到四号线仙林湖地铁站 D5：到二号线经天路地铁站 191: 经天路、仙林湖地铁站、宝华山  191路公交车 2017年8月23日起，南京经天路地铁站至宝华山公交直通车正式开通。为了方便游客游览宝华山，宝华镇政府和宝华山管委会积极与南京江南公交客运有限公司沟通协调，新增191路公交，同步撤销G9路。\n服务时间： - 经天路地铁站西：8：40-20：10 - 宝华山：9：40-21：10 - 约 20-30分钟一班\n","date":1539216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539216000,"objectID":"1299e515af6bda2418b160421974bdb0","permalink":"https://chengjunwang.com/note/note_archive/2015-12-30-house/","publishdate":"2018-10-11T00:00:00Z","relpermalink":"/note/note_archive/2015-12-30-house/","section":"note","summary":" ","tags":[""],"title":"关于房子","type":"note"},{"authors":null,"categories":null,"content":" 防风眼镜 前两天，米粒妈妈说给米粒买了一个防风的眼镜，今天早上要出门上学时，\n米粒突然提出要去取快递。\n米粒对爸爸说：妈妈给我买的眼镜到了，我们现在去取好吗？\n爸爸回答：爸爸不知道取货码。\n米粒：你看看手机。\n爸爸：妈妈没有发给爸爸，你去问问妈妈到了吗？\n米粒跑去问妈妈：眼镜到了没。\n妈妈回答：宝贝，你先出门。\n爸爸问米粒：妈妈说什么？\n米粒说：妈妈说眼镜今天早上起床的时候就到了，现在可以取了。\n爸爸暗笑，没有想到娃按照个人意愿扭曲现实的能力这么强大。\n于是，爸爸大声问妈妈：米粒的眼镜到了吗？\n妈妈不回答或者答非所问。\n最后，爸爸受不了，大声问：到底到了没有。\n妈妈说：没有。\n于是爸爸对米粒说：没到，咱们先上学去吧。可能今天下午就到了。\n说完，爸爸感觉在给自己挖坑赶紧补充：是可能，也许因为其他很多原因到不了。\n米粒默默跟着爸爸出门，走进电梯还说：我不喜欢妈妈，妈妈不遵守交通规则。\n五味打架 晓青常有惊人之语，罗列一二。\n一次，她很生气，说：太气人了，五味打架！\n坐火车路过潼关，她说：这个地方很有名，“西出潼关无故人”！\n最近，暮白对我很失望，经常说：我要揍死你。\n","date":1536019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536019200,"objectID":"e7d8018a79106ec2c8debc3ab063bd0d","permalink":"https://chengjunwang.com/note/note_archive/2014-08-29-her-words/","publishdate":"2018-09-04T00:00:00Z","relpermalink":"/note/note_archive/2014-08-29-her-words/","section":"note","summary":" ","tags":[""],"title":"语录","type":"note"},{"authors":null,"categories":null,"content":"新进职工教学培训 jsfz@nju.edu.cn\n以学生能力培养为中心的教学：如何成为卓越的大学老师？\n感谢南京大学教师教学发展中心的组织，非常荣幸参加了2017年南京大学新进教师教学能力提升专题培训（2018年1月16日-17日，一天半）。我重点听了陈道蓄、李满春、张洋、王自强、吕筠、张莉、郑伟娟、周奕伦几位老师的分享，对于以学生为中心的大学教学及其不同的形式和方法有了更加全面的认识。对于此次培训内容，我简要对我产生共鸣和影响的内容进行归纳和总结，具体如下：\n以学生为中心的课程设计的目的是用能力培养替代知识传递。陈道蓄和郑伟娟两位老师都提到了大学教育以传授知识为核心的局限性。科学的发展不断改写我们对于自然和人类社会的认识，大学教育所强调的知识体系往往会很快被新的知识所替代，当学生大学毕业之后，很多在校园里学到的知识都可能过时了，或者在每个人职业生涯更晚一些的时候，这些知识最终过时了，甚至被证明是错误的或有失偏颇。社会生活和工作是一个实实在在的试金石，总会有层出不穷的新问题涌现出来。仅仅靠着在大学里学到的有限的知识，也无法应对异常丰富的实际问题。如何让学生能够更好的适应社会和工作中的这种挑战就成了一个非常紧迫的问题。这也迫使大学老师不断反思大学教育的本质和目的。一个被广泛接受的答案是：大学教育的核心在于培养学生的能力。\n陈老师主张大家思考什么才是能力。将能力培养作为核心的大学教育就一定要说清楚能力是什么。从计算机科学的角度，他主张从计算思维的角度来定义和衡量能力。面对社会现象，能够抽象出其中的问题，并将该问题分解为几个可以执行的步骤，通过编写程序等方式实现自动化的实现即为计算思维的基本形式。在这种定义计算思维的过程中，涉及到了可计算性的问题。以通过编程来解决问题为例，所编写的算法本身存在一个可计算函数，如果这个可计算函数的复杂度较低，这种算法的可计算性就越强。能够运行的程序背后都对应了一个可计算函数，运行时间的长短就对应了函数本身的复杂度的高低。计算思维关注的核心是任务的分解和自动化的实现。具备计算思维的能力，就能够更加高效地解决问题，更清晰地理解社会现象。\n陈道蓄关于课程组织的介绍有很多翻转课堂的理念。比如： 1. 没有课内和课外之分；学习应当是随时随地的，打破空间和时间限制的，只有如此每个学生才能找到自己的节奏。但是需要注意的是：为什么学生还需要来课堂呢？我想这是因为课堂将提供超乎知识点的对于能力的训练。不过做到这一点缺失很难，因为很多学生非常繁忙，忙着上课、社团活动，压力很大。翻转课堂所推崇的增加作业和阅读量给学生带来更多的挑战。如何平衡本课程与其它老师开设的课程就形成了一个不小的问题。 2. 教学材料提前发给学生，并且告诉学生不是预习，就是学习；需要有一本或几本参考书，并形成自己的讲义。 3. 编程是一种技能，学生可以自学，需要课堂讲授，以作业的形式推动学生主动学习编程；我想这一点也许适用于计算机专业的学生，他们以计算机为终身的志业，接受很多系统的计算机教学，容易触类旁通。但对于文科编程而言，并非如此。很多学生完全没有接触过编程，缺乏对于编程背后的数据结构和算法的理解。我自己的很多课程都是以编程为核心的，切身体会到社会科学和人文学科的学生对于编程的热情和无奈。不过，陈老师的观点有启发意义，即可以让学生通过作业深入掌握编程的问题，减少学生在编程方面对于老师的依赖。 4. 知识点只是能力的载体，不是能力本身。因此拼命讲课的老师可能不是以学生为中心，而是以教学任务为核心。这一点非常重要，很多侧重于讲的老师语速很快，缺少与学生的沟通和互动，没有办法与学生产生真正的交流，将学生丢弃在了知识的汪洋当中。其实是一种不负责任。当然，学生必然会因为跟不上而不感兴趣，甚至产生挫败感。 5. 内容只是载体，就可以做减法，减到不能再减。 6. PPT是用来组织知识点的，因而不是给学生看的！有学生反馈说陈老师，PPT上的知识点不连贯。陈回答：这本来就不是给你们看的。对此，我的理解是：学生应该看的是内容详尽的教学材料，而PPT是高度简化的。PPT只是在学生看了教学材料、讲义之后才能理解的逻辑线索。\n李满春老师从GIS学科的发展介绍了教学的设计思路。本硕博都应当处于前沿，区别只在于程度。为了达到这一目标就需要持续更新教材。在这个过程中非常重要的一个方面在于抓住新生学科的发展机遇。以科研促进教学的思路还需要注意紧密结合国家和社会需求，做顶天立地的研究，促进国家和社会的发展。\n张洋老师作为青年教师代表，介绍了回国之后开设《大气环流》基础课程的经历。教学首要需要解决的问题是如何吸引学生，如何激发学生的学习兴趣。张老师的思路是依靠课程内容的专业性，尽可能发展为专业核心课程。一般需要参考多本教材和讲义，集众家之所长建立学科体系，注重逻辑性和理论性，避免碎片化的知识堆砌。作业以鼓励为主，做好课程主页。\n同时，教学需要尽量贴近自己的研究方向，教自己擅长的东西，尽可能去选择课程，而不是反过来被课程选择。要在教学中触摸学科前沿，尤其是高年级专业课和研究生课程。这样可以有助于吸引学生，进入自己的研究组，充实科研团队。\n张老师强调，PPT具有直观呈现的不可替代的优势，但往往不适用于讲公式推导。做好PPT的方法是模仿板书的形式，一点一点、逐行呈现知识点，避免一下子展现一整页ppt，减少学生的认知压力，强调循序渐进的教学思路。\n南京大学依据四个融通原则，建立了三三制本科教学方案。让每个学生可以建立自己的课表，但跨院系选课一学期不超过四门，公选不超过三门。开学前两周为退补选时间。缺课三分之一（6周）就是零分。补考成绩只能按60分记。但南大有一个邪恶的“弃课”传统，即对于已经获得学分的课程，可以申请注销。\n在激发学生互动性方面，王自强老师介绍了课立方网站，可以让课程动起来，将课堂小测、签到、抢答等基本过程通过微信公众号来实现。\n就简化PPT而言，吕筠老师强调不要把PPT当word或者黑板，以简洁为第一原则。规避字太多、色彩不清、换行错误、重点不清楚等问题。另外，现在ppt的比例多为16:9，未来会以4：3的宽屏为主流。纯白色背景容易视觉疲劳，建议灰色更好，字体方面黑体28号字体比较合适。PPT只是关键词，是逻辑线索，不是讲义。\n张莉老师介绍了MOOC制作和教学的经验。内容是王道。讲给谁、讲什么、怎么讲？怎么呈现？非常重要。开设慕课需要做好已经开设慕课的调查，明确是针对专业还是非专业学生开设？讲传统内容还是热点内容？就其自身开设《使用python玩转数据》课程为例，张老师强调了以数据为基础，构建一系列案例的教学方式。以现实的数据和问题为出发点，实现个性化、多层次、案例式教学。就形式而言，张莉老师指出她不适应一直出镜的讲课方式，七周的课程，她每周录制一个自己出镜介绍的片头。使用surface电脑自带的笔在ppt上边写边讲。对于已经开设好的慕课，可以服务于每个学期开设的课程，构成课下学习视频，上课深入交流的混合式教学模式。此外，可以把自己在做的研究项目融入慕课的案例当中。\n郑伟娟老师以从教二十多年的经历指出相对于使用板书、薄膜投影的教学方式，使用ppt教学老师的教学压力很大，很多都是老师讲满一节课。但是现在知识更新快，自主学习和批判思维更重要。提升学生学习兴趣和参与度是教学成功的第一步，一定要与时俱进，选择适合现在的大学生的教学方式。郑老师就翻转课堂教学指出只有那些适合学生自学，也能找到学习视频和资料的课程才适合翻转，通过布置学习任务、出思考题的方式，引导学生自学和思考。在翻转课堂上，学生是学习的主体，但当学生参与度有限出现冷场时，老师要引导，但不是自问自答。翻转课程往往通过自学和分组来进行，会出现学习压力大、学生只对自己负责的部分认真学习的问题。因而不是所有的课程都要全部翻转，部分翻转是比较合适的。针对学生只认真学习自己小组的内容的情况，平时的考试和期末考试相互结合是必要的。\n周奕伦老师则介绍了在windows环境下下载和编辑视频的方法，此外还介绍了录制视频的一些简单方法。\n整体而言，此次工作坊就很多教学问题进行了简单的介绍，尤其是针对我一直存在困惑的翻转课堂和慕课问题、讲义和图书编写问题、编程教学问题、ppt制作问题、教学和科研协同的问题，都有深入的交流，激发了我对于教学的兴趣，期待以后可以参加更多教师教学发展中心的活动。\n上课时间 8:00-8:50 9:00-9:50\n10:10-11:00 11:10-12:00\n14:00-14:50 15:00-15:50\n16:10-17:00 17:10-18:00\n18:30-19:20 19:30-20:20\n学生使用github上传作业问题 https://github.com/liruonanfdu/cjc2016/tree/gh-pages/homework/liruonan\n录制公开课视频 Quicktime可以比较方便地录制屏幕，因而是录制公开课的好方法。但录制屏幕的时候，我们往往还希望能够看到讲课的人，所以还需要录制视频。\n解决方法很简单：\n 首先，打开录制视频，但是并不点击开始录制。 然后，打开录制屏幕，点击开始。  不过，我后来觉得使用这种方法其实比较没意义，读者看到教师的形象意义有多大呢？有或者没有其实影响不大。\n上课总结与自我评估材料 每门课都需要教师总结与自我评估，大概500字左右。本学期我为本科生开设两门课《数据新闻》、《计算传播与广告》\n该课程的开课历史 -《数据新闻》为南京大学第一门数据新闻相关课程 -《计算传播与广告》为南京大学第一门计算广告相关课程\n备课或其它准备工作 《数据新闻》是南京大学新闻传播学院新闻采写课程包系列中的核心课程之一，旨在为所有新闻专业和有志于从事新闻工作的同学提供数据新闻的知识和基本训练。数据新闻（data journalism）是指基于数据的抓取、挖掘、统计、分析和可视化呈现的新型新闻报道方式。本课程以《The Data Journalism Handbook》（2012）和《数据可视化的基本原理与方法》（陈为等，2013）作为授课教材。通过本课程的同学应该具备基本的数据新闻素养，具体包括收集数据、清洗数据、分析数据、可视化数据的能力，能准确地运用数据语言报道新闻事实。就数据新闻的生产过程而言，例如有人将数据新闻的生产过程分为四个阶段：数据（Data）、过滤（Filter）、可视化（ Visualize）、故事（ Story）。我们将之分为五个阶段：• 1. 数据新闻选题\u0026mdash;-关于数据新闻的理论（1）• 2. 新闻数据抓取\u0026mdash;-Python（2）• 3. 新闻数据分析\u0026mdash;-Python,R（2）,Excel• 4. 传播数据新闻（如数据可视化）\u0026mdash;-Tableau（1）,HTML5（1）, Javascript（1）, echarts（1）, D3.js（1）, Processing（1）, Adobe Illustrator（1）• 5. 分析数据新闻效果\u0026mdash;-网站分析工具\n《计算传播与广告》是南京大学新闻传播学院为广告方向的本科生开设的任选课程之一，旨在为广告专业和有志于从事互联网广告工作的学生提供计算传播和广告的基础知识。计算传播学是计算社会科学的重要分支。它主要关注人类传播行为的可计算性基础，以传播网络分析、传播文本挖掘、数据科学等为主要分析工具，大规模地收集并分析人类传播行为数据，挖掘人类传播行为背后的模式和法则，分析模式背后的生成机制与基本原理，可以被广泛地应用于数据新闻和计算广告等场景。本课程注重编程训练、数学建模和可计算思维的培养。要求选课学生对于计算社会科学（computational Social Science）感兴趣；保持开放的头脑；不排斥基本的统计学和简单的计算机编程。计算广告（computational advertising）是计算传播学的重要研究方向和应用领域，由雅虎研究院资深研究员Andrei Broder首次提出，他认为，计算广告学是一门由信息科学、统计学、计算机科学以及微观经济学等学科交叉融合的新兴分支学科。之后，Andrei Broder和另一位Yahoo!的资深研究员一起在斯坦福开设了这门课程，被称为互联网广告从业人员的“必修课”。通过本课程的同学应该具备基本的计算传播与广告的基础知识。• 传播网络分析 Network Analysis• 博弈论基础 Gaming theory• 数据科学与编程工具 Data Science \u0026amp; Programming Tools• 互联网广告的理论框架• 了解计算广告在互联网广告中的位置和作用；•了解并掌握各种计算广告类型，包括广告投放样式、广告投放系统、广告计费方式分析等；• 掌握搜索广告检索的基本流程及常用技术，如信息检索、广告排序、广告投放定位等内容。• 学习使用软件程序对相关数据进行分析；\n遇到的困惑或难题、存在的不足与局限 《数据新闻》但是产业发展已经开始倒逼学术研究，今天的媒体市场和广告市场已经发生天翻地覆的变化。随着信息渠道的拓展，海量的信息扑来，但受众的注意力却非常有限。传统媒体面临广告下滑，读者背离，朝不保夕的窘境，纷纷抓住各种救命稻草，媒体融合和数据新闻就成了重点考虑对象。这反过来将压力传递到新闻传播教育中来。因为，数据新闻涉及到前端、设计等复杂的内容，所以并非计算机科学拓展的重点（与计算广告相比），所以本专业的学生还比较积极。但是存在学生统计基础薄弱、可视化训练不足、畏惧编程、上课玩手机等问题。\n《计算传播与广告》但是，对于计算广告的崛起，传统的广告系的学生还毫无感受。也许，基于社会分工，这本来就应当是计算机系的学生考虑的问题，但无疑精细化的计算广告也要考虑广告的内容和形式，因为只有这样才能匹配媒体平台、受众、广告主三方的利益。所以，广告系的同学其实迫切需要普及计算广告技巧。新闻传播专业的学生整体而言需要与计算机专业更好的融合。\n尝试的创新与改革 《数据新闻》因为我所带的课都是新课，所以在备课方面花了很多时间。因为我讲的课涉及到很多编程练习的环节，所以平时的作业是必须的。我采用github作为管理学生作业的平台，感觉非常好。可以非常好地实现对于学生分组、小组人物安排、学生问题答疑、作业发布、作业审核的全部过程。此外，还可以较好地以网页的形式展现学生的学习成果。这一点是我比较满意的。\n《计算传播与广告》因为我所带的课都是新课，所以在备课方面花了很多时间。因为我讲的课涉及到很多编程练习的环节，所以平时的作业是必须的。我采用github作为管理学生作业的平台，感觉非常好。可以非常好地实现对于学生分组、小组人物安排、学生问题答疑、作业发布、作业审核的全部过程。此外，还可以较好地以网页的形式展现学生的学习成果。这一点是我比较满意的。\n对学生学习态度及课堂反馈的评价  对学生态度友好 认真审阅学生作业  未来的计划与设想等。  两门课程均需要课堂上机练习，而目前学院仙林校区的机房仅仅有20个机位，迫切需要扩充机房。 减少课堂教学量，增加互动内容。  取得成绩与经验  完成教学任务 增加师生互动 完成通过github交作业、批改作业 完成微信公号《微议题排行榜》的运营  关于计算传播教学的感悟 2012年的时候，我还在香港城市大学读博士，有一门必修课是教如何给学生上课。课程要求必须要写自己的“教育哲学”。我写了我自己的计划：一、如何给ssci期刊投稿；二、网络分析的理论和应用；三、媒介市场分析。时光荏苒，三年过去，我回到大陆教书。第一门课变成遥不可及的梦想，没有本科生和研究生对这个感兴趣；第二门课和第三门课倒是有一部分开始变成现实。我在2015年春季给研究生开了《计算传播学导论》的工作坊，秋季开了两门课，一门是《数据新闻》，另一门是《计算传播与广告》。我给自己的定位很明确：发展和传播“计算传播学”。计算传播学是计算社会科学的一个重要分支。它主要关注传播网络分析、媒介文本挖掘、数据新闻、计算广告、数学模型、编程工具以及开放数据。理论起源于数据，阶及模式、法则、机制，而达根本原理。将人类传播行为（开放数据）可计算化的转化过程依赖于我们的研究方法（数学模型、编程工具），专注于我们的研究领域（传播网络分析、媒介文本挖掘），而应用于数据新闻和计算广告领域。\n在过去的五年里，计算社会科学成为了一个不可抵挡的浪潮。这个浪潮有很多表现形式，比如“大数据”、“媒体融合”、“人工智能”纷纷成为周围人火热讨论的话题。虽然，很多人唱衰这些东西，但我一直认为说一个东西不行太容易了，每个人在批评别人的时候总能超水平发挥，因为我们倾向于盯着比人的短处。但是批评太容易了，难点其实一直在于怎么解决问题。没有意义之物，注定被历史的尘埃淹没，关键是要做出好的东西出来。在社会科学家们磨拳搽掌围攻大数据的时候，一群物理学家和计算机科学家开始投入到计算社会科学的研究中来。\n社会科学内部对于变革并不敏感，计算机科学和自然科学加入社会科学的研究并不鲜见。实际上，这种场景太让人熟悉，80年代的时候，计算机科学发展计算语言学的时候就出现过。结果是两帮人说不到一块去，乔姆斯基作为语言生成学派反对计算语言学的基本观点，双方各自开自己的会议，办自己的期刊。但是，随着互联网的发展，传统语言学面对计算语言学的飞速发展已经失去了往日的那种反抗，二者终于在一方胜出的情况下开始产生有益的融合。问题是现在其他各个社会科学分支如何看待计算社会科学呢？如果对抗20年，基本上学科发展的一代人的时光就耗进去了。仅从学术争论而言，孤注一掷不是明智之举，似乎短期内依然没有明确答案。\n但是产业发展已经开始倒逼学术研究，今天的媒体市场和广告市场已经发生天翻地覆的变化。随着信息渠道的拓展，海量的信息扑来，但受众的注意力却非常有限。传统媒体面临广告下滑，读者背离，朝不保夕的窘境，纷纷抓住各种救命稻草，媒体融合和数据新闻就成了重点考虑对象。这反过来将压力传递到新闻传播教育中来。因为，数据新闻涉及到前端、设计等复杂的内容，所以并非计算机科学拓展的重点（与计算广告相比），所以本专业的学生还比较积极。但是，对于计算广告的崛起，传统的广告系的学生还毫无感受。也许，基于社会分工，这本来就应当是计算机系的学生考虑的问题，但无疑精细化的计算广告也要考虑广告的内容和形式，因为只有这样才能匹配媒体平台、受众、广告主三方的利益。所以，广告系的同学其实迫切需要普及计算广告技巧。新闻传播专业的学生整体而言需要与计算机专业更好的融合。\n教学是一个互动的过程。对于学生而言，是增长知识；对于老师而言，是教学相长。作为一个良性的互动，需要有一个正反馈的过程。但往往现实没有那么美好，比如春季给研究生开的《计算传播学导论》工作坊，后来发现根本不算教学量。给广告系本科生开的《计算传播与广告》没有几个广告系的同学选课，相反，开设的《数据新闻》则选课众多。另外，我在鼓楼面向研究生开的课程和读书会、一起公开课活动，来的主要是专业硕士，学术硕士并不感兴趣。硕士和博士的反馈让我更多我反思是为什么文科的研究生越做研究越固步自封，为什么本科生对于找工作更有兴趣？从我的角度而言，乐见其对于应用的关注，但也期望能够抓住那些对研究感兴趣的学生。\n因为我所带的课都是新课，所以在备课方面花了很多时间。因为我讲的课涉及到很多编程练习的环节，所以平时的作业是必须的。我采用github作为管理学生作业的平台，感觉非常好。可以非常好地实现对于学生分组、小组人物安排、学生问题答疑、作业发布、作业审核的全部过程。此外，还可以较好地以网页的形式展现学生的学习成果。这一点是我比较满意的。\n附《我的教育哲学》：\nTeaching Philosophy Teaching is one process of self-presentation, through which you represent the long-living knowledge of human kind. It really matters what you are thinking about your teaching philosophy. For me, according to my understandings of teaching, I would like to highlight the equality of teaching and learning, the nature of human beings, and being open-minded.\n Everyone is equal  Respect Your Audience. A good lesson I learnt from this class come with a question: what should you do when your students did a good job? If not, what will you do? Reflect about the answer. Do you want to reward or punish them? Remember your answer in heart.\nI would like to introduce Skinner’s box invented by Frederic Skinner, which contains levers that an animal can press, stimulus lights, electric grid, and food pellet. Following the logic of behaviorism, when the subject correctly performs the behavior, the chamber mechanism delivers food or another reward. Or else, the box delivers a punishment for incorrect or missing responses.\nThus, you may realize that you are treating your students as passive experimental subjects. The beginning point is never to treat your students as experimental rats, and even animals deserve your respects. Students are human beings who have their own feelings, emotions, and values. The first step of teaching should be to learn to respect your audiences, even though they behave passively, or make no progress.\n Understanding human nature  Effective teaching is to impose a set of values \u0026amp; beliefs on the student. The most important part should be teaching the students how to learn. The best way of learning should be acting according to the nature of human beings. Everyone had been a curious kid who wanted to explore every part of the world. Just like the cat is curious about the fish (sometime, for eating, while sometimes just for fun), human beings, in the nature, are curious about the part of knowledge they are interested in. The second step of effective teaching should be inspiring your students to fulfill their interests in the learning process.\nI was always not surprised about the story of Thomas Suarez, the 12 years old kid who made two iphone Apps by learning python, java, and c. Little Thomas has been fascinated by computers and technology before kindergarten. What the teacher should think is how could we contribute to the audiences’ real interests, rather than beat around the bush complaining why the students have no passion in the boring class.\n Being Open-minded  The world is always changed by new comers. The teacher will finally find his or her understandings about the cutting-edge scientific study are not perfect. The best way is not to constrain the students from challenging the tradition. Being open-minded, sit down, and enjoy the new outline drawn by the young people.\n","date":1516060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516060800,"objectID":"7465def13bcdb067e92f42c2035906be","permalink":"https://chengjunwang.com/note/note_archive/2015-10-30-on-teaching/","publishdate":"2018-01-16T00:00:00Z","relpermalink":"/note/note_archive/2015-10-30-on-teaching/","section":"note","summary":" ","tags":["教学"],"title":"On teaching","type":"note"},{"authors":null,"categories":null,"content":" 新职工逐月住房补贴发放比例由目前24%调整为26% 南京大学房地产管理处 南房产【2018】1号 《关于调整老职工租金补贴、新职工逐月住房补贴发放比例的通知》\n各院系、各单位: 根据苏事管【2017】63 号《关于统一新老职工住房货币化分配政策的通知》文件精神，参照江苏省机关事业单位的一般做法，经学校党政联席 会议研究决定，对 1998 年 11 月 30 日以前参加工作的老职工(含离退休) (以下简称老职工)提租补贴比例及 1998 年 12 月 1 日以后参加工作的新职工(以下简称新职工)逐月住房补贴发放比例调整如下:\n一、比例调整 老职工提租补贴发放比例由目前20%调整为26% ;新职工逐月住房补贴发放比例由目前24%调整为26%。\n二、补发办法 本次老职工租金补贴及新职工逐月住房补贴发放比例调整从2017年7 月起补发调整差额。预计补发差额将于本月到账。\n特此通知。 房地产管理处 2018年1月23日\n新聘用教职工住房租金补贴、货币补贴 《南京大学新聘用教职工住房货币补贴、租金补贴及贷款贴息暂行办法》（2004）文件，\n 租金补贴税前总额1.44万元  每个月发放1200元，发放12个月。  货币补贴税前总额17万元  首次发放11万 剩余6万每月发放500元，发放10年。 工作不满十年，退换11万中相应比例。   2018年1月收入    岗位工资 2210 薪级工资 890 省贴 165 岗贴 395     交补 500 同城 410 岗责考勤 690 岗位津贴 4400   安家费 2500 绩效扣减 -650 应发 11510 会费 15.5   养老预扣 588 大病互助 20 个税 929.4 实发 9957.1    公积金好像没有了呀！\n更新 一直以来，蓝鲸大学都是南京高校里收入最低的，当然是指中位平均数1。2016年4月开始，根据建设双一流大学的需要，对岗位工资进行调整。岗位工资增加3333元。另外，发新职工住房补贴2400；应发总额变成了16033元。比起中山大学一月两万的专职科研收入还要少4000元。但同时，国家的养老政策调整了，加入了大幅度的养老预扣1600，减去其它杂七杂八，到手11718元。到了7月份，交通补贴增加了200元。\n   岗位工资 交补 新职工房贴 应发 会费 公积 养老预扣 大病互助 个税 实发     13333 300 2400 16033 66.67 1200 1600 20 1428.25 11718.08    薪资纳税计算  学校财务处 http://ndcw.nju.edu.cn/\n 江苏省南京地方税务局 http://nj.jsds.gov.cn/art/2011/6/28/art_16724_418203.html\n  交补300、会费50、大病互助20、公积金1200，不算入纳税范围。交补是交通补贴；会费是工会会费是在工资中提取的工会经费。大学没有医疗保险，只有大病互助。住房公积金是1200元，年初还会交一次失业险50。其中，*只有*住房公积金不交税。\n10000+300-1200 = 9100  3500以上为纳税标准，我的账单上写565元所得税，\n应纳个人所得税税额=应纳税所得额×适用税率-速算扣除数； ((10000- 1200 + 300)- 3500)*0.2 - 555 = 565  扣除标准3500元/月（2011年9月1日起正式执行）（工资、薪金所得适用）；个税免征额3500元（工资薪金所得适用）。关于税率和速算扣除数参见：http://www.chinaacc.com/kuaijishiwu/gssw/ni1501272983.shtml\n假设其它工薪收入为50万，那么可以使用以下公式计算。基本工资应交税部分9100元，该部分交税565。其它工薪收入x加上9100即为该月总纳税金额，应纳税所得额乘以税率，再减去速算扣除数就是本月应缴纳税收，减去基本工资缴纳税收565，就是本月其它工薪收入部分缴纳的税额。具体如下：\ndef tax(x, rate, extra): return (x+9100-3500)*rate-extra-565 tax(10000, 0.25, 1005)*50 = 116500 tax(20000, 0.25, 1005)*25 = 120750 tax(40000, 0.30, 2755)*12 + tax(20000, 0.25, 1005) = 129150 tax(50000, 0.35, 5505)*10 = 133900 tax(500000, 0.45, 13505) = 213450  从2016年1月到2018年1月，共计25个月。\n劳务报酬纳税计算 您输入的税前劳务报酬总额为：500000， 应纳所得税额为：153000， 税后劳务报酬总额为：347000\n 青椒最可怜，但是院士，各种国家人才收入并不低。 ^   ","date":1514678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514678400,"objectID":"dccaf1ab91ee17588f66d2be01b7638f","permalink":"https://chengjunwang.com/note/note_archive/2015-12-31-income/","publishdate":"2017-12-31T00:00:00Z","relpermalink":"/note/note_archive/2015-12-31-income/","section":"note","summary":" ","tags":null,"title":"理解个人所得税","type":"note"},{"authors":null,"categories":null,"content":" 计算传播2017非毕业班的同学们：我8月8日登陆教务处系统录入成绩，发现系统暂时关闭了成绩录入；联系教务处（025-89682303）回复说因为系统原因，我需要开学后才能给你们录入成绩。\nhttps://github.com/computational-class/cc2017/issues/4\nSUNBELT2017社会网络分析国际研讨会 2017年6月4日上午，实验中心成员王成军在北京参加了2017年XXXV|| International Network for Social Network Analysis Conference 社会网络分析国际研讨会及第十三届中国社会学会社会网与社会资本研究专业委员会年会，发表论文Leveraging the Flow of Collective Attention for\u000bComputational Communication Research，并主持社会网络与计算传播学分论坛第二场。\n本科生论文答辩  5月27日 14:00 费彝民楼A407  指导学术论文  专硕  周纬 《权威与中心:基于HITS算法的收视率分析》  本科生  黄浩 134056004 􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰关于搭讪艺术家的行为动机与策略的调查报告 沈越 《“梦之队”统治奥运会？》 曾维靓 131050038 《大学生群体对于微博原生广告的态度及其影响因素》 􏴊􏴋􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓   云南白族扎染暑期社会实践指导  Q: 关于实际想探究问题，我们又探究了一下，但感觉都找不到很具体的研究方向，我整理了一下我们大概的想法，麻烦老师你看看有没有哪个想法具有可研究性😶\n  1. 民族旅游发展下的“扎染女”的生存现状与角色变迁 2.扎染工艺需要做出怎样的改变，才能继续发展? 3.当地工艺在过去是怎么发展和延续的？ 4.我们可以研究当地人在怎么努力挽救这个工艺么\u0014 5.从扎染看当地经济结构的变迁？ 6.探究云南白族扎染工艺当前生存状况并以白族扎染为例探究对传统手工艺的生产性方式保护. 7.探究白族扎染的工艺特色，艺术特征，在现代社会的创新运用.  A: 首先概念化，白族扎染是一种国家非物质文化遗产，也是一种传传统手工技艺。这背后对应着什么概念？然后是寻找新的问题。白族扎染作为一种手工技艺，在传承的过程中存在什么新的问题（其它手工艺没有的）？当前产业化的趋势使部分传统扎染技艺走向消亡，原有的民间特色开始退化，污染问题日益突出，市场经营滋生了对经济利益的过度追求，植物染料板兰根供不应求。在此情势下，白族扎染技艺的传承受到困扰。产业化是手工艺凋亡的关键原因，这个解释力很强，白族扎染很难幸免。要确保找到的问题是新的问题，即明确而且有意义。如有可能，要尝试理论化，找找既有的理论如何解释传统工艺的传承。研究问题要将个体（研究者）的困惑与社会结构（问题）联系起来。你们要好好琢磨一下，面对这种手工艺，你们有什么困惑？它又反应了什么social issue？强烈建议你们首先查询相关的论文和图书。\n华人思想库-省侨办共建智库（华智）项目讨论 《全球治理时代的中国新型智库》\n 陈晓晨 （人大重阳金融研究院专家） 2017-04-28 9:00 am 费彝民楼5楼圆桌会议室  信得过、用得着、靠得住；建设自己的报送渠道；资金来源稳定，不干涉。\n计算传播学——用AI穿透你的注意力壁垒  集智学园简介：http://campus.swarma.org/gvid=10140 时间：2017-04-12 20:00-23:00 网址：http://xue.duobeiyun.com  硕士预答辩  费彝民楼503 2017-03-30 16:00  计算传播讲座 2017年3月22日 10：00-12：00， 费彝民楼A418， 王成军向2016级博士生同学介绍计算传播学研究进展，包括计算社会科学的发展状况、代表性研究成果，如何评价其理论创新问题，并对社会科学理论进入丛林的问题进行了讨论。\n博士之家  地点：费彝民楼A418 时间：3月10日 12：00-14：00 主讲者：吴愈晓 主持人：王成军  创享沙龙：对话音乐与虚拟现实技术  地点：南京大学（仙林校区） 大学生活动中心南花园206 时间：2月27日 18：30-19：30 主讲者：向雪怀、王成军  南大新闻 音乐人向雪怀与我校师生对话VR技术与校园音乐 \n","date":1514442727,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514442727,"objectID":"baad682259984c3ed1ef26e4eed76593","permalink":"https://chengjunwang.com/zh/cn/news2017.zh/","publishdate":"2017-12-28T14:32:07+08:00","relpermalink":"/zh/cn/news2017.zh/","section":"zh","summary":"\n","tags":["news"],"title":"2017年“大事记”","type":"zh"},{"authors":null,"categories":null,"content":"养老保险基数核定 上交时如签字则视为确定（所以大家还是可以照此ppt算一下，虽然真的有点烧脑）有问题及时私信联系我。其他各类签字领卡等请各位老师在9月30日前至我办公室440完成。\n 当年度缴费基数按照上一年度12月份工资水平（含基本工资改革部分）确定； 基数=（岗位工资+薪级工资）+（综合补贴+省定岗贴+同城待遇 +岗责考勤奖）+年度岗位津贴/12+绩效扣减； 根据国办发[2015]3号文，自2014年10月起国家工资标准调整并做绩效扣减。我校于2015年12月工资发放后完成调标补发，因此在计算基数时2014年和2015年12月工资中岗位工资和薪级工资需由0607标准转换为1410标准并增加绩效扣减项（相应标准附后）； 2015年薪级调整在12月工资发放后完成，因此薪级需先增加一级后再对应1410标准；  链接: https://pan.baidu.com/s/10UXihs7gYjdTjUZvOEZdzA 提取码: ndbs\n2014年 第二批次 应发C 50000 个税C 3725 实发C 46275\n 备注C 14年09月起薪，补5个月\n 2015年 2015-2 第一批次 岗位工资 10000 交补 300 应发 10300 会费 50 失业险 50 大病互助 20 个税 795 实发 9385\n2015-3 第一批次 岗位工资 10000 交补 300 应发 10300 会费 50 公积 1200 失业险 50 大病互助 20 临时扣款 7200 实发 1780\n2015-4 第一批次 岗位工资 10000 交补 300 应发 10300 会费 50 公积 1200 大病互助 20 个税 565 实发 8465\n2015-5 第一批次 岗位工资 10000 交补 300 应发 10300 会费 50 公积 1200 大病互助 20 个税 565 实发 8465\n 从2015年5月到2017年3月，每个月都固定是8465.\n 2016年 2016-12 第一批次 岗位工资 10000 交补 300 应发 10300 会费 50 公积 1200 大病互助 20 个税 565 实发 8465\n2017年 2017-4 第一批次 岗位工资 10000 交补 300 应发 10300 会费 50 公积 1200 大病互助 20 个税 565 实发 8465 第三批次 应发D 2400 个税D 600 实发D 1800 备注D 新职工房贴 第四批次 应发E 600 个税E 150 实发E 450 备注E 房贴比例调整补差\n2017-5 第一批次 岗位工资 13333 交补 300 新职工房帖 2400 应发 16033 会费 66.67 公积 1200 养老预扣 1600 大病互助 20 个税 1428.25 实发 11718.08\n2017-6 第一批次 岗位工资 13333 交补 300 新职工房帖 2400 应发 16033 会费 66.67 公积 1200 养老预扣 1600 大病互助 20 个税 1428.25 实发 11718.08\n第四批次 应发E 600 个税E 150 实发E 450 备注E 交补调标补发\n2017-7 第一批次 岗位工资 13333 交补 500 新职工房帖 2400 应发 16233 会费 66.67 公积 1200 养老预扣 1600 大病互助 20 个税 1478.25 实发 11868.08\n 从2017年7\u0008月到11月都是11868.08\n 2017-11 第一批次 岗位工资 13333 交补 500 新职工房帖 2400 应发 16233 会费 66.67 公积 1200 养老预扣 1600 大病互助 20 个税 1478.25 实发 11868.08\n第二批次 应发C 10714 个税C 887.8 实发C 9826.2\n 备注C 17年12月起薪（博后类）\n 2018年 2018-1 第一批次 岗位工资 2210 薪级工资 890 省贴 165 岗贴 395 交补 500 同城 410 岗责考勤 690 岗位津贴 4400 安家费 2500 绩效扣减 -650 应发 11510 会费 15.5 养老预扣 588 大病互助 20 个税 929.4 实发 9957.1\n第三批次 应发D 1146 个税D 229.2 实发D 916.8 备注D 当月50%绩效奖励\n2018-2 第一批次 岗位工资 2210 薪级工资 890 省贴 165 岗贴 395 交补 500 同城 410 岗责考勤 690 岗位津贴 4400 安家费 2500 新职工房帖 8925 货币补贴 500 租房补贴 1200 绩效扣减 -650 应发 22135 会费 15.5 公积 1373 养老预扣 588 失业险 18.3 大病互助 20 个税 2467.85 临时扣款 2764.3 实发 14888.05\n第三批次 应发D 1145.8 个税D 286.45 实发D 859.35 备注D 当月50%绩效\n2018-3 第一批次 岗位工资 2210 薪级工资 890 省贴 165 交补 500 岗责考勤 690 岗位津贴 4400 安家费 2500 货币补贴 500 租房补贴 1200 绩效扣减 -650 应发 16185 会费 15.5 公积 1373 养老预扣 588 失业险 18.3 大病互助 20 个税 891.14 实发 13279.06\n第二批次 应发C 1145.8 个税C 229.16 实发C 916.64 备注C 当月50%绩效\n2018-7 第一批次 岗位工资 2210 薪级工资 955 省贴 165 交补 500 岗责考勤 690 岗位津贴 4400 安家费 2500 货币补贴 500 租房补贴 1200 绩效扣减 -650 应发 16250 会费 15.83 公积 1373 养老预扣 588 失业险 18.3 大病互助 20 个税 904.14 实发 13330.73\n2018-8 第一批次 岗位工资 2210 薪级工资 955 省贴 165 交补 500 岗责考勤 690 岗位津贴 4400 安家费 2500 货币补贴 500 租房补贴 1200 绩效扣减 -650 应发 16250 会费 15.83 公积 1373 养老预扣 588 失业险 18.3 大病互助 20 个税 904.14 实发 13330.73\n第二批次 应发C 1145.8 个税C 229.16 实发C 916.64 备注C 当月50%绩效奖励\n住房补贴提取 自从去年开始，住房补贴不在和住房公积金一起交，而是直接发给个人。累计的住房补贴也需要办理提取。住房补贴查看办法：我的南京APP-公积金，差不多64408元。\n签领表中无卡人员备注“照片需采集”，原因多为户口不在江苏或本人未更新身份证导致公安系统中无相关人员照片信息，省社保制卡中心暂无法制卡，请提醒该类人员按以下要求补全照片信息后提交至我处：\n 参照第二代居民身份证照片标准执行，使用的照片为申领人近期彩色正面白底免冠人像的数码化图像； 规格为32mm*26mm，即数字照片为358像素（宽）441像素（高）规格，文件大小10kb-60kb； 文件名：“身份证号码_姓名.jpg”（身份证号如有X，为大写的X）  南房产【2017】3号 关于简化住房公积金提取手续的通知 各院系、单位：\n根据南京住房公积金管理中心《关于进一步简化住房公积金提取手续的通知》文件精神，为简化我校教职工办理住房公积金提取手续，进一步提高服务水平，自2018年1月1日起，对我校教职工办理住房公积金提取手续调整变更如下：\n 一、 取消提取申请单。今后我校教职工办理住房公积金提取手续，无需在学校办理任何手续，直接携带相关证明材料至南京市建设银行办理即可。需提供证明材料请参见《南京住房公积金提取审核管理规程》。 二、 取消我校原规定每月11日至15日办理公积金提取业务的限制。今后我校教职工在南京市建设银行的服务时间可以随时办理住房公积金提取业务。 三、 可以办理同行提取通兑业务。今后我校教职工可以到建设银行在南京市主城区（玄武区、秦淮区、建邺区、鼓楼区、栖霞区、雨花台区）内任一提取办理网点申请提取住房公积金。具体办理网点附后。 四、可以办理购房提取网上业务。今后我校教职工及其配偶在南京市主城区（玄武区、秦淮区、建邺区、鼓楼区、栖霞区、雨花台区）购买自住住房的，可以在南京市住房公积金管理中心网上办事大厅（www.njgjj.com）申请办理提取业务。操作指南详见南京住房公积金管理中心网站。  请各院系、各单位将本次住房公积金提取手续调整内容务必传达至本单位教职工。如有疑问，请与房地产管理处住房管理科联系，联系电话89686054。\n 附件1：《关于进一步简化住房公积金提取手续的通知》 附件2：《南京住房公积金提取审核管理规程》 附件3：建设银行承办公积金归集业务网点信息一览表（主城区内）\n 房地产管理处 2017年12月26日   关于进一步简化住房公积金提取手续的通知 2017-12-25 各住房公积金缴存单位、职工： 为贯彻落实“简政放权、放管结合、优化服务”改革要 求，进一步方便缴存职工提取住房公积金，提高服务水平， 现就简化住房公积金提取手续有关事项通知如下：\n 一、取消提取申请单。自 2018 年 1 月 1 日起，职工办理住房公积金提取业务无需单位开具申请单。 二、开展购房提取网上业务。自 2018 年 1 月 1 日起，职工及其配偶在南京市主城区（玄武区、秦淮区、建邺区、鼓楼区、栖霞区、雨花台区）购买自住住房的，可以在中心网上办事大厅（www.njgjj.com）申请办理提取业务。操作指南详见中心网站。\n 三、开展同行提取通兑业务。自 2018 年 1 月 1 日起，在南京市主城区（玄武区、秦淮区、建邺区、鼓楼区、栖霞区、雨花台区）缴存住房公积金的职工可以到其缴存银行主城区内任一提取办理网点申请提取住房公积金。\n  南京住房公积金管理中心\n关于进一步加强购买自住住房提取审核的通知 2017-04-13\n各住房公积金归集业务承办银行，中心各处室、分中心： 为贯彻落实国务院《住房公积金管理条例》关于“住房公积金应当用于职工购买、建造、翻建、大修自住住房”的规定，更好地发挥住房公积金保障性和互助性，引导缴存职工住房消费回归“房子是用来住的、不是用来炒的”定位，现就进一步加强购买自住住房提取（含提取偿还购房贷款本息,下同）审核有关事项通知如下：\n 一、支持职工刚性住房消费提取。职工（配偶）在本市行政区域内购买首套或第二套改善型自住住房，申请提取住房公积金时无需补充提供自住证明材料。 二、限制投机投资性购房提取。职工（配偶）在本市行政区域内无产权住房，在本市行政辖区以外购房，通过审核其（配偶）身份证、婚姻、购房材料以及购房所在地的户口簿或社保缴纳证明等材料，核实其自住情况。  　**南京住房公积金管理中心 **\n　2017年4月12日\n南京住房公积金管理中心 南京市玄武区太平北路51号 http://j.map.baidu.com/B-qLN 3号线浮桥、2号线大行宫\nhttp://gjj.nanjing.gov.cn/wsbsdt/\n 公积金账号：801017435215 住房补贴账号：804001045006  温馨提示：反显的银行账号是公积金联名卡号，如需修改或没有反显可录入本人公积金缴存行的储蓄卡号，此账号作为网上提取资金收款账号，请认真核对填写。\n领卡 使用建设银行的银行卡，领卡：身份证\n南大仙林校区学生宿舍24幢一楼、第十一学生食堂对面。网点设有电子银行体验区、自助填单机、自助发卡机等先进设备，让南大师生体验在建行办理业务的便利，实现足不出户就能办理各类非现金业务。\n20100466817 南京大学 网点号0001\n山西路68号 http://j.map.baidu.com/PLrLN\n通过当地025-12329热线输入身份证号查询。\n住房公积金、住房补贴提取申请单 银行也可以领取住房公积金、住房补贴提取申请单。\n 先查询自己有多少钱。 去银行领这个单子，可以多领几张 填完了单位盖章 同时拿着购房合同贷款合同 去取钱。  南京住房公积金管理中心文件 宁金管〔2017〕51号\n关于开展南京住房公积金网上提取业务的通知\n各住房公积金缴存单位，缴存职工： 为认真落实“放管服”改革和住房租赁试点工作要求，进一步方便缴存职工提取住房公积金，提升服务效能和水平，中心于2017年9月1日起开展离退休和支付房租网上提取住房公积金业务。\n附件：南京住房公积金网上提取业务操作指南\n南京住房公积金管理中心 2017年8月23日\n附件：\n南京住房公积金网上提取业务操作指南 为方便和规范职工办理住房公积金网上提取业务，保证网上提取业务顺利开展，制定本操作指南。\n一、网上登录\n职工需登录南京住房公积金管理中心网上办事大厅（www.njgjj.com）办理网上提取业务，登录方式有人脸识别和密码两种。\n （一）人脸识别登录 职工点击“人脸识别用户”，输入姓名和证件号码，点击“立即登录”，系统自动生成二维码，职工用支付宝扫描二维码并进行人脸识别操作，人脸识别通过即登录成功。 （二）个人密码登录 职工点击“个人密码用户”，输入证件号码、密码和验证码即可登录。初始密码为个人住房公积金账号后四位数字加两个“0”（建议登录后修改初始密码）。  二、身份认证\n为保证网上提取业务安全，职工办理网上提取业务需进行身份认证。身份认证方式有柜面和网络两种。\n （一）柜面身份认证 职工携带本人身份证和住房公积金联名卡（住房公积金账户所在银行的银行卡）到缴存银行网点进行身份认证。职工需签订《南京住房公积金网上办理业务协议书》，签订后缴存银行网点工作人员在中心业务系统（提取子系统-提取登记-网上提取身份认证）中输入职工联名（银行）卡卡号和手机号，获取并输入验证码后提交即完成身份认证。 （二）网上身份认证 职工登录网上办事大厅后，点击“身份认证-网厅业务个人身份认证”菜单，系统自动生成二维码，职工用支付宝扫描二维码并进行人脸识别操作，人脸识别通过后录入职工联名（银行）卡卡号和手机号，获取并输入验证码后提交即完成身份认证。如人脸识别无法通过请到柜面进行身份认证。  三、网上申请\n职工身份认证后即可办理网上提取申请，目前网上可以办理离退休和支付房租提取申请。\n （一）离退休提取申请 达到国家法定退休年龄且单位已为其办理住房公积金账户封存手续的职工可以在网上申请。职工登录网上办事大厅后点击“提取业务-网上退休销户提取登记”，获取并输入手机验证码提交后即申请成功。 （二）支付房租提取申请 职工及其配偶在南京市无产权住房的可以在网上申请。职工登录网上办事大厅后点击“提取业务-网上租房提取登记”，输入婚姻状况信息、提取金额、手机验证码提交后即申请成功。  四、资金支付\n职工申请成功后，系统于次日（工作日）将提取资金转入职工本人联名（银行）卡，同时给职工发送资金到账提示短信。\n南京住房公积金管理中心办公室 2017年8月23日印发\n","date":1512993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512993600,"objectID":"567d87fd069ac7b3f0c0f641c7623c5e","permalink":"https://chengjunwang.com/note/2017-12-12-housing-accumulation-fund/","publishdate":"2017-12-11T12:00:00Z","relpermalink":"/note/2017-12-12-housing-accumulation-fund/","section":"note","summary":" ","tags":["南京","公积金","补贴"],"title":"南京住房公积金和补贴","type":"note"},{"authors":null,"categories":null,"content":" 文献综述：采用引文分析等方法系统整理舆论扩散研究领域的论文和成果。尤其是针对舆论扩散的讨论模型进行了系统的总结，从参与者、议题、行动三个维度刻画了舆论扩散的过程。 数据获取：基本完成数据收集方案，获取1千万新浪微博用户的数据信息，建立新浪微博舆论扩散数据库；收集了占领华尔街这一主题的推特数据库；收集了Digg新闻扩散数据库。 数据分析：对这个数据进行数据清洗、分析，按照门槛模型、扩散深度等概念的要求，从多个维度对舆论扩散数据进行测量。一、尝试采用网路科学分析方法，文本挖掘的方法挖掘微博信息扩散的网络门槛与扩散规模之间的关系，发现扩散深度对于网络门槛影响的调节作用。二、对于占领华尔街的推特数据，从时间序列分析方法对数据进行分析和挖掘，有针对性地提取了舆论的讨论模型的三要素：参与者、议题、行动，建立了结构化贝叶斯模型，分析了三者对于舆论演化的整体影响；三、针对Digg数据，从注意力流动网络的角度刻画了新闻舆论扩散的过程； 整理了现阶段的研究成果，发表了一系列相关的论文，其中包括五篇英文论文和三篇中文论文，以及多篇会议论文。 经费使用：主要用于会议、差旅和少数办公用品，共花费18735元。  ","date":1511568000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511568000,"objectID":"deebd170d9a0914951e812dabe98ef72","permalink":"https://chengjunwang.com/zh/cn/2017-11-25-cn-project.zh/","publishdate":"2017-11-25T00:00:00Z","relpermalink":"/zh/cn/2017-11-25-cn-project.zh/","section":"zh","summary":"　基本完成数据收集方案，获取1千万新浪微博用户的数据信息，建立新浪微博舆论扩散数据库；收集了占领华尔街这一主题的推特数据库；收集了Digg新闻扩散数据库。\n","tags":["news"],"title":"2017年社科项目进展","type":"zh"},{"authors":null,"categories":null,"content":" turkserver\nhttp://turkserver.readthedocs.io/\nTutorials：quick start http://turkserver.readthedocs.io/en/latest/quick-start.html\nTurkServer/tutorial https://github.com/TurkServer/tutorial\n install meteor sign up AWS Account, get the id and secret.  浏览器歧视: - 一个可以打开 http://localhost:3000/experiment - 另一个打开 http://localhost:3000/turkserver\nOops, looks like there\u0026rsquo;s no route on the client or the server for url: \u0026laquo;http://localhost:3000/mturk/externalSubmit.\u0026quot;\nmlab https://mlab.com/\nazure https://portal.azure.cn/\n chengjunwang@chengjunwang.partner.onmschina.cn Datalab2017  error chengjuns-MacBook-Pro:server chengjun$ MONGO_URL=mongodb://localhost:27017/test PORT=3000 ROOT_URL=http://localhost:3000 npm start\n meteor-dev-bundle@0.0.0 start /Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server node ../../main\n /Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/node_modules/fibers/future.js:313 throw(ex); ^\nError: failed to connect to [localhost:27017] at Object.Future.wait (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/node_modules/fibers/future.js:449:15) at new MongoConnection (packages/mongo/mongo_driver.js:213:27) at new MongoInternals.RemoteCollectionDriver (packages/mongo/remote_collection_driver.js:4:16) at Object. (packages/mongo/remote_collection_driver.js:38:10) at Object.defaultRemoteCollectionDriver (packages/underscore/underscore.js:750:1) at new Mongo.Collection (packages/mongo/collection.js:103:40) at AccountsServer.AccountsCommon (packages/accounts-base/accounts_common.js:23:18) at new AccountsServer (packages/accounts-base/accounts_server.js:18:5) at meteorInstall.node_modules.meteor.accounts-base.server_main.js (packages/accounts-base/server_main.js:9:12) at fileEvaluate (packages/modules-runtime/.npm/package/node_modules/install/install.js:153:1) - - - - - at . (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm/node_modules/meteor/npm-mongo/node_modules/mongodb/lib/mongodb/connection/server.js:556:25) at emitThree (events.js:116:13) at emit (events.js:194:7) at . (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm/node_modules/meteor/npm-mongo/node_modules/mongodb/lib/mongodb/connection/connection_pool.js:156:15) at emitTwo (events.js:106:13) at emit (events.js:191:7) at Socket. (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm/node_modules/meteor/npm-mongo/node_modules/mongodb/lib/mongodb/connection/connection.js:534:10) at emitOne (events.js:96:13) at Socket.emit (events.js:188:7) at emitErrorNT (net.js:1272:8)\nnpm ERR! Darwin 17.2.0 npm ERR! argv \u0026laquo;/usr/local/bin/node\u0026raquo; \u0026laquo;/usr/local/bin/npm\u0026raquo; \u0026laquo;start\u0026raquo; npm ERR! node v6.2.2 npm ERR! npm v3.9.5 npm ERR! code ELIFECYCLE npm ERR! meteor-dev-bundle@0.0.0 start: node ../../main npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the meteor-dev-bundle@0.0.0 start script \u0026lsquo;node ../../main\u0026rsquo;. npm ERR! Make sure you have the latest version of node.js and npm installed. npm ERR! If you do, this is most likely a problem with the meteor-dev-bundle package, npm ERR! not with npm itself. npm ERR! Tell the author that this fails on your system: npm ERR! node ../../main npm ERR! You can get information on how to open an issue for this project with: npm ERR! npm bugs meteor-dev-bundle npm ERR! Or if that isn\u0026rsquo;t available, you can get their info via: npm ERR! npm owner ls meteor-dev-bundle npm ERR! There is likely additional logging output above.\nnpm ERR! Please include the following file with any support request: npm ERR! /Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm-debug.log chengjuns-MacBook\n","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509235200,"objectID":"d4a04e25d0e067a93f7eb2ee27f8c257","permalink":"https://chengjunwang.com/zh/cn/2017-12-14-turkserver.zh/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/cn/2017-12-14-turkserver.zh/","section":"zh","summary":"TurkServer is a framework based on the JavaScript app platform Meteor that makes it easy to build interactive web-based user experiments for deployment on Amazon Mechanical Turk.\n","tags":["news"],"title":"2017年黑客马拉松之turkserver","type":"zh"},{"authors":null,"categories":null,"content":" scholarNetwork Developed by Cheng-Jun Wang \u0026amp; Lingfei Wu\nCheng-Jun Wang wangchj04@gmail.com Lingfei Wu wlf850927@gmail.com\nIntroduction scholarNetwork is a python package for crawling and visualizing the co-author network of Google Scholar.\nTo use it, you must have access to Google Scholar, and you would also install beautifulsoup4 and networkx during the installation process.\nInstall Install from pypi using pip or easy_install\n pip install scholarNetwork  or\n easy_install scholarNetwork  Use  from scholarNetwork import scholarNetwork import matplotlib.pyplot as plt import networkx as nx ## The seed of crawler seed = 'https://scholar.google.nl/citations?user=nNdt_G8AAAAJ\u0026amp;hl=en\u0026amp;oe=ASCII' ## How many nodes do you want to visulize? Always start with a small one. Nmax = 21 ## Get the graph g g = scholarNetwork.getGraph(seed, Nmax) ## plot the network pos=nx.spring_layout(g) #setup the layout nx.draw(g, pos, node_shape = 'o', edge_color = 'gray', width = 0.5, with_labels = True, arrows = True) plt.show()  Of course, you can get a much larger graph to see what\u0026rsquo;s happening around you, just to change the value of Nmax. However, you have to be patient to wait for much longer time.\n","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509235200,"objectID":"756dd770af7cf858bf195bbab200aa56","permalink":"https://chengjunwang.com/post/en/2015-02-22-scholarnetwork/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/post/en/2015-02-22-scholarnetwork/","section":"post","summary":"scholarNetwork is a python package for crawling and visualizing the co-author network of Google Scholar.\n","tags":["news"],"title":"scholarNetwork: Visualizing Google Scholar Network","type":"post"},{"authors":null,"categories":null,"content":"  中文名称：计算传播学 拼音：jisuan chuanbo\n 外文名称：Computational Communication Research  基本概念条（长）\n1. 定义和定性叙述 计算传播学是计算社会科学一个重要分支，它主要关注人类传播行为可计算的基础问题，以传播网络分析、传播文本挖掘、数据科学等作为主要的分析工具，大规模地收集并分析人类传播行为背后的模式或法则，并分析模式背后的生成机制以及基本原理，可以被广泛地应用到新闻学研究、 数据新闻和计算广告等场景。狭义的计算传播是指数据驱动的、借助于可算方法所进行的传播过程，而分析计算传播现象的研究领域就是计算传播学。\n2. 名称来源、又名 计算传播学（英文：computational communication research）起源于计算社会科学（英文：computational social science）。2009年，Lazer等一批社会科学家、计算机科学家和物理学家在《科学》杂志上发表题为 “网络中的生活:计算社会科学时代的到来”的论文，宣告计算社会科学的诞生，提出发展计算 社会科学的主要逻辑在于我们就生活在网络之中，例如发邮件、打电话、在线支付。这些网络化的行为以数字化痕迹的方式被记录下来。计算社会科学是一个正在涌现的研究领域，强调采用计算方法研究社会科学，在利用人类社会不断增强的数据收集和分析能力方面。21世纪是计算社会科学的时代。计算社会科学具备前所未有的广度、深度和规模，为研究者提供了一个理解复杂社会系统的崭新机会。毫无疑问，采用可算方法、基于大规模的互联网上的人类传播行为数据为代表的传播学研究属于计算社会科学这一研究传统。\n3. 概念形成过程 计算传播学的概念起源于是计算社会科学的发展。计算社会科学以分析社会系统的复杂性作为主要研究范式。社会系统作为一个复杂系统，本身包含了多重本体以及他们之间众多的联系，既有从微观到宏观的联系，也有从宏观到微观的影 响，这造就了社会现象所特有的复杂性。计算社会科学研究主要关注复杂社会系统中的社会现象、社会行为、社会 组织的涌现，例如居住隔离、合作、互惠、社会规范、市场、国家。计算社会科学中的“涌现” 往往表现为一种群体智慧，它是通过海量的异质性个体之间的互动而在群体层面出现的结果。作为一种崭新的研究范式，计算社会科学从数据基础和计算方法两个层面丰富了人们对于 社会现象的认识。\n互联网上的人类传播行为是驱动计算社会科学发展的一个主要动力。与自然科学相比，社会现象卷入了海量的异质性个体的互动行为，因而异常复杂并且难以预测。通常社会科学研究的数据往往是用户报告的、静态的、小规模数据。互联网行为数据和大规模的互联网实验却提供了另外一种可能性。邓肯•瓦茨认为互联网传播数据将会变革我们对于群体人类行为的理解，并产生了一种新的社会科学，邓肯•瓦茨称之为“二十一世纪的科学”，也就是后来广为人知的“计算社会科学”。\nShah等人曾提出目前社交数据多为传播文本数据，并且与图形数据和视频数据相比，传播文本数据相对容易分析，因而计算社会科学将 传播文本数据作为关注焦点之一，并认为这意味着计算传播学(computational communication science)的兴起。Cohen等人2011年就提出采用计算机科学技术发展新闻学的主张。发展计算传播学研究已经成为计算社会科学在新闻传播领域主要工作。2014年祝建华等人回顾和讨论了计算社会科学在新闻传播领域的应用，按照经典的5W模型，系统介绍了计算社会科学在传播者、渠道、受众、内容、效果 五个领域的主要应用案例;(祝建华等，2014:p.3-13)。2014年，计算传播学作为一个正式的研究领域被提出，王成军从计算社会科学的视角论述了计算传播学的理论框架，强调了寻找人类传播行为“可计算的基因”作为计算传播学发展的基础，以传播网络分析和传播文本挖掘作为主要的研究方法。2015年第一本计算传播学相关的图书《社交网络上的计算传播学》出版，这本书系统总结了采用计算传播学的视角进行社交网络研究的方法、理论和进展。2015年，南京大学成立了计算传播学实验中心，2016年第一届计算传播学论坛召开。计算传播学研究社群的涌现及其建制化发展有助于建立身份认同、促进科研合作、增强 学科间对话、运用群体智慧解决现实和理论问题。\n4. 基本内容 一、计算传播学的定义首先强调的的人类传播行为可计算的基础。人类的传播行为、传播过程和传播技术构建了一种社会复杂系统。海量的数据和不断提升的计算能力为回答人类传播学的可计算性问题提供了重要条件。以新闻扩散研究为例， 1945年Miller 在《美国社会学评论》发表题为“一个大众传播研究笔记:我们的社区怎样知道罗斯福总统的 死讯”一文。这一研究传统经历了由盛到衰，直到社交媒体发展起来又重新复兴的过程。新闻扩散研究主要关注人们通过何种渠道获知新闻，尤其是社交和(大众)媒体在其中所扮演的角色。其中，以 Greenberg的研究最为精彩，他发现社交作用与新闻扩散规模之间存在“J”形曲线关系，即对于一些小的新闻事件，社交影响与扩散规模呈反比(可能主要靠媒体传播);对于重大的新闻，社交作用则可以促进新闻扩散。然而受到传统研究方式的限制， 研究者只能采用调查问卷的方式请受访者回忆并填写相应情况，所研究的议题也往往是总统遇 刺等突发新闻事件(往往需要被动地组织研究)，因而无论所选取的新闻事件的数量还是受访者的数量均有限，这在很大程度上限制了这一研究传统。而计算社会科学的方法和工具则可以 帮助新闻扩散研究突破选题和样本的限制。王成军利用新浪微博上的大规模信息扩散数据，采用网络门槛来度量社交影响。网络门槛起源于格兰诺维特所提出的门槛理论。门槛理论假设个体是否参加某种行为的决定主要取决于他或她的朋友参与的比例。该研究验证了“J”形曲线理论;并且发现信息扩散的深度可以调节社交作用的影响，那些扩散深度低的信息往往是局部社区的信息(无法穿透社区的束缚)，社交作用(以网络门槛度量)将限制它的扩散，例如传播一个普通人生日信息的人往往 是他或她最亲密的朋友，社交作用很强，但扩散规模很小。\n二、计算传播学强调了对海量数据的收集、分析和挖掘。驱动计算传播的数据主要来自人类使用数字媒体时记录下来的数字痕迹或数字指纹。例如，当我们通过有线电视观看电视节目的时候、通过手机打电话的时候、通过互联网使用社交网站的时候，我们的行为都会被数字媒体详细地记录下来。这些海量的人类传播行为数据和媒体使用记录的数据构成了采用计算方法研究人类传播行为的基础。\n三、计算传播学强调对于基于数据的清洗、分析、挖掘等计算的过程。恰如伽利略通过自己改进的天文望远镜研究天文学，计算传播学主张利用强大的计算工具研究社会问题，例如自动化信息提取、网络分析、地理空间分析、复杂性模型、社会模拟模型等。在传统的内容分析中，需要编码员人工识别文本中的信息，采用文本挖掘的方法，可以自动地提取社会事件的属性，如事件、地点、参与者、文本的主题、文本的情感等。\n四、计算传播学强调了将大问题、大理论和大数据相结合。驱动计算传播学发展的主要力量来源于人类传播行为当中的重大问题，发展计算传播研究有助于解决新闻产业变革过程中发现的理论问题和实际困惑。就理论视角而言，计算传播学更加倾向于从复杂性的角度看待传播行为和传播过程。这种复杂性的思维方式需要研究者具备对复杂系统分析的能力和方法。值得注意的是，2017年瓦茨再次发表多篇反思计算社会科学的文章，提倡计算社会科学应该更加强调以寻找 解决方案为导向(solution-oriented)，因为社会科学存在太多的相互之间不一致的理论，而这些理论往往不能很容易地验证。寻找解决方案为导向对于新闻产业非常有价值，以新闻推荐系统为例(比如今日头 条)，如何实现更为精准的新闻推荐亟需寻找更加有价值的视角、方法和理论，可以预见经过新闻传播产业检验的理论也将具有更强的解释力和预测力。\n五、计算传播学强调了计算社会科学在理论建构方面所追求的抽象阶梯，即一个好的研究必须是重大的社会问题驱动的，并且能够找到好的数据作为支撑(第一个阶梯);要能够从数据当中挖掘出行为的模式 (第二个阶梯);最好可以阐明模式背后对应的机制(第三个阶梯);并尝试理解背后的基本原理(第四个阶梯，往往难以企及)。从数据、模式、机制、原理这样一个不断提高的抽象的阶梯，可以衡量不同的研究所处的状态和水平，为衡量计算传播学的研究提供了一个基本的标准。\n5. 意义和影响 计算传播的应用有很多，例如数据新闻、计算广告、媒体推荐系统等。计算传播学在过去的几年里，产生了深远的影响。数据新闻风靡全球，重要的国际媒体纷纷采用数据新闻，基于开放数据、数据挖掘与可视化的方式为公众提供信息和经过数据分析所发现的知识；不管是门户网站、搜索引擎、社交媒体，纷纷将计算广告作为数据变现的重要渠道，以计算方法对广告进行拍卖，实现媒体、用户、广告主三方利益的匹配；媒体推荐系统成为个性化的信息获取途径，不管是传统的社交新闻网站，还是今日头条等后起之秀，纷纷采用协同过滤的方式为用户提供信息。\n6. 参考文献 Watts, D.J., \u0026laquo;A twenty-first century science,\u0026raquo; Nature 445 (127) (2007):p.489.\nLazer, D., et al., \u0026laquo;Life in the network: The coming age of computational social science,\u0026raquo; Science 323 (5915)(2009):pp.721-723.\nGreenberg, B.S., \u0026laquo;Person-to-Person Communication in the Diffusion of News Events,\u0026raquo; Journalism Quarterly 41 (4)(1964):pp.489-494.\nWatts, D.J., \u0026laquo;Should social science be more solution-oriented?\u0026raquo; Nature Human Behaviour 1 (2017):p.0015.\n王成军.计算传播学:作为计算社会科学的传播学[J].中国网络传播研究，2014，第193-206页.\n王成军.计算传播学的起源、概念和应用[J].编辑学刊，2016(3)，第59-64页.\n祝建华、彭泰权、梁海、王成军、秦洁、陈鹤鑫.计算社会科学在新闻传播研究中的应用[J].科研信息化技术与应用，2014(2)，第3-13页.\n王成军 (2017).计算社会科学视野下的新闻学研究：挑战与机遇[J]. 新闻大学, 4:26-32\n7. 推荐书目 许小可、胡海波、张伦、王成军 （2015）社交网络上的计算传播学. 北京：中国科学出版社.\n 撰稿：王成军 审稿：巢乃鹏  ","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509235200,"objectID":"0b9cfd6338aec6f65381de8ab12c425e","permalink":"https://chengjunwang.com/zh/cn/2017-10-29-ccr.zh/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/cn/2017-10-29-ccr.zh/","section":"zh","summary":"计算传播学是计算社会科学一个重要分支，它主要关注人类传播行为可计算的基础问题，以传播网络分析、传播文本挖掘、数据科学等作为主要的分析工具，大规模地收集并分析人类传播行为背后的模式或法则，并分析模式背后的生成机制以及基本原理，可以被广泛地应用到新闻学研究、 数据新闻和计算广告等场景。狭义的计算传播是指数据驱动的、借助于可算方法所进行的传播过程，而分析计算传播现象的研究领域就是计算传播学。\n","tags":["news"],"title":"中国大百科：计算传播学","type":"zh"},{"authors":null,"categories":null,"content":"2010年9月，我作为博士生进入到香港城市大学互联网挖掘实验室以来，切身感受到了传播学研究者在互联网时代的身份焦虑。1998年邓肯-瓦茨关于小世界网络的模型和1999年阿尔伯特-巴拉巴西关于幂律和无标度网络的研究复兴了网络科学。一石激起千层浪，在学术领域产生了深远的影响。对于万维网上的人类行为的研究也形成了一个子领域，被称之为万维网科学(Web Science);伴随着社交媒体等数字媒体的发展，对于社会学而言，社会网络分析开始受到前所未有的重视，对于传播学而言，社交网络上的信息流动网络研究也引起广泛的兴趣；与此同时，机器学习和数据科学取得了突飞猛进的发展，进一步加速了计算化的浪潮；在新闻传播产业当中，数据驱动的新闻生产、计算广告和媒体推荐系统开始成为席卷世界的潮流。面对海量的互联网数据、持续困扰人类的重大社会问题、崭新的理论视角、诱人的物理学模型，在世界大战中发展起来的新闻传播学研究会走向什么地方？这构成了困扰我们的时代问题。\n面对这些挑战，或许很多人可以做一群鸵鸟，只盯住让自己感觉舒适的领域，当危险来的时候干脆把头埋进沙子里，但是年轻人没有逃避的理由。年轻研究者必须敢于冒险，才能走出不一样的路来。计算传播学正是回应这一时代叩问的一种尝试，它也给了传播学这个领域一个革命的火种。\n“计算传播学”这个词的提出源于香港城市大学互联网挖掘实验室成员之间在2012年初的一次组会讨论。每周，祝建华老师都会组织实验室成员进行内部讨论，讨论的主要内容除了每个人的研究进展之外，还包括文献分享、经验见闻等内容。在我的印象里，在这次讨论当中，我们再一次讨论了2009年大卫-拉泽等人发表在科学杂志上的一篇文章《计算社会科学》。在这篇文章当中，来自社会科学、计算机科学、网络科学等领域的资深研究者们宣告了计算社会科学的诞生，它以大规模数据收集和数据分析作为主要的工具，采用网络科学作为主要的研究视角，力图揭示个体和群体行为的模式。2012年1月29日，我在新浪博客上写了一篇短文《计算传播学:宣言与版图》，强调了将寻找人类传播行为的可计算基因作为计算传播学的发展使命。这篇小文章首先在一个名为《数字媒体阅读报告》的小圈子里流传。 在2月14日，我在与澳大利亚国立大学的指导老师Robert Ackland的邮件通信中，我提出了我想要做计算传播方面的研究的想法。2012年2月21日-23日，林武来实验室交流，分享了关于Python编程基础、数据抓取、hadoop使用等方面的知识。应该是2月21日或者2月22日，在实验室组会上，当我们再次讨论到在计算社会科学时代，我们自己期待传播学将走向什么地方这一时代问题的时候，我再次提出了计算传播（computational communication）的思路。当天晚上，吴令飞、汪臻真、我三个人在又一城散步的时候，令飞很郑重地说应该重视计算传播学的发展，在他的提议之下，2012年2月22日计算传播学谷歌邮件组建立。2月29日吴令飞在计算传播学谷歌邮件组发了第一封邮件，分享了抓取Alexa点击流网络的Python代码；2012年3月26日，计算传播学豆瓣小站正式建立。2012年底，吴令飞在多贝上发布了一系列计算传播学课程，后来更名为计算社会科学系列课程，之后他完成新书《Data Mining in Social Science》，发布在GitBook上，可免费在线阅读或者下载PDF。\n2017年春季，在酝酿第二届计算传播学论坛暨工作坊的过程中，许小可老师、张伦老师、胡海波老师和我开始计划写一本《计算传播学导论》书。按照祝建华老师的建议，我们曾对参加了2016年第一届计算传播学论坛的研究者公开征集计算传播学工作坊的题目。经过汇总整理之后的题目包括：计算机模拟/多主体建模、社交媒体数据爬取、传播文本挖掘和主题模型分析、使用深度学习进行传播学研究、社交媒体数据的时间序列分析和空间分析、传播学研究和数据新闻的可视化方法、传播网络分析（社区识别、复杂网络与信息流动）、机器学习、意见形成、Python编程，以及如何教授新闻传播学专业的学生网络分析/数据新闻/编程。我们的想法是每年遴选两个主题组织计算传播学工作坊，系统地整理和组织工作坊教学材料，基于此形成《计算传播学导论》一书的基本材料。2017年2月22-23日，第一届计算传播学工作坊在南京大学成功举办。为期一天半，分为两个子题并行进行，分别为“信息传播的网络分析”(Network Approaches to Information Diffusion)和“文本数据处理方法”(Processing Text Data)。前者定位为高级程度，聚焦于计算传播学研究中的一个核心而又困难的题目，以探讨研究设计、理论模型、数据要求、方法选择等问题为主、操作问题为辅，适合已掌握基本方法并有一定研究经验者。后者定位为入门程度，介绍用于文本数据处理的各个步骤上的方法、工具、算法等，含有众多动手操作。这次工作坊“信息传播的网络分析”部分由张子柯和王成军主讲《网络信息传播基础》、许小可讲《网络信息传播实证研究》、胡海波和阮中远讲解《网络信息传播模型》，“文本数据处理方法”部分又张伦主讲《文本分析的基本步骤与方法》、王成军介绍《主题模型》、汪臻真主讲《情感分析》。\n","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509235200,"objectID":"ca20bd97c576087db0b446b739f3a544","permalink":"https://chengjunwang.com/zh/cn/2017-12-05-backwords.zh/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/cn/2017-12-05-backwords.zh/","section":"zh","summary":"计算传播学是传播学研究者对于传播学研究方向的一次新的探索。\n","tags":["news"],"title":"后记","type":"zh"},{"authors":null,"categories":null,"content":"党的十九大报告再次对打赢脱贫攻坚战作出部署，明确指出重点攻克深度贫困地区脱贫任务，确保到2020年我国现行标准下农村人口实现脱贫，贫困县全部摘帽，解决区域性整体贫困，做到脱真贫、真脱贫。\n全国6000多万贫困人口稳定脱贫，贫困发生率从10.2%下降到4%以下。精准扶贫，不仅要精准施策，而且要精准到户。\n眼下，脱贫攻坚战的主战场正在转移到深度贫困地区。今年6月份，习近平总书记在山西考察时，深刻论述了深度贫困问题。扶贫攻坚从精准扶贫到瞄准深度贫困，既是认识的深化\n","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509235200,"objectID":"f3968bae21723e5ddfdb2e968532c111","permalink":"https://chengjunwang.com/zh/cn/2017-11-20-poverty.zh/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/cn/2017-11-20-poverty.zh/","section":"zh","summary":"　　让贫困人口和贫困地区同全国一道进入全面小康社会，是党向全国人民作出的庄严承诺。党的十九大报告再次对打赢脱贫攻坚战作出部署，明确指出重点攻克深度贫困地区脱贫任务，确保到2020年我国现行标准下农村人口实现脱贫，贫困县全部摘帽，解决区域性整体贫困，做到脱真贫、真脱贫。\n","tags":["news"],"title":"扶贫数据","type":"zh"},{"authors":null,"categories":null,"content":"Cheng-Jun Wang (Nanjing University)\nDr. Cheng-Jun Wang got his Ph.D degree of Media and Communication from City University of Hong Kong in 2014. He received his bachelor degree from Lanzhou University in 2008 and his master degree from Peking University in 2010. He joined Nanjing University as an assistant research fellow in 2014. Cheng-Jun Wang has served as the director of Ogilvy Data Science Lab, Computational Communication Collaboratory, since 2014, and currently he is an associate professor. His research on computational communication appears in both SSCI and SCI indexed journals, such as Scientific Reports, PloS ONE, Physica A, Cyberpsychology, and Journal of Social and Personal Relationships.\n王成军\n 通讯地址：南京市汉口路22号南京大学新闻传播学院A306 邮编：210093 Email: wangchj04@gmail.com 所在系：新闻与新媒体系  个人简历 王成军，传播学博士。现为南京大学新闻传播学院副教授、奥美数据科学实验室主任，计算传播学实验中心副主任、兼任香港城市大学互联网挖掘实验室研究员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》(2015)。致力于采用计算社会科学视角研究人类传播行为，研究成果发表于SSCI和SCI索引的期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology。2014年发起创建了计算传播网。\n欢迎对计算社会科学、网络科学、文本挖掘、统计分析、数据挖掘、机器学习感兴趣的同学报考我的硕士或加入计算传播学实验中心。更多信息见个人网站：https://chengjunwang.com/\n研究领域： 计算传播学；信息扩散；注意力流动；公共讨论；互联网数据挖掘\n开设主要课程：  《数据新闻》 《计算传播》 《大数据挖掘与分析》  主持和参与科研项目：  中国博士后科学基金面上项目（第57批，2015M571722), 找回失落的参考群体:对“沉默的螺旋”进行多主体建模，2015/01-2018\u0026frasl;01, 5万元，主持 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015/07-2018\u0026frasl;12, 20万元，主持 互联网上的集体注意力流研究，国家自然科学基金（常规面上项目），61673070，2017/01-2020\u0026frasl;12,￥655200, 参与  出版专著：  许小可、胡海波、张伦、王成军 （2015）社交网络上的计算传播学. 北京：中国科学出版社. 王薇、王成军、王颖、刘璟 翻译. 社会网络分析：方法与实践. 北京：机械工业出版社  发表论文：  Wang, C.J., Wu, L*, Zhang, J., Janssen, M. (2016) The Collective Direction of Attention Diffusion. Scientific Reports. 6: 34059. doi:10.1038/srep34059 Wu, L., Wang, C.J. * (2016) Tracing the Attention of Moving Citizens. Scientific Reports. 6, 33103. doi: 10.1038/srep33103 Wang, C.J., Wu, L.*(2016) The Scaling of Attention Networks. Physica A: Statistical Mechanics and its Applications.448:196–204, doi: 10.1016/j.physa.2015.12.081 Chandra, Y.*, Jiang, C.L., Wang, C.J. (2016) Mining Social Entrepreneurship Strategies Using Topic Modeling, PLOS ONE, 11(3):e0151342, doi: 10.1371/journal.pone.0151342 Jiang, C.L*, Yang, M, Wang, C.J. (2017) Self-Disclosure to Parents in Emerging Adulthood: Examining the Roles of Perceived Parental Responsiveness and Separation-Individuation. Journal of Social and Personal Relationships. 34(4): 425-445. doi: 10.1177 /0265407516640603 Wang, C.J. *, Wang, P.P, Zhu, J.J.H (2013). Discussing Occupy Wall Street on Twitter: Longitudinal network analysis of equality, emotion, and stability of public discussion. Cyberpsychology, Behavior, and Social Networking, 16(9): 679-685. doi:10.1089/cyber.2012.0409. [SSCI, Ranking 4\u0026frasl;72 in Communication by 5-year IF]. 王成军 (2017).计算社会科学视野下的新闻学研究：挑战与机遇. 新闻大学, 4:26-32 杜骏飞, 曲飞帆, 王成军（2016）2015年中国新闻传播学论著评析. 新闻与传播研究，12:108-119 王成军 (2016) 大数据计算与《纸牌屋》生成. 传媒评论. 5:63-66 王成军 (2016) 计算传播学的起源、概念与应用. 编辑学刊,3:59-64. 王成军（2015）计算传播学: 作为计算社会科学的传播学.中国网络传播研究,8:193-208. 王成军（2015）“今日头条”的技术逻辑: 网络爬虫+矩阵筛选.传媒评论,10:34-37. 祝建华,彭泰权,梁海,王成军,秦洁,陈鹤鑫 (2014) 计算社会科学在新闻传播研究中的应用. 科研信息化技术与应用. 5 (2), 3-13  所获奖励荣誉：  Best paper Award of Asian Symposium of Doctoral Students in Communication (ASDSC), City university of Hong Kong, Hong Kong (Nov, 2013) Best paper Award of 3rd Honours Symposium for Asian Ph.D Students in Communication Research, Yonsei university, Seoul, Korea (Oct, 2012) Research Tuition Scholarship (RTS, Oct, 2012- Aug, 2013) Outstanding Academic Performance Award for Research Degree Students (OAPA, Aug, 2012)  简历 王成军，博士，南京大学新闻传播学院助理研究员。奥美数据科学实验室主任、计算传播学实验中心研究员、香港城市大学互联网数据挖掘实验室研究员、集智俱乐部核心成员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》（2015）。致力于采用计算社会科学视角研究人类传播行为，其研究成果发表于SSCI/SCI期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology和Journal of Social and Personal Relationships。\n 计算传播网（http://computational-communication.com）。 计算传播学实验中心（http://ccc.nju.edu.cn:8089)  对数据科学感兴趣，主要采用python和R编程，写了一个R包和两个python包：\n networkdiffusion（https://github.com/chengjun/networkdiffusion） iching (https://pypi.python.org/pypi/iching) scholarNetwork (https://pypi.python.org/pypi/scholarNetwork/)  研究领域：计算传播学，致力于采用计算社会科学地研究方法分析人类传播行为，具体包括社会化媒体与信息扩散、公共讨论、注意力流动、互联网数据挖掘等。\n开设主要课程： 计算传播学导论》、《计算传播与广告》、《数据新闻》等。\n通讯地址：南京市汉口路22号南京大学新闻传播学院A306 邮编：210093\nEmail: wangchj04@gmail.com\n所在系：新闻与新媒体系\n 老师最开始为何选择了传播学这个专业呢？  我选择传播学专业是一个偶然，因为我大学二年级想要转一个专业，而此时已经错过了转专业的时间，恰好新闻学院有一个2+2的项目，就是在原来专业基础上，只需要用两年时间学完专业课。通过选拔考试后，我就转到网络新闻专业，算是进入了传播学的专业。之后，考研、申请博士都要考虑怎么才能发挥自己的既有的知识储备，于是硕士读了一个媒体经营管理的方向。读硕士是一个转折点，因为我的硕士老板很强调数据分析技能的培养和“社会学的想象力”，于是开始做一些小的研究项目。我就钻进书丛，读各种和数据分析和社会科学理论相关的书。在北大和人大的方法类的暑期班里听了不少课。硕士毕业那年，香港城市大学的祝建华老师来京做博士招生的宣讲。我很感兴趣就申请了香港的传播学博士项目。博士毕业之后先在腾讯实习了半年，后来就到南京大学新闻传播学院做助理研究员。\n 又为何选择计算传播学作为研究方向？  计算传播学也非我有意识地选择的结果。我对扩散现象一直感兴趣，从沙堆到信息扩散，我一直认为这里面有很多值得挖掘的地方。来到香港读博之后，我主要在互联网挖掘实验室从事研究工作。读格兰诺维特的论文时，读到门槛模型，与我在读复杂性科学地书籍时所接触到多主体模型等都有关联。2008年正是社会化媒体方兴未艾大放异彩的时候，我想我或许可以采用这个模型来分析社会化媒体上的信息扩散。于是，开始分析各种基于互联网的人类传播行为数据，主要是Digg, Youtube, Twitter和Sina Weibo。恰逢计算机科学家转向这条主线的研究，于是读了很多类似文章。但我对计算机科学家做社会科学研究很不满，因为多数研究都是会议论文，其研究发现往往不够深刻，这部分工作具有很强的数据科学的特点，强调数据挖掘和机器学习技术的使用；同时，我也注意到物理学家对于人类传播行为的研究工作，主要是统计物理和网络科学部分。对我影响最大的依然是网络科学，因为我分析信息扩散的起点就是基于关系网络和信息扩散网络展开。网络科学无疑提供了理想的工具；除此之外，计算语言学的工作使得对于传播文本的挖掘更加系统，例如主题模型鼓舞了计算人文学科的发展。与此同时，我开始放弃mathematica，学习R语言，后来又转向python语言（因为要抓数据）。如何概括类似这些研究范式？我们一度采用了各种标签，比如统计物理、人类动力学、社会物理学、社会计算，但都不贴切。2011年，我在和实验室的同学和老师讨论之后，提出了computational communication的提法，就有了计算传播学。当然，此时距离Lazer等人在2009年提出计算社会科学已经是三年之后了。之后，大家发现这个提法很好地概括了我们的研究兴趣和研究方向，于是就慢慢开始使用这个词语。2012年建立了豆瓣计算传播学小站。2013年，互联网挖掘实验室推出了一系列的计算传播研究工作坊，2014年我到南大之后，筹建了现在计算传播学实验研究中心。我们开始参与一些计算社会科学为主题的国际会议，在与其他学科的研究者交流的时候，采用计算传播学研究者介绍自己的工作。\n 老师港城大毕业后，选择留在了象牙塔任教，而非进入公司。不知道这里面又有什么样的考量？  研究兴趣占了很大比重。我在腾讯的数据挖掘部门实习了半年，后来拿到了他们的offer。腾讯正在急于建设一个连接人和物的互联网公司，很多研究问题都涉及到网络科学。他们对于采用传播的视角建立数据科学模型充满兴趣。但腾讯与百度、阿里相比更为注重实务，所以原来的腾讯研究院被分拆了，在腾讯工作就要面临业务和研究两边跑的问题。与此同时，国内高校也意识到“大数据传播”、数据新闻、计算广告的重要性，也提出一些不错的offer。我一度想去公司，后来博士老板建议我先去高校，家人也希望我能离家近一些，多一些时间照顾家人。当然，他们不知道做研究虽然时间灵活，但更费时间。\n 老师最近正在看的一本书是什么？以及自己选择看这本书的原因？  《社交网络上的计算传播学》，这本书刚刚出版，已经可以订购。这本书是第一本和计算传播直接相关的书，较为系统地整理了关于采用计算传播学视角分析社交网络的理论、方法和工具。另外，也这是我参与编著的第一本书（此处是硬广），之前看的都是电子稿，买几本纸本帮助我备课，还有看看如果出第二版怎么改。\n最后要提醒老师一下，讲座的最后会请您推荐3本与这次讲座相关的书籍。\n-《网络、群体与市场》、《社交网络上的计算传播学》、《计算广告》\n研究方向 作为一个新人，提所谓的大词是没有什么意义的，重要的是解决问题。解决中层问题是非常关键的。一个理想的研究者的视野是橄榄球形状的。两端小中间大。分为三层：\n 底层：模型和方法（如物理模型） 中层：研究问题 （令飞选了知识生产，如讨论网络、问答网络、引文网络） 高层：研究视野（如注意力科学、计算传播学）  通常容易欠缺的是中层的研究问题。什么是中层问题？为什么要选中层问题？中层问题可以较好的建立自己的生态位，可以做的东西太多了，人的精力却很有限。\n","date":1505260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505260800,"objectID":"85263a84e2cbf74a0e6cd164c0762cc3","permalink":"https://chengjunwang.com/note/note_archive/2015-08-13-self-intro/","publishdate":"2017-09-13T00:00:00Z","relpermalink":"/note/note_archive/2015-08-13-self-intro/","section":"note","summary":"","tags":null,"title":"自我介绍","type":"note"},{"authors":null,"categories":null,"content":" JCR Journal Data Filtered By: Selected JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: \u0026lsquo;COMMUNICATION\u0026rsquo; Selected Category Scheme: WoS\nSCI和SCIE SCI和SCIE（SCI Expanded）分别是科学引文索引及科学引文索引扩展版（即网络版），主要是收录自然科学、工程技术领域最具影响力的重要期刊，包括2000多种外围刊。\nTable    Rank Full Journal Title Total Cites Journal Impact Factor Eigenfactor Score     1 NEW MEDIA \u0026amp; SOCIETY 3,592 4.180 0.009310   2 Journal of Computer-Mediated Communication 4,011 4.113 0.005010   3 JOURNAL OF COMMUNICATION 5,579 3.914 0.008400   4 MEDIA PSYCHOLOGY 1,264 3.125 0.001440   5 COMMUNICATION RESEARCH 3,459 3.021 0.004410   6 JOURNAL OF ADVERTISING 3,425 2.896 0.001740   7 COMMUNICATION THEORY 1,834 2.773 0.002080   8 Information Communication \u0026amp; Society 2,005 2.692 0.006010   9 PUBLIC UNDERSTANDING OF SCIENCE 2,007 2.552 0.003150   10 POLITICAL COMMUNICATION 1,645 2.467 0.002930   11 International Journal of Advertising 1,308 2.451 0.001150   12 Comunicar 641 2.212 0.000650   13 IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION 515 2.184 0.000470   14 TECHNICAL COMMUNICATION 615 2.100 0.000340   15 JOURNAL OF ADVERTISING RESEARCH 2,514 2.034 0.000920   16 Journalism Studies 1,335 1.927 0.002760   17 RESEARCH ON LANGUAGE AND SOCIAL INTERACTION 1,016 1.896 0.003010   18 SCIENCE COMMUNICATION 968 1.852 0.001640   19 COMMUNICATION MONOGRAPHS 2,134 1.738 0.001150   20 Journal of Public Relations Research 961 1.720 0.001000   21 JOURNAL OF HEALTH COMMUNICATION 3,233 1.614 0.007080   22 HUMAN COMMUNICATION RESEARCH 2,836 1.549 0.001950   23 TELECOMMUNICATIONS POLICY 1,509 1.526 0.002270   24 International Journal of Press-Politics 546 1.523 0.002120   25 International Journal of Communication 1,277 1.498 0.005030   26 HEALTH COMMUNICATION 2,207 1.487 0.004080   27 Journalism 1,204 1.484 0.003890   28 JOURNAL OF SOCIAL AND PERSONAL RELATIONSHIPS 2,675 1.425 0.003050   29 Environmental Communication-A Journal of Nature and Culture 371 1.414 0.000820   30 EUROPEAN JOURNAL OF COMMUNICATION 885 1.408 0.001570   31 PUBLIC OPINION QUARTERLY 4,893 1.386 0.005970   32 Television \u0026amp; New Media 417 1.365 0.001080   33 JOURNAL OF BROADCASTING \u0026amp; ELECTRONIC MEDIA 1,874 1.311 0.002040   33 PUBLIC RELATIONS REVIEW 2,704 1.311 0.003070   35 Mass Communication and Society 984 1.308 0.001660   36 JOURNALISM \u0026amp; MASS COMMUNICATION QUARTERLY 1,574 1.301 0.001620   37 JOURNAL OF LANGUAGE AND SOCIAL PSYCHOLOGY 1,011 1.272 0.000910   38 INTERNATIONAL JOURNAL OF PUBLIC OPINION RESEARCH 851 1.254 0.001770   39 WRITTEN COMMUNICATION 669 1.200 0.000850   40 MEDIA CULTURE \u0026amp; SOCIETY 1,533 1.128 0.003180   41 Games and Culture 436 1.109 0.000410   42 Management Communication Quarterly 995 1.091 0.001130   43 Discourse \u0026amp; Communication 326 1.085 0.000850   44 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION 243 1.062 0.000260   45 Journal of Media Psychology-Theories Methods and Applications 292 1.057 0.000680   46 Ecquid Novi-African Journalism Studies 153 1.056 0.000450   47 DISCOURSE \u0026amp; SOCIETY 1,354 1.029 0.001420   48 Discourse Context \u0026amp; Media 89 1.000 0.000590   49 Interaction Studies 370 0.958 0.000660   50 Convergence-The International Journal of Research into New Media Technologies 455 0.950 0.000870   51 Communications-European Journal of Communication Research 340 0.933 0.000460   52 Critical Discourse Studies 308 0.882 0.001090   53 CRITICAL STUDIES IN MEDIA COMMUNICATION 448 0.881 0.000560   54 DISCOURSE STUDIES 1,046 0.833 0.001650   55 LANGUAGE \u0026amp; COMMUNICATION 848 0.793 0.001080   56 INTERNATIONAL JOURNAL OF CONFLICT MANAGEMENT 652 0.786 0.000290   57 Communication and Critical-Cultural Studies 249 0.767 0.000670   58 PERSONAL RELATIONSHIPS 1,856 0.739 0.002100   59 Argumentation 324 0.689 0.000310   59 Visual Communication 353 0.689 0.000760   61 Translator 236 0.686 0.000280   62 Asian Journal of Communication 347 0.638 0.000570   63 International Communication Gazette 486 0.622 0.001030   64 Chinese Journal of Communication 129 0.562 0.000430   65 Social Semiotics 344 0.484 0.000720   66 Continuum-Journal of Media \u0026amp; Cultural Studies 496 0.468 0.000910   67 QUARTERLY JOURNAL OF SPEECH 737 0.460 0.000270   68 Communication Culture \u0026amp; Critique 209 0.448 0.000710   68 Text \u0026amp; Talk 297 0.448 0.000830   70 Journal of Mass Media Ethics 243 0.419 0.000370   71 JAVNOST-THE PUBLIC 191 0.413 0.000330   72 Media International Australia 264 0.346 0.000680   73 Rhetoric Society Quarterly 204 0.333 0.000300   74 NARRATIVE INQUIRY 379 0.317 0.000430   75 JOURNAL OF APPLIED COMMUNICATION RESEARCH 692 0.308 0.000720   76 JOURNAL OF MEDIA ECONOMICS 187 0.217 0.000170   77 African Journalism Studies 12 0.171 0.000020   77 Tijdschrift voor Communicatiewetenschap 42 0.171 0.000070   79 Journal of African Media Studies 66 0.154 0.000180    ","date":1504656000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504656000,"objectID":"9d21e11b686c9807d65e9b865c17ec60","permalink":"https://chengjunwang.com/zh/cn/2017-09-06-jcr.zh/","publishdate":"2017-09-06T00:00:00Z","relpermalink":"/zh/cn/2017-09-06-jcr.zh/","section":"zh","summary":"Journal Data Filtered By:  Selected JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: 'COMMUNICATION' Selected Category Scheme: WoS\t\n","tags":["news"],"title":"JCR2017 for COMMUNICATION","type":"zh"},{"authors":null,"categories":null,"content":"各位老师，大家晚上好，很高兴有机会和大家讨论一下网络舆论生态治理研究的问题。\n习近平指出，\u0026raquo;没有网络安全就没有国家安全，没有信息化就没有现代化\u0026raquo;。\n习近平总书记指出:“要依法加强网络社会管理，加强网络新技术新应用管理，确保互联网可管可控。”\n国家互联网信息办公室25日公布《互联网跟帖评论服务管理规定》提出,网站要建立跟帖评论审核管理、实时巡查、应急处置等信息安全管理制度,及时发现和处置违法信息，新规定自2017年10月1日起施行。1 实名制发帖对于打击网络水军、网络谣言等问题具有重要作用，符合2016年底通过的《中华人民共和国网络安全法》的精神。2 2016年11月7日第十二届全国人民代表大会常务委员会第二十四次会议通过《中华人民共和国网络安全法》3，自2017年6月1日起施行。\n 本规定所称跟帖评论服务，是指互联网站、应用程序、互动传播平台以及其他具有新闻舆论属性和社会动员功能的传播平台，以发帖、回复、留言、“弹幕”等方式，为用户提供发表文字、符号、表情、图片、音视频等信息的服务。\n 其实，在此之前，公民网络身份的管理已经越来越严格。比如，针对微信舆情治理的“微信十条”的发布。2014年8月7日，网信办发布《即时通信工具公众信息服务发展管理暂行规定》 ①服务提供者从事公众信息服务需取得资质 ②强调保护隐私 ③实名注册，遵守“七条底线” ④公众号需审核备案 ⑤时政新闻发布设限 ⑥明确违规如何处罚。“微信十条”发布后，国家互联网信息办公室进入立“法”密集期，《互联网用户账号名称管理规定》（“账号十条”）和《互联网新闻信息服务单位约谈工作规定》（“约谈十条”）也先后出台。\n除了政府的管制以外，商业的因素也在其中发挥了非常大的作用，尤其是伴随着智能手机的普及，手机号码成为了识别公民身份的重要手段。为了促进移动端的发展，各大网站积极推进绑定手机号码的规定，例如2017年知乎网回帖要求必须绑定手机号码。\n网络舆论同生态环境中的有机体一样具有开放性、自组织性 、适应环境的能力和一定的 生命周期，具有自然生态系统的一般特征。每一个网站独立地构成一个“虚拟的生命组织”，其内部的信息内容连接在一起构成一个资源和能量流动的网络：通过吸收开放的注意力流维持其新陈代谢，而产出大量的内容并进一步维系着公众注意力。网络媒体的传播范围、信息量、开放性、交互性等特点是传统媒体所不能相比的，随着手机互联网的普遍使用，网络媒体的影响力大幅度放大。\n根据《第40次中国互联网络发展状况统计报告》4， - 截至2017年6月，中国网民规模达7.51亿，半年共计新增网民1992万人。互联网普及率为54.3%，较 2016 年底提升了1.1个百分点。 - 截至2017年6月，中国手机网民规模达7.24亿，较2016年底增加2830万人。 - 网民中使用手机上网人群占比由2016年底的95.1% 提升至96.3%。 - 截至2017年6月，中国网民中农村网民占比26.7%，规模为2.01亿。\n舆论 社会转型期，贫富差距、腐败、公平正义等问题的交织，让越来越多的群体心理不平衡感上升，获得感降低。舆论是社会的皮肤和晴雨表，网络舆论则是人们获得发声的话语场，将线下社会被压抑的诉求转向网络空间寻找替代性补偿的结果。越来越多的网络热点事件将地方政府置于舆论的风口浪尖，使其成为人们利用互联网抗争的对象。如何实现这种线上线下的双重舆论治理，不断考验着地方政府的治理能力。\n钟智锦等研究2002-2012年十年的网络事件，发现每三个网络事件，就有一件与地方政府有关， 意味着地方政府和普通民众之间的矛盾是网络事件的主要诱因; 在大多数情况下， 地方政府能进行积极的回应， 但还没有形成制度化的危机管理机制。网络行动以非暴力形式为主， 绝大多数能够促使利益诉求得到满足， 但只有少量网络事件会对社会制度带来深远影响。\n李良荣等对2010至2011年间发生的195个网络群体性事件进行分析，发现比例最大的是有关政府与政策的事件，占到总数的35%，在69个政府与政策事件中，22件(占31%) 涉及官员腐败，凸显了网民对政府执政不 当和官员行为失范的集中关注。\n张伦等研究了2012-2014年间我国3359个公共事件，发现涉事群体个体身份多集中于政府部门、 官员和公检法机关；事件类型中制度危机与社会公平类问题占有压倒性优势；从地理分布来看，公共事件多发生于经济较发达地区; 从事件演化模式来看，不同类别的事件呈现出竞争关系， 即大部分事件发生频度呈负相关关系。\n在舆论形成与扩散的过程中，个人意见和与群体意见内部及其之间相互作用、相互影响，建构了舆论的动态演化(Price, 1992; 陈力丹, 1999)。舆论的形成与扩散可以分为五个阶段：问题阶段（problem phase）、建议阶段(proposal phase)、对策阶段(policy phase)、执行阶段(program phase)、评估阶段(appraisal phase)(Price, 1992)。前两个阶段，舆论的社会影响具有明显的信息扩散的特质，而后两个阶段则具有明显的社会规范的特征。概括而言，围绕着舆论形成与扩散机制，国内外相关的研究可以分为以下三种研究路径：\n研究路径一：强调舆论形成的构成要素（element）。理论上而言，舆论的构成要素包括：舆论参与者、舆论信息、传播渠道等，而目前被研究较多的是前两者。首先，舆论形成的参与者包括公众、组织机构（例如政府、公司、媒体、 NGO）、社会精英等(陈力丹, 1999)。其中，公众根据参与的程度和类型可分为一般公众、选举公众、热心公众、积极公众、议题公众和旁观者(Price, 1992)；根据是否公开身份区分为实名用户和匿名用户(夏雨禾, 2011)。以往的研究发现不同类型的舆论参与者对于舆论形成都起着重要的作用(Price, 1992; 夏雨禾, 2011)。另外，舆论信息的特点对于舆论的形成和扩散具有显著影响。一般而言，社会关注度高的舆论内容，其扩散的速度更快(Greenberg, 1964)。例如，钟瑛等(2010)发现网络舆论事件多聚焦于政治与民生问题。最后，传播渠道制约着舆论扩散。舆论传播渠道主要包括大众媒体和人际网络，其中，各种形式的大众媒体作为传播渠道被研究得更加透彻(Greenberg, 1964)。\n研究路径二：强调大众媒体对于舆论形成的效果（effect）。舆论扩散的渠道主要涉及人际网络和大众媒体，但目前国内外关于舆论的形成与扩散的相关研究主要集中于大众媒体的作用。早在1922年，李普曼就认为公众通过媒体获取关于外在世界的信息，而外在世界在公众脑海中形成的各种图像即为舆论(Lippmann, 1922)。围绕着大众媒体在不同维度的舆论效果，一系列基于实证研究的经典传播学理论被提出，包括框架理论(Goffman, 1974)、议程设置理论(McCombs \u0026amp; Shaw, 1972)、沉默的螺旋(Noelle-Neumann, 1993)等。\n研究路径三：强调舆论扩散的演化过程（evolution）。描述舆论演化的模型包括传统的病毒扩散模型（epidemic model）和舆论动力学模型（opinion dynamic model）。二者都侧重于采用数学模型和仿真的方式研究舆论的形成。病毒扩散模型中的SIR模型将公众分为三种基本状态：未接触舆论信息（S状态）、接触并传递信息（I状态）、接触但拒绝传递信息（R状态）。进而建立微分方程，并采用解析或者仿真的方法求解(Pastor-Satorras \u0026amp; Vespignani, 2001; 何大韧等, 2009)。舆论动力学模型则主要关注行动者之间、行动者与环境（包括媒体）之间的互动，根据互动规则进行计算机仿真。根据互动规则的差异可分为选举者模型(Holley \u0026amp; Liggett, 1975)、 多数原则模型(Krapivsky \u0026amp; Redner, 2003)、Sznajd模型(Sznajd, 2000)等。值得一提的是，门槛也是病毒扩撒模型和舆论动力学模型的核心概念，只有当超过一定的阈值之后，模型中的参与者才会行动。\n舆论研究作为一个发展良好的研究范式，在扩散机制分析方面依然存在着一些局限。具体包括：（1）多数研究致力于描述舆论的要素，对扩散机制的分析不够系统；（2）意见动力学等针对演化过程的研究主要建立在计算机仿真的基础上，实证分析相对薄弱；（3）对于传播学而言，舆论研究过于关注媒介效果而对人际作用关注不够。在大众媒体主导的环境下，受限于信息把关、媒介使用时间有限、公众获知的信息太少等因素，使得研究者担忧舆论主要产生于想象(Lippmann, 1922; Price, 1992)。随着媒体融合的发展，社交网络使得人际作用对于舆论扩散的意义凸显。综上，采用实证的方法分析舆论形成与扩散机制中的人际作用不可避免。\n结构困境 徐世甫（2015）在《南京社会科学》发表题为《网络舆论生态治理研究》的文章，指出了中国舆论治理的问题：\n 在由官方、媒体和公众三方舆论场建构的网络舆论生态系统中,存在着结构性问题:政府视公众为客体,在舆论引导中遭到总体性困境;媒体的舆论受到过度的政治经济干预,公信力递减甚至缺失;公众生产的网络谣言满天飞,冲击社会正常秩序。\n 为超越这些危机,政府应实施主体间性理念,推动舆论生产、消费与分解的理性合一;媒体要实现结构化转型,以增强公信力来提升舆论影响力;公众须提升信息素养,以言论自律形成人人把关的和谐舆论生态,最终实现网络舆论生态文明。\n从舆论治理到社会治理 网络舆论是社会的皮肤和晴雨表，治理者需要从各种网络舆论中发现深层次的社会问题，不能拘泥于舆论表层的治理。\n从地方政府网络安全的角度来看，运动式的舆论治理虽然可以减少网络谣言、虚假信息等有害信息，但是也会因为缺乏宽容致使社会积怨难以正常释放，无法从根本上解决问题。\n政府对待网民舆论需要摆脱敌对思维，通过尊重、对话、信任以及符合网民需要的话语表达，来扩大公众同意凝聚共识。\n、\n完善网络舆情监测、研判和预警机制，落实网络事件应急处置机制 各政府部门要与宣传部、公安局等互联网管理部门建立联动机制，实现资源及时共享，发现苗头及时通报，密切跟踪。要进一步加强网络舆情会商，联合涉情部门梳理事件相关社会背景、诱发因素、 发展态势等，在全面掌握信息的前提下实现对舆情走势和发展节点的科学、精准研判，研究制定合适的舆论引导和议程设置策略，用准确全面的信息和恰到好处的舆论引导对冲负面舆论的影响，在舆情事件演变为线下行动前化解危机。\n建立舆情事件应急处置工作办法。明晰责任、机制和流程，启动重大舆情事件快速处理程序，做到发现快、判断快、协调快、处理快 、反馈快，打破地区、行业部门界限。例如，2015年南京市宣传部就制定了《南京市舆情事件应急处置工作办法》。\n重视舆论治理中的对话沟通 地方政府一方面需要从单一依靠强制力和运动式治理理念转向对话沟通，并在策略上提高大数据在网络舆论治理中的运用能力，及时发现潜舆论做好预警引导;另一方面需要拓宽沟通渠道，借助新媒体重塑官方话语体系，深刻把握网络舆论背后的社会心态，通过平等、尊重、对话等进 行调适舒缓，进而推进地方网络舆论生态的健康发展。\n把舆情当民情，而非敌情或社会噪音。深入网络，了解问题，体察民意。\n一、要及时发布信息，改变“封、捂、堵、压、瞒”的治理思维; 二、要深入网络舆论场，通过“在场”来了解民意 诉求与舆论的焦点; 三、要从运用新技术实现传统媒体、网站“两微一端”等媒介信息发布的协同，最大限度地消除信息死角; 四、要理解网民话语表达方式，重拾生动表达传统，创新表达体系。\n有效推进数据开放 建立统一的开放数据门户，为公众提供一站式的政府数据获取及相关服务。明确数据的开放范围与保密范围 ，加快制定数据安全、信息安全、隐私保护方面的法律法规。同时，为确保政策的有效执行，建议建立有效的公众反馈机制和健全的问责制度，对各部门的执行 情况进行实时监督。对现有资源进行全面整合， 构建一个跨系统、跨部门的统一开放数据平台，为公众提供开放的数据服务。\n提升网络舆论大数据治理能力。 对于网络舆论治理实践，舆论大数据蕴含了 与传播内容、传播心理、传播行为、传播关系等相关 的多维度信息，为我们更大范围、更加全面地洞察 “舆论景观”提供了新的机会。通过机器学习、语义分析、社会网络分析等手段，描述网络舆论场中的议题分布与意见分布，以及从历史角度追溯其议题与意见分布的变化，进而提升预警能力。\n侧重潜在舆论的引导。 陈力丹认为，对于舆论引导来说，容易被忽视的潜舆论十分重要，如果在舆论处于潜舆论的时候进行引导，容易得到较好的效果;而引导显舆论的困难程度，则远大于潜舆论。\n政府回应机制。网络协商机制。  http://media.people.com.cn/n1/2017/0825/c14677-29495044.html ^ 国家网信办发布管理规定:未实名认证不得跟帖评论 http://news.bandao.cn/news_html/201708/20170826/news_20170826_2757801.shtml ^ http://www.miit.gov.cn/n1146295/n1146557/n1146614/c5345009/content.html ^ http://www.cac.gov.cn/2017-08/04/c_1121427728.htm ^  ","date":1503835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503835200,"objectID":"9eb9392499b97c577e6b91d389a3e69e","permalink":"https://chengjunwang.com/note/2017-8-27-public-opinion/","publishdate":"2017-08-27T12:00:00Z","relpermalink":"/note/2017-8-27-public-opinion/","section":"note","summary":" ","tags":[""],"title":"网络舆论生态治理研究","type":"note"},{"authors":null,"categories":null,"content":"南京住房公积金管理中心 南京市玄武区太平北路51号\nhttp://gjj.nanjing.gov.cn/wsbsdt/\n 公积金账号：801017435215 补贴账号：804001045006  使用建设银行的银行卡，领卡：身份证\n20100466817 南京大学 网点号0001\n通过当地025-12329热线输入身份证号查询。\n中山陵景区  景区图 携程网介绍 钟山风景名胜区官网   如果你想一并游览明孝陵、灵谷寺、音乐台和美龄宫这几个收费景点，可以购买钟山风景区套票（100元），比单独购票划算。 在钟山风景区内，可乘小火车或观光车前往中山陵、明孝陵、灵谷寺等景点，小火车和观光车的车票都是10元/人。 景区内提供导游服务，让你进一步了解这些建筑背后的历史，费用为30人以下95元/时，30人以上100元/时。 祭堂内原则上是不允许拍照的，请给予尊重。 官方微信号：zschina_nj （南京钟山风景名胜区），可享受免费语音导览。  如图所示，三大景区从西到东依次是明孝陵、中山陵和灵谷寺。\n 在地铁苜蓿园1号口出站，乘小火车观光车一号线先去美龄宫，凭刷身份证入。 再步行5分钟至明孝陵博物馆 参观完从大金门进明孝陵景区 经过神兽石道一路到孝陵。  四方城（即神功圣德碑及碑亭）-御河桥-石象路-神道望柱-翁仲路-棂星门-金水桥-文武方门（即正门）。 散客可以在景区金水桥旁租一个电子感应的导游器（10元） 进入文武方门，开始游览主体建筑，依次为：碑殿-享殿-内红门-升仙桥-方城-明楼-宝顶。  再坐小火车去中山陵 然后去对面的音乐台（很近），喂喂鸽子。 最后乘小火车去灵谷景区 从灵谷景区出来可乘202公交到地铁站。  门票购买 南京钟山风景区（明孝陵+灵谷寺+美龄宫+音乐台）成人票（当天订）\nhttp://zschina.nanjing.gov.cn/jqfw/gzzs/\n","date":1502884800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502884800,"objectID":"92bdf45ab2cc70023f06571f3bd84ba1","permalink":"https://chengjunwang.com/note/2017-8-16-nanjing-tourist/","publishdate":"2017-08-16T12:00:00Z","relpermalink":"/note/2017-8-16-nanjing-tourist/","section":"note","summary":" ","tags":["南京","景区"],"title":"南京旅游攻略","type":"note"},{"authors":null,"categories":null,"content":"因公出国护照办理 http://wb.nju.edu.cn/zzbl/list.htm\n一、公务（普通）护照办理 （一）办证要求 1、在办结因公出国校内审批后，由申请者本人到仙林校区行政楼818室采集指纹，并提交以下材料： （1）身份证原件 （2）身份证复印件（标明出生地所在省、直辖市或自治区名） （3）两寸白底彩照1张 2、现无公务（普通）护照/护照过期/护照有效期不足（本次出访后，距护照到期不足6个月；部分国家所需有效期更长） （二）办理时间：1至2周（不含节假日）\n因公出国人员申报流程及材料须知 http://wb.nju.edu.cn/splc/list.htm\n因公临时出国人员根据“OA申报材料清单”,通过OA系统提交申报材料；\n香港 在携程网订票，支付宝支付，非常方便。微信的客服非常差。机票总价2395元，酒店5003元，往返香港大巴共360元，共计7758元。\n机票  订单4463239049『南方航空 CZ3560\n 南京禄口机场T2-深圳宝安机场T3 8月18日11:35-8月18日13:55 王成军，票号784-5730593747』 请提前2小时至机场值机。 成行后5天内您会收到报销凭证。 退改点击http://t.ctrip.cn/FaJHbdg  订单4463239084『深圳航空 ZH9847\n 深圳宝安机场T3-南京禄口机场T2 8月22日13:35-8月22日16:00 王成军，票号479-2122234103』 请提前2小时至机场值机。 成行后5天内您会收到报销凭证。 退改点击http://t.ctrip.cn/FbubGHB   酒店 入住香港皇家太平洋酒店(The Royal Pacific Hotel and Towers)\n 2017/8/18 雅尚客房(内宾)，1间4晚晚，总价￥5003.00，每晚单早。 订单不能取消修改。 特别提示：此单通过代理商预订，请直接报W办理入住。 酒店地址：尖沙嘴 广东道33号中港城，近港威大厦，T：00852-27361188。 请点击手机客户端 t.ctrip.cn/?GmaPA7NF885 查看订单详情。 携程电话：10106666(免长话费)。  机场大巴 共计360元，往返保安机场与香港。预计耗时1.5小时中不包含过关时间，请注意为行程保留充足的时间。国内电话4008833128香港电话0085223841108\n您预订的08月18日深圳机场-香港旺角太子（深圳宝安国际机场-尖沙咀）1张购票成功，取票号71xxxx。凭取票号验票上车，有效期截止08月18日。\n 价格180元 上车地址：深圳机场T3航站楼地面交通中心（GTC柜台）C-205，17号门旁217柜台（330售票台旁） 车辆经深圳湾口岸出境，免下车过关；  您预订的08月22日香港尖沙咀-深圳机场（香港尖沙咀-宝安国际机场）1张购票成功，取票号49xxxx。凭取票号验票上车，有效期截止08月22日。\n 价格180元 上车地址：香港尖沙咀中港城地下LG32A地铺 购票成功后，凭取票号到下面地址取票验票上车，先到先上 ","date":1502884800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502884800,"objectID":"81b083077dcedb6ca6537a34d69b3ab4","permalink":"https://chengjunwang.com/note/2017-8-16-tavel/","publishdate":"2017-08-16T12:00:00Z","relpermalink":"/note/2017-8-16-tavel/","section":"note","summary":" ","tags":["出差","机票"],"title":"因公护照办理、出差订票","type":"note"},{"authors":["王成军"],"categories":null,"content":" 引用: 王成军(2017).计算社会科学视野下的新闻学研究：挑战与机遇. 新闻大学,(04):26-32 （入选人大复印资料新闻与传播2017年第10期）\nJournalism Studies in the Perspective of Computational Social Science: Challenges and Opportunities WANG Cheng-Jun1\n[Abstract] Our society has entered the brand new era of computational social science. The new style of news production and the new paradigm of computational social science created both challenges and opportunities for the development of classic journalism research, which empower journalism research in the aspects of data, computational methods, network theory, and etc. This article aims to review the research on computational social science, especially its potential applications in journalism research. Finally, we offer a discussion on establishing the framework of computational communication research for better understanding of journalism research, with an emphasis on big questions, data, patterns, mechanisms, and general principles. [Key Words] Computational Social Science; Journalism; Network Science; Big Data； Computational Communication Research\n参考文献 1 Watts, D.J., “A twenty-first century science,” Nature 445(7127) (2007): p. 489.\n[2] Lazer, D., et al., “Life in the network: The coming age of computational social science,” Science 323(5915) (2009): p. 721-723.\n[3] 王成军. 计算传播学:作为计算社会科学的传播学[J]. 中国网络传播研究, 2014.第193-206页\n[4] 王成军. 计算传播学的起源、概念和应用[J]. 编辑学刊, 2016(3): 第59-64页.\n[5] 祝建华, 彭泰权, 梁海, 王成军, 秦洁, 陈鹤鑫. 计算社会科学在新闻传播研究中的应用[J]. 科研信息化技术与应用, 2014. 5(2): 第3-13页.\n[6] Fu, J.S., “Leveraging Social Network Analysis for Research on Journalism in the Information Age,” Journal of Communication 66(2) (2016): p. 299-313.\n[7] Strohmaier, M. and C. Wagner, “Computational Social Science for the World Wide Web,” Intelligent Systems IEEE 29(5) (2014): p. 84-88.\n[8] Conte, R., et al., “Manifesto of computational social science,” The European Physical Journal Special Topics 214(1) (2012): p. 325-346.\n[9] Moran, E.F., et al., “Opinion: Building a 21st-century infrastructure for the social sciences,” Proceedings of the National Academy of Sciences of the United States of America 111(45) (2014): p. 15855-15856.\n[10] Cioffi-Revilla, C., “Computational social science,” WILEY Interdisciplinary Reviews: Computational Statistics 2(3) (2010): p. 259-271.\n[11] Giles, J., “Computational social science: Making the links,” Nature 488(7412) (2012): p. 448-450.\n[12] Watts, D.J. and S.H. Strogatz, “Collective dynamics of \u0026lsquo;small-world\u0026rsquo; networks”, Nature 393(6684) (1998): p. 440-442.\n[13] Kleinberg, J.M., “Navigation in a small world,” Nature 406(6798) (2000): p. 845.\n[14] Ugander, J., et al., “Structural diversity in social contagion,” Proceedings of the National Academy of Sciences 109(16) (2012): p. 5962-5966.\n[15] Eagle, N., M. Macy, and R. Claxton, “Network Diversity and Economic Development,” Science 328(5981) (2010): p. 1029-1031.\n[16] Dzogang, F., et al., “Discovering Periodic Patterns in Historical News,” Plos One 11(11) (2016): p. e0165736.\n[17] Michel, J.B., et al., “Quantitative analysis of culture using millions of digitized books,” Science 331(6014) (2011): p. 176-182.\n[18] Lansdall-Welfare, T., et al., “Content analysis of 150 years of British periodicals,” Proceedings of the National Academy of Sciences 114(4) (2017) p. E457-E465.\n[19] Wang, W., et al., “Growing pains for global monitoring of societal events,” Science 353(6307) (2016): p. 1502-1503.\n[20] Shumate, M. and N. Contractor, “The Emergence of Multidimensional Networks,” The SAGE handbook of organizational communication, editied by L.L.P.D.K. Mumby. 2013, Thousand Oaks: CA: Sage. p. 449-474.\n[21] Wang, C.J., et al., “The Collective Direction of Attention Diffusion”, Scientific Reports 6 (2016): p. 34059.\n[22] Hong, T.V., G. Lei, and M.E. McCombs, “Exploring \u0026laquo;the World Outside and the Pictures in Our Heads\u0026raquo;: A Network Agenda-Setting Study,” Journalism \u0026amp; Mass Communication Quarterly 91(4) (2014): p. 669-686.\n[23] Guo, L., “The Application of Social Network Analysis in Agenda Setting Research: A Methodological Exploration,” Journal of Broadcasting \u0026amp; Electronic Media 56(4) (2012): p. 616-631.\n[24] Himelboim, I., T.K. Chang, and S. McCreery, “International Network of Foreign News Coverage: Old Global Hierarchies in a New Online World”, Journalism \u0026amp; Mass Communication Quarterly 87(2) (2010): p. 297-314.\n[25] Miller, D.C., “A research note on mass communication: How our community heard about the death of president Roosevelt,” American Sociological Review 10(5) (1945): p. 691-694.\n[26] De Fleur, M.L., “The Growth and Decline of Research on the Diffusion of the News, 1945-1985,” Communication Research 14(1) (1987): p. 109-130.\n[27] Greenberg, B.S., “Person-to-Person Communication in the Diffusion of News Events,” Journalism Quarterly 41(4) (1964): p. 489-494.\n[28] Wang, C.J., “Information diffusion on Microblogs: Testing the threshold hypothesis of interpersonal effects,” in Conference on Complex System (CCS\u0026rsquo;15). 2015: Tempe, Arizona, USA.\n[29] Granovetter, M., “Threshold Models of Collective Behavior,” American Journal of Sociology 83(6) (1978): p. 1420-1443.\n[30] Singh, P., et al., “Threshold-limited spreading in social networks with multiple initiators,” Scientific Reports 3(7) (2013): p. 2330.\n[31] Shah, D.V., J.N. Cappella, and W.R. Neuman, “Big Data, Digital Media, and Computational Social Science: Possibilities and Perils,” Annals of the American Academy of Political \u0026amp; Social Science 659(1) (2015): p. 6-13.\n[32] Cohen, S., Hamilton, J. T., \u0026amp; Turner, F. “Computational journalism,” Communications of the ACM 54(10) (2011): p. 66-71.\n[33] Watts, D.J., “Should social science be more solution-oriented?” Nature Human Behaviour 1 (2017): p. 0015.\n[34] Jake M. Hofman, Amit Sharma, and Duncan J. Watts. \u0026laquo;Prediction and explanation in social systems.\u0026raquo; Science 355(2017): p 486-488.\n  Computational Communication Collaboratory, School of Journalism and Communication, Nanjing University, Nanjing, Jiangsu, China, 210093 ^   ","date":1502768029,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502768029,"objectID":"b2f07cde3591a4e8d26f10329f67b515","permalink":"https://chengjunwang.com/publication/computational-journalism/","publishdate":"2017-08-15T11:33:49+08:00","relpermalink":"/publication/computational-journalism/","section":"publication","summary":"人类社会已经进入了计算社会科学时代，新的新闻生产方式和研究范式的确立给传统新闻学研究带来了挑战和机遇。计算社会科学从数据、计算方法、网络科学理论等多个层面丰富了新闻学研究。本文尝试梳理计算社会社会科学的发展脉络，总结代表性成果，分析其对新闻学研究的影响。本文最后讨论了计算传播学，强调了从研究问题、数据、模式、机制和基本原理的角度来理解新闻学研究。","tags":null,"title":"计算社会科学视野下的新闻学研究：挑战与机遇","type":"publication"},{"authors":null,"categories":null,"content":" 今年的研读营主要由吴令飞和尤亦庄负责。吴令飞主张研读营应该解决只有研读营才能做的事情。最初大家想分组搞一些研究项目，但考虑到大家因为项目的压力，每一个人都想得是一个可以deliver的东西。虫洞和weak tie有什么关联？boltzmann machine与社会计算？ising model与图灵机：一个社会系统在做计算。就人员组成而言，主要分成了社会科学组合物理学组两大阵营。\n社科与物理两大阵营是否可以理解对方的工作？ 社科和物理两大阵营作为两个组，每个组提议五对文献，任意一对论文有一篇好的，一篇是相对差的。于是两组分别出了一套题目，仅仅给出标题和摘要。\n 社会科学组出的题目\n 物理组出的题目  过程如下：首先，每个人选出自己认为正确的选项；然后，汇总并公示组内结果，每个人发表意见；最后，小组决议，投票决定。最终的结果如下图所示，社科组错了一个，物理组错了三个。\n这个结果略微让人吃惊，因为一般人认为物理组比较难，社科的人难以理解。结果却是对于那些发表出来的文章而言，物理组更搞不清楚社科的难度（“水”）有多深。当然，第二种解读就是，社会科学太软、太水，需要太多的口耳相传的训练，仅仅习得表面的功夫就只能做表面文章。\n玻尔兹曼机  A graphical representation of an example Boltzmann machine. Each undirected edge represents dependency. In this example there are 3 hidden units and 4 visible units. This is not a restricted Boltzmann machine.\n They are named after the Boltzmann distribution in statistical mechanics, which is used in their sampling function. It was invented by Geoffrey Hinton and Terry Sejnowski in 1985.\n unsupervised machine learning  unsupervised learning需要记住所有的东西 supervised learning是建立mapping  ising model  graph as the background geometric structure node  there is a binary spin on each node $\\sigma_v = 1 \\; or -1$  edge  hamiltonian (energy)    $$E = -\\left(\\sum{i\u0026lt;j} w{ij} \\, s_i \\, s_j + \\sum_i \\theta_i \\, s_i \\right)$$\nWhere: * $w_{ij}$ is the connection strength between unit $j$ and unit $i$. * $s_i$ is the state, $s_i \\in {0,1}$, of unit $i$. * $\\theta_i$ is the bias of unit $i$ in the global energy function. ($-\\theta_i$ is the activation threshold for the unit.)\nOften the weights are represented as a symmetric matrix $W$, with zeros along the diagonal.\nNewmann q modularity hamiltonian on the network\nsbm stochastic block model\n deepwalk http://www.perozzi.net/publications/14_kdd_deepwalk.pdf node2vector http://snap.stanford.edu/node2vec/  闭上眼猜测，睁开眼观察，比较二者的差别。\n袁行远介绍雾霾预报 肖达介绍RNN原理 word2vec https://www.tensorflow.org/tutorials/word2vec\n为什么深度学习有效? The humans working behind the ai curtain\n董磊介绍城市研究 制造业的衰落\n贫穷\n回到北京 结束了四天古北水镇的研读营，来到清华参加集智年会。\n浮光掠影 参加了夜游长城的活动。\n","date":1500359527,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500359527,"objectID":"3b24fad2d51cd00ae7a411ee6a072bd3","permalink":"https://chengjunwang.com/zh/cn/swarma-summer-camp.zh/","publishdate":"2017-07-18T14:32:07+08:00","relpermalink":"/zh/cn/swarma-summer-camp.zh/","section":"zh","summary":"\n","tags":["news"],"title":"集智俱乐部暑期研读营","type":"zh"},{"authors":null,"categories":null,"content":" Data Tech2017大赛由中国移动浙江公司与浙江大数据交易中心联合主办，大赛以“数据众智美好未来”为主题，解锁运营商数据，整合气象、交通、空间等数据， 以“开放、互联”的精神激发全社会创新能量，共创美好未来。\n数据改变了人类的生活方式，从衣、食、住、行到生产生活都离不开数据的支撑。数据，让一切有迹可循，让一切有源可溯。为了挖掘数据价值、实践数据赋能，推动大众创业、万众创新，由浙江省经济和信息化委员会指导，中国移动浙江公司和浙江大数据交易中心主办的Data Tech 2017浙江大数据建模与创新应用大赛即将拉开序幕。\n本次Data Tech 2017浙江大数据建模与创新应用大赛以”数据众智美好未来”为主题，分为“模型挑战赛”和“众智创新赛”，并面向全社会开放，高等院校、科研单位、互联网企业、创客团队等人员均可报名参赛。数据集由中国移动浙江公司和浙江大数据交易中心会员单位授权提供，所有数据均以经过脱敏处理，切实保障数据安全。参赛者们利用数据分析方法，挖掘数据价值，探索数据应用，寻找真实业务问题和社会问题的解决方案。\n同时为了推动参赛者创业与就业，大赛组委会联合中国通信信息研究院、数据中心联盟等行业权威研究机构和重点联盟，浙江大学计算机学院、浙江大学管理学院、浙江省计算机学会等学术机构，发动创新工场、百分点等知名企业参与，为参赛选手提供资深的技术支持和创业辅导。此外，本次大赛还将汇集Preangle十维资本、星路资本、银杏谷资本等多家投资机构，为参赛者优秀成果的展示与孵化提供更多的机会，打造技术、产业、资本相融合的良性发展环境。\n大赛启动日期2017年7月15日，初赛截止日期2017年9月2日。报名及查看详细信息请登录大赛官网，网址：http://datatech.zjdex.com。\n初赛阶段提供7000个用户的完整行为数据。决赛阶段提供20万用户的完整行为数据。\n模型挑战赛初赛数据 获取方式：\n选题一 用户旅游出行意向和类型预测 选题一（数据包大小97.5M）下载链接： http://caiyun.feixin.10086.cn/sh/tHlKp3-XYvfebUgC\n选题二用户购买意向预测 选题二（数据包大小1.56M）下载链接： http://caiyun.feixin.10086.cn/sh/YlpDClB0h6vIqeRr\n选题三通信信用风险评估 选题三（数据包大小24K）下载链接： http://caiyun.feixin.10086.cn/sh/xllHu0ExJAZhdmuc\n公共数据集（大小210.7M），下载链接： http://caiyun.feixin.10086.cn/sh/UMtCD38q-V2FoIHn\n模型挑战赛决赛数据获取方式\n模型挑战赛决赛参赛队伍将会通过邮件收到浙江大数据开放平台提供的用户名及密码，可进入中国移动浙江公司大数据开放平台使用海量真实数据。\n众智创新赛数据 获取方式：\n移动_基础信息数据包（大小193.7K），下载链接： http://caiyun.feixin.10086.cn/sh/2R9GuE4S1BhmyUIR\n移动_通话信息数据包（大小972.9K），下载链接： http://caiyun.feixin.10086.cn/sh/OvRMzW7hoe8cHZM1\n移动_轨迹信息数据包（大小4.2M），下载链接： http://caiyun.feixin.10086.cn/sh/fAZG6k9UU-hdj0eZ\n移动_上网信息数据包（大小886.4M），下载链接： http://caiyun.feixin.10086.cn/sh/aKdAJmlM3Ga1Rv2J\n四维_地理空间数据包（大小55.2M），下载链接： http://caiyun.feixin.10086.cn/sh/BlVCEFUO-RT-Phfy\n四维_交通数据包（大小145.5M），下载链接： http://caiyun.feixin.10086.cn/sh/rQFBaFwZhx7atZOO\n四维_气象数据包part1（大小911.9M），下载链接： http://caiyun.feixin.10086.cn/sh/d65GTWEvzAuMF8BF\n四维_气象数据包part2（大小1.3G），下载链接： http://caiyun.feixin.10086.cn/sh/2zFL6Hj_3OowNiCq\n其他数据获取方式：\n参赛选手在参赛过程中，如有获取聚合数据平台的数据需求，可以邮件形式（需包含及个人姓名、团队名称、数据需求清单）将需求发送至zhaoyu@zjdex.com，参赛选手的数据需求经审核通过后，会有专门的工作人员与参赛选手联系，为参赛选手提供聚合数据平台数据使用账号。\n","date":1500186727,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500186727,"objectID":"632399dc5f567cda48eeec79c0da0dcc","permalink":"https://chengjunwang.com/zh/cn/zjmobile.zh/","publishdate":"2017-07-16T14:32:07+08:00","relpermalink":"/zh/cn/zjmobile.zh/","section":"zh","summary":"\n","tags":["news"],"title":"Data Tech2017大赛","type":"zh"},{"authors":null,"categories":null,"content":"健身 健身是很容易受到周围人影响的行为。\n知乎：如何在办公室健身？\n首先，要有正确的坐姿。 其次，要经常健身！\n 俯卧撑 健腹轮 牵拉深蹲  南大公费医疗 南字发〔2017〕80号\n各院系、各单位： 为进一步加强我校公费医疗管理工作，结合工作实际，学校对《南京大学公费医疗管理暂行办法》（南字发〔2006〕151 号）进行了修订完善，形成了《南京大学教职工公费医疗管理办法》。现印发给你们，请遵照执行。 特此通知。\n附件：南京大学教职工公费医疗管理办法 南京大学 2017 年 6 月 26 日\n为进一步加强我校公费医疗管理工作，结合工作实际，特对《南京大学公费医疗管理暂行办法》（南字发〔2006〕151 号）进行修订和完善，形成本办法。 公费医疗遵循国家、单位和个人共同负担的基本原则，在国家给予拨款的基础上，部分自筹经费，保障教职工的基本医疗需求，合理使用有限的医疗经费。\n第一条 适用范围 1.我校事业在编教职工（留职停薪人员除外）和离退休人员。 2.按照学校人力资源处规定，给予享受学校公费医疗待遇的特殊人员。 3.由各单位交费参加公费医疗的企业编制职工的医疗待遇，按原办法执行，交费标准按人均公费医疗支出调整。\n第二条 挂钩医院  江苏省人民医院、江苏省中医院、江苏省肿瘤医院、南京军区总医院、南京鼓楼医院、南京市口腔医院、江苏省口腔医院、南京市胸科医院、南京市脑科医院、南京市妇幼保健医院、南京市第二人民医院、泰康仙林鼓楼医院。\n 第三条 特需医院 在紧急情况下，病人就近选择急诊的非挂钩医院以及医 保定点的康复病院、养老院。\n第四条 就诊的有关规定 1.教职工患病应首先在校医院就诊，凭本人校园卡挂号。 2.因病情需要，需转上级医院诊治的，必须经校医院转诊到挂钩医院就诊，否则医疗费用自理。 3.急诊病人无需转诊，挂钩医院按正常比例报销，非挂钩医院按特需医院报销。 4.住医保定点的康复病院、养老院产生的药费和检查费按特需医院报销，其他费用自理。 5.教职工因公出差在异地（境内）生病就诊，凭派遣函和所在单位证明，医疗费用按挂钩医院报销。 6.离退休人员回原籍、长期探亲或长期外派工作人员离开本市半年以上，须事先在医疗保险管理办公室申请、备案，选择当地一所社区医院和一所二级以上的公立医院定点，同时取消本地所有挂钩医院；当地医疗费用按挂钩医院报销。 7.特殊疑难病例，需到外地医院就诊或会诊者，须凭本市挂钩医院医务处的转诊证明，经医疗保险管理办公室批准后，可转院诊治并按挂钩医院报销，未办理转诊手续者，医疗费用自理。 8.各类人员出国（境）工作、学习、生活期间，发生的一切医疗费用全部自理。\n第五条 医疗费报销有关规定 1.公费医疗的药品报销范围按《南京大学公费医疗药品报销范围》执行。 2.各类人员医疗费用自付比例如下：\n校医院 挂钩医院 特需医院 在职人员 10% 15% 报销总额减半 退休人员 10% 15% 报销总额减半 离休人员、院士、 副省级干部 0 0 报销总额减半\n3.在南京市医保范围内的检查项目，按正常比例报销。 4.材料费单价在 100 元以下的按正常比例报销，单价在100 元以上的报销 50%，离休人员、院士、副省级干部报销60%。 5.特殊治疗（如射频消融、χ-刀、γ-刀、激光治疗、高压氧、粒子射线治疗、机器人手术以及医保范围的靶向治疗等新技术）给予报销 50%，离休人员、院士、副省级干部报销 60%；器官移植者的器官供体费用自理；透析治疗费按90%报销；特别护理、心电、血压、血糖等监护（测）费按增加自付比例 20%报销。 6.住院床位费规定：正常报销标准 50 元/日，副高（副处）及以上按照 80 元/日报销，院士、副省级按照 150 元/日报销。 7.自理费用：参照南京市医保。 8.经确诊为精神分裂症、癌症的病人，凭“三甲”医院疾病诊断证明、病理检查报告单，符合公费医疗报销范围内的住院医药费全额报销，门诊医药费按正常比例报销。 9.实行计划生育的育龄女教职工，上环、取环、人流、结扎、引产等符合计划生育技术服务基本项目的手术费及检查费，经计划生育办公室审定后，按 100%报销。孕期建小卡及药物流产等医疗费用自理。 10.个人自投商业医疗保险，按正常报销比例测算，原则上为公费医疗报销加保险赔款总额不超过患者公费医疗范围内医疗费总额。\n第六条 教职工子女参加南京市城镇居民基本医疗保险，每年个人自付金额超过 1500 元（即从 1501 元起），按男单女双的原则，凭南京市医保定点医院就诊刷卡的发票，医保范围内的自付部分，由学校给予 50%的补助，全年最高补助额 5000 元。\n第七条 除上述规定外，其它未尽事宜，参照南京市医保相关报销规定执行。\n第八条 本办法由学校医疗保险工作领导小组负责解释。\n第九条 本办法自发布之日起施行，我校被地方政府接纳参加城镇职工医保后，本办法自行废止。\n南京大学校长办公室 2017 年 6 月 26 日印发\n","date":1498953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498953600,"objectID":"9fba9518d5fd6816571a524232754bf1","permalink":"https://chengjunwang.com/note/note_archive/2017-07-02-body-building-health-care/","publishdate":"2017-07-02T00:00:00Z","relpermalink":"/note/note_archive/2017-07-02-body-building-health-care/","section":"note","summary":"健身 健身是很容易受到周围人影响的行为。\n知乎：如何在办公室健身？\n首先，要有正确的坐姿。 其次，要经常健身！\n 俯卧撑 健腹轮 牵拉深蹲  南大公费医疗 南字发〔2017〕80号\n各院系、各单位： 为进一步加强我校公费医疗管理工作，结合工作实际，学校对《南京大学公费医疗管理暂行办法》（南字发〔2006〕151 号）进行了修订完善，形成了《南京大学教职工公费医疗管理办法》。现印发给你们，请遵照执行。 特此通知。\n附件：南京大学教职工公费医疗管理办法 南京大学 2017 年 6 月 26 日\n","tags":[""],"title":"健身、医保","type":"note"},{"authors":null,"categories":null,"content":"2017年7月1日—2日南京大学数字人文大会在仙林校区国际会议中心召开。此次大会主题为“数字人文：大数据时代学术前沿与探索”。“数字人文”是目前国际最具潜力的新兴学科和前沿研究领域，具有创新性强、多学科交叉、研究者年轻化的特点。近十多年来，越来越多独立的“数字人文中心（系）”在北美和欧洲开设，比如美国的斯坦福大学、弗吉尼亚大学、加州大学，英国的国王学院，加拿大的阿尔伯特大学等等。这些机构不仅拥有专职研究人员和技术工程师，同时还开展了很多跨学科项目，涉及历史、考古、艺术史、文学、建筑等多个学术领域，并开始招收、培养硕士和博士研究生。\n视频回放，链接， 密码5954\n中国学界自2010年前后开始关注“数字人文”领域，武汉大学2011年成立了中国内地高校中的第一个数字人文中心。台湾大学及台湾中央研究院自2009年起每年举办“数位人文/数位典藏”的国际研讨会，北京大学与清华大学在2016年1月共同组织了主题大会，上海大学在2015年12月，南开大学在2016年11月都召开了相关的国际研讨会，受到了学界的广泛关注和学者们的积极参与，影响巨大。\n“数字人文：大数据时代学术前沿与探索”学术研讨会正是在此学界浪潮下应运而生，旨在聚集国内外学者探讨数字人文的前沿思想与主要议题，从而使得国内学者、学生了解数字人文国际前沿动态和主要焦点，并促进学者们的相互交流，提升数字人文在国内学术界的认知度，促进数字人文跨学科发展。\n会议议题主要包括，但不限于以下课题：\n· 图像分析与艺术、数字博物馆 （召集人：陈静、殷曼楟） · 文本挖掘与文学研究 （召集人：但汉松） · 数字史学的方法与案例 （召集人：王涛） · 数据分析及社交网络 （召集人：陈静、王成军） · 历史地理信息系统（HGIS）（召集人：陈刚） · 数字人文与空间 （召集人：鲁安东） · 数字人文前沿问题 （召集人：邓柯）\n 会议召开时间为2017年7月1日—2日，6月30日报到。 会议地点：南京大学仙林校区（具体地点待定）。 会务联系方式：digitalhumanities@163.com.  南京大学“数字人文：大数据时代学术前沿与探索”会务组 2017年4月6日\n","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"495871a3acc080ddef297e476f445e51","permalink":"https://chengjunwang.com/zh/cn/2017-07-01-digital-humanities.zh/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/zh/cn/2017-07-01-digital-humanities.zh/","section":"zh","summary":"2017年7月1日—2日南京大学数字人文大会在仙林校区国际会议中心召开。此次大会主题为“数字人文：大数据时代学术前沿与探索”。“数字人文”是目前国际最具潜力的新兴学科和前沿研究领域，具有创新性强、多学科交叉、研究者年轻化的特点。\n","tags":["news"],"title":"王成军参与组织数字人文大会","type":"zh"},{"authors":null,"categories":null,"content":" Data for Climate Change Big data has big potential for applications to climate change adaptation. PNAS 2016 http://www.dataforclimateaction.org/home/data/\n Anonymized records of cell-phone use could in principle enable the large-scale tracing of people’s movements in the wake of a climate change-related disaster. Image courtesy of Shutterstock/Athi Aachawaradt.\n  GlobeScan pew 马里兰大学世界公共舆论 WPO http://worldpublicopinion.net PIPA 世界银行 盖洛普 BBC NSEE 欧盟民意委员会 美国气候地图  人口迁移、极端气候、青藏高原、西北地区\n中国气候指数 中国气候指数系列分为年度和月度指数,包括雨涝、干旱、台风、高温、低温冰冻五类指数,以及在此基础上合成的中国气候风险指数。以中国气候风险指数为例,风险等级从低至高分为0到10。1981年至2016年,中国气候风险指数平均值为4.19。对比1999年前后的平均值就可明显看出,风险指数从3.69上升为4.69,气候风险呈逐步增加趋势。 http://news.sciencenet.cn/htmlnews/2017/3/370039.shtm\n环保部 - 工作简报内容分析\n国内调查数据  CGSS 中国国家调查数据库CNSDA 环保部 中国气候传播项目中心 零点 汇丰银行。  内隐联想测试 IAT  概念词和属性词， e.g. 花\u0026amp;好的，蜘蛛\u0026amp;不好的，不一类的时候反应时间长 The candidate IAT, 有两个候选人，一个候选人支持气候变化保护，另一个没有强调，判断这两个人与一些好的品质之间的配对，看反应时间长度。  对气候变化的信念、心理问题、政策支持、迫切性、好坏\n气候变化建构出来的社会事实，态度和行为存在鸿沟，心理学可以发挥优势进行行为干预；社科领域的研究还比较少，15%，多数社会科学；中外差异明显，国内关注度低，环境问题排不到前十，主要关注雾霾和环境污染；在手段在技术层面。知识、教育、收入、价值观、党派，但心理因素可以干预。人类中心主义vs自然关联性，正念（mindful）干预，一类以冥想为主，另一类以认知和信息加工。经过干预之后，看待自然更加敏感了，更加相信和支持气候变化。\n","date":1498717927,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498717927,"objectID":"59449873a5acb96542b36ccdc7691440","permalink":"https://chengjunwang.com/zh/cn/climate-change.zh/","publishdate":"2017-06-29T14:32:07+08:00","relpermalink":"/zh/cn/climate-change.zh/","section":"zh","summary":"\n","tags":["news"],"title":"气候变迁研究：数据、调查、视角","type":"zh"},{"authors":null,"categories":null,"content":" 实验法 实验研究方法是由伽利略所发明的一种研究方法，成为了自然科学和社会科学研究最为重要的工具。自然科学取得了辉煌的研究成果，以物理学为例，主要的实证研究成果都来自于实验研究方法。社会科学的发展仅仅经历了不到三百年，最初主要模仿物理学的发展路径，例如，孔德最初将社会学命名为社会物理学，他认为人类社会是自然界的一个部分，人为的社会秩序通常可以看作自然秩序的延伸。然而，社会科学研究的研究对象\u0026ndash;人类具有意识、通过社会互动相互关联，构成了一种复杂系统，其复杂度远远超过自然科学，被邓肯-瓦茨称之为“二十一世纪的科学”。社会科学的实验往往局限于实验室内部，只能针对有限的人群（多为高校学生）开展实验研究，其外部效度有限，难以帮助研究者理解真实的社会和人类行为。\n问题 伴随着数据科学、网络科学的发展，采用计算方法为主的计算社会科学蓬勃发展。计算社会科学采用互联网大数据、网络科学等计算方法研究重要的社会科学问题。然而，既有的数据虽然规模巨大，但往往在很多维度上缺失，不能很好的回答因果关系、缺少控制，依然存在局限。如何针对大量的个体及其互动进行实验研究构成了互联网公司的产品经理、高校研究者共同的问题。\n问题：如何针对大量的个体及其互动进行实验研究？\n思路 基于众包的人类计算搭建“行为实验室”为解决这一问题提出了崭新的思路。通过互联网平台招募实验参与者，通过智能的程序匹配实验者、实验对象，允许实验对象在虚拟的网络环境内进行互动共同完成一个实验任务，允许实验者进行灵活的实验控制，可以较低的价格吸引更多的实验设计者和参与者。采用这一思路最成功的案例来自于亚马逊的Mechanic Turk（机械驱动的土耳其人）平台。\n 机械驱动的土耳其人（Mechanical Turk）原指18世纪一个打扮成土耳其人的机器人，曾巡回欧洲各国打败不少西洋棋高手，甚至跟名人如拿破仑或富兰克林都下过棋，后来被揭露为其实是里头藏着人的骗局。亚马逊借用这个典故，隐喻所提供的服务是一种外表提供机械性功能可是背后却是有人类智能支持。\n 来源：turkserver1\n互联网产品经理和高校研究者可以基于Mechanical Turk平台搭建虚拟实验室开展大规模的人类行为实验。虚拟实验室以这个互联网作为实验室，与传统的实验室相比，具有很多优点：\n 可以获取大规模的数据和互动关系 持续时间可以较长、对于地理位置的约束更小 可以让实验参与者开展更为现实而非抽象的简单的任务 可以实现更为精准的记录。  微软研究员科学家邓肯-瓦茨及其合作者一直致力于发展线上虚拟实验室（virtual lab），例如他们之前曾搭建music lab网站研究音乐的流行度。最近，他们借助于Mechanical Turk平台搭建了turkserver，研究发表了两篇论文，分别研究了囚徒困境 和灾难救助过程中的团队合作及其绩效 。\nMechanic Turk与turkserver相互配合的思路为实现大量的个体及其互动进行实验研究铺平了道路。但是目前在中国的互联网产业中，还缺乏提供类似Mechanic Turk的服务，而turkserver目前也缺少进一步的开发，这是提出本研究项目的主要目标。\n目标：搭建一个简单的turkserver的扩展版，搭建一个社会行为研究在线实验平台。\n参考文献  turkserver http://turkserver.readthedocs.io/en/latest/examples/tutorial.html, 基于amazon的mechanic turk建设virtual lab ^   ","date":1498262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498262400,"objectID":"1c7f3b0849b7fba5c08af638eb26ac11","permalink":"https://chengjunwang.com/zh/cn/2017-6-24-turk.zh/","publishdate":"2017-06-24T00:00:00Z","relpermalink":"/zh/cn/2017-6-24-turk.zh/","section":"zh","summary":"通过互联网平台招募实验参与者，通过智能的程序匹配实验者、实验对象，允许实验对象在虚拟的网络环境内进行互动共同完成一个实验任务，允许实验者进行灵活的实验控制，可以较低的价格吸引更多的实验设计者和参与者。采用这一思路最成功的案例来自于亚马逊的[Mechanic Turk](https://www.mturk.com/mturk/welcome)（机械驱动的土耳其人）平台。\n","tags":["news"],"title":"社会行为研究在线实验平台","type":"zh"},{"authors":["Cheng-Jun Wang"],"categories":null,"content":" The Panel of Social Networks and Computational Communication, The XXXVII Sunbelt Social Networks Conference of the International Network for Social Network Analysis(INSNA), May 30th – June 4th, 2017 Beijing, China. 网络与数据科学前沿论坛，2017年11月11-12日，西北工业大学，国际会议中心第二会议室，西安，中国  In preparing.\n","date":1497536456,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497536456,"objectID":"89af149cbb908c1a51bf6657d72065f7","permalink":"https://chengjunwang.com/publication/flow-network-analysis/","publishdate":"2017-06-15T22:20:56+08:00","relpermalink":"/publication/flow-network-analysis/","section":"publication","summary":"Human attention becomes an increasingly scarce resource in the age of information explosion. To better understand the flow of collective attention, we construct the attention flow network using anonymous smartphone data of 100,000 users in a major city of China. In the constructed network, nodes are websites visited by users, and links denote the switch of users between two websites. We find a strong concentration of collective attention allocated to popular websites for smartphone users, and strong scaling relationships for the flow of collection attention in the flow networks. Especially, there is a centralized flow structure, the website of large traffic can control the circulated collective attention. Finally, we discussed the benefits and limitations of using the flow network analysis for computational communication research.  ","tags":null,"title":"Leveraging the Flow of Collective Attention for Computational Communication Research","type":"publication"},{"authors":["Xue-Fei Yan","Cheng-Jun Wang*"],"categories":null,"content":"To be submitted.\n","date":1497536456,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497536456,"objectID":"4e7232008f1e0aa29de64c971547e105","permalink":"https://chengjunwang.com/publication/weibo-participation/","publishdate":"2017-06-15T22:20:56+08:00","relpermalink":"/publication/weibo-participation/","section":"publication","summary":"Although popular users are relatively more influential on social media, there may exist a popularity fallacy in terms of their civic participation. We quantify the popularity, influence, and participation of 233 most influential verified users (big Vs) of Sina Weibo in 63 most salient public issues (2013-2016). We find that the popularity of big Vs has a negative influence on their participation in public issues. We explain this finding in the perspective of social identity and impression management. The results of this study shed light on our understanding of the most popular users on social media.","tags":null,"title":"With Great Popularity Avoids Great Responsibility: The Influentials' Participation in Public Issues on Sina Weibo","type":"publication"},{"authors":null,"categories":null,"content":"联系施工方，2018年4月交付使用，之后学院装修，计划9月搬入。\n紫金楼终于来了，现在正在封顶。\n 根据中共江苏省委宣传部与南京大学签订的共建新闻传播学院协议，经教育部可研评估批复，南京大学新闻传播学院楼已完成开工前手续办理，于近日正式开工建设。\n2016年4月25日下午，江苏省委宣传部和南京大学新闻传播学院共建的紫金楼奠基仪式在仙林校区举行，省委宣传部部长王燕文、南京大学党委书记张异宾等领导和新闻传播学院师生代表共同见证紫金楼奠基。\n据了解，新闻传播学院楼坐落于仙林校区文科组团北部，总建筑面积10137.8平方米，建筑高度17.3米，为地上四层的框架结构。项目总投资6400万元，由江苏广播电视集团负责建设，预计于2018年3月底竣工验收投入使用。\n ","date":1497398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497398400,"objectID":"c0e4b6821964f04c89ca0f75a0bab891","permalink":"https://chengjunwang.com/note/note_archive/2017-06-14-school-building/","publishdate":"2017-06-14T00:00:00Z","relpermalink":"/note/note_archive/2017-06-14-school-building/","section":"note","summary":"联系施工方，2018年4月交付使用，之后学院装修，计划9月搬入。\n紫金楼终于来了，现在正在封顶。\n","tags":[""],"title":"紫金楼","type":"note"},{"authors":["Cheng-Jun Wang","Xinzhi Zhang"],"categories":null,"content":" 2017 ICA Conference Temporal and Spatial Analysis of Mobility Data Sat, May 27, 12:30 to 13:45, Hilton San Diego Bayfront, 3, Aqua 307\nSession Submission Type: Panel\nAbstract Every human behavior, including communicative behavior, involves four basic elements (4Ws): Who does What at When and Where. Out of these 4Ws, we have accumulated some knowledge about Who and What with traditional research methods (e.g., survey, experiment, and content analysis). However, due to the unavailability of time-stamped and geo-tagged data, little is known about the When (i.e., temporal) and Where (i.e., spatial) elements in human behavior. The increasing popularity of social media, the expanding capabilities of mobile devices, and the rapid advancement of computational methods provide social researchers a “social telescope” (Golder \u0026amp; Macy, 2014, Annual Review of Sociology) to examine the temporal and spatial characteristics of human behavior at different levels of granularities.\nThe proposed panel focuses on how to model the temporal and spatial features of human behavior with mobility data in a precise and parsimonious way. The interdisciplinary panelists will use empirical examples from their own studies and others’ research to demonstrate: (1) how we can conceptualize and/or operationalize temporal and spatial variables with different mobility datasets (e.g., mobile phone use and mobile apps use); (2) how we can develop empirical/mathematical models to capture and explain the temporal and spatial characteristics of human behavior; and (3) what are the theoretical and/or practical implications in the temporal and spatial analysis of mobility data. Moreover, the panelists will discuss some “critical” questions that have been voiced: What are major challenges communication researchers need to handle in analyzing mobility data? How can communication researchers work with researchers from other disciplines in mobility modeling? How can we deal with personal privacy, replicability, and other legal/ethical dilemmas?\nThe panel aims to help raise the awareness among communication scholars of opportunities and risks in the modelling of mobility data. Moreover, the panel will try to build an interdisciplinary dialogue on computational research between communication researchers, computer scientists, and research scientists from the industry.\nSub Unit： computational methods\nshort-bio Cheng-Jun Wang, Ph.D. He is currently an assistant research fellow in the School of Journalism and Communication, Nanjing University. He is also the director of Ogilvy Data Science Lab, Computational Communication Collaboratory. His research on computational communication appears in both SSCI and SCI indexed journals, such as Scientific Reports, PloS ONE, Physica A, Cyberpsychology, and Journal of Social and Personal Relationships.\nNotes Hello everyone. My name is Xinzhi Zhang, from baptist university of hong kong. The title of our presentation is analyzing mobile phone data with network science. I will briefly introduce the authors. Cheng-Jun Wang is currently an assistant research fellow in the School of Journalism and Communication, Nanjing University. And Xinzhi Zhang is currently a Research Assistant Professor at the Department of Journalism of Hong Kong Baptist University.\nComputational social science provides a new lens for our research of human communication behaviors. Especially, it emphasizes the perspective of network science and big data,including website logs and web-based experiment. Duncan Watts claims that “If handled appropriately, data about Internet-based communication and interactivity could revolutionize our understanding of collective human behaviour”. D. Watts, A twenty-first century science. Nature 445, 489 (2007).\nNetwork science is important for communication research because: Firstly, we live our life in networks; and complex is a mathematical representation of various social systems. More important, compared with the other computational methods, such as computer simulations, network science is more closely connected with the real world data.\nThe mobile phone widely used in contemporary society supplies many social data for our studies, including the calling \u0026amp; messaging data, the online surfing data, and the mobility data. Just as Michael Macy said, it’s been really transformative. The digital traces help understand individual and group behavior at unprecedented scales and levels of detail.\nFor the human mobility data, we have small-scale travel surveys before, it can be coupled with GPS loggers. The rapid rise and prevalence of digital media provides a lot of big data, including: Mobile hone data, social media data, smartcard data, taxi trips data, game data.\nMobile phone positioning is required when a user communicates with the network. When a user initiates a network connection event (e.g. a voice-call), the cellular network operator needs to know his/her location in order to determine the cell tower used to channel this event. In this way, the subsequent positions of the user can be well documented.\nWith the aid of the available data, researchers tried to study human mobility. For example, Brockman 2006 used the trajectories of dollar bills to study the dispersal of human, and they find that the distribution of length r can not be described as levy flights. Random processes with such a single-step distribution are known as Levy flights. Levy flights assumes that there is a power-law relationship between pr and r, the power exponent beta is usually smaller than 2. The simple Levy flight picture for dispersal is incomplete, since the dispersal is weak than expected. This is because the antagonistic interplay between scale-free displacements and waiting times: people might be less likely leave larger cities, and there are long periods of rest. Instead, they tried to describe human moblity as a continuous-time random walk, CTRW. The probability Wr(r,t) of having traversed a distance r at time t, where Lα,β is a universal scaling function that represents the characteristics of the process. According to ctrw model, t^(-α/β)*W(r, t) = Lα,β= (r/t^(α/β))**-gamma. Thus, they can fit the relationship between t^(-α/β)*W(r, t) and r/t^(α/β).\nGonzalez 2008 tried to study individual human mobility, and find that the distribution of both displacements and radius of gyration over all users is well approximated by a truncated power-law (see the left figures and the equations, here Rg is the radius of gyration for each user). However, after After rescaling the distance and the distribution with rg (main panel), the different curves collapse (see the right figure).\nSong 2010 further finds that the predictions of the ctrw models are in systematic conflict with the empirical results. We introduce two principles that govern human trajectories, allowing us to build a statistically self-consistent microscopic model for individual human mobility. ” Give the number of distinct locations S(t) visited by a user is expected to follow the euation, S(t) ~ t^u, individuals has two choices, i) explore new locations. p_new = ro * s^(-gamma), and ii) preferential return to old locations, p_return = 1 – p_new\nThey observed that the distribution of time intervals of mobility follows a power law distribution, implies strong bursts. q stands for the probability of unknown locations, p(q) follows a normal distribution with a mean  = .7, indicating that we have no location update for about 70% of the hourly intervals, which masks the user’s real entropy S. The big nodes in the mobility networks are those old locations the individual preferentially return to.\nSong measure the entropy of each individual’s trajectory to understand the potential predictability in user mobility. They distinguished three kinds of entropy, i) the random entropy s_rand, ii) the temporal uncorrelated entropy, s_unc, and iii) the reall entropy S. Let ∏ (/paɪ/ ) denote the predictability, it measures how can a algorithm predict correctly. Panel a shows the distribution of three kinds of entropies; Panel b shows the distribution of the predictability. Panel C shows the relationship between ∏max and rg We can find that a 93% of potential predictability in Panel C.\nBrockmann and Helbing 2013 uses the global mobility network to study the arrival time of epidemics. The global mobility network is constructed from the worldwide air traffic between 4069 airports with 25,453 direct connections. Let pmn denote the fraction of travelers that leave node n and arrive at node m, we define the effective distance dnm from a node n to a connected node m as dnm = 1 – log pmn \u0026gt;= 1 . The effective distance between two undirectly connected nodes can be computed as the minimum value of the product of a series of dij between m and n. In this way, the arrival time of epidemics can be precisely predicted.\nSchich 2014 construct historical migration network using the birth-death location data of 120,211 individuals, which provide historical evidence for global patterns and local instabilities in human mobility dynamics.\nWe will talk in details about the study Titled Tracing the Attention of Moving Citizens. With the widespread use of mobile computing devices in contemporary society, our trajectories in the physical space and virtual world are increasingly closely connected. Using the anonymous smartphone data of 1×105 users in a major city of China, we study the interplay between online and offline human behaviors by constructing the mobility network (offline) and the attention network (online).\nWe can find strong correlations between offline and online behaviors.To systematically study the relationship between mobile users’ online surfing behaviors and offline mobility, we constructed mobility networks. Mobility network, nodes are physical locations and edges represent the movements between locations.Attention network, nodes are websites and edges represent the switch of users between websites\nWe primarily study their difference in terms of the network structure. Most complex networks are found to be small-world, but also many networks are fractal. For example, the internet is a small world. While the WWW is fractal. Fractals look the same on all scales = `scale-invariant’. There is a famous question about how long is the coastline of Norway. The answer depends on the length of your ruler. We can study the fractal patterns using the method of box covering. The box length is lb, and the number of boxes is nb, there is a power law relationship between them.\nUsing the box-covering method in networks, we can also calculate the box dimension db from the equation of nb(lb). Using the box-covering method, song renormalize the www network and find lb = 3, ie, within three steps, the www network can be transformed to a star network. We renormalize mobility network and attention network to compute db. There are 9899 nodes and 39,083 edges in the mobility network (Density = 7.9×10−4), and there are 16,476 nodes and 144,909 edges in the attention network (Density = 10.6 × 10−4). The diameter of the mobility network is 15, and the diameter of the attention network is only 10.\nWe find that (A) The number of boxes N(lB) is a power law function of box length lB in the attention network, and these two variables show an exponential relationship in the mobility network. (B) In the mobility network, the degree correlation (measured by the Pearson correlation coefficient Cor(Knn, k)) decreases from positive to negative when lB = 4, while the correlation remains negative in the attention network. Panel (C,D) show the transition of degree correlation in details. For the mobility network \u0026copy;, the slope of data points is positive when lB ⩽ 3, and the slope turns negative when lB ⩾ 4. Meanwhile, the correlation is always negative in the attention network (D).\nThe spatial division manifests the location-based online behaviors. There are obvious spatial constrained patterns. We show the geographical distribution of three kinds of mobile Internet use behaviors. A. Shopping (red), B. Dating (blue), and C. Taxi-calling (orange). The spatial-constrained attachment is well developed in geometric network models. We use it to reproduce our findings. We use geometric network models of different linking dynamics to test our assumptions on the origins of the observed fractal and small-world patterns in individual behaviors. In all, we suggest that we find that they belong to two different classes: the mobility network is small-world, whereas the attention network is fractal. online and offline behavior could be governed by very different mechanisms.\nFinally, we would like to highlight some resources for human mobility research. NetworkX is a Python language software package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. http://networkx.github.io/ geopy is a Python client for several popular geocoding web services. It helps to locate the coordinates of addresses, cities, countries, and landmarks across the globe using third-party geocoders and other data sources. bandicoot (http://bandicoot.mit.edu) is Python toolbox to analyze mobile phone metadata. With only a few lines of code, load your datasets, visualize the data, perform analyses, and export the results. Folium builds on the data wrangling strengths of the Python ecosystem and the mapping strengths of the Leaflet.js library. Manipulate your data in Python, then visualize it in on a Leaflet map via Folium.\nThank you for your attention. This is the end.\n","date":1494770637,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494770637,"objectID":"89d4cfd24ff09e83fba3a89ed043bd22","permalink":"https://chengjunwang.com/publication/ica2017/","publishdate":"2017-05-14T22:03:57+08:00","relpermalink":"/publication/ica2017/","section":"publication","summary":"With the widespread use of mobile computing devices in contemporary society, our trajectories in the physical space and virtual world are increasingly closely connected. Using the anonymous smartphone data, we can construct the communication network, mobility network, and attention network, and further analyze the data in the perspective of network science.","tags":null,"title":"Analyzing Mobile Phone Data With Network Science","type":"publication"},{"authors":null,"categories":null,"content":"重庆大学计算传播学论坛 共建大数据实验室 新闻传播学院与信管学院联合创办大数据实验室可以帮助解决共同关心的研究问题。但需要避免虚拟的实验室架构，现实的情况往往是一人身兼多职，难以兼顾，对于并非全力投入的实验室的认同感不高。因而，大数据实验室应该具有明确的人员配置和物理空间，探索建立激励机制，建立科学共同体，形成紧密的实验室群体，能够切实地开展科研与教学合作。\n 开展大数据实验室讲座：组织大数据实验室系列讲座，通过分享、沟通与交流的方式进行有效的互动，发现双方共同感兴趣的研究话题。 科研方面：大数据实验室依托正在建设的大数据计算平台，基于重要科学问题和实际存在的大规模数据作为合作的基础，发表双方认可的高水平研究成果。 教学方面：  1. 大数据实验室提供大数据挖掘和分析的基础课程、工作坊； 2. 尝试双方共同建立数据新闻专业，结合新闻传播学院和信管学院双方的优势。 3. 推动研究生的联合培养模式。   2017年10月17日会谈备忘录\n 落实新闻传播学院一级博士点，条件成熟后合作申请“计算传播学”博士点，与信管学院合作招收联合培养的博士，不占双方名额。 联合开展本科实验班跨文理招生，系统培养数据新闻和计算传播人才。 联合申请重大工程类的项目，围绕传统文化、大运河、媒体融合等题目。例如研究中国传统文化在世界各国的传播与接纳。 用好双创、双一流计划的经费，申请省级和国家项目，建立联合实验室 开展人才的双聘机制，增强双方交流。 落实联合实验室在紫金楼的部署，依托正在建设的大数据计算平台，基于重要科学问题和实际存在的大规模数据作为合作的基础，发表双方认可的高水平研究成果。  南大科学园 如图，4.2m*6m的空间， 团队6所在的3#东南角。\n可沟通城市是一种实践，致力于让城市空间与人形成机密的互动，是一种将建筑设计和技术（3D打印、VR、AR、可视化、语音对话等）紧密融合的艺术。作为艺术，它具有探索的过程，可以通过展览的形式展现，迅速吸引眼球。从展览到生活的过渡，则存在一条需要跨越的鸿沟。因而，需要从宏达的框架中提炼可以为普通人提供的服务。\n国内外计算传播学方向发展的的观察 学校很关心我们的计算传播学科崛起，请近期考虑引进若干名专职科研岗的具体推进方法！包括广告内容、宣传渠道、工作任务。可否你在黄俊楠配合下，这两天给一个初步思路。我们来积聚资源。\n互联网大数据使得计算社会科学等相关领域迅猛发展，国内外传播学院校也开始拥抱这一发展潮流。南京大学新闻传播学院于2015年2月正式建立计算传播学实验中心，加州大学戴维斯分校传播系成立了计算传播研究实验室，领风气之先。其它高校虽然没有使用计算传播作为为名字，但是也大幅度招收采用大数据和计算科学进行传播学研究的学者。例如，宾州大学安尼斯伯格传播学院也挖来了Damon Centola和Sandra González-Bailón；斯坦福大学传播系招来了Jennifer Pan；国内高校以北京师范大学（吴晔、徐敬宏、王蕊）、中山大学发展最为迅速，尤其是北京师范大学通过跨学科招人的方式获得跳跃式发展。\n关于公开招聘新闻传播学院专职科研人员的启事（计算传播学研究方向）  南京大学新闻传播学院因工作需要，现公开招聘计算传播学研究方向专职科研人员3名。\n计算社会科学的发展为传播学研究指明了新的方向；基于因特网的人类传播行为和互动可以深刻地变革我们对人类群体行为的理解。计算传播是指数据驱动的、借助于计算方法所进行的传播过程。分析计算传播现象的研究领域即计算传播学。计算传播学是计算社会科学的重要分支，主要关注人类传播行为的计算基础；以传播网络分析、传播文本挖掘、数学建模等为主要分析工具；大规模地收集并分析人类传播行为数据；挖掘背后的模式和法则；分析模式背后的生成机制与基本原理；被广泛地应用于数据新闻和计算广告等场景；注重编程训练、数学建模、计算思维。\n南京大学新闻传播学院在2015年2月创建了计算传播学实验研究中心，主要使命在于挖掘互联网数据，分析人类传播行为。经过两年多的发展，目前中心已经建成基础计算平台，包括小型计算集群、大内存服务器、数据存储平台、网络服务器，同时储备了大量数字媒体相关大数据资源，在注意力流动网络等领域发表了一系列研究成果。\n2016年9月，第一届计算传播学论坛在南京召开，同年，国际传播学会成立了计算方法组；2017年加州大学戴维斯分校召开主题为Recomputing social science的会议，计算传播学分论坛开始出现在Sunbelt社会网络会议，计算传播学的讲习班和分论坛在中国中文信息学会所主办的全国社会媒体处理大会成功举办。越来越多的人开始对计算传播学感兴趣，为了使得更多的新闻传播学领域的研究者采用计算传播学的研究范式，第二届计算传播学论坛拓展为3天，其中包括了一天半的工作坊，过去的两天里将近80人学员参加文本挖掘基础班和网络信息传播高级班。今天大家再次汇聚一堂，很荣幸地邀请到了五位主题演讲嘉宾，同时还有poster展示、圆桌论坛多个环节，切磋学问，砥砺学术，共同推动计算传播学的发展学术共同体的成长。\n一、岗位描述：\n主要从事计算传播学相关研究和教学工作，独立开展科研工作以及研究课题，努力取得一定的基础和应用研究成果；具备一定的数据科学基础，熟悉Python或其它计算工具；积极与中心团队科研合作；每学期开设至少一门课程；每年以南京大学为第一单位，在相关领域发表SCI/SSCI论文不少于1篇，或CSSCI不少于3篇；参与组织计算传播学年会；积极开展国内外学术交流；积极参加科学普及与社会服务活动，积极承担校、所安排的其他工作。\n二、应聘资格： 1、具有较强的计算传播学研究能力和较好的论文写作能力。 2、具有新闻学、传播学、社会学、政治学、计算机科学、物理学或其它相关学科的博士学位，35周岁以下； 3、具备一定的数据科学基础，熟悉Python或其它用于海量数据分析的编程语言；\n三、工资待遇 本岗位为南京大学专职科研岗位，相关政策详见人力资源处网站《南京大学专职科研系列岗位聘任办法（试行）》文件。\n四、申请程序及提交材料 凡有意应聘者请将个人简历、学历学位证书复印件、科研成果目录等相关材料寄送至南京大学新闻传播学院。确定正式申请后再依规定提交其他材料。\n五、聘后管理 1. 对招聘到上述岗位的人员按学校相关规定管理，年薪??万不等，年均奖励或科研补助??万元左右。 2. 专职科研系列岗位以聘用制聘用，专职从事科学研究工作，聘期三年。优秀的专职科研系列人员，聘期内或聘期结束前，可以应聘学校副教授及以上岗位。\n五、联系方式 通信地址：南京市鼓楼区汉口路22号，南京大学新闻传播学院 邮政编码：210093 联系人：黄老师 联系电话：025-83686260\n大力建设具有学科领先意义的实验室 2）加大科研硬件投入。围绕不断发展的互联网技术，不断改造现有科研实验室，淘汰或彻底改造已经落后于技术发展的电话调查实验室，改进和完善正在建设的计算传播学实验室，兴建媒介认知心理学实验室与数据云实验室，以一系列在国内领域具有领先意义的学科实验室支持最前沿的新媒体研究。\n2）大力建设具有学科领先意义的实验室。以手机、互联网为代表的数字媒体技术迅猛发展，一方面为新闻传播研究方法提出巨大挑战，另一方面也提供了“弯道超车”的发展机遇。通过加大科研硬件投入，完善正在建设的计算传播学实验中心，兴建媒介认知心理学实验室、数据云实验室，彻底改造或淘汰不适应新媒介环境的电话调查实验室，增强新闻传播学研究对大数据的计算、分析和挖掘能力。\n全球华人思想库  全球华人思想库这个项目，资金到位了。现在需要开发一个工具，1、便于全球分主题投稿、整理、档案管理。2、自动生成分主题的元研究：学术搜索和整理综述。你看这个开发怎么做？需要多久？哪些成本？目前急于要开设备清单，以便李晓愚申述双创经费。你们可否在仙林或电话聊一下？只能买硬件。\n  投稿系统，可以考虑博客系统 Web服务器， 建设搜索引擎 自动主题生成  硬件 大数据实验室是计算传播学研究中心的一个重要组成部分。这个实验室目前落到了我和fm两个做project leader，系里从奥美研究院拿出50万支持这个实验室的硬件设施。\n它的组成包括了分布式数据抓取和计算平台、共享计算平台、数据存储平台和实验室网站服务器四个部分组成。另外，接受计算士的意见，我决定购买2-3台macbook。\n软件 巢老师的意见是要实验室表现出传播力。因为我们从论文发表到资源积累，都落后与其他文科院系。但是即便是这些院系中的相关实验室，也较少为外界所知。这不得不让我好奇@北大新媒体这个微博账号是如何运营的啦。\n同时他也告诉我近期的发展，实验室的人手缺乏是重要的问题。我想模仿城大的策略：吸引优秀的本系和外系本科生。目前南大鼓楼主要是商法传播物理这些院系。我想通过一些方式（读书会、沙龙）来吸引更多的本科生加入。采用一定的考核机制，实验室可以成为他们学习的空间，但他们必须参加实验室组会和其他活动，并承担一定的义务。\n按照他的设想，11月完成硬件配置；11月和12月共组织四次活动；我在明年准备开设计算传播学导论的课程。\n我将把我的一些合作者列为实验室的合作成员。参与weblab的组会、与计算士的午间讨论、与信纸的合作项目都可以展开了。\n同时我自己的论文也迫在眉睫啦。\n如何订购实验室电脑 按要求填写申购贵重仪器设备可行性论证报告，需要寻找三家销售代理，细化装备的金额情况。在Hp和dell官网打电话找销售代理，打电话。看了apple中国的报价，以老师或学生身份购买会便宜很多。\n","date":1494158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494158400,"objectID":"62983d65f04613ad82fed0a97ef70ebe","permalink":"https://chengjunwang.com/note/note_archive/2017-05-07-lab-thinktank/","publishdate":"2017-05-07T12:00:00Z","relpermalink":"/note/note_archive/2017-05-07-lab-thinktank/","section":"note","summary":"重庆大学计算传播学论坛 共建大数据实验室 新闻传播学院与信管学院联合创办大数据实验室可以帮助解决共同关心的研究问题。但需要避免虚拟的实验室架构，现实的情况往往是一人身兼多职，难以兼顾，对于并非全力投入的实验室的认同感不高。因而，大数据实验室应该具有明确的人员配置和物理空间，探索建立激励机制，建立科学共同体，形成紧密的实验室群体，能够切实地开展科研与教学合作。\n","tags":[""],"title":"实验中心2017年相关事项","type":"note"},{"authors":null,"categories":null,"content":"新闻史学会二级分会申请 白丹\n 地址：北京海淀区清华大学新闻与传播学院207（100084） 电话：010-62782107 Email：shixuehuitsjc@163.com  清华大学新闻与传播学院\n 地址:北京市海淀区清华大学宏盟楼 邮编100084 电话:010-62781145 传真: 010-62771410 Email:  tsjc@tsinghua.edu.cn xwdjjy@tsinghua.edu.cn   青椒会议 上午\n 吴志远 - 卞冬磊 郑佳雯 - 祁玲玲 朱江丽 - 赵曙光  下午\n 姜海 - 朱丽丽 赵梦溪 - 邹军 林羽丰 - 张宁 许媚媚 - 孙扬  会议邀请函\n祁玲玲，您好，李永刚老师推荐我联系您。南京大学新闻传播学院将在11月30日（周四）举办第一届青椒论坛。由我院7位专职科研老师提交论文，邀请对口的专家老师一对一参会评议。按照国家的财务要求《中央财政科 研项目专家咨询费管理办法》，对高级专业技术职称的专家支付咨询费2000元/人天。非常期待能够有机会邀请您作为专家参会评议《中国城市网民的后物质主义价值转向及对政治信任的影响》一文！非常感谢。王成军、胡翼青\nSMP会议 http://www.cips-smp.org/smp2017/\n 会议时间：9月14日~17日 会议报到时间：2017年9月13日至9月17日 会议报到地点：北京友谊宾馆 地址： 海淀区中关村南大街1号(四通桥西南角) 电话：(010)68498888  参加会议代表可根据个人的报销标准，自行预订酒店。\n订房时请报“第六届全国社会媒体处理大会（SMP2017）”。\nhttp://www.cips-smp.org/smp2017/public/register.html\n9月13日 9月17日 500 大床\n南京大学差旅住宿费标准明细表 https://hr.nju.edu.cn/62/72/c6664a156274/page.htm\n北京 1100 650 500（三类）\n2017年计算传播学年会暨工作坊 会议帐号 https://nic.nju.edu.cn/9003/list.htm\n仅事业在编教职工、博士后、预任职员可开通此功能。资费为：50 线程，200 元/ 天；200 线程，800 元/ 天；500 线程，2000 元/ 天\n办理办法：本人登录OA 、综合办公、“请示报告”，将填写完整的《南京大学会议网络帐号申请表（ 2016 试用版）》作为附件上传，提交网络信息中心审核。\n 100线程，22-23两天，共200元。会后财务处转账网络中心，拍照并且发邮件给yyyu@nju.edu.cn 用户名 ccc2017 密码 barabasi99 我们周四下午会打电话给杨育红老师89684795开通测试。  内容分工  网络科学基础  信息扩散的计算因素（python+networkx基础）成军\n 单条信息传播的测量\u0026amp;机器学习框架 小可 信息传播中的节点重要性\u0026amp;可视化 行为的传播机制 海波 信息传播模型 海波、成军、阮中远  标准  以工作坊为契机，为教学课程、科研、书籍做准备。 有一个编程实现的例子作为遴选标准 使用notebook做slides，一个例子  Deadline 7月15日提交使用jupyter notebook\n使用notebook制作slides的方法  安装Anaconda Python Downnload from https://github.com/damianavila/RISE open your teminal, cd to the RISE folder, e.g., cd /github/RISE/ To install this nbextension, simply run python setup.py install from the RISE repository.  In the notebook toolbar, a new button (\u0026laquo;Enter/Exit Live Reveal Slideshow\u0026raquo;) will be available. The notebook toolbar also contains a \u0026laquo;Cell Toolbar\u0026raquo; dropdown menu that gives you access to metadata for each cell.\nIf you select the Slideshow preset, you will see in the right corner of each cell a little box where you can select the cell type (similar as for the static reveal slides with nbconvert).\n","date":1491004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491004800,"objectID":"cd1407b229426a5b05dfbded3638c66f","permalink":"https://chengjunwang.com/note/note_archive/2017-04-01-conference-host/","publishdate":"2017-04-01T00:00:00Z","relpermalink":"/note/note_archive/2017-04-01-conference-host/","section":"note","summary":"新闻史学会二级分会申请 白丹\n 地址：北京海淀区清华大学新闻与传播学院207（100084） 电话：010-62782107 Email：shixuehuitsjc@163.com  清华大学新闻与传播学院\n 地址:北京市海淀区清华大学宏盟楼 邮编100084 电话:010-62781145 传真: 010-62771410 Email:  tsjc@tsinghua.edu.cn xwdjjy@tsinghua.edu.cn   青椒会议 上午\n 吴志远 - 卞冬磊 郑佳雯 - 祁玲玲 朱江丽 - 赵曙光  下午\n 姜海 - 朱丽丽 赵梦溪 - 邹军 林羽丰 - 张宁 许媚媚 - 孙扬  会议邀请函\n祁玲玲，您好，李永刚老师推荐我联系您。南京大学新闻传播学院将在11月30日（周四）举办第一届青椒论坛。由我院7位专职科研老师提交论文，邀请对口的专家老师一对一参会评议。按照国家的财务要求《中央财政科 研项目专家咨询费管理办法》，对高级专业技术职称的专家支付咨询费2000元/人天。非常期待能够有机会邀请您作为专家参会评议《中国城市网民的后物质主义价值转向及对政治信任的影响》一文！非常感谢。王成军、胡翼青\nSMP会议 http://www.cips-smp.org/smp2017/\n 会议时间：9月14日~17日 会议报到时间：2017年9月13日至9月17日 会议报到地点：北京友谊宾馆 地址： 海淀区中关村南大街1号(四通桥西南角) 电话：(010)68498888 ","tags":[""],"title":"计算传播学年会工作坊组办","type":"note"},{"authors":null,"categories":null,"content":"关于2018年度“中央高校基本科研业务费”项目额度使用完毕的通知 http://scit.nju.edu.cn/96/e5/c10916a300773/page.htm\n发布时间：2018-10-31 浏览次数：216\n各院系、各单位、各相关项目负责人：\n根据《南京大学“中央高校基本科研业务费专项资金”管理办法》及经费使用安排，2018年度中央高校基本科研业务费（项目号为“143”开头）使用截止日期为10月30日，现已到期，同时国库额度也已使用完毕，故10月31日起不再受理中央高校基本科研业务费的网上预约业务。根据中央财政经费使用规定，2018年度中央高校基本科研业务费项目剩余额度将自动清零。\n已在网上完成预约的单据请务必于11月9日下班前提交至财务处，逾期不予受理。未冲销的暂付款请务必抓紧时间办理冲账报销手续，原则上必须在12月15日前冲销完毕。\n特此通知。\n财务处、科技处\n2018年10月31日\n2017年度社科基金中期检查工作的通知 2012、2013、2014、2015、2016年度未结项的国家社科基金重点、一般和青年项目。\nhttp://skch.nju.edu.cn/notice/1268556158\n南京大学税务识别号及银行账号 南京大学开具增值税专用发票的资料：\n 纳税人名称：南京大学　 纳税人识别号：12100000466007458M 地址、电话：南京市栖霞区仙林大道163号　025-89684117 开户行及账号：工行汉口路支行　4301011309001041656  财务处网站 蓝鲸大学财务网站 http://ndcw.nju.edu.cn/ 终于搞明白了，好像只有校内网络才能登录!!!\n如何发放专家咨询费？\n 学生劳务费  我居然用了这么长的时间才搞明白这个系统，主要是自己一直在家里待着，用不了这个系统。2333\n 专家咨询费  在收入申报部分填写!!! 选择”校外专家” 选择“校外人员信息采集”录入银行卡信息   已经填写了张伦的专家咨询费。填写了生成的表格，学院盖章后交给财务处报销。\n公务卡 公务卡报销过程中的问题解答\u000b2017年3月16日\n2017-05-31在仙林校区外的工行激活了我的公务卡，在图书馆里使用公务卡买了火车票两张，还是挺方便的。后面去桔子酒店预订住宿一晚。希望早日学会使用公务卡消费。\n Note: 使用12306手机App买火车票并支付，选择短信验证，输入手机号码、后六位公务卡号。\n  不能透支转账 且转账后的纪录在报销系统里是没有的，不能编制。  消费满25日内还款还是有压力的吖，要去跑财务处了。\n先在财务处网站，编制公务卡消费记录。然后，点击差旅生成公务卡消费表格。具体流程如下：\n 登录“网上自助平台” 点击”网上报账” 点击“公务卡” 然后，选择“日常报销”、”差旅报销”、“本市交通报销”中的一项生成表格，保存为pdf 学院财务一支笔签字盖章“公务卡消费表格” 出差的话，还需要填写”出差审批表”和“预算表”  校外接入功能的设置和使用 https://nic.nju.edu.cn/e1/29/c8913a188713/page.htm\n电话咨询了网络中心技术人员，对方不熟悉mac电脑！！！说可能是其他vpn修改了注册表。建议我重新安装，我重新安装了之后，依然没有什么作用。要考虑在windows下来完成这个过程了。\n 通过virtualbox可以方便地实现bras连接，如上图打开了财务处网站。设置了一个共享文件夹。    In a Windows guest, shared folders are browseable and therefore visible in Windows Ex- plorer. So, to attach the host’s shared folder to your Windows guest, open Windows Ex- plorer and look for it under “My Networking Places” -\u0026gt; “Entire Network” -\u0026gt; “VirtualBox Shared Folders”.\n 1）上宽带； 2）首次使用时，须先在电脑上建立“南大BRAS校外拨入”的VPN连接。根据您的操作系统，查看校外拨入连接的设置办法：WIN10系统 WIN8系统 WIN7系统 WIN XP系统 Macintosh 系统 - 另：WINXP等旧系统可下载 BRAS客户端.rar ，解压后安装，并重启机器。注意：连接时，必须勾选 □off-campus 选项\n3）需在校外访问校内图书馆资源时，点击“南大BRAS校外拨入”进行连接。\n4）无需访问校内图书馆资源时，请断开BRAS连接。\n注：本操作方法在苹果leopard10.5.5和10.5.6中测试通过。 如有疑问或无法成功设置，请联系网络信息中心 89683791 。\n当使用BRAS校外拨入功能时，您需要在Macintosh系统上如下操作：\n1、在菜单中点击System Preferences，打开Network选项,点击左下角“”＋”号，新建一个“VPN”连接；\n2、选择连接类型为“l2tp over ipsec”，写入该连接的名称（任意); 在“server address ”填入地址：218.94.142.114; 在“account name”中填入您的bras账号；\n3、打开“advanced”选项：并勾选上“send all traffic over vpn connection”；\n4、在/etc/ppp文件夹（可能需要提供系统安装时的密码）下建一个文件，文件名为：options ( 注意，该文件名没有后缀！)，文件内容见options内容（两行文字）； 方法之一：打开MAC系统的“终端（Terminal）”，然后用命令行方式操作（如： cd /etc/ppp 目录，nano 或 vi 一个文件options，将两行文字写入该文件）。编辑文件前，可能需要先取得root权限。\n5、在系统网络连接中选择前面建立的连接，点击“connect”，在弹出对话框中输入您的上网账号密码即可上网。\n更新：\n这样虽然不能进入财务处页面，但是可以下载论文。\n","date":1489979922,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489979922,"objectID":"4c1511bc81bd8281c8a662fafa0d3759","permalink":"https://chengjunwang.com/note/note_archive/2017-03-20-ndcw/","publishdate":"2017-03-20T11:18:42+08:00","relpermalink":"/note/note_archive/2017-03-20-ndcw/","section":"note","summary":"关于2018年度“中央高校基本科研业务费”项目额度使用完毕的通知 http://scit.nju.edu.cn/96/e5/c10916a300773/page.htm\n发布时间：2018-10-31 浏览次数：216\n各院系、各单位、各相关项目负责人：\n根据《南京大学“中央高校基本科研业务费专项资金”管理办法》及经费使用安排，2018年度中央高校基本科研业务费（项目号为“143”开头）使用截止日期为10月30日，现已到期，同时国库额度也已使用完毕，故10月31日起不再受理中央高校基本科研业务费的网上预约业务。根据中央财政经费使用规定，2018年度中央高校基本科研业务费项目剩余额度将自动清零。\n已在网上完成预约的单据请务必于11月9日下班前提交至财务处，逾期不予受理。未冲销的暂付款请务必抓紧时间办理冲账报销手续，原则上必须在12月15日前冲销完毕。\n特此通知。\n财务处、科技处\n2018年10月31日\n2017年度社科基金中期检查工作的通知 2012、2013、2014、2015、2016年度未结项的国家社科基金重点、一般和青年项目。\nhttp://skch.nju.edu.cn/notice/1268556158\n南京大学税务识别号及银行账号 南京大学开具增值税专用发票的资料：\n 纳税人名称：南京大学　 纳税人识别号：12100000466007458M 地址、电话：南京市栖霞区仙林大道163号　025-89684117 开户行及账号：工行汉口路支行　4301011309001041656 ","tags":[""],"title":"大学财务报销","type":"note"},{"authors":null,"categories":null,"content":"人员调动登记表 https://hr.nju.edu.cn/60/be/c6666a155838/page.htm\n 调动人员户口登记表.doc 人员调动登记表.doc 填写说明.doc  新入职人员进校流程 中国博士后办公系统处于审批中，无法修改，所以《工作期满登记表》和其中的迁移户口信息无法修改。\nhttps://lxggxz.nju.edu.cn/15/32/c411a5426/page.htm\n国内博士后：若新进人员为校内博士后，我处开具博士后出站接收函由对方自行办理出站手续，然后持博士后出站工作分配介绍信、最终学位原件与复印件和体检表来我处进行材料审核；\n 工作协议与合同的签订 新进人员根据入职岗位的不同在我处领取不同的工作协议及合同，带回入职院系填写并加盖行政公章。对调入和国外引进人员开具人事档案《商调函》办理相关档案商调工作、并尽快将人事档案转入我校，最后到我处交验合同及干部履历表。\n 登记注册 新进人员填写报到登记簿，提供南京工商银行借记卡和身份证（护照）复印件用作工资卡，带一寸照片一张办理工作证，最后给新进人员开具“工作人员介绍信”到用人单位报到。\n 报到后续工作 1)起薪：起薪时间从报到手续完备之日起算，岗位津贴从起薪的当月开始发放（2 月、8 月不发岗位津贴）。\n  2)校园一卡通：报到起薪后的次月 15 号后到校园一卡通中心办理“一卡通”。电话：83596529, 83596989。网址：http://ecard.nju.edu.cn\n3)安家费与科研启动经费：为适应创建世界一流大学的需要，根据建设高水平教师队伍的需要，学校颁布《南京大学人才引进培养基金管理办法》。针对2002年后入校或选留具有博士学位的教学科研人员可申请科研启动经费和安家费。发放办法为：新入职人员入校手续办理完毕后每隔三个月逐批定期发放。\n4）住房福利申请与落实：学校不再为新进人员提供宿舍，新进人员（专职科研岗除外）可以申请住房货币补贴、租金补贴和贷款贴息等相关福利。详见南大人力资源处主页“政策法规”栏“学校有关规章制度”中《新聘用教职工住房货币补贴、租金补贴及贷款贴息暂行办法》的有关规定。原已交公积金的新进人员，请与房产处房产科联系，联系电话：83596054。\n5）落户：鉴于学校不再提供宿舍，经商校保卫处，凡新进人员的户口实行市场化管理，即全部落户在各大人才市场，由个人自行解决。如确实需落户学校集体户口的新进人员可按照下列情况办理相关手续：应届毕业生需办理户口迁移手续的，请将“户口迁移证”交至我处加盖公章，再由本人持《户口迁移证》及《报到证》复印件等材料到保卫处户籍科办理落户，联系电话：83592226。引进、调入人员需办理户口迁移手续的，可凭江苏省人社厅开具的调令直接到南京市公安局鼓楼分局（地址：定淮门大街1号）办理落户手续。联系电话：84421443。\n博士后出站 居然有十八个表格要填！faint，暑期也搞不完了。\n 博士后编号 152283 招收类型 流动站自主招收 进站单位 南京大学政治学 -\u0026gt; 南京大学 一级学科 政治学 进站时间 2015-01-09  博士后出站研究报告书写规范\n博士后  魏强 89681559 学院导师签字，政府管理学院张冰老师盖章。 提交《中国博士后科学基金资助总结报告》  办公室工作人员 魏强\n主要负责: 1、办理博士后进、出、退站手续，包括通知发放、网上预审、预约报到、户口迁移、证书发放等； 2、博士后起薪、止薪以及调薪工作； 3、博士后人事档案保管、核对与转递工作； 4、博士后办公系统的更新与维护工作； 5、承担领导交办的其他工作。\n 联系电话：025-89681559（仙林）025-83593304（鼓楼） 联系邮件：weiqiang@nju.edu.cn 办公地址：仙林校区行政北楼518室 鼓楼校区南园综合楼418室  To-do：学校财务处审核《中国博士后科学基金资助总结报告》并加盖章，拿给魏强看一下。\n基金审核  您好！在站期间您获得了博士后基金资助。根据《中国博士后科学基金资助规定》，您需提交《中国博士后科学基金资助总结报告》。 请登录中国博士后科学基金管理信息系统填写《中国博士后科学基金资助总结报告》，并与出站报告一并请设站单位管理人员网上审核，审核通过后方可办理出站手续。 以上完成后可继续点击【提交申请】。\n http://jj.chinapostdoctor.org.cn/V1/Program3/Default.aspx\n生成的word文档，填写，签字，盖章，扫描，上传。\nhttp://jj.chinapostdoctor.org.cn/V2/FundReport/FundReport_BSH.aspx?rnd=8683e8e1-0be3-475e-8ad1-0f0f8ad25d98#\n公共管理（政府管理学院）张 冰 党政人事秘书 博士后流动站秘书 352 89680757 ytzhang@nju.edu.cn\n流动站联系教师：张冰；办公电话：025－89680757；Email：ytzhang@nju.edu.cn\n博士后出站  流动站自主招收出站申请材料清单 2016-11-24 流动站自主招收博士后出站申请流程图 2016-10-12  http://hr.nju.edu.cn/6334/list.htm\nhttp://www.chinapostdoctor.org.cn/WebSite/program/InfoCate_Show.aspx?INFOCATEGORYID=website003005001\n注：办理进(出、退)站手续时，请您按要求携带“上传材料”和“纸质材料”中列出各项材料（1份原件和2份复印件），并且按要求上传原件电子数据扫描件。\n 红色上传 为必需上传材料; 灰色上传为可选上传材料; 没有上传按钮的为个人携带材料。 上传后的材料可删除后重新上传。为确保顺利办理进出站手续，请下载并使用系统“电子数据”和“纸质材料”中的表格。  发表论文  Wang, C.J., Wu, L*, Zhang, J., Janssen, M. (2016) The Collective Direction of Attention Diffusion. Scientific Reports. 6: 34059. doi:10.1038/srep34059 Wang, C.J., Wu, L.*(2016) The Scaling of Attention Networks. Physica A: Statistical Mechanics and its Applications.448:196–204, doi: 10.1016/j.physa.2015.12.081  博士后退站 http://hr.nju.edu.cn/6342/list.htm\n办理落户 今天青椒村外来务工人员一个狗去公社人力资源部办理了申请集体户口迁移的第一道手续，路过公社保卫处户籍科门口的时候，一只红脖子的鸟站在树上红了眼眶使劲叫，一个狗听了半天没听懂，当然因为它说的是鸟语。\n到鼓楼校区北京西路附近的机械大厦找鲜峰办理博士后集体户口申请，去鼓楼保卫处户籍科办理户籍介绍的证明，然后去鼓楼公安局的办证大厅办理迁入申请，然后回老家迁移户口，最后到大方巷的鼓楼派出所办理入户。\n流动站自主招收博士后出站申请材料清单 发布者：贾静发布时间：2017-04-18浏览次数：294\n 博士后研究人员工作 期满登记表 （一式3份） 在“中国博士后”网站网上填报，自动生成下载后打印； 其中，该表中的出站单位与地址必须填写，若尚未落实单位，须填写档案寄往单位（外籍人员回国的除外）。 接收单位意见表/接收函 （一式3份） 统招统分博士后由出站单位出具，需加盖接收单位人事公章；在职博士后回原单位，不需提供。 身份证复印件（正反）\n 博士后研究人员工作期满 业务考核表 （一式3份） 博士后研究人员工作期满 审批表 （一式3份） 联系导师对博士后研究人员研究 工作评价表 （一式2份） 由流动站合作导师签字盖章\n 南京大学博士后期满离站科研 工作评审表 （一式2份） 由流动站组织答辩\n 南京大学博士后离站 个人总结表 （一式2份） 流动站责任人签署意见，签字并盖章 《博士后研究人员更换资助项目负责人申请表》 （一式2份） 《江苏省博士后科研资助计划项目总结报告》 （一式2份） 《江苏省博士后科研资助计划项目经费决算表》 （一式2份） 须到学校财务处盖章确认 《中国博士后科学基金资助总结报告》 （一式2份）； 提交网上申请，并到学校财务处盖章确认，报校人资处审核（该表审核通过后方可提交网上出站申请） 南京大学教职工离校手续表 （一式1份） 需相关部门盖章 南京大学博士后研究工作报告 （一式两份） 与博士毕业论文格式相似，包括封面（胶装）、目录、内容 出站博士后科研 成果汇总表 （一式1份） 在站期间发表论文 （一式1份） 包括封皮、目录、首页复印件及获奖情况 结婚证、独生子女证（或子女出生证）复印件（各2份）；\n统招博士后请提供3 份身份证复印件 （身份证须正反复印） 18.博士学位证书复印件（一式1份）；博士后工作证原件\n  注：\n 1）中国博士后系统的附件必须为原件 的扫描或拍照上传； 2）表格4-11、13、15可到南京大学人力资源处官网-博士后-表格下载处下载打印； 3) 把第1、2、3、4、5项表格装订成份,共上报3份，至少一份为原件；\n 4）表格6、7、8装订成份，共两份，至少一份为原件； 5）表格9，博士后在站期间取得江苏省博士后科研资助计划或中国博士后面上资助，且出站时未完成资助项目的情况下填写； 6）表格9、10、11、12，如博士后在站期间未获得过江苏省博士后科研资助计划和中国博士后基金项目，不必填写； 7）表格13，文科类博士后不需要盖“科技处”公章；理工科类不需要盖“社会科学处”公章； 9）所有书面材料请用A4纸打印复印，保证至少一份是原件。 10）出站申请递交至省人社厅审批通过后，会以短信形式告知申请人通过审批，并携材料办理相关手续。而申请人本人不用再次携带材料办理手续，已经代为办理。 8）关于迁移户口的说明：\n A、落本人房产人员须提交《不动产权证书》或《房屋产权证》,尚未取得《不动产权证书》或《房屋产权证》的可提供《购房合同》和物业公司出具的《入住证明》。\n B、配偶、子女办理落户所需材料： （1）配偶、子女《户口簿》首页及《常住人口登记卡》； （2）配偶“居民身份证”、《结婚证》； （3）子女《出生医学证明》、《独生子女证》或《生育服务证》（说明：多胎子女及2016年1月1日后出生的子女提供生育服务证）；\n C、离异博士后研究人员办理子女落户需提交《离婚证》、离婚判决书或经当地民政局盖章（公证处公证）的《离婚协议书》；\n D、在港、澳、台及国外出生的婴儿，还须提交国外或境外医疗机构出具的出生证明原件、复印件，翻译机构出具的出生证明翻译件以及我驻外使领馆签发的《中华人民共和国旅行证》或《护照》。   今日单词 集体户口 collective registered residences.\n","date":1489579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489579200,"objectID":"db7ee13e411c7feff15dd8bd93374369","permalink":"https://chengjunwang.com/note/2017-7-10-postdoc/","publishdate":"2017-03-15T12:00:00Z","relpermalink":"/note/2017-7-10-postdoc/","section":"note","summary":" ","tags":["工作","户口"],"title":"博士后出站与入职","type":"note"},{"authors":null,"categories":null,"content":"根据《南京大学关于增列硕士生导师资格评定的暂行办法》（修订稿）精神，2017年度硕士生导师的申报正常进行，申请人6月30日前将材料提交所在院系学位评定分委员会，院系8月31日前将讨论通过的申请材料交学位办。\n关于2017年度增列硕士生导师工作的通知 7月30日收到胡老师电话，提醒我提交硕士生资格申请，而8月31日是最后期限。\n硕导申报需要提交以下纸质材料： (1）增列硕士生导师表决票(附统计表)；\n (2)《南京大学申请培养硕士学位研究生指导教师审批表》一式三份； (3)申请人正式发表或出版的代表作的复印件及国内、外对本人从事或指导的有代表性的研究成果的评价(如有，提供复印件)； （4）发表文章的检索证明。理工科SCI图书馆查新中心出具的报告（包括清单），文科社科评价中心出具的CSSCI检索报告（包括清单）； （5）承担的科研项目任务批准书（复印件）。  材料2、3、4、5由申请人提交给院系。\n院系讨论后将表决票及通过的申请人材料送学位办　增列办法及申报表详见附件。\n　研究生院学位办 2017.5.25\n公示 20170712，请于2017年7月19日前与南京大学人力资源处联系。\n63 新闻传播学院 副教授 王成军 AP20162051\n具体信息见这里。\n高级职称评审会议 各院系、各单位： 2016年教师高级岗位专业技术职务述职通知时间如下：\n新闻传播学院 AP20162051 副教授 王成军 1986/10/11 15:06 仙林校区行政北楼409\n教授述职时间共12分钟（8分钟述职+4分钟提问），副教授述职时间共8分钟（6分钟述职+2分钟提问）。时间安排在本周六（7月1日），地点在仙林校区行政北楼会议室。上午8:30开始教授述职，下午13:30开始副教授述职。请各单位务必通知到上述每一位申报教师按预计时间提前15分钟到场做好准备，还没有发送ppt的老师请尽快将ppt于明天中午12点前发送至邮箱huwener@nju.edu.cn，过期不再接收，如有疑问请及时跟我们联系。谢谢！\n联系人：周恒、刁忠弈 联系电话：89683309、89683046\n人力资源处培训发展办公室\n各位老师好： 现通知本周六（7月1日）上午8:30开始，在仙林校区进行2016年度教师高级职称述职，上午教授，下午副教授，请各位老师通知相关申报人做好准备，具体述职时间、地点我们明后天会再通知。谢谢！ 人力资源处\n拟定于六月底、七月初进行各系列高级职称评审会议（全部在仙林校区），述职与提问时间\n 教授：8+4min， 副教授、教育管理、思政和其他系列高级述职时间：6+2min。 PPT文件名请人事秘书老师按“申报序列编号_申报职称_单位名称_姓名”存放并打包  申报序列编号：教师01，实验工程02，图书编辑03，教育管理04，思想政治05； 例如：01_教授_文学院_XXX 如有视频，不要通过邮件发送。  另外，请通知述职人自备优盘和述职材料述职当天带到述职现场，以备不时之需。  请各位老师及时通知到各系列申报人员，做好述职准备以及ppt，各单位人事秘书老师邮件于6月27日中午12点前发送至huwener@nju.edu.cn。具体安排述职地点及时间另行通知，谢谢！\n人力资源处培训发展办公室\n主要优势  王成军博士毕业于香港城市大学，曾在澳大利亚国立大学访学半年和在腾讯研究院实习数月，从中广泛接触到国际学术界和互联网产业的一系列前沿理论、方法、工具和经典应用案例。 读博时间曾在SSCI传播学顶级期刊Cyberpsychology上发表了一篇有关Twitter网上社会运动信息扩散的论文；在南京大学任职之后，又先后发表了多篇论文，合著了《社交网络上的计算传播学》。其中包括在自然出版集团旗下的刊物Scientific Reports上发表的关于注意力流动的论文,这也是国内新闻传播学领域的学者首次在这样的刊物中发表论文。 这些论文和专著的数量和质量，如严谨性、创新性、挑战性等，不仅在国内传播学青年教师中、甚至在亚太地区相同传播学者中，都是名列前茅的。 “计算传播学”是一个新闻传播学、计算机科学、网络科学等多学科交叉的研究领域,也是国际学术界较为关注的一个重要领域。 成军是国际传播学界内最早提出“计算传播学”（Computational Communication）概念的学者之一，为宣传、普及和发展计算传播学作出了诸多重要贡献。他参与创建了国内第一家计算传播学研究机构:南京大学计算传播学实验中心,并担任其中奥美数据科学实验室主任。自2016年起，每年在南京大学负责筹备一次全国计算传播学年会，有效地奠定了南京大学在计算传播学领域的领先地位。 王成军博士治学严谨、成果丰硕，已在国内传播学界崭露头角，符合并超越了一流大学副教授的标准。  述职报告 各位评委老师，大家好。我是王成军，来自南京大学新闻传播学院。\n我的述职报告的题目是《计算社会科学视角下的传播学研究》，具体包括四个部分：个人简介、研究成果、教学服务、工作计划。\n第一部分个人简介 我本科毕业于兰州大学，硕士毕业于北京大学，博士毕业于香港城市大学。 2014年9月加入南京大学新闻传播学院，担任奥美数据科学实验室主任，计算传播学实验中心成员。 我的主要研究兴趣聚焦于计算传播学，包括但不限于：注意力流动网络、公共讨论，团队科学。 更多信息参见我的个人网站。\n第二部分是研究成果 共发表了六篇英文论文，包括四篇SCI/SSCI一作或通讯、两篇SCI/SSCI三作。此外，还有十六篇国际会议论文以及部分中文论文。 四篇论文当中包括两篇自然出版集团期刊Scientific reports，一篇Physica A， 还有一篇Cyberpyschology。 这些期刊的影响因子均较高，例如，Scientific Reports的影响因子是5.228， Cyberpyschology在2013年影响因子是2.41，在传播学72本国际期刊中排名第四。\n其中，Tracing the attention of moving citizens一文是中国新闻传播学科在自然出版集团旗下刊物发表的第一篇研究成果，也是在注意力流动网络方向的第一篇正式研究成果。\n瓦茨在2007年提出“基于因特网的传播和互动数据可变革我们对于人类群体行为的理解”，他认为社会科学将成为21世纪的科学。 Lazer等一批学者2009年在Science上发表题为“计算社会科学”的文章，标志着计算社会科学的出现；无独有偶数字人文也开始出现。 如何将从计算社会科学的视角出发进行传播学研究成为重要问题？ 对此我提出了“计算传播学”的发展思路，发表了几篇关于计算传播学的中文论文，尝试确立计算传播学的概念和目标。\n参与翻译了使用Python进行社会网络分析的书籍。 合著了《社交网络上的计算传播学》一书。\n探索计算传播学的研究路径，即从社会科学的重大问题出发，收集大规模的数据，采用成熟的算法，建立简单的模型，解决实际问题。例如： - 这四篇文章分别试图总结注意力流动的模式、方向、和人类移动的关联、公共讨论的异质性； - 分别采用了百度贴吧的数据、digg社交新闻网站数据、北京移动用户数据、推特数据； - 开发或运用已经成熟的算法，尤其是流网络分析的算法； - 建立了一系列简单的数学或物理学模型，例如tracing一文采用的是随机几何图模型。\n研究项目方面，我主持了一项国家社会科学基金青年项目、一项博士后科学基金面上项目，并参与了一个自然科学基金项目。\n第三部分是教学和社会服务。 同样主要围绕建设计算传播学社区展开 在过去三年里为研究生和本科生课设《计算传播》、《数据新闻》、《计算广告》相关课程。\n2015年参与创建了计算传播学实验中心， 并发起建立了计算传播网。\n2015年主办了集智注意力科学年会； 2016年主办了第一届计算传播学论坛； 2017年该会议发展为计算传播学年会，为期3天，并包括一个两天的工作坊。\n积极参与计算传播学跨学科的交流。例如： - 组织sunbelt2017计算传播学分论坛； - 组织中国信息学会SMP计算传播组征文； - 此外我参加了南京大学数字人文小组，参与组织南京大学数字人文大会。\n在期刊审稿方面，担任多家国内外期刊的审稿人； 在软件开发方面，开发了三个python软件包和一个R软件包。\n最后一部分是未来的工作计划。 除完成副高岗位要求之外，我打算在以下方面做出贡献： 教学方面，继续开设《数据新闻》、《计算传播》等课程。还将于2017年开设233改革硕士品牌课程 《大数据挖掘与分析》； 科研方面，定位发表高影响因子期刊的英文论文、兼顾中文论文；出版《计算传播学导论》一书。 社会服务方面，继续举办“计算传播学工作坊和年会”，积极参与学校智库和双创建设。 在力所能及的范围内，冲击登峰B计划\\青年长江等人才计划，为学科发展做出贡献。\n我的述职汇报完毕，感谢聆听，欢迎提问！\n找工作 蓝鲸大学人力资源处3月8日发布2016年教授、副教授招聘公告, 其中新传院的招聘公告包括了教授要求 和副教授（校外）要求。看了一下细节，达到了副教授的基本要求。15日问了下学院黄老师，直接按照网页的要求填写即可，学院还没有收到具体通知。\n首先按照这个网址填写校外申报的材料, 使用Winebottler的IE浏览器未果，结果发现使用FireFox可以填写！但是不能打印。IE7或者IE11都不能打印。最后发现图书馆里用的浏览器是Win10系统里的Microsoft EDGE 20，可以打印, 原来也不是IE。\n一天后（3月16日），学院人事通知最好能在3月24日前交齐材料，后面院系还有一系列公示，并给了一系列可以下载填写的资料和详细纸质版本报送方式，详见关于2016年教师高级职务岗位评聘有关工作的通知中的下载资料，其中需要注意的是，有关应聘人员做好准备（提供PPT），述职时间6分钟。\nTo-do list 1. 填写任职资格申报表 格式调整，解决方法：在word里填写表格并打印 打印2份  2. 推荐信 3. 填写教师系列申请表 打印6份  4. 打印5篇代表作6份 5. 科技查新 6. 学历学位 7. 教师资格 [ ] 述职6分钟，准备PPT\n 科技查新 http://lib.nju.edu.cn/html/article.htm?id=30\u0026amp;fid=24\n 校内访问 http://cx.nju.edu.cn/ 状态 http://cx.nju.edu.cn/novelty/status.php 1、请用校内经费卡转账至图书馆账号0301 0011 3101。 2、携转账发票黄色联至鼓楼图书馆104室或仙林图书馆2310室领取报告。祝您一切顺利！（鼓楼取报告的需多等待1~2个工作日）。 3、如需要，可将此邮件打印提供给校财务处作检索记录证明清单。 【在本次委托完成前请将以往尚未交费或缴纳过押金但未转账，以及尚未提供转账单黄色联的委托记录结算完毕后再领取此次查新报告，如无欠费情况可忽略此信息。谢谢您的合作。】 ISI Web of Knowledge http://lib.nju.edu.cn/html/database.htm?id=6\u0026amp;fid=3 C刊被引用情况 http://cssci.nju.edu.cn/ 鼓楼图书馆505   注意事项 最好能在3月24日前交齐材料，后面院系还有一系列公示啥啥的 - 关于2016年教师高级职务岗位评聘有关工作的通知.rar\nhttp://hr.nju.edu.cn/cb/85/c5977a183173/page.htm\n有关应聘人员做好准备（提供PPT），述职时间6分钟。\n 一、根据学校专业职务评聘工作的计划安排，2016年度教师高级职务招聘岗位已经发布，请各院系根据教师高级职务岗位要求进行公开招聘，并按规定接受应聘后，对申报人员材料进行公开展示、成果审查核对，以及思想政治、教学与科研等业务能力与潜力评审等工作。在评审结果公示后，院系推荐候选人的评审材料须于4月5日前报送人力资源处培训发展办公室（个人网上申报、单位审核推荐工作须同步完成）。逾期不报送者，责任由相关院系单位承担。 二、申报教师高级职务人员所提供的研究成果必须为任现职以来的成果，同时提交的检索证明中，需提供申报人成果“被收录情况”和“被引用情况”，并分别标出“自引”和“他引”,成果截止至2016年12月31日。  关于报送教师高级职务岗位评聘材料的要求 3、聘任候选人员应交的材料：\n ①高等学校教师职务任职资格申报表（一式两份）（表格中照片、个人签名、院系领导签字盖章等手续须完备） ②2位专家推荐意见(每个专家各两套，对应①) （须由推荐专家亲笔签名，每套分别附于任职资格申报表后） ③《南京大学教师高级职务岗位申请表》（一式六份） ④反映个人水平的代表作5篇（部）（六套） ⑤任现职以来代表成果的引用情况和检索证明（需提供申报人成果“被收录情况”和“被引用情况”，并分别标出“自引”和“他引”）。（一份） ⑥学历学位证书复印件（一份） ⑦教师资格证书复印件（一份） ⑧海外研修经历证明材料 ⑨校外申请者如已具有专业技术职务，请提供相应证书或文件等证明材料  以上材料请装档案袋、粘贴封面提交，封面以A4纸打印，申请材料格式见第2页（包括①②③④⑤⑥⑦⑧⑨）。今年开始，所有岗位申报人员还需另外提供五个档案袋作为鉴定材料，鉴定材料档案袋封面格式见第3页，每个档案袋包括③④成套装好。\n注：\n 报送材料电子文本接收信箱：zydiao@nju.edu.cn（院系报送） 文科检索可到图书馆五楼“中国社会科学研究评价中心”，联系电话：025-83595841。 理科检索可到图书馆一楼“教育部科技查新工作站（南京大学站）”联系电话：025-83593401（鼓楼），025-89683401（仙林），或其他经国家认定的科技查新站。  四、 应聘所须材料：\n 1、应聘者可通过互联网或邮件、传真向我校人力资源处提出应聘申请，所需提供的材料如下：  ①《高等学校教师职务任职资格申报表（两份） 下载 ②《南京大学教师专业技术职务高级岗位申请表》 (由系统填报后自动生成,调整格式后打印，四份) ③两封专家推荐信（两套）  注:1、申请人员的推荐信可直接转至申报岗位所在院系；2、请将两份专家推荐意见以扫描或电子转换方式生成JPG或PDF格式文档上传至系统内相应位置  ④代表性论文论著5篇（部）（原件1份，复印件3份） 注:请将个人近五年内最具代表性的论文或论著以扫描或电子转换方式生成PDF格式文档上传至系统内相应位置，其中论文请扫描全文， 论著请扫描著作的封面、书名页、封底三页 ⑤其他成果证明复印件 ⑥学历学位证书复印件 放在哪里？ ⑦专业职务聘任证书复印件 放在哪里？ ⑧外语能力证明复印件、教师资格证、海外研修证明材料等 放在哪里？  2、应聘者提供材料必须真实准确。 3、所有应聘材料一般不予退还，需要退还的材料请特别说明。  一、教学要求\n （1） 每年至少为本科生独立开设一门课，周学时不少于 2 学时。 （2） 在 5 分制的课堂教学质量测评中，测评得分不能低于 4.5分。 （3） 积极参与本科生的实验、实习、学年论文和毕业论文等指导工作；协助指导过硕士研究生培养。  二、正常申报科研要求 总体要求：专注于本学科有关方向的研究，能独立开展科研工作，取得了具有一定质量和数量的研究成果。 具体要求：\n （1） 任现职以来，主持 1 项省部级课题或主持 1 项国家社科基金重大招标、教育部人文社科重大招标课题的子课题（以批准的项目投标书为依据）。 （2） 作为横向课题负责人，社会科学学科申请人获得经费 30 万元以上、人文科学学科申请人获得经费 15 万元以上，可以折算为 1 个省部级课题（以实际到帐金额为准）。 （3） 任现职以来，至少 8 篇论文被 CSSCI 收录  如果成果中包含 1 篇 SSCI/A\u0026amp;HCI 期刊论文或 CSSCI 一流期刊论文，则数量要求为 6 篇，并且在同等条件下优先。 专著（第一作者）可折算 2 篇 CSSCI 期刊论文，有多部专著时仅可折算1 部专著。  （4） 积极参加学校与院系单位的发展规划、学科建设、平台建设等工作；积极参加国际国内学术交流活动；积极参加社会服务活动。  副教授岗位职责  承担传播学专业本科生2门以上专业课程教学。 成为硕导后，承担传播学专业研究生1门以上专业课程教学，指导硕士生若干名。 定期参加全国范围内相关学术研讨会，同时参与新闻传播业界的相关事务。 任期内主持省级以上课题1项。 每三年内发表SCI A区及以上级别期刊论文至少1篇，或SCI B区期刊论文至少1篇；或SSCI\u0026amp; HCI 论文、CSSCI一流期刊论文至少1篇，或CSSCI论文至少3篇，或有影响的学术专著1部（由院学术委员会认定）。成果均以本人为第一作者或通讯作者，第一署名单位为南京大学。 担负传播学专业本科生专业辅导工作，完成院里或系里交给的相关工作。积极参加学校与院系单位的发展规划、学科建设、平台建设等工作；积极参加国际国内学术交流活动；积极参加社会服务活动。  申请教授的要求  （1） 任现职以来，主持 1 项国家级课题或 2 项省部级课题。 （2） 作为横向课题负责人，社会科学学科申请人获得横向经费60 万元以上、人文学科申请人获得横向经费 30 万元以上，可以折算为 1 个省部级课题（以实际到帐金额为准）。 （3） 任现职以来，至少 12 篇论文被 SSCI/A\u0026amp;HCI 或者 CSSCI收录，  其中必须至少包含 1 篇 SSCI/A\u0026amp;HCI 期刊论文或CSSCI 一流期刊论文，SSCI 发文期刊分区要求在三区以上。 专著（第一作者）可折算 2 篇 CSSCI 期刊论文，有多部专著时最多可折算 3 部专著。  （4） 积极参加学校与院系单位的发展规划、学科建设、平台建设等工作；积极参加国际国内学术交流活动；积极参加社会服务活动。  助理研究员管理办法修订 https://hr.nju.edu.cn/_upload/article/files/0a/06/4770fc374cb1bc758a322e02be26/cf48adbc-9466-48d6-9614-06b40a851462.pdf\n","date":1489579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489579200,"objectID":"45eeff4517e2e49973798d27975a69e3","permalink":"https://chengjunwang.com/note/note_archive/2017-03-15-job/","publishdate":"2017-03-15T12:00:00Z","relpermalink":"/note/note_archive/2017-03-15-job/","section":"note","summary":" ","tags":["工作","户口"],"title":"找工作","type":"note"},{"authors":null,"categories":null,"content":"米果 2017年4月10日，我的第二个孩子二女儿米果出生了。这个名字是暮白给孩子取得，我和暮白经常记错。暮白对米果说：爱你就像爱生命。米果的大名是知乐。1\n 《论语》·雍也篇，子曰：“知（zhì）者乐（yào）水，仁者乐（yào）山；知（zhì）者动，仁者静；知者乐（lè），仁者寿。”\n 译义有多种。孔子说：“智慧的人喜爱水，仁义的人喜爱山；智慧的人懂得变通，仁义的人心境平和。智慧的人快乐，仁义的人长寿。” 另一理解为 “智者乐，水” ——智者之乐，就像流水一样，阅尽世间万物、悠然、淡泊。“仁者乐，山” ——仁者之乐，就像大山一样，岿然矗立、崇高、安宁。  https://chengjunwang.com/data/miguo.html\n 米果有肠绞痛，休息不好，不太好带。暮白说米果是树懒熊，因为她经常挂在妈妈身上，必须要抱着才能安静。\n宝华卫生院 地图链接\n需要找一个打预防针和体检的地方。4月18日，我打车去了宝华卫生院，在二楼妇产科办理了回执卡，但是没有去后面的楼预约打预防针，而满月后第一周就要打针了。\n走玉兰路，经过大宅门，过了沪霍线，就到了宝华镇所在，沿着159线路走就可以到达宝华卫生院，也叫宝华医院。赶不上159路，我徒步走到狮子山站公交坐D5路公交回到恒大雅苑。\n5月8日，米果28天，我下午两点多打滴滴去了宝华卫生院，办理了接种证书，4天后，本周五，给知乐打预防针，滴滴打车到宝华卫生院，去公共卫生楼一楼大厅排队，不要手机预约，10点之前到。下载了一个叫“金苗宝”的app 2。\n2017年11月15日长沙迁户口、公积金 0. 南京南站 \u0026ndash;\u0026gt; 长沙南站\n 长沙南站乘坐2号线至人民东路4号口 地铁出来可打车10.5公里，17分钟。  人民东路4号口 \u0026ndash;\u0026gt; 远大二路475号\n1. 长沙市芙蓉区公安分局东湖派出所\n远大二路475号 湖南省长沙市芙蓉区\n携带物品\n 委托书 身份证原件复印件 结婚证原件复印件 户口页原件复印件  2. 亚热带所\n远大路644号 湖南省长沙市芙蓉区\n13787797045 谢聪 取离职六个月以上证明\n远大路644号 \u0026ndash;\u0026gt; 人民中路35号\n25分钟11公里打车约25元\n3. 湘直公积金中心识字岭营业厅\n人民中路35号\n携带物品\n 离职六个月以上证明 委托书 公积金卡 银行卡 夫妻双方身份证原件复印件 夫妻双方结婚证原件复印件。  4. 7天连锁酒店（长沙识字岭天心阁店）\n长沙 天心区 人民中路24号\n去长沙高铁站\n11月16日G578次15车3D号,长沙南站13:30-18:11，4小时41分钟。\n人民中路24号 \u0026ndash;\u0026gt; 迎宾路口地铁站-2口 1.5km\n 人民中路24号 从起点向正西方向出发，沿人民中路走130米，向左前方转过阶梯，向右后方转进入白沙路 沿白沙路走710米，右转进入解放中路 沿解放中路走250米，左转 走240米，向右前方转 走180米，向左前方转 走10米，右转进入五一大道 沿五一大道走30米，到达终点 迎宾路口地铁站-2口  米果降临 2016年8月20日发现米粒妈妈怀孕了，我给肚子里的小朋友取名米奇或米琪，就是那个漂亮的米老鼠Mickey。小米还不到一岁半。得知这个消息，我和晓青都很崩溃：怎么又这么容易？米粒妈妈和我面对一个困境：生还是不生？！他来的太突然了。\n我意识到这个责任只能我和晓青来抗。父母都表示不干涉，没有意见。时代真得变了。或许是因为要担责任，所以没有心绪。晓青一开始坚决不生，多次落泪。我们去市妇幼做了检查，上网搜索了一些细节。人工流产对子宫是不小的伤害，要越早越好，最好在50-55天的范围内。\n想到这个还没有成形的小人的命运，晓青又转念想生下来。因为如果我们想要二胎，那么晚不如早。但是做出这个决定并不容易，因为：\n 一、生下ta将是艰苦时代的到来，米粒一个本来就够缠人的了，再来一个将会耗费很多时间。十月怀胎，十月养育。朝夕陪伴，十分辛苦。 二、米粒妈妈的工作就毁了，又要耗费大半年时间在孩子身上。 三、不确定性，不知道是男孩还是女孩。二胎政策只能生两个。如果想要一个男孩，那么就只有这一次机会了。于是乎变得很纠结。清宫图说女孩；金钱卦是一个夬卦，据说是男孩。抛硬币三局两胜说生。做判断和做决定是两回事.  米果的做法 米果是一种以米为主要原料制成的点心。在松阳一般称米果，糕是甜的，而米果是不甜的，在乡下，米果还是用人工锤打出来的，因此称打米果。\n 主料：糯米粉 (200G) 调料：黄豆粉 (20G), 辣椒粉3G，白砂糖15G。  步骤\n　1、先将糯米粉放入洗干净的电饭锅，倒入适量水，用力揉搓糯米粉，直至面饼状，再揉搓成条状。 2、揪成小米团，揉搓成汤圆大小的团子。 3、煮锅中加水，水开后将糯米团子放入锅中煮沸，直至团子浮上水面，即可捞出。 4、在煮团子的时间内，可以准备裹团子的外衣-米果豆粉+白砂糖，放入干净的容器中，糖的比例看个人口味调节。 5、 团子煮好后，捞出，放入准备好的豆粉中，晃动容器，直至团子被外衣全部裹住，即是成品米果。 6、用筷子将米果夹出，放入盘中，就可以享用了。\n米粒 https://chengjunwang.com/data/mili.html\n 2017年7月1日晚上米粒开始反复发热，最高到40多度，家里却没有剩下的退烧贴了。7月2日带米粒去仙林鼓楼医院挂了专家号。打车过去20多块钱，开了发炎药，消除炎症很重要，才能抑制反复发热。3以后小孩得病就不去鼓楼儿童医院了，来回距离很长。\n 子曰：“岁寒，然后知松柏之后凋也。”\n 《梅花》 唐 崔道融\n 数萼初含雪，孤标画本难。 香中别有韵，清极不知寒。 横笛和愁听，斜枝倚病看。 朔风如解意，容易莫摧残。  《淮阴夜宿二首》 唐 孙逖\n 水国南无畔，扁舟北未期。乡情淮上失，归梦郢中疑。 木落知寒近，山长见日迟。客行心绪乱，不及洛阳时。 永夕卧烟塘，萧条天一方。秋风淮水落，寒夜楚歌长。 宿莽非中土，鲈鱼岂我乡。孤舟行已倦，南越尚茫茫。  《红线毯》 唐 白居易\n 红线毯，择茧缲丝清水煮，拣丝练线红蓝染。 染为红线红于蓝，织作披香殿上毯。披香殿广十丈馀， 红线织成可殿铺。彩丝茸茸香拂拂，线软花虚不胜物。 美人蹋上歌舞来，罗袜绣鞋随步没。太原毯涩毳缕硬， 蜀都褥薄锦花冷，不如此毯温且柔，年年十月来宣州。 宣城太守加样织，自谓为臣能竭力。百夫同担进宫中， 线厚丝多卷不得。宣城太守知不知，一丈毯，千两丝。 地不知寒人要暖，少夺人衣作地衣。  故事从2015年3月11日早上十一点五分开始讲起，在这一刻我的女儿在东南大学附属中大医院降生了。我给女儿取名叫米粒，大名叫知寒，希望她可以“知寒问暖”。她的到来令我和妻子万分高兴。然而就在一个多月前，我和妻子还在为异地生产的问题焦头烂额。\n2014年我来南京工作，然而短期之内无法解决户口问题。而妻子在湖南生产则面临产后坐月子我无法陪护的问题，不得已我们只能选择在南京生孩子。然而做出这选择并不容易，因为我和妻子对于南京并不熟悉，在这里我们的朋友也不多，也许更为严重的问题是我们对于异地生产所存在的问题缺乏清晰的认识。断断续续地，我咨询了单位和一些医院，然而得到的回复并不乐观。正当我不知所措的时候，我听别人介绍了中大医院的产科门诊。怀着忐忑的心情，我拨通了中大医院产科的电话。顾晓霞护士长耐心地回答了我的各种问题，提醒我办理各种必要的手续，并指导我的妻子进行产前准备。一个月后，孩子出生了，然而我和妻子对于如何照顾孩子却并不擅长；幸亏有值班护士在，她们充满耐心得进行指导、不断鼓励，从各个方面照顾着产妇和孩子。在很多微小的细节当中，我感受到了医护人员对于工作的尽职尽责。\n如今，我的爱人和孩子顺利出院了。围绕着孩子，家里多了很多欢声笑语。很多时候，我为自己这样一个小家庭感到幸运，更深感自己应该感谢中大医院产科的医护人员。正因为有了你们辛勤的付出，很多崭新的小生命所降临的世界变得更加美好。\n给米粒的第一封信 亲爱的米粒：\n你好！虽然每天朝夕相处，却没有想到要正式地给你写一封信。感谢幼儿园布置的这个家庭作业，爸爸和妈妈可以对你说说心里话。今年八月入学的时候，我在幼儿园的调查表格中填写了对你的期待：希望你可以在幼儿园这个大集体当中实现个人的社会化。\n群体是最好的老师：当你身处在同龄的小朋友和老师当中时，当你们一起玩耍、一起学习、一起吃饭、一起参加运动会、一起上兴趣班的时候，你可以从同龄人和老师那里学习到更多的知识，更重要的是你将学会如何更好地与人相处，既包括如何更好地尊重他人、帮助他人，也包括学习如何独立而勇敢地体会每一个崭新的生活细节。经过在小四班将近半年的学习，你闹过情绪也哭过鼻子，但总能很快适应生活的变化，这一切都让爸爸妈妈感觉非常欣慰非常自豪。\n虽然爸爸妈妈也早已忘记自己在三岁半的时候做过什么事情，但是我们相信这种宝贵的社会化的经验、以及和同学老师以及爸爸妈妈爷爷奶奶之间真挚的情感将会沉淀在你的性格和智慧里。爸爸和妈妈祝愿你能一直保有童心、健康快乐地成长，做一个正直而有智慧的人！\n爱你的爸爸妈妈\n2018年11月15日\n米粒去长沙 [2015-06-14]作为一个爸爸，我挺失败的。因为没有办法将老婆孩子留在自己身边。暮白的产假时间快到了，24日打过第三次疫苗之后，米粒就要开始跟暮白和奶奶去长沙了。这是我对自己的孩子的亏欠。作为爸爸，自己工作不努力，让孩子受到这些折磨，于我是很大的愧疚。但我有时候会忘记这些愧疚。这么多年，我对家庭说不上好，29岁结婚，为了家庭（很大程度上）我回到了南京。却忽略了南京的高房价、雾霾、暮白在长沙的工作。半年之后，孩子出生，我和暮白也是学着做爸爸妈妈。女儿的出生的确让我的学术研究变得更加雪上加霜。但造成这一问题的主要责任在我。我必须要抓紧一切时间来弥补这一缺失，否则孩子就不是没有户口那么简单。电视一度占用了很多时间，我也体会到一个独立的空间的重要性，它不能是卧室，不能是客厅，就是独立的书房，我现在在厨房外的桌子上。\n米粒百日礼 带米粒去拍照，米粒妈妈在美团上团的券。照例是在一个小区里。打车过去，司机欺负我不识路想绕路，被我用百度地图拆穿（是的，移动互联网让很多坏人很头痛）。我们没有带U盘，所以没有办法拷照片，于是我跟对方要求网络传输，最后还是传到了手机里。给米粒选了三套衣服拍。一个人鱼，一个萝莉，一个袜子一样的，结果很失败的是米粒第二套衣服忘了带帅气的小领结，结果拍出来显得很土。然后，米粒不会做，趴也不成，看镜头就瞪着眼很严肃。所以整个拍摄很痛苦。这类拍摄都是热心的妈妈折腾孩子。所以，我们庆幸只拍了72张。\n带米粒体检，可气的是体检时医生说米粒是慢慢性子，原因是米粒对于医生手上测智力的红色环子不感冒。她瞪着眼瞅自己想看的地方。打疫苗时因为红屁股没有成功，直接打车去了金盛华东家具城。理发、游泳。理掉了头发的米粒又恢复了靓丽的形象。回家后，突然发觉米粒可以趴，但是要垫高，手臂的摆放很重要，并排在胸前。\n长沙廿日 转眼之间在长沙过了二十余天。一到长沙就感觉很疲惫，想睡觉。看女儿的日子充满了挑战和乐趣。米粒喜欢出去玩，主要是睁大眼睛看。她对世界很好奇。每天一早起来，米粒妈妈就带着米粒出去，去研究所外面的小花园看老人舞剑。米粒妈妈说“耍剑”。回来吃过了奶，米粒就要睡觉。我妈特别辛苦，负责哄米粒睡觉。有时候不得要领，小坏蛋就苦啊哭啊。到了十一点半，我就去食堂打饭。四个菜两盘子端回来。一般中间十点半的时候，米粒喂过了一次水就饿了，要电话米粒妈妈回来喂奶。中午吃饭后，午睡。米粒也睡。下午米粒妈妈三点去上班。一般四点半之后还要喂奶。五点半我去打饭。我妈会带着米粒出去。有一段时间是站在实验楼旁等米粒妈妈。后来，去小操场看小伙伴们。因为都是一个单位的，所以大家高度信任，非常友好。\n米粒不好哄。小家伙脾气挺大的。当然，吃饱了就好了。但是，往往有吃不饱的时候。她就哭。我妈很喜欢米粒，经常惯着她。常说米粒“跟着大鱼上串”。米粒嗓子粗，她哼哼的时候，我妈就说“米粒，你又再嘿呼谁？”我妈还喜欢说“米粒是个大孩子，米粒可管了。”我妈对米粒是隔代亲。\n米粒有一个可爱的日本风的小帽子。戴着它，没有人说米粒是小男孩了。长沙人说米粒长得极好，很漂亮。但也有说好胖啊，小胖子。米粒妈妈和我妈都不喜欢别人说米粒胖。后来自我解嘲也叫米粒小胖子了。\n米粒五个半月了，我也要回南京了。很怀念抱着米粒在芙蓉树边、樟树下、操场上、房间里。米粒对我刚刚熟悉，现在又得分开了。\n我这段时间的效率也不行，执行力很差。主要是因为兴趣突然被时间序列给带走了。尝试了好几种贝叶斯建模的方法。一开始是给米粒妈妈的数据建模，后来是给美国2012大选建模。关于公众注意力部门的模型算清楚了。媒介注意力、舆论支持率、公众情绪都会影响到公众注意力。使用公众注意力预测公众注意力当然效果不错，比如用query预测tweets。但是poll本身因为具有很强的trend和seasonality所以不需要采用regression预测。而sentiment和news则主要受到query的影响。4\n米粒回南京 2015年12月19日，米粒从长沙回到了南京。米粒妈妈辞掉了在长沙中科院的工作，下定决心回到南京了。我要能见到亲爱的女儿了。除了高兴，也感觉到肩上的担子更重了。\n 知寒、知乐是我对两个女儿的寄托。希望她们能够晓得民间疾苦，可以享受知识带来的乐趣。我想的是论语里的意思：智者乐，“忍者瘦”😀。暮白想的是“知道享乐”。社区探访的阿姨听了小孩的名字说“真简单”。 ^ 为什么现在app都比网站好用啊？我猜是因为背后 ^ 这也回答了我以前的问题，为什么一些表面上看起来没事的人，在傍晚会莫名其妙的发热 ^ 我觉得自己很长时间都没有进入写作的流程，而是将精力浪费在了很多类似这种数据探索上面。 ^  ","date":1489190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489190400,"objectID":"fb1829120e5c34def49d8ac8585884d2","permalink":"https://chengjunwang.com/note/note_archive/2017-03-21-my-children/","publishdate":"2017-03-11T00:00:00Z","relpermalink":"/note/note_archive/2017-03-21-my-children/","section":"note","summary":"","tags":[""],"title":"我的女儿","type":"note"},{"authors":["陈志聪","秦强","王成军 *"],"categories":null,"content":"In submission.\n","date":1489027749,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489027749,"objectID":"cf8dc8d4901acf1cff907cfa10d6dfda","permalink":"https://chengjunwang.com/publication/crowdfunding-charity/","publishdate":"2017-03-09T10:49:09+08:00","relpermalink":"/publication/crowdfunding-charity/","section":"publication","summary":"互联网众筹公益项目的筹款过程是一个社会动员的过程。本文从资源动员理论的角度切入，利用从腾讯乐捐网站抓取的数据，考察了影响众筹公益项目的社会动员能力（筹款能力）的因素。本文研究发现：互联网众筹公益项目的筹款能力差异很大，筹款金额与排名的分布具有明显的长尾特征；项目自身的属性特点如项目类型、目标金额、项目发起人和地点均显著影响其社会动员能力；对社交媒体使用，能够大大地提高公益项目的资源动员能力，尤其是腾讯乐捐特有的“一起捐”机制，能够有效地发挥社会关系网络中强大的人际传播能力，以超线性增长的速度带来捐助人数的提升，从而大大提升项目的资源动员能力。","tags":null,"title":"作为社会动员过程的互联网众筹公益：以腾讯乐捐为例","type":"publication"},{"authors":["Cheng-Jun Wang*","Linzhuo Lin","Yang Yang","Lingfei Wu"],"categories":null,"content":"Keywords:team science; turnover; task allocation; uncertainty; collective wisdom\nThis is an ongoing work under preparation.\n","date":1488464424,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488464424,"objectID":"1ad1f6a4e3c1f5290a4ec528ec438cbd","permalink":"https://chengjunwang.com/publication/team-turnover/","publishdate":"2017-03-02T22:20:24+08:00","relpermalink":"/publication/team-turnover/","section":"publication","summary":"Contrary to popular belief that member turnover is harmful to organizational performance, evidence from millions of software development projects suggests that teams of a high turnover rate can also achieve success, if not more successful (Klug \u0026 Bagrow, 2016). Targeting on this novel observation, we argue that task allocation is important in understanding team success. Our analysis reveals two types of tasks, one of low uncertainty and requires the commitment of a small team, or a small group of core members in teams of considerable size, the other of high uncertainty and takes the collective wisdom from a large pool of team members. The “parallel path” effect, which means that the probability of a challenging sub-task being solved by a “walk-in” user increases with the pool size, ensures benefits offset the cost of maintaining a big team. The lessons from the studied big teams, who have been trying to adapt to and survive from the dynamic online environment, provide valuable insights into the management practices of teams in general. ","tags":null,"title":"Building Open Teams to Leverage the Power of Turnover","type":"publication"},{"authors":["王成军","吴令飞"],"categories":null,"content":"王成军、吴令飞(2017)空间约束的人类行为. 胡泳、王俊秀（编）《连接之后: 公共空间重建与权力再分配》.北京:人民邮电出版社. pp. 262-271\n","date":1487921023,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487921023,"objectID":"1d98a7d1da143b75d62c9d38ef20b2a4","permalink":"https://chengjunwang.com/publication/lbs-behavior/","publishdate":"2017-02-24T15:23:43+08:00","relpermalink":"/publication/lbs-behavior/","section":"publication","summary":"比较人类在虚拟世界和现实空间的移动行为是科学研究的一个重要方面。本文的研究为完成这一个目标,构建并比较了注意力网络和移动网络。将人类的行为的数学结构表达为网络的形式,并采用网络科学的视角进行分析。通过对网络进行重整化,我们发现注意力网络是分形的,而移动网络是小世界的。Zhao 等(2014)的研究 认为人类在虚拟空间和现实世界的移动行为具有很强的相关;而我 们的研究则进一步发现这两类行为其实属于两类普遍的人类行为。更为重要的是空间约束不仅仅在物理空间发挥作用,在虚拟空间里同样发挥着重要作用,甚至更强。局部结构缺失空间约束使得移动网络表现出了小世界的特征并具有正的度相关;随着重整化的粗粒化过程空间约束开始发挥作用,度相关发生由正到负的变化。手机浏览的网站和应用之间具有明显的自相似的特点,使得移动网络空间约束更强,强制其嵌入几何网络的结构当中,并表现为很强的分形特点和与之相对应的负的度相关。通常我们认为虚拟空间解放了人的行为,因而可以表现出更多近乎随机的行为,而实际的发现则恰好与之相反。","tags":null,"title":"空间约束的人类行为","type":"publication"},{"authors":null,"categories":null,"content":" Cheng-Jun Wang is currently an associate professor in the School of Journalism and Communication, Nanjing University. He is also the director of Computational Communication Collaboratory. His research on computational communication appears in both SSCI and SCI indexed journals, such as Internet Research, Cyberpsychology, Telematics and Informatics, Scientific Reports, PloS ONE, and Physica A.\nContact Information  Computational Communication Collaboratory, School of Journalism and Communication, Nanjing University. 307 Zijin Building, Nanjing University (Xianlin Campus), 163 Xianlin Road, Qixia District, Nanjing, Jiangsu, China (210023). Email: wangchj04 at 126.com ORCID: 0000-0002-9507-2888  Education  Ph.D, City University of Hong Kong, Hong Kong. Department of Media and Communication (September, 2010-November, 2014).  Dissertation: Jumping over Network Threshold: Information Diffusion on Information Sharing Websites (pdf). Supervised by Jonathan J.H. Zhu  M.A., Peking University, Beijing, China. Department of Journalism and Communication (September, 2008-June, 2010). B.A., Lanzhou University, Lanzhou, China. Department of Journalism and Communication (September, 2006-June, 2008). Academic Visiting, Australia National University,Canberra, Australia. Australian Demographic \u0026amp; Social Research Institute.  Supervised by Robert Ackland. (February-June, 2012).   Professional Experience  Associate Professor, School of Journalism and Communication, Nanjing University (December 2017-Present). Director, Ogilvy Data Science Lab, Computational Communication Collaboratory, Nanjing University (January 2015-Present). Assistant Research Fellow, School of Journalism and Communication, Nanjing University (November 2014-July 2017). Research Memember, Web Mining Lab, City University of Hong Kong (September 2010-Present). Internship, Knowledge Discovery Group, Tencent Company (March-September 2014).  Research Projects  Bringing Back the Reference Group: Agent-based Modeling of Spiral of Silence. National postdoc grant (￥50000, 2015M571722) 中国博士后科学基金面上项目（第57批), 找回失落的参考群体:对“沉默的螺旋”进行多主体建模，2015/01-2018\u0026frasl;01, 5万元，主持 The Network Threshold of the Formation and Diffusion of Public Opinion. The National Social Science Foundation of China (￥200\u0026rsquo;000, 15CXW017) 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015/07-2018\u0026frasl;12, 20万元，主持 互联网上的集体注意力流研究，国家自然科学基金（常规面上项目），61673070，2017/01-2020\u0026frasl;12,￥655200, 参与 人工智能时代数字媒体上的注意力流动研究，江苏省社会科学基金基地项目，(￥50000，项目编号 19JD001)，2020/01-2021/12，主持 人工智能时代的计算传播研究，南京大学青年跨学科团队项目，中央高校基本科研业务费专项资金资助(项目编号 011014370119，￥100000），The Fundamental Research Funds for the Central Universities (Grant number 011014370119)，2020/01-2020/12，主持  Journal Articles * denotes corresponding author\n Wang C.J. * , Zhu, J.J.H.(2021) Jumping over the Network Threshold of Information Diffusion: Testing the Threshold Hypothesis of Social Influence. Internet Research.31(2):1-18 doi:10.1108/INTR-08-2019-0313 Wen N, Chao N*, Wang C.J. (2020) Predicting the Intention of Sustainable Commuting among Chinese Commuters: The Role of Media and Morality, Environmental Communication. doi: 10.1080\u0026frasl;17524032.2020.1855222 Xu H, Zhang Z, Wu L*, Wang C.J. * (2019) The Cinderella Complex: Word embeddings reveal gender stereotypes in movies and books. PLoS ONE 14(11): e0225385. doi:10.1371/journal.pone.0225385 Wang C.J. * , Zhu, J.J.H.(2019) Jumping onto the Bandwagon of Collective Gatekeepers: Testing the Bandwagon Effect of Information Diffusion on Social News Website, Telematics and Informatics. 41:34-45, doi:10.1016/j.tele.2019.03.001 Jiang C.L*, Yang M, Wang C.J. (2017) Self-Disclosure to Parents in Emerging Adulthood: Examining the Roles of Perceived Parental Responsiveness and Separation-Individuation. Journal of Social and Personal Relationships. 34(4): 425-445. doi: 10.1177 /0265407516640603 Wang C.J., Wu, L*, Zhang, J., Janssen, M. (2016) The Collective Direction of Attention Diffusion. Scientific Reports. 6: 34059. doi:10.1038/srep34059 Wu L., Wang C.J. * (2016) Tracing the Attention of Moving Citizens. Scientific Reports. 6, 33103. doi: 10.1038/srep33103 Wang C.J., Wu, L.*(2016) The Scaling of Attention Networks. Physica A: Statistical Mechanics and its Applications.448:196–204, doi: 10.1016/j.physa.2015.12.081 Chandra Y.*, Jiang, C.L., Wang C.J. (2016) Mining Social Entrepreneurship Strategies Using Topic Modeling, PLOS ONE, 11(3):e0151342, doi: 10.1371/journal.pone.0151342 Wang C.J. *, Wang, P.P, Zhu, J.J.H (2013). Discussing Occupy Wall Street on Twitter: Longitudinal network analysis of equality, emotion, and stability of public discussion. Cyberpsychology, Behavior, and Social Networking, 16(9): 679-685. doi:10.1089/cyber.2012.0409. [SSCI, Ranking 4\u0026frasl;72 in Communication by 5-year IF]. 王成军 * (2021) 寻找公众注意力爆发的起源：以YouTube视频扩散为例. 东岳论坛. 42(2):174:185. 卢功靖, 卢林艳, 李媛媛, 王成军 *（2021）基于议题类型的临近预测：使用社交媒体预测新冠确诊人数. 中国网络传播研究. 卢林艳, 李媛媛, 卢功靖, 刘熠, 王成军 * (2020) 社交机器人驱动的计算宣传：社交机器人识别及其行为特征分析. 中国传媒大学学报（自然科学版). 5. 王成军，党明辉，杜骏飞 (2019) 找回失落的参考群体:对沉默的螺旋理论的边界条件的考察. 新闻大学. 156:13-29. （入选人大复印资料新闻与传播2019年第8期） 王成军 (2017).计算社会科学视野下的新闻学研究：挑战与机遇. 新闻大学, 4:26-32. （入选人大复印资料新闻与传播2017年第10期） 杜骏飞, 曲飞帆, 王成军（2016）2015年中国新闻传播学论著评析. 新闻与传播研究，12:108-119. 张晓雨,王成军 *(2016)数据可视化报道在数据新闻中的实践——以《卫报》和财新网为例.中国网络传播研究.(01):283-308. 陈志聪,秦强,王成军 *(2016)作为社会动员过程的互联网众筹公益——以腾讯乐捐为例.中国网络传播研究.(01):173-190. 王成军 (2016) 大数据计算与《纸牌屋》生成. 传媒评论. 5:63-66. 王成军 (2016) 计算传播学的起源、概念与应用. 编辑学刊,3:59-64. 王成军（2015）计算传播学: 作为计算社会科学的传播学.中国网络传播研究,8:193-208. 王成军（2015）“今日头条”的技术逻辑: 网络爬虫+矩阵筛选.传媒评论,10:34-37. 祝建华,彭泰权,梁海,王成军,秦洁,陈鹤鑫 (2014) 计算社会科学在新闻传播研究中的应用. 科研信息化技术与应用. 5 (2), 3-13 王成军,刘德寰,杨旭 (2011) 从自我实现到群体互动——“人肉搜索”的动机、态度和行为研究,中国传媒报告，10(02):63-73. 王成军,刘德寰 (2011) 移動的時尚: 追求時尚與手機互聯網的使用，香港《传媒透视》, (07):12-15. 王成军,张昕之 (2011) “众说纷纭”抑或“一言九鼎”？——以卡扎菲官邸攻陷事件在新浪微博上的信息扩散为例，香港《传媒透视》, (09):12-13.  Conference Papers  Xuefei Yan, Cheng-Jun Wang * (2020) With Greater Popularity Comes Less Responsibility? The Popularity Fallacy of Big Vs’ Public Participation on Sina Weibo. The 70th Annual Conference of International Communication Association (ICA). 21-25 May 2020. Gold Coast, Australia. Huimin Xu, Zhicong Chen, Ruiqi Li, Cheng-Jun Wang * (2020) The geometry of information cocoon. The 6th Annual International Conference on Computational Social Science (IC2S2), Cambridge, MA USA. Zhi-Cong Chen, Lingfei Wu, Naipeng Chao, Cheng-Jun Wang * (2018) The Poor Read for Entertainment and the Rich Read for Education: Poverty, Fragmentation, and Knowledge Homogeneity. The 4th Annual International Conference on Computational Social Science (ic2s2), July 12–15, 2018. Evanston, Illinois, United States. Hui-Min Xu, Zhi-Cong Chen, Cheng-Jun Wang * (2018) Social Classes Shapes Our Trajectories in Both Online and Offline Space. The 4th Annual International Conference on Computational Social Science (ic2s2), July 12–15, 2018. Evanston, Illinois, United States. Wang, C.J. (2017) networkdiffusion: Simulating and Visualizing Network Diffusion Using R. The 10th China R Conference. Beijing, May 20-21. Slides. Wang, C.J. Zhang, X. (2017) Analyzing Mobile Phone Data With Network Science. The 67th Annual Conference of International Communication Association (ICA), San Diego, USA, May 27, 2017. Wang, C.J. (2015). Information diffusion on Microblogs: Testing the threshold hypothesis of interpersonal effects. Conference on Complex System (CCS\u0026rsquo;15), Tempe, Arizona, USA. Sep 28-Oct 2. Wang, C.J., Chen, H.X., Zhang, X.(2015) The Landscape of Information Diffusion on Sina Weibo: Investigating the Rich-Club Effect. The 65th Annual Conference of International Communication Association (ICA), San Juan, Puerto Rico, 21-25 May 2015. Lingfei Wu, Jiang Zhang, Marco Janssen, Cheng-Jun Wang, Min Zhao (2014). Attention Balls. The 6th International Conference on Social Informatics. Barcelona, 10-13 November 2014. Wang, C.J. (2014). The Origin of Bursts in Public Attention: The Temporality Hypothesis for the Diffusion of YouTube Videos. The 64th Annual Conference of International Communication Association (ICA), Seattle, Washington, USA. May 22-26. Wang, C.J, Chen, H.X (2013). Social selection or social influence: Network analysis of information flow within the Rich-club of Sina Weibo. The annual conference of International Association for Media and Communication Research (IAMCR), Dublin, Ireland, June 25-29. Wang, C.J, Liu, J. (2013). Looking for the signposts on the web: Clickstream analysis of the flow of public attention. The 63rd Annual Conference of International Communication Association (ICA), London, UK, June 17-21. Wang, P.P, Wang, C.J (2013). Rational information sharing or emotional expression in the online discussion: How does leadership spark conversations and trigger feedbacks. The 63rd Annual Conference of International Communication Association (ICA), London, UK, June 17-21. Wang, C.J. (2012). The origin of Bursts in public attention: Peak fraction, popularity, diffusion channels, and categories of YouTube videos. Honours Symposium for Asian Ph.D Students in Communication Research, Seoul, Korea, Oct 27-28. Wang, C.J., Wang, P.P (2012). Discussing Occupying Wall Street on Twitter: Longitudinal network analysis of equality, emotion, and stability. The 65th Annual Conference of World Association for Public Opinion Research (WAPOR), Hong Kong, June 14-16. Wang, C.J., Peng, T.Q (2012). Evaluating public discussion of Occupying Wall Street on Twitter: Linking Twitter streams with search quires, opinion polls, media coverage, and stock market index. The 65th Annual Conference of World Association for Public Opinion Research (WAPOR), Hong Kong, June 14-16. Wang, C.J. (2012). Jumping over the network threshold: How widespread could news diffuse on news sharing websites? The 62nd Annual Conference of International Communication Association (ICA), Phonix, Arizona, May 24-28. Wang, C.J., Wang, P.P (2012). Does the unkown information matter for online daters. The 62nd Annual Conference of International Communication Association (ICA), Phonix, Arizona, May 24-28. Wu, L.F., Wang,C.J. (2011). Heterogeneity and allometric growth of human collaborative tagging behavior. The 7th Chinese Conference of Complex Networks (CCCN’11), Chengdu, China, October 21-24. Wang, C.J.(2011).The emergence of spiral of silence from individual behaviors: Agent-based modeling of the spiral of silence. The 64th Annual Conference of the World Association for Public Opinion Research (WAPOR), Amsterdam, The Netherlands, September 21-23. Wang, C.J.(2011).Surfing mobile Internet motivated by fashion attentiveness: An empirical study of China mobile Internet use. International Telecommunications Society Asia-Pacific Regional Conference (ITS), Taibei, Taiwan, June 26-29.  Workshops  Wang, C.J.(2014) Web Data Analysis. City University of Hong Kong, Department of Media and Communication. The Web Mining Workshop. 4.22-4.25 Wang, C.J.(2013) The Way to Computational Communication (通往计算传播学之路). Department of Journalism and Communication, Shenzhen University. Jan 4th. Wang, C.J.(2012) Jumping over Network Threshold: News Diffusion on News Sharing Website. The seminar of IR and Friends. Commonwealth Scientific and Industrial Research Organisation (CSIRO), Australia National University, Canberra. May 14.  Book Review, Translation, and Chapters  \u0008张伦、王成军、许小可（2018）《计算传播学导论》. 北京：北京师范大学出版社. 王成军、吴令飞 (2017) 空间约束的人类行为. 胡泳、王俊秀（编）《连接之后: 公共空间重建与权力再分配》.北京:人民邮电出版社. pp. 262-271. 许小可、胡海波、张伦、王成军 （2015）《社交网络上的计算传播学》. 北京：高等教育出版社. 張倫、彭泰權、王成軍、梁海、祝建華 (2021)從邊陲到主流的自然路徑：華人計算傳播學者的參與和體驗. 《中華傳播研究的傳承與創新》.pp. 69-88. 王薇、王成军、王颖、刘璟 （翻译）(2013). 《社会网络分析：方法与实践》. 北京：机械工业出版社. [Translation of the book Social Network Analysis for Startups: Finding connections on the Social Web., by Maksim Tsvetovat \u0026amp; Alexander Kouznetsov. (2011). O’Reilly Media] 王成军 (2012, Aug 17). 爆发：人类行为在时间尺度上的特征. 中国科学报, 06. [Review of the book Bursts: The Hidden Pattern Behind Everything We Do., by Albert-Laszlo Barabasi]. 王成军 (2012, Jul 03). 人类 90%的行为是可以预测的. 中国图书商报, 1857.[Review of the book Bursts: The Hidden Pattern Behind Everything We Do., by Albert-Laszlo Barabasi].  Teaching My teaching interests focus on social networks and new communication technologies, communication theory, and quantitative research methods (e.g., Network analysis). I teach the following courses:\n Introduction to Python Programming for Data Science (数据科学Python编程基础). Semester A, Nanjing University Data Journalism (数据新闻). Semester B, Nanjing University Big Data Mining and Analysis (大数据挖掘与分析). Semester B 2015-2016, Nanjing University  I worked as a TA for the following courses:\n COM5106 Integrated Marketing Communication. Semester B 2012-2013, City University of Hong Kong COM3106 Media and Society. Semester A 2012-2013, City University of Hong Kong COM2401 Fundamentals of Advertising. Semester A 2011-2012, City University of Hong Kong COM3413 Writing for Public Relations. Semester B 2010-2011, City University of Hong Kong  Professional affiliations I served as a reviewer for\n International Journal of Public Opinion Research (IJPOR) Computers in Human Behavior (CHB) Journal of the Association for Information Science and Technology (JASIST) Communication Methods and Measures (CMM) The Annual Conference of International Communication Association (ICA). 《新闻与传播研究》 《新闻大学》  My professional affiliations include:\n Complex System Society (CSS) International Communication Association (ICA) World Association of Public Opinion Research (WAPOR) International Telecommunications Society (ITS)  Awards/Honors  Best paper Award of Asian Symposium of Doctoral Students in Communication (ASDSC), City university of Hong Kong, Hong Kong (Nov, 2013) Best paper Award of 3rd Honours Symposium for Asian Ph.D Students in Communication Research, Yonsei university, Seoul, Korea (Oct, 2012) Research Tuition Scholarship (RTS, Oct, 2012- Aug, 2013) Outstanding Academic Performance Award for Research Degree Students (OAPA, Aug, 2012) Travel Grant from Interpersonal Communication Division of ICA 2012 (May, 2012) Top 3 Conference Paper Award of 2nd Honours Symposium for Asian Ph.D Students in Communication Research, Singapore (Nov, 2011) Outstanding Paper Award of 11th China Communication conference (Jun, 2010) P \u0026amp; G Award of China Market Research (Nov, 2009) Outstanding Paper Award of People.com (Oct, 2009) Top Award of the Challenge Cup of Peking University (Jun, 2009)  Softwares  flownetwork, a Python package for flow network analysis. iching, a Python package that employs the Achillea millefolium method to practise divination of I Ching (易经的蓍草卜卦方法). networkdiffusion, a R package which can help simulate and visualize the network diffusion. scholarNetwork, a Python package to crawl and visualize the coauthor network of Google Scholars.  Visualizations  News Map of China using D3.js. Global Terrorism using googleVis.  ","date":1487462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487462400,"objectID":"7e6115c4d209379befeb3847e8c4905b","permalink":"https://chengjunwang.com/cv/","publishdate":"2017-02-19T00:00:00Z","relpermalink":"/cv/","section":"","summary":"Cheng-Jun Wang is currently an associate professor in the School of Journalism and Communication, Nanjing University. He is also the director of Computational Communication Collaboratory. His research on computational communication appears in both SSCI and SCI indexed journals, such as Internet Research, Cyberpsychology, Telematics and Informatics, Scientific Reports, PloS ONE, and Physica A.\nContact Information  Computational Communication Collaboratory, School of Journalism and Communication, Nanjing University. 307 Zijin Building, Nanjing University (Xianlin Campus), 163 Xianlin Road, Qixia District, Nanjing, Jiangsu, China (210023).","tags":null,"title":"Cheng-Jun Wang","type":"page"},{"authors":null,"categories":null,"content":"借助评论功能，发一些个人的只言片语、胡言乱语、风言风语。\n","date":1487462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487462400,"objectID":"0ffa3a0e5a0af33ce037674a213e6752","permalink":"https://chengjunwang.com/tweet/","publishdate":"2017-02-19T00:00:00Z","relpermalink":"/tweet/","section":"","summary":"借助评论功能，发一些个人的只言片语、胡言乱语、风言风语。","tags":null,"title":"只言片语","type":"page"},{"authors":["Cheng-Jun Wang"],"categories":null,"content":"To be submitted.\n","date":1487427656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487427656,"objectID":"01d5e91fe3d3823d0236e5b28967aa93","permalink":"https://chengjunwang.com/publication/weibo-threshold/","publishdate":"2017-02-18T22:20:56+08:00","relpermalink":"/publication/weibo-threshold/","section":"publication","summary":"In light of both threshold models and the J-curve model of information diffusion, this present study reformulates the threshold hypothesis for interpersonal effects and tests it using a dataset of information diffusion on Sina Weibo. The findings confirm the threshold hypothesis of interpersonal effects. There is a J-curve relationship between interpersonal effects and diffusion size. Further, such curvilinear relationship is moderated by the depth of diffusion networks. Additionally, the depth of diffusion is relatively limited and the temporal diffusion curves are featured by strong bursts. In all, this research extends threshold models of interpersonal effects by linking it with the J-curve model, and further explicates it with the moderation effect of the depth of diffusion networks. ","tags":null,"title":"Jumping over the Network Threshold of Information Diffusion","type":"publication"},{"authors":["Cheng-Jun Wang *","Hexin Chen","Xinzhi Zhang"],"categories":null,"content":"Under review.\n","date":1487427181,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487427181,"objectID":"09e06fe556106eecd8ad8829dfcaa30a","permalink":"https://chengjunwang.com/publication/weibo-landscape/","publishdate":"2017-02-18T22:13:01+08:00","relpermalink":"/publication/weibo-landscape/","section":"publication","summary":"The rich-club is a closely connected sub-community in networks that has important impacts on the online information diffusion. To investigate the rich-club effect in information diffusion on social media and its origins, we studied the mechanisms of information diffusion on the biggest microblog of China—Sina Weibo. The results demonstrated that there are obvious rich-club effects in both influential users and randomly sampled users; For the information diffusion within the rich-club, social selection, geographic proximity, and social influence were found to have significant influence, and the impact of social influence is overwhelmingly strong. The findings outline the landscape of information diffusion on Microblogs and the theoretical generalizations help us understand the hierarchical feature of rich-club phenomenon in information diffusion.","tags":null,"title":"The Landscape of Information Diffusion on Sina Weibo","type":"publication"},{"authors":null,"categories":null,"content":" 最近一年多一直和令飞折腾团队合作的东西，也在思考如何进行团队合作。之前是把开会当成头脑风暴，后来发现太浪费时间，尤其是团队成员超过三个人之后（也要兼顾别人没有那么多时间），合作的成本开始上升，如何高效地进行合作就成了一个重要的问题。我们研究的主题也就是这个东西。\n直接表达claim 直接地表达claim，然后使用数据证明自己的观点，就会发现其中的断裂的逻辑链条，进而不断完善。Polish your claim 比如，我去统计了用户在不同的repos里的push的次数计算其multi-tasking的香农熵和core team ratio，发现： \u0026gt; Github用户倾向于比较平均但深入地参与到团队项目（claim）。\n为什么水分可以增加影响？ 找一个novelty的点，需要一个narrow down的concrete的research question。要避免一开始要有一个想法，somehow connect to something, 挖来挖去做出来很多unconnected的findings。apparent team不是真实的team， 我们想要找到real team， 因此可以去分析workload distribution and skill set overlapped，及其对于impact的影响。我们想要找一个metric to correct team size. team的充水程度。story！为什么充了水的team的impact更大？what is a real team is research topic。怎么定义水分就靠近hypothesis。\n我之前说的一大堆只是想说一个论点：因为我们不是duncan watts，所以我们还是要用正轨的research道路。define topics, narrow it down, implement, provide prospects四部曲的方式。令飞之前说的“什么样是真正有效的合作，从技能的重合度和贡献量来衡量”是research topic, 不是一篇文章的research question。从workload的分布定义一个metric，core team size or effective team size\n 加一个时间维度， 新陈代谢， m(t) diversity，做过多少个不同的项目，experience好测量 repeated collaboration  组织为什么会失败。junior和senior scholar合作效果不错。\nTask Assignment 勾勒一个图景，早期/核心用户对任务的分配是如何切割了任务空间的。我们其实是观察不到用户之间的交流，所以只能通过用户各自的工作来推测他们协商任务分配的结果。一种分析角度是，大的任务会由核心用户在早起就“认领”吗？还是大任务（大修改）随时间分配是均匀的。\nRoberta Sinatra等人2016年发表Quantifying the evolution of individual scientific impact 1， 把一个科学家当一个sample,发现impact的分布无法简单用sample size N（发文章数量）rescale到一起。于是给每个sample一个参数Qi，这样就能把所有科学家的所有论文的影响力分布collapse 到一起，解释了为什么高量产的科学家，论文影响力极大值比根据样本规模随机从系统取还要大的问题-其实没有解释，就是管这个叫Q 了。\n Science paths 网页可视化 Is a scientific career predictable? nature视频  科学探索和合作写代码还不一样，前者有可能真的不知道最重要的工作什么时候出现，后者的任务空间是个有限集合，任务的重要性和完成度是排他性的\nTeam Assembly Mechanisms Determine Collaboration Network Structure and Team Performance2 一文题目应该叫“学术圈”。三个结论1. ）科学家是有圈子的，类似于渗流模型的giant cluster 好几个学科都是这样，越是好刊物的合作者数据，越能看到这个圈子存在2. ）模型参数m 团队规模, p 选择已经发表过文章老鸟合作的概率，q 选择已经合作过的人再次合作的概率，发现要想发高影响力的文章，p要大，q要小，也就是不要轻易和菜鸟合作，但也不要总是和同一批人合作；3）该模型可以复现团队规模的相变-稳定增长到收敛在一个优化值，和学科内部合作网络出现精英圈子的消息。\n 哈佛商业评论 Using the Crowd as an Innovation Partner Management Science上的Incentives and Problem Uncertainty in Innovation Contests: An Empirical Analysis Uzzi B, Mukherjee S, Stringer M, Jones B. 2013. Atypical combinations and scientific impact. Science 342:468–72 Lee Y N, Walsh J P, Wang J. Creativity in scientific teams: Unpacking novelty and impact. Research Policy, 2015, 44(3):684-697.  拟合代码量的累积增长 可以先把10个人的team的代码总量随（绝对）时间的变化看一下C是t时刻的代码总量，A是无穷远时代码总量，tau大概就是半衰期。然后画一个所有大team的tau的分布，如果是双峰的分布，说明确实有两种team。20120311之后出现的team好像都有显示代码量。\n$$C(t)=A(1-e^{-t/\\tau})$$\n两边求导再离散化,先求导的：$\\frac{dC (t)}{dt} =\\frac{A}{\\tau} e^{-t/\\tau}$\n左边的导数可以用两点间的斜率近似， $\\frac{dC (t)}{dt} =\\frac{(C (t+\\delta t)-C (t))}{\\delta t} $，离散一下 $\\delta t =1$，即：\n$$C(t+1)-C(t) = \\frac{A}{\\tau} e^{-t/\\tau}$$\n两边取对数，$log(C(t+1)-C(t))= log\\frac{A}{\\tau} - t/\\tau$\n令$\\beta = -1/\\tau$，$y = log(C(t+1)-C(t))$, $constant = log\\frac{A}{\\tau}$, 则存在:\n$y = constant + \\beta t$\n对数据进行处理得到$y$和$t$，采用线性回归进行拟合，即可得到constant和$\\beta$。那么显然：$\\tau = -1/\\beta$, $ A = e^{constant} $, $\\tau = - e^{constant}/\\beta $\n我尝试去拟合了tau和A, 结果产生了大量的负的tau和A，另外，多数R方都不大，效果不好。这里的$\\tau$与这个代码增长速度随时间变化是负的反比关系。因为挺多项目的代码增长速度是非线性的，比如相邻两次的变化量是先递增，后减小，或者一直增加。都会导致线性拟合的效果不好。\n一个例子见以下代码：\nimport statsmodels.api as sm import numpy as np import matplotlib.cm as cm from datetime import datetime def interpolating(data): # To interpoloate data bad_indexes = np.isnan(data) good_indexes = np.logical_not(bad_indexes) good_data = data[good_indexes] interpolated = np.interp(bad_indexes.nonzero()[0], good_indexes.nonzero()[0], good_data) data[bad_indexes] = interpolated return data d = ['2014-01', '2012-09', '2013-08', '2013-09', '2012-10', '2013-05', '2013-06'] v = ['1192' ,'163', '605', '1189', '167' ,'199', '199'] d = [datetime.strptime(i+'-01', \u0026quot;%Y-%m-%d\u0026quot;) for i in d] d = [(i - np.min(d)).days/30 + 1 for i in d] v = [int(i) for i in v] dv = zip(d, v) dv = sorted(dv,key=lambda x:x[0]) d, v = np.array(dv).T yt = np.array(v[1:]) - np.array(v[:-1]) t = d[:-1] x = t#np.log(t) y = np.log(yt+1) y = interpolating(y) # fit xx = sm.add_constant(x, prepend=True) res = sm.OLS(y,xx).fit() constant, beta = res.params r2 = res.rsquared tau = - 1.0/beta A = tau*np.exp(constant) print 'Tau = ',tau,'A=', A, 'constant = ',constant, 'beta =', beta,'rsquare = ', r2 fig = plt.figure(figsize=(10, 5)) ax = plt.subplot(1,2,1) plt.plot(d, v, 'r-s') plt.xlabel(r'month');plt.ylabel(r'size') ax = plt.subplot(1,2,2) plt.plot(x, y, 'rs') plt.plot(xx, constant+xx*beta,\u0026quot;red\u0026quot;) plt.xlabel(r't');plt.ylabel(r'log(c(t+1)-c(t))') plt.show()  To-do:\n 最大的push次数的人和最多push代码量的人是否一个人，计算一个rate 算sleeping beauty index 如果把每个人的工作量换算成绝对代码增减量, 还是可以仿照m的定义计算熵。熵小的大石头放好了，大部分人都是添沙子。大石头什么时候放进去的也很有信息量。  尽快确定一下最大代码贡献者和最频繁贡献者的重合率，感觉这个还是比较影响整个故事走向的。另外，试一下最大代码出现时间的分布。\n结论：随着团队规模增加，团队内部的确变得多元化，有人频繁参与，有人则高强度参与，二者未必相同。的确可能出现大象🐘和老鼠🐭并存的情况。按照“固定”任务空间的假设，在位者有累积优势（经验、任务分配、责任心），但人多了竞争激烈，也会给在位者带来冲击，尤其是大象的进入，他们可以靠少数的push，贡献大量的代码。\n水分不仅在活跃次数衡量的有效团队中发挥作用，同样在代码量衡量的有效团队中发挥作用，应该有点深刻的东西在这里。Lakhani (2011)发表在Management Science上的文章要回答一个问题3，像Netflix 这样的竞赛，团队多好还是少好？传统经济学理论认为参与团队越多，单个团队获奖概率越低，团队越没有积极性，平均表现越差。他们分析数据发现，扩大参赛团队数后，平均表现变差，但最强团队的表现变好。\n参与的均匀性 昨天看了一点Alex \u0026lsquo;SANDY\u0026rsquo; Pentland的书social physics，关于如何合作Sandy有很多看似惊世骇俗的观点，其中提到team的collective intelligence他说social sensitivity、话轮的均匀性可以提到团队绩效（群体智慧），见Evidence for a Collective Intelligence Factor in the Performance of Human Groups一文，sandy还在哈佛商业评论吹了一通The New Science of Building Great Teams，强调face-to-face的团队互动、均匀的参与对于team performance的重要性：\n (Group intelligence) was negatively correlated with the variance in the number of speaking turns by group members.\n 他们就用variance测量的参与的均匀程度，方差越小越好。variance越大，香农熵越大，m越大，m/M越大，绩效越低，与实际数据发现一致。\n数据 arXiv bulk data access amazon S3\nReference  Sinatra, R., Wang, D., Deville, P., Song, C., \u0026amp; Barabási, A. L. (2016). Quantifying the evolution of individual scientific impact. Science, 354(6312), aaf5239-aaf5239. ^ Guimerà R, Uzzi B, Spiro J, et al. Team Assembly Mechanisms Determine Collaboration Network Structure and Team Performance. Science, 2005, 308(5722):697-702 ^ Boudreau, K. J., Lacetera, N., \u0026amp; Lakhani, K. R. (2011). Incentives and problem uncertainty in innovation contests: an empirical analysis. Management Science, 57(5), 843-863. ^   ","date":1487289600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487289600,"objectID":"a294da07fd713fbb876949678631508d","permalink":"https://chengjunwang.com/note/note_archive/2017-02-17-data-insight/","publishdate":"2017-02-17T00:00:00Z","relpermalink":"/note/note_archive/2017-02-17-data-insight/","section":"note","summary":" ","tags":[""],"title":"团队合作中的任务分配","type":"note"},{"authors":null,"categories":null,"content":" News Map is built upon cartogram.js (a JavaScript implementation of an algoritm to construct continuous area cartograms ©1985), d3.js and colorbrewer. This visualization combines TopoJSON-encoded boundaries of the Chinese provinces with GDP data from National Bureau Statistics of the People\u0026rsquo;s Republic of China to size each province proportionally. Designed and built by Chengjun Wang and Zhicong Chen at Computational Communication Collaboratory, School of Journalism and Communication, Nanjing University.\nRead More \u0026gt;\u0026gt;\nRelated Publication: 王成军 (2016) 计算传播学的起源、概念与应用. 编辑学刊,3:59-64.\n","date":1486967527,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486967527,"objectID":"ce37681c597de399f7b795e018dba6a4","permalink":"https://chengjunwang.com/post/post_archive/news-map/","publishdate":"2017-02-13T14:32:07+08:00","relpermalink":"/post/post_archive/news-map/","section":"post","summary":"[News Map](http://chengjunwang.com/newsmap/#edu/2011) is built upon cartogram.js to visualize the Chinese provinces.\n","tags":["news"],"title":"News Map of China","type":"post"},{"authors":null,"categories":null,"content":"Using the Data from Global Terrorism Database (GTD) and googleVis-0.5.8, I visualize the global terrorism attacks over time. The remarkable negative relationship between kills and political stability can clearly observed.\nRead More \u0026gt;\u0026gt;\n","date":1486967527,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486967527,"objectID":"f9820e55c33515bc30b518221f960572","permalink":"https://chengjunwang.com/post/post_archive/global-terrorism/","publishdate":"2017-02-13T14:32:07+08:00","relpermalink":"/post/post_archive/global-terrorism/","section":"post","summary":"Using the Data from Global Terrorism Database (GTD) and googleVis-0.5.8, I visualize the global terrorism attacks over time. The remarkable negative relationship between kills and political stability can clearly observed.\n","tags":["news"],"title":"Visualizing Global Terrorism using googleVis","type":"post"},{"authors":null,"categories":null,"content":" networkdiffusion, an R package which can help simulate and visualize the network diffusion. Slides.\nRelated Activity Wang, C.J. (2017) networkdiffusion: Simulating and Visualizing Network Diffusion Using R. The 10th China R Conference. Beijing, May 20-21.\n","date":1486966565,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486966565,"objectID":"9fca26518b4ebcf67a16e64a8ebb7612","permalink":"https://chengjunwang.com/post/post_archive/networkdiffusion/","publishdate":"2017-02-13T14:16:05+08:00","relpermalink":"/post/post_archive/networkdiffusion/","section":"post","summary":"networkdiffusion, an R package which can help simulate and visualize the network diffusion. Slides.\nRelated Activity Wang, C.J. (2017) networkdiffusion: Simulating and Visualizing Network Diffusion Using R. The 10th China R Conference. Beijing, May 20-21.","tags":["news","R"],"title":"networkdiffusion: Simulating and Visualizing Network Diffusion Using R","type":"post"},{"authors":null,"categories":null,"content":"scholarNetwork, a Python package to crawl and visualize the coauthor network of Google Scholars.\n","date":1486966551,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486966551,"objectID":"0b1419d451976594fcd71e0a18bbb788","permalink":"https://chengjunwang.com/post/post_archive/scholarnetwork/","publishdate":"2017-02-13T14:15:51+08:00","relpermalink":"/post/post_archive/scholarnetwork/","section":"post","summary":"scholarNetwork, a Python package to crawl and visualize the coauthor network of Google Scholars.","tags":["news","Python"],"title":"scholarnetwork: Crawl and Visualize the Coauthor Network","type":"post"},{"authors":null,"categories":null,"content":"iching, a Python package that employs the Achillea millefolium method to practise divination of I Ching (易经的蓍草卜卦方法).\n ","date":1486966536,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486966536,"objectID":"5737324906efa3d335cae07f9588f06e","permalink":"https://chengjunwang.com/post/post_archive/iching/","publishdate":"2017-02-13T14:15:36+08:00","relpermalink":"/post/post_archive/iching/","section":"post","summary":"[iching](https://pypi.python.org/pypi/iching/), a Python package that employs the Achillea millefolium method to practise divination of I Ching (易经的蓍草卜卦方法).\n","tags":["news","Python"],"title":"iching: Practising Divination of I Ching","type":"post"},{"authors":null,"categories":null,"content":" I tried to move from jekyll to hugo to enhance my personal website. But I still want to use Github Pages to host the generated html files (in the Public folder). The trick is you have to move the files in the Public folder to the local folder of your github folder.\n Create on GitHub mywebsite-hugo repository (it will host Hugo’s content) Create on GitHub chengjun.github.io repository (it will host the public folder: the static website) cd github git clone https://github.com/chengjun/mywebsite-hugo.git hugo new site mywebsite-hugo --force cd mywebsite-hugo download Academic and extract it into a themes/academic folder within your Hugo website. If you are creating a new website, copy the contents of the exampleSite folder to your website root folder, overwriting existing files if necessary. Manage the content and hugo server --watch Once you are happy with the results, Ctrl+C (kill server) Almost done: add a deploy.sh script to help you (see the following script) and make it executable: chmod +x deploy.sh ./deploy.sh \u0026quot;Your optional commit message\u0026quot; to send changes to .github.io (careful, you may also want to commit changes on the -hugo repo).  The following script is content of the deploy.sh.\n#!/bin/bash echo -e \u0026quot;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace by `hugo -t \u0026lt;yourtheme\u0026gt;` # Go To Public folder cd .. cd chengjun.github.io cp -av /Users/chengjun/github/mywebsite-hugo/public/* . # Add changes to git. git add -A # Commit changes. msg=\u0026quot;rebuilding site `date`\u0026quot; if [ $# -eq 1 ] then msg=\u0026quot;$1\u0026quot; fi git commit -m \u0026quot;$msg\u0026quot; # Push source and build repos. git push origin master # Come Back cd ..  Each time when I want to add some files, I can easily do it using atom and terminal. for exmaple, add a markdown file to the post, I can simply run hugo new post/example.md in my terminal, and then edit it using atom.\nI can inspect the effect by running hugo server --watch\ndeploying the html files After I make some changes, I can conveniently run the following code to deploy the html files to github pages.\n ./deploy.sh \u0026quot;Your optional commit message\u0026quot;   For the source code in the mywebsite-hugo folder, I can also easily archive them within Atom using the \u0026lsquo;Git Plus\u0026rsquo; package.\nUpdate There is another way to avoid opening a terminal by using the Script package.\n install the Script package of Atom, open the deploy.sh within Atom press Ctrl + I  ","date":1486961667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486961667,"objectID":"dbae7a9dbb9ccc6a0d57e8def90c40c0","permalink":"https://chengjunwang.com/post/post_archive/hugo2github/","publishdate":"2017-02-13T12:54:27+08:00","relpermalink":"/post/post_archive/hugo2github/","section":"post","summary":"I tried to move from jekyll to hugo to enhance my personal website. But I still want to use Github Pages to host the generated html files (in the Public folder). The trick is you have to move the files in the Public folder to the local folder of your github folder.\n Create on GitHub mywebsite-hugo repository (it will host Hugo’s content) Create on GitHub chengjun.github.io repository (it will host the public folder: the static website) cd github git clone https://github.","tags":["hugo","news"],"title":"Deploy Hugo-Academic on Github Pages","type":"post"},{"authors":null,"categories":null,"content":" 宁在一思进，莫在一思停。 1月19日 今天老爸回老家了，我要负责做饭了。压力好大。今天上午打车去仙林医院，说儿科只有周三周四上午才有，仙林鼓楼医院的儿科也只有内科，没有皮肤科。住在仙林，小孩看病还有去鼓楼儿童医院。往返打车画了61块钱。\n1月20日\n今天写了一点创业项目的基本情况，还差挺多的。卸载了好几个app，才安装了新版支付宝。今天上午我和暮白带着米粒去儿童医院，结果挂错科室了，转过去之后今天没号了，打电话给鼓楼医院不看14岁以下病人，只好去迈皋桥妇幼保健院。吃过淮南牛肉汤之后又折腾回来。\n1月21日\n下午趁着米粒睡着，我开始写了一点论文，看了会文献。突然想起，今天么有拿快递。唯有写作使人心安。\n1月22日\nteam formation仅仅是group formation的一种类型，big team never expand，为什么我却觉得如此困难呢。因为我对这个领域可以验证的理论还不了解。我在过去的几年里学到的一点是，不管有多少人质疑一个有潜力的方向，作为年轻人你要做的不是插着腰加入他们，而是沿着那个方向做出有价值的东西，让他们闭嘴。年轻人要想出头，必须冒险。\n1月22日\n‘friends of friends’. 三角闭合显然是group formation的重要动力。写东西很像修行，你会被磨砺着动心忍性，不为所动，神思千里。\n1月22日回复顶转发\n在达沃斯论坛，马云接受纽约时报专栏作家索尔金采访，提出三个30改变世界的观点 http://weibo.com/1642634100/ErzQLt8yd?type=comment\n1月23日回复顶转发\nDecision and hard work based on enduring passion will never fail you. Edward E. Wilson ​​​​\n1月23日回复顶转发\n今天下午写到了6000字，争取今天写到8000字。一篇文章写十天，真实不容易。写到了六点多，才写了6800字。\n1月23日回复顶转发\n今天下午写到了6000字，争取今天写到8000字。一篇文章写十天，真实不容易。写到了六点多，才写了6800字。写到晚上，写了7544字。\n1月23日回复顶转发\n今天超过9700字了，其实正文只有8544字。\n1月24日回复顶转发\n尤克里里完全入门24课 http://list.youku.com/albumlist/show?id=18501294\u0026amp;ascending=1\u0026amp;page=1 练习了一个小时，看了同名的视频和书，终于知道do re mi fa sol la ti do怎么弹了。\n1月24日回复顶转发\n妈妈今天早上离开了，今天我和晓青在家看米粒。我要把论文审核一遍，发了邮件提交。松一口气。\n1月25日回复顶转发\n1月31日，初四，今天去超市买了电池，给尤克里里调了弦，今天妈妈从老家回来，晚上自习看了F调音阶，弹了一会祝你生日快乐。\n1月31日回复顶转发\nUkulele零基础入门视频教程 http://www.tanukulele.com/?tag=xsrm http://www.ukulelefan.com/?p=3432\n2月1日回复顶转发\nUkulele零基础入门视频教程 http://www.tanukulele.com/?tag=xsrm http://www.ukulelefan.com/?p=3432 http://rockv.net/e/action/ShowInfo.php?classid=40\u0026amp;id=208\n2月1日回复顶转发\n下载team science的文章，From Solo Investigator to Team Scientist: Trends in the Practice and Study of Research Collaboration，发现很多其他的文章。team science这是一个被广泛关注的领域，已经积累了大量的工作在里面。\n2月1日回复顶转发\n子曰：“知之者不如好之者，好之者不如乐之者。” 子曰：“知者乐水，仁者乐山；知者动，仁者静；知者乐，仁者寿。” [礼物] 王知乐 [心] 名字的来源。\n2月3日回复顶转发\n越来越感觉到重要的是你急切的想要做什么，否则就会丧失战斗力。 ​​​​\n2月6日回复顶转发\nscience也曾说将github作为研究的一环，来开放代码，这个是否可以识别出来呢？\n2月6日回复顶转发\n把合作的图做到claim的高度，方便团队成员理解。\n2月10日回复顶转发\n愈发感觉到我是一个肤浅的人，对于做网站天然没有抵抗力。或许，骨子里是想做得更好，让别人看到眼前一亮。其实是一种无奈的求胜的欲望。失去抵抗力，几乎飞蛾扑火地搞了个人新网站之后却依旧感觉少了点什么，什么呢？显摆的东西啊！因为没有成果，所以还是要滚去写论文啊。放弃是一种很无奈的事情，总是期待能够拾起来。另外就是学到东西。\n总结：leap year 2016年就这么过去了，我也已经32岁了，变成了大叔，胖得有些可恶，面目狰狞，内心可憎。青椒两年半了，不知道未来会怎样，生出莫名的烦恼。青椒是一段非常折磨人的时光。家庭、论文、项目、教学，一股脑全来了。我的博士四年多多少少是失败的，略高于平均水平吧。生活也是一样，暮白和我对现状都不满意。我们对于南京市没有一丁点儿的归属感。赶上了这个城市狂飙突进式的房价飞涨，就像玩一个比大小的游戏，一轮输掉之后就完全挤不进去了。对于南京市政府卖地度日的虚假繁荣，我感到非常无语。大城市的发展瓶颈开始凸显出来，过去的人文文化、教育优势、医疗优势，在资本主义的房地产市场面前变得非常无力。工作和博后的生活相比混杂了太多。心态不一样了，干的事情也不一样了，唯有忍耐。或许一切都有点晚，2015年做的最正确的事情是买了句容的房子，否则就要漂泊在南京三年了；而做的最错误的事情是没有及时买南京的房子。\n2014年是转折之年，实习、毕业、结婚、暮白怀孕、工作，全在这一年。2015年是危机之年，因为自己没有什么收获，几乎一无所获，还要在行政类的工作中颠簸。2015年米粒出生了；申请了国家社科项目；买了九曲花苑的房子；卷入了智库的工作。2016年是转机之年，我和令飞的3篇东西陆续出来，和crystal合作的东西也出来了。搬到宝华后忙着装修房子。松了一口气之后，还没缓过来，暮白又怀孕了。\n米粒已经21个月了，她进入了人生当中的叛逆期，执着于融入三岁少年的群体，迷恋游乐场、游戏机，小老虎丹尼尔。管教米粒的时候，我意识到自己非常没有耐心，非常粗鲁。\n 从松散到紧凑 最近这段时间过着猪一样的生活，也没有照顾米粒，一个人晚上睡书房、看电视剧，人也没有精神，不想对着电脑工作，经常看电视，欠了一堆工作没有做。我需要一种可以持续紧凑的生活方式。要牢记：没有危机感就是最大的危机，认为人会懈怠！\n博士后办理落户 费劲心力，终于办理了博士后落户。对于南京大学的集体户口，我只能说没有任何诚意。\n涂鸦 米粒周岁之后，经常给她临摹一些小画，画的都很普通，还不如希特勒的水平，聊以自娱。\n懦弱的拖延症 开始陷入了严重的拖延症。当我无法克服困难的时候，就会陷入这种拖延症，开始做别的事情打发时间，结果就更浪费时间了。想到这里，我就会觉得自己太不给力，也太自私了。我觉得问题是自己懦弱的性格。2016年大年初二，去了红山动物园，米粒妈妈感冒了。今年马上也要开学了，回首这段时间我可以说是一无所成。我不知道为什么，我陷入了这种绝境，这段时间确实不好过。时间总在看手机、看米粒的碎片过程中过去了。writing a lot给了我很多启发：任务要小，不要一口吃个胖子，有明确的步骤和要求，比如写完50个字。循序渐进。流动的状态，乐而忘忧废寝忘食，这是做自己擅长的事情的体验。比如我编写程序的时候，克服一个个具体的小问题。写作是第一生产。首先写作，然后其他。\n要更有意义的学习和生活！ 【2016-07-16】知道自己前进的方向非常重要。每天练习四组平板撑对于自己非常有帮助，这个和健腹轮有异曲同工之妙。加油！⛽️ 【2016-08-02】这个平板撑的计划根本没有实行下去。体育锻炼是我青椒三年的噩梦吧。\n年终奖年终奖评奖标准主要看上课、带学生、发论文、主持讲座活动（绩效）。\n骗子公司Lambert图书出版 最终放弃了lambert的出版计划，主要是它们实质是一个骗子公司，并不对书籍进行任何有价值的编辑工作。\n计算传播学论坛 小可老师提了几个会议改进方案，非常有启发，与大家分享：- 增加期刊合作，推荐期刊发表；- 稿件被接收者可以选择自己承担差旅费用+领取会议补贴 或者 由会议承担差旅而不提供会议补贴；- 会议延长为两天，第一天为工作坊时间，安排网络科学家为传播学研究者讲网络科学的研究方法，或者传播学者为网络科学研究者讲社会科学的理论和方法；第二天为主题发言+分组讨论。基于研究项目的合作计划：合作计划的目标就是促进跨学科的合作，吸引其他学科、其他学校学者的注意力，将研究项目尽快转化为研究成果。在无法引进人才的条件下，依然可以“为我所用”。成功合作的基础在于匹配双方的利益，尤其是在数据、资金、论文署名三个方面，达到最大化的效果。- 找到双方都关注的研究问题和好的数据是吸引合作者的第一步。- 提供适当的资金补助是必要的一环。- 双方在论文署名方面按照通行的规则。- 明确项目需求，比如共同发表几篇国际论文。\n合作计划分为两个阶段：项目合作、访问计划。- 项目合作：这是合作的初级阶段，我方提供问题和数据，双方一起参与，共同分析，承担写作的一方一般为一作。- 访问计划：针对具体的项目和数据，组织短期的访问项目，时间长度为1-2个月，主要任务为共同讨论和动手解决数据分析和研究设计问题。- 第一个阶段项目合作是广撒网，访问计划是精准定位。二者可以结合项目合作+访问计划。\n百度阅读研究计划 研究问题和视角：本研究试图从网络科学的角度分析用户的注意力如何在书籍构成的人类知识版图当中流动。研究方法：构建以书籍为节点、以用户的阅读行为为链接的人类阅读行为的注意力流动网络。同时，每一天构建一个注意力流动网络，这样可以观察到每一天的活跃用户数量和阅读规模，进而可以分析用户的数量（UV）和用户的浏览量（PV）之间的异速增长关系。研究意义：基于这个网络可以观察到人类在知识获取过程，将书籍嵌入到一个流动网络所对应的几何空间中，进而可以进行节点的聚类，计算任意两个节点的相似性，划分以书籍为单位的知识版图的层级关系。数据需求：1. 数据抽样：- 首先，从总体当中随机抽取10万用户；- 然后，对于每一个用户抽取2016年1月1日到6月30日之间的所有阅读行为记录。格式如下：用户id、时间、书籍id、阅读量（字数等指标）、持续时间（秒钟）- 此外，抽取这10万用户所阅读的所有的图书的基本信息，例如：书籍id、书名、作者、出版社、年份、定价，等。- 最后，对于这10万用户的图书购买行为进行记录，格式如下：用户id、时间、书籍id、花费金额。\n","date":1483185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483185600,"objectID":"f4e9b1b535caea9fe3eeca73e6c3e2fb","permalink":"https://chengjunwang.com/note/note_archive/2016-12-31-summary/","publishdate":"2016-12-31T12:00:00Z","relpermalink":"/note/note_archive/2016-12-31-summary/","section":"note","summary":" ","tags":["记录"],"title":"2016年总结","type":"note"},{"authors":null,"categories":null,"content":" 二十一世纪的科学 邓肯*瓦茨在2007年的时候写了一篇名为《二十一世纪的科学》的文章，提出了”二十一世纪的科学“的概念。瓦茨认为二十一世纪的科学不是自然科学，而是社会科学。因为社会科学涉及到了海量的异质化个体之间的互动，所以研究社会科学所面临的挑战特别大；但是基于数字化媒体（如互联网、手机）等手段收集的人类行为数据则为这种研究提供了丰富的数据。类似这种视角，Lazer等人（2009）更完整地表达为”计算社会科学”研究的思路。基于计算社会科学的研究思路为分析社会现象（尤其是人类传播行为）提供了丰富的可能性，因而我们见证了最近十年里的社会科学的飞跃。\n但是计算社会科学的发展思路依然留下了很多问题，比如如何来把握不同学科的资源来发展计算社会科学。研究者习惯于使用韦恩图来表达这种跨学科的研究的特点，比如讲数据科学表达为科学（一个领域的知识）、统计、机器学习等算法三个领域的重叠。我自己越来越倾向于认为计算社会科学是社会科学的领域知识、物理学模型、计算机算法三个领域的重叠。但是这种重叠不是完全平等的重合。因为几乎没有一个人可以熟练地掌握三个领域的知识，这种人非常罕见，因而可以称之为“独角兽”。多数人其实只是在一个方面发展得比较好，比如传统的社会科学研究者其实是对本领域的知识方面比较了解，而对于计算机算法和物理学模型方面则有所欠缺。这个时候有两个平行的发展思路：一个是扬长避短、一个是取长补短。\n在读博士等初级阶段往往是一个取长补短的这样一个阶段，这个时候的研究者往往广泛涉猎其它学科的知识，尤其是物理学的理论模型和计算机算法的知识，所以可以说这是一个做加法的过程。但是科学研究往往是在一个点上突破的，为了论文发表，研究者必须要有所取舍，不可能什么都去研究，后者会导致研究者非常疲惫。持之以恒的将研究兴趣聚焦于一个点就是一个做减法的过程。这往往出现在科研职业的阶段当中。当你博士毕业进入到了一个职业阶段，你就必须考虑聚焦兴趣、做减法。\n我个人正是经历了这样的一个先做加法后做减法的过程。读博士的时候对各种编程语言和工具感兴趣，广泛地接触各种计算机方面的基础知识。但这也是一个让人疲惫的阶段，因为种种原因，我们不断地被吸引到各种看似非常有吸引力的话题上面，于是出现注意力耗散的现象（当然，你不学习看电影其实也很累），这些都是不利于发表的。当你进入研究的职业生涯之后，你就不许考虑产出的问题，被迫地做减法。我一直觉得或许此后也将处于做减法的过程，将自己的研究聚焦于可以产出论文的领域，知道参加了第一届“凯风-集智训练营”。\n凯风-集智训练营 2016年集智俱乐部与凯风合作，组织了第一届“凯风-集智训练营”，这次训练营于2016年10月7日集合，10月12日结束，10月13日训练营正式结束。\n作为团队的微信群 将微信群看为一个知识分享的团队，不同团队的类型。我们假设存在着一个有效团队， 这里面存在着一种集体智慧，是一个crowdsoucing众包的过程，团队的成功，活跃性。Pentland所思考的是团队内部的沟通。规模和消息数量，指数增加。贡献的有效，这个和团队的绩效或者成功是不容易的。引用带来成功！\n解决业务问题，搞营销和赚钱，推荐系统。创新的扩散。进群的过程。关键节点，群的影响力最大化。\n激活微信群\n知识传播、流动网络\n","date":1476360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476360000,"objectID":"381c29cb2a2c8ac890745f85e9d967ac","permalink":"https://chengjunwang.com/note/note_archive/2016-10-13-swarma-camp/","publishdate":"2016-10-13T12:00:00Z","relpermalink":"/note/note_archive/2016-10-13-swarma-camp/","section":"note","summary":" ","tags":["集智俱乐部"],"title":"记凯风-集智训练营","type":"note"},{"authors":["Lingfei Wu","Cheng-Jun Wang*"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1473379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473379200,"objectID":"e022ec17ae32f910c215eb49f326612c","permalink":"https://chengjunwang.com/publication/tracing-attention/","publishdate":"2016-09-09T00:00:00Z","relpermalink":"/publication/tracing-attention/","section":"publication","summary":"With the widespread use of mobile computing devices in contemporary society, our trajectories in the physical space and virtual world are increasingly closely connected. Using the anonymous smartphone data of $1 × 10^5$ users in a major city of China, we study the interplay between online and offline human behaviors by constructing the mobility network (offline) and the attention network (online). Using the network renormalization technique, we find that they belong to two different classes: the mobility network is small-world, whereas the attention network is fractal. We then divide the city into different areas based on the features of the mobility network discovered under renormalization. Interestingly, this spatial division manifests the location-based online behaviors, for example shopping, dating, and taxi-requesting. Finally, we offer a geometric network model to help us understand the relationship between small-world and fractal networks.","tags":null,"title":"Tracing the Attention of Moving Citizens","type":"publication"},{"authors":["Cheng-Jun Wang","Lingfei Wu","Jiang Zhang","Marco A. Janssen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1473033600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473033600,"objectID":"2149898d87394f2b9baae9ff375fbc86","permalink":"https://chengjunwang.com/publication/collective-direction/","publishdate":"2016-09-05T00:00:00Z","relpermalink":"/publication/collective-direction/","section":"publication","summary":"We suggest that the tree-like, stable structure of clickstream networks reveals the time-sensitive preference of users in online browsing. To test our assumption, we discuss three models on individual browsing behavior, and compare the simulation results with empirical data.","tags":null,"title":"The Collective Direction of Attention Diffusion","type":"publication"},{"authors":null,"categories":null,"content":" Could not read Username for Github fatal: could not read Username for 'https://github.com': Invalid argument  Go to the github repository of my personal computer，and running the following scripts in the terminal.\nssh-add ~/.ssh/id_rsa git remote set-url origin git@github.com:username/repo.git  Create a ssh key 1- Create a ssh key using Git Bash using following command\nssh-keygen -t rsa -b 4096 -C \u0026quot;your-github@email.com\u0026quot;  After running this command just install the by default options and enter the password balnk when it prompts.\n2- Then run the following commands to locate the public/private key generated from step1\ncd .ssh cd ~/.ssh  3- Then run the following command to view your public:\ncat id_rsa.pub  4- Copy your public key and go to your GitHub account -\u0026gt; settings -\u0026gt; create a SSH and GPG keys then click new ssh key and past your public key in the in key text field.\n5- Verify your public key using Git Bash by running the following command:\nssh -vT git@github.com  Hugo on github  Create on GitHub mywebsite-hugo repository (it will host Hugo’s content) Create on GitHub chengjun.github.io repository (it will host the public folder: the static website) cd github git clone https://github.com/chengjun/mywebsite-hugo.git hugo new site mywebsite-hugo --force cd mywebsite-hugo download Academic and extract it into a themes/academic folder within your Hugo website. If you are creating a new website, copy the contents of the exampleSite folder to your website root folder, overwriting existing files if necessary. hugo server --watch Once you are happy with the results, Ctrl+C (kill server) and rm -rf public (don’t worry, it can always be regenerated with hugo -t ) git submodule add https://github.com/chengjun/chengjun.github.io.git public --force Almost done: add a deploy.sh script to help you and make it executable: chmod +x deploy.sh ./deploy.sh \u0026quot;Your optional commit message\u0026quot; to send changes to .github.io (careful, you may also want to commit changes on the -hugo repo).\n#!/bin/bash echo -e \u0026quot;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace by `hugo -t \u0026lt;yourtheme\u0026gt;` # Go To Public folder cd .. cd chengjun.github.io cp -av /Users/chengjun/github/mywebsite-hugo/public/* . # Add changes to git. git add -A # Commit changes. msg=\u0026quot;rebuilding site `date`\u0026quot; if [ $# -eq 1 ] then msg=\u0026quot;$1\u0026quot; fi git commit -m \u0026quot;$msg\u0026quot; # Push source and build repos. git push origin master # Come Back cd ..   domain name 在godaddy上花了122块钱买了两年的域名 chengjunwang.com。简单设置cname和goddy上的a record和cname www record就好了。主要参考了这里。\n我对于html的无知可以说是到了某种无以附加的程度。虽然我投入了很多时间，但往往都是干中学。而不是系统的模仿。通常会发现很多困惑，然后每次对我而言都是一个个小trick就解决了问题。\n平行的文本框 如何添加一个平行的文本框？这个困惑了我很久的问题，解决方法是设置position为absolute。\n#textbox { position:absolute; top: 200px; width: auto; margin-left: 50px; background-color: rgba(0,0,0,0.2); opacity:1; }  修改之后又觉得不好看。又尝试了iframe，也不是很合适。\n之后发现一篇好文章The Shapes of CSS.\n修改了其中的talkbubble，放在application.css中。\n#talkbubble { position:absolute; top: 250px; margin-left: 50px; width: 300px; height: 150px; background-color: rgba(0,0,0,0.2); -moz-border-radius: 10px; -webkit-border-radius: 10px; border-radius: 10px; } #talkbubble:before { content:\u0026quot;\u0026quot;; position: absolute; margin-left: 300px; top: 80px; width: 0; height: 0; background-color: transparent; #border-top: 5px solid transparent; border-bottom: 30px solid rgba(0,0,0,0.2); border-right: 120px solid transparent; }  在index.html里加入talkbubble来显示新闻。\n\u0026lt;div id=\u0026quot;talkbubble\u0026quot;\u0026gt; \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;http://chengjun.github.io/cv/news.html\u0026quot;\u0026gt;News\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;[Feb 23] \u0026lt;a href=\u0026quot;https://pypi.python.org/pypi/scholarNetwork/\u0026quot;\u0026gt;scholarNetwork\u0026lt;/a\u0026gt;--a python package which can help crawl and visualize the coauthor network of Google Scholar is released to Pypi. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt;  谷歌字体 俺天朝跟谷歌成了死敌。背后的很多想法让人很无奈。虽然米果是两党制，但是谷歌据说也在检查之列。到了俺朝，美利坚放不下身段了，天朝也放不下，于是就僵住了。于是很多谷歌的服务都不好用了。比如谷歌学术，谷歌邮箱。哎妈呀，老伤心老。我这里要说的却是谷歌的字体格式。\n在天朝载入我的博客慢的原因就是因为style.css里（media/css/style.css）调用里谷歌字体。好伤心，每次访问速度都很慢，非得翻墙才行。可是不能让俺的读者们也翻墙吧，这也太虎了。反正我的审美要求也没那么高。雪藏了吧。\n#@import url(http://fonts.googleapis.com/css?family=Galdeano); #@import url(http://fonts.googleapis.com/css?family=Electrolize); #@import url(http://fonts.googleapis.com/css?family=Cuprum);  改过来之后 我了个去，怎么英文字体变这么大了，BIG好吧，只能骗自己感觉萌萌哒啦。\n把谷歌字体放在本站 其实很早就注意到andy wang的这个解决方法，一直比较懒。还是去在mac上安装了github for mac，于是把andy wang的media文件夹偷到我这里来用。\nAndy Wang: 你好，我扒走了你的模板，然后在天朝用发现非常慢，然后调试了一下，发现是在style.css和home.css里面有从别的网站下载字体文件的, http://fonts.googleapis.com/这个网站在天朝访问非常不稳定，所以做了一些小改动，把字体文件都下载到网站上了，页面渲染速度也快了很多。https://github.com/synckey/synckey.github.io/tree/master/media/css\n终于，世界再次变得一片清凉了。真好。\ncategories 我喜欢在网页端更新github上的日志，通过设置只显示categories为blog的文档，我可以每次修改一点东西就完全在网页端写日志。图片附件什么的可以放在七牛网站，感觉非常好。\n下面是我用来复制和重命名1000个md文本的python代码：\n # -*- coding: utf-8 -*- \u0026quot;\u0026quot;\u0026quot; Created on Thu Aug 07 14:05:09 2014 @author: chengjun \u0026quot;\u0026quot;\u0026quot; import shutil path = \u0026quot;D:/github/chengjun.github.io/_posts/\u0026quot; demo = path + \u0026quot;2010-01-01-demo.md\u0026quot; for i in range(1000): newFile = path + \u0026quot;2010-01-\u0026quot; + str(i) + \u0026quot;.md\u0026quot; print newFile shutil.copy(demo, newFile)  jekyll3.0 这个是一个测试，jekyll更新到了3.0版本，所以github也相应发生了改变（见这里）。这导致了我的文章无法显示，解决的方法是去掉表头的时间一行，就可以了，我还没有明白原因。\n某一类的博文目录 主要参考 filtering-posts-using-categories-in-jekyll-bootstrap\n这个是使用liquid写的，介绍见这里。\n主要添加两行liquid代码：\nif post.categories contains '生活'  不要忘记endif\n由于liquid语言本身不能在本网站呈现，读者可以查看这里。\n琢磨出一个不用每次在jekyll上写博客都要上传的方法：将要显示的博客的categories设为blog，一次上传n个草稿（不指定categories），使用liquid语言指定在博客列表中只显示blog类的。这样草稿不会被显示，每次在线登录github，更改一个草稿的标题和categories就可以了。图片用外链flickr。\npaginator 今天下午鼓捣了半天jekyll的设置，最初是想弄一个paginator给文章列表分页，结果搞了半天，没搞定。各种问题。Patrick McKinley说是因为不是网站第一层的index.html，所以jekyll官方设置时没有用的。于是，直接用他的方法，发现没有办法在我的网站上实现。\nPatrick McKinley的博客以图片来显示博客文章的方法似乎很酷。感兴趣，去研究了下他的代码，大致是设置了post.image，图片存放在assets中的图片文件夹。我弄了下，也没弄成功。\n又看到Mr Trường at RMIT的网页，翻了半天，加了related_posts功能。\n没想到晚上更惨，被python的encoding error搞得很头大！\n","date":1470182400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470182400,"objectID":"a3284c9f0018be4f2730b173bb90c246","permalink":"https://chengjunwang.com/note/note_archive/2016-08-03-github/","publishdate":"2016-08-03T00:00:00Z","relpermalink":"/note/note_archive/2016-08-03-github/","section":"note","summary":" ","tags":[""],"title":"Github个人网站维护","type":"note"},{"authors":["王成军"],"categories":null,"content":"","date":1463284416,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463284416,"objectID":"c1710d2c9c40b5c2e40eba6b02452968","permalink":"https://chengjunwang.com/publication/cc-origin/","publishdate":"2016-05-15T11:53:36+08:00","relpermalink":"/publication/cc-origin/","section":"publication","summary":"计算传播是指数据驱动的、借助于可计算方法所进行的传播过程,而分析计算传播现象的研究领域就是计算传播学。文章首先分析了计算传播的起源、概念和应用,然后从计算社会科学的角度对计算传播学的理论脉络进行了介绍。基于以上内容,文章介绍了一个计算传播学研究的例子新闻地图研究项目。最后讨论了计算传播学研究中存在的从数据到模式,再从模式到机制的研究思路。","tags":null,"title":"计算传播学的起源、概念和应用","type":"publication"},{"authors":["王成军"],"categories":null,"content":"","date":1462406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462406400,"objectID":"29a38efaf1313ec1dfa9b60c1821ce14","permalink":"https://chengjunwang.com/publication/big-data-house/","publishdate":"2016-05-05T00:00:00Z","relpermalink":"/publication/big-data-house/","section":"publication","summary":"本文探求根据大数据策划专题的可能性,目的是看大数据计算出来的受众爱好,是否能够为新闻IP变现建立受众需求的基础。王成军的这篇文章,以美剧《纸牌屋》作为对象来展现大数据运作的过程,这个流程本身对于新闻IP变现有着十分重要的借鉴意义。我们可以借文章了解计算传播过程(获取数据、挖掘数据、互联网实验、推荐系统、分析反馈)对集体智慧的挖掘和运用,并最终将此方法推广到新闻IP变现领域的实践当中。","tags":null,"title":"大数据计算与《纸牌屋》生成","type":"publication"},{"authors":null,"categories":null,"content":" 使用Atom来编写markdown非常不错，按ctr+shift+m就可以进入预览模式，我想markdownpad可以抛弃掉了。这个软件更流畅，非常棒！因为我经常要写github的博客，使用atom时最容易的形式。减少了甚多负担，非常的自由，如果它具有上传功能就好了。\n数学公式 安装了markdown-preview-enhanced，可以很方便的展示数学公式，比如 $x = y^2$。\n$E = MC^2$\n需要按 ctrl+ shift+ x，按ctrl+ shift+ m无法展示数学公式。\n参考文献 插入一个参考文献123\n再次插入一个参考文献2\n插入一个参考文献[^a][^b][^c] [^a]: author1, 2014, This is a title. Journal. 00-00 [^b]: author2, 2014, This is a title. Journal. 00-00 [^c]: author5, 2014, This is a title. Journal. 00-00 再次插入一个参考文献[^b]  图片上传功能 结果就发现阿里巴巴程序员knightli的两个atom插件：qiniu-uploader和markdown-assistant。设置好七牛的账号既可以非常方便地使用图床了。赞。\nGit上传功能 接着又找到了git-plus这个强大的插件，可以直接在atom里上传了。好吧！社区的力量真强大。太好了。\n 按 *command+shift+H*打开操作界面。 选择add all commit+push就可以上传了！  填写commit的内容 command+s保存即可上传   震惊脸！！！!\natom-html-preview 如果你需要修改的html文件的话，可以很方便地使用atom-html-preview插件。\n 快捷键ctr+shift+h  script 安装了script插件，可以运行包括shell等多种语言。我使用它来运行deploy.sh脚本，实现半自动上传功能。\n参考文献  author1, 2014, This is a title. Journal. 00-00 ^ author2, 2014, This is a title. Journal. 00-00 ^ author5, 2014, This is a title. Journal. 00-00 ^   ","date":1462320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462320000,"objectID":"9fe86b05a9f8dcda3126ae97fe29781f","permalink":"https://chengjunwang.com/note/note_archive/2016-05-04-atom/","publishdate":"2016-05-04T00:00:00Z","relpermalink":"/note/note_archive/2016-05-04-atom/","section":"note","summary":" ","tags":[""],"title":"测试Atom软件","type":"note"},{"authors":null,"categories":null,"content":" Billing Bill to\nCheng-Jun Wang wangchengjun@nju.edu.cn +8617751010496\nBilling method Invoice Billing address\nNanjing University 22 Hankou Road, Gulou District, Nanjing University A306 Feiyimin Building, School of Journalism and Communication Nanjing China China 210093\nScientific Reports —出版业的一个新时代 Scientific Reports 是来自 Nature 杂志出版者的一个发表原始研究工作的刊物，在线出版，公开访问，内容涉及自然科学所有领域。托管在 nature.com（该网站是由Springer Nature出版的80多种刊物的共同门户，每月全球有数百万科学家访问）上， Scientific Reports 是任何人都可以公开访问的，发表在技术上可靠的、各领域内的专业人员感兴趣的原始研究论文，其相关内容的访问不受任何限制。\n文章处理费自2015年1月起将按如下标准执行，以下费用包括增值税或其他当地税费。\n £990 (UK \u0026amp; RoW) $1,495 (The Americas) €1,165 (Europe) ¥170,000 (Japan) ¥9,900 (China)  Scientific Reports 是：\n 快速的（Fast）—迅速审稿和发表 严格的（Rigorous）—由学术界至少一个成员来进行同行评审 公开的（Open）—文章对所有人都是免费的，作者保留版权 可见的（Visible）—增强的浏览和搜索功能，确保您的文章能够被注意到 互联的（Interlinked）—与整个 nature.com 网站上的相关文章相互之间建立链接 全球的（Global）— 托管在 nature.com 上，全球媒体覆盖  根据南京大学超一流、学科群一流、SCI A 区和 B 区期刊目录，Scientific reports属于SCI索引期刊的A区。2016年公布的Scientific Reports 影响因子5.228* *2015 Journal Citation Reports® Science Edition (Thomson Reuters, 2016)\n南京大学关于Scientific Reports论文发表的新闻： http://news.nju.edu.cn/searchsite.php?r=scientific%20reports\n 2015-11-26 Scientific Reports刊登我校博士生俞恂大陆火山成因研究新成果 2014-10-29 大气科学学院符淙斌院士团队在Scientific Reports杂志发表最新研究成果  8月19日 hidden direction 中间因为editor换了，又更新过一次reviewer，耽搁了时间。2015年12月10日进入decision started的状态；过了一个半月，也就是2016年1月24日到了2月2日才收到editor回复，之后又过了十天时间收到SR的邮件。所以概括一下：这个editor的速度灰常慢，再等半个月。\n突然发现9月2日editor提交了审稿意见，经过了一个多月终于Manuscript Submitted。一般而言进入此环节表示editor做好了决定，Finger crossed！耐心地等待下一周吧。9月5日，文章被接收。\n Manuscript Submitted 2nd September 16\n Decision Started 26th July 16\n Manuscript assigned to peer-reviewer/s 26th July 16\n Manuscript Assigned to Peer-Reviewer/s 14th June 16\n Manuscript Assigned to Editor 11th June 16\n Submission Not Complete 11th June 16  二审论文提交是在6月11日（中间隔了四个月），14日送审，到7月26日审完，发给编辑做决定。编辑似乎需要一个月才愿意给决定。到本月26日，编辑就消耗了一个月了，拭目以待。\n Decision Started 26th July 16\n Manuscript assigned to peer-reviewer/s 26th July 16\n Manuscript Assigned to Peer-Reviewer/s 14th June 16\n Manuscript Assigned to Editor 11th June 16\nSubmission Not Complete 11th June 16 Manuscript Submitted 24th January 16\n Decision Started 10th December 15\n Manuscript assigned to peer-reviewer/s 10th December 15\n Manuscript Assigned to Peer-Reviewer/s 17th November 15 Manuscript Assigned to Editor 30th September 15\n Manuscript Submitted 29th September 15\n Submission Not Complete 22nd September 15\n Quality Check Started 9th September 15\n Submission Not Complete 29th August 15  tracing 二审8月5日提交修改版本，进入quality check环节，8月12日收到邮件说要修改格式，当晚修改完毕提交。quality check到8月18日，进入decision started环节。没有想到当天就进入了Manuscript Submitted环节。一般而言进入此环节表示editor做好了决定。果然，晚上十一点半收到了acceptance letter。\nCurrent Stage: Decision Started (1 days)\n Manuscript Submitted 18th August 16\n Decision Started 18th August 16\n Manuscript Assigned to Editor 5th August 16\n Submission Not Complete 9th July 16 Manuscript Submitted 6th July 16\n Decision Started 6th July 16\n Manuscript Assigned to Editor 2nd June 16\n Manuscript Submitted 2nd June 16\n Quality Check Started 29th May 16\n Submission Not Complete 24th May 16  SR的LaTeX模板 8月12日，SR邮件说我的reference不合规范，发现只有严格按照overleaf上的模板才能生成，索性直接使用这个模板\nhttps://www.overleaf.com/5874225tbgnxc#/19389854/\n点击project，点击 download as zip即可下载。\n因为不允许上传bib和cls文件，所以每次validation的时候还可以选择自己上传一个pdf。修改时只需要删除原来的tex文件，重新上传tex，并在validation的时候重新上传一个pdf即可。\n积极向上的心智 突然我挺烦“正能量”这个词，因为使用这个词的地方往往是政府缺位的地方。\n但是对于个体而言，找到正能量确实非常有必要的。每一个人都会面对生活的各种挑战，我们无法预测未来会是怎样，上天将会如何试探我们。\n面对生活，积极向上的精神是不可或缺的。\n这是一种心智的力量，需要个体去修炼。禅宗讲行走坐卧皆是修行是有道理的，因为每一个细节都在锤炼着我们的意志。我喜欢心智这个词，因为当我们面对挑战的时候，仅仅强调勇气、勤奋是远远不够的。因为我们可能是那个面对风车的堂吉诃德；因为我们可能已经在错误的道路上渐行渐远。要有智慧来面对挑战。\n不仅仅是蔑视困难，而且要能积极地应对挑战。  自强不息 2016年8月3日，最近比较累。lingfei将tracing一文全面改了一遍，增加了可读性，文章的长度大幅度降低。我却变得更懒了，没有动力去修改。感觉我的个性里消极的成分太多了。\n自强不息是一个多么艰难的目标。但是我应当牢记，这是最困难的阶段，跨过这个阶段，我要做的更好。放下那些不必要的压力，做回来自我。\n要善于给自己鼓劲，在黑暗里看到希望的光。加油！\nThe collective direction of attention diffusion 2016年7月26日，晚上习惯性地刷了下sr，发现42天后，状态变为decision started。于是我想说要cross my fingers，没想到在西方是这样交叉手指祈祷的，姿势是把食指放在中指前面。\n关于cross fingers的解释如下图：\n这一张图片更有爱！ 到现在快有一个月了，还是这个状态：没有消息就是好消息。不要杞人忧天，庸人自扰。\nProofread We find that the flow of attention on the Web forms a directed, tree-like structure. Using the data of a news sharing website, we construct clickstream networks in which nodes are news stories and edges represent the consecutive clicks between two stories. To identify the flow direction of clickstreams, we define the “flow distance” of nodes (Li), which measures the average number of steps a random walker takes to reach the ith node. It is observed that Li is related with with the clicks (Ci) to news stories and the age (Ti) of stories. Putting these three variables together help us understand the rise and decay of news stories from a network perspective. We also find that the studied clickstream networks preserve a stale structure over time, leading to the scaling between users and clicks. The universal scaling behavior is confirmed by the data from 1,000 Web forums. We suggest that the tree-like, stable structure of clickstream networks reveals the time-sensitive preference of users in online browsing. To test our assumption, we discuss three models on individual browsing behavior, and compare the simulation results with empirical data.\n我们发现万维网上的注意力流动构成了一个有向的树状结构。使用一个新闻分享类网站的数据，我们构造了点击流网络：节点是新闻，链接是两个新闻之间的点击流。为了确认点击流的流动方向，我们定义了节点的流距离Li：它测量了一个随机游走者需要多少步才能走到该节点。研究发现Li与新闻点击量Ci和新闻的年龄Ti有关。同时分析这三个变量可以帮助我们从一个网络的视角理解新闻的出现和消亡过程。我们也发现构造的点击流网络在不同的时间可以维持一个稳定的结构，而这个稳定的结构解释了用户和点击流之间的标度关系。1000个网络论坛的数据验证了这种普世的标度行为。我们认为点击流网络的这种树状的稳定结构表明了用户浏览行为的时间敏感性偏好。为了验证这个假设，我们讨论了三种用户浏览行为的模型，并比较了计算机模拟的结构与实证数据之间的关系。\n念兹在兹，我手写我心真的是不容易实现的状态。语言是一道门槛，只有越过它才能更好地与人交流。\narxiv 5月27日，我开始尝试将bib嵌入tex的方法：\n 正常编译tex和bib文件生成bbl文件， 复制bbl文件所有内容放进tex文件 编译一次bbl，然后一次latex，就可以显示正确了。  其中，复制bbl文件所有内容放进tex文件的格式如下：\n\\section*{Competing financial interests} The authors declare no competing financial interests. %\\section*{References} % The bibtex filename apalike unsrt ieeetr acm alpha plain \\bibliographystyle{unsrt} \\begin{thebibliography}{10} \\bibitem{ginsberg2009detecting} Jeremy Ginsberg, Matthew~H Mohebbi, Rajan~S Patel, Lynnette Brammer, Mark~S Smolinski, and Larry Brilliant. \\newblock Detecting influenza epidemics using search engine query data. \\newblock {\\em Nature}, 457(7232):1012--1014, 2009. \\end{thebibliography}  之后，我按这个方法将转化后的tex文件，图片文件上传到了arxiv上面。You may update your submission at: https://arxiv.org/submit/1571860 Your article is scheduled to be announced at Mon, 30 May 2016 00:00:00 GMT. 之前遇到的问题说上传的latex不符合规定，修改半天也不得要领。\n更新arXiv的论文版本也挺方便，重新上传上述内容即可较快更新。\nbibitem bibtex被编译之后其实是这些bibitem。它们的格式其实很简单，如果google scholar可以直接另存为bibitem就省事了。\n\\bibitem{penrose2003random} Mathew Penrose. \\newblock {\\em Random geometric graphs}. \\newblock Number~5. Oxford University Press, 2003. \\bibitem{papadopoulos2012popularity} Fragkiskos Papadopoulos, Maksim Kitsak, M~{\\'A}ngeles Serrano, Mari{\\'a}n Bogun{\\'a}, and Dmitri Krioukov. \\newblock Popularity versus similarity in growing networks. \\newblock {\\em Nature}, 489(7417):537--540, 2012. \\bibitem{brockmann2013hidden} Dirk Brockmann and Dirk Helbing. \\newblock The hidden geometry of complex, network-driven contagion phenomena. \\newblock {\\em Science}, 342(6164):1337--1342, 2013. \\bibitem{eagle2010network} Nathan Eagle, Michael Macy, and Rob Claxton. \\newblock Network diversity and economic development. \\newblock {\\em Science}, 328(5981):1029--1031, 2010.  ","date":1462320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462320000,"objectID":"ef1d9a9277a90f0389f8be81cd12915f","permalink":"https://chengjunwang.com/note/note_archive/2016-05-04-sr-revising/","publishdate":"2016-05-04T00:00:00Z","relpermalink":"/note/note_archive/2016-05-04-sr-revising/","section":"note","summary":" ","tags":[""],"title":"语言是一道门槛","type":"note"},{"authors":null,"categories":null,"content":" Tracing the Attention of Moving Citizens The Collective Direction of Attention Diffusion The scaling of attention networks  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"5982cd910fe5cd1bc2fadb6e2fee4fec","permalink":"https://chengjunwang.com/project/attention-networks/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/attention-networks/","section":"project","summary":"This project aims to study the attention dynamics using flow network analysis.","tags":["attention-networks"],"title":"Attention Networks","type":"project"},{"authors":null,"categories":null,"content":" 计算社会科学视野下的新闻学研究 计算传播学的起源、概念和应用 计算传播学:作为计算社会科学的传播学 计算传播学导论  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"1ebb926de398d2ac3992bec205216c0d","permalink":"https://chengjunwang.com/project/computational-communication/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/computational-communication/","section":"project","summary":"This project aims to establish the framework of computational communication","tags":["computational-communication"],"title":"Computational Communication","type":"project"},{"authors":null,"categories":null,"content":" The Academic framework enables you to easily create a beautifully simple personal or academic website using the Hugo static site generator.\nKey features:\n Easily manage your homepage, blog posts, publications, talks, and projects Configurable widgets available for Biography, Publications, Projects, News/Blog, Talks, and Contact Need a different section? Just use the Custom widget! Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Easy to customize  Installation  Install Hugo and create a new website by typing the following commands in your Terminal or Command Prompt app:\nhugo new site my_website cd my_website  Install Academic with git:\ngit clone https://github.com/gcushen/hugo-academic.git themes/academic  Or alternatively, download Academic and extract it into a themes/academic folder within your Hugo website.\n If you are creating a new website, copy the contents of the exampleSite folder to your website root folder, overwriting existing files if necessary. The exampleSite folder contains an example config file and content to help you get started.\ncp -av themes/academic/exampleSite/* .  Start the Hugo server from your website root folder:\nhugo server --watch  Now you can go to localhost:1313 and your new Academic powered website should appear.\n Customize your website - refer to the Getting Started section below\n Build your site by running the hugo command. Then host it for free using Github Pages. Or alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as your university\u0026rsquo;s hosting service).\n  Getting Started Assuming you created a new website with the example content following the installation steps above, this section explores just a few more steps in order to customize it.\nCore parameters The core parameters for the website can be edited in the config.toml configuration file:\n Set baseurl to your website URL (we recommend GitHub Pages for free hosting) Set title to your desired website title such as your name The example Disqus commenting variable should be cleared (e.g. disqusShortname = \u0026quot;\u0026quot;) or set to your own Disqus shortname to enable commenting Edit your details under [params]; these will be displayed mainly in the homepage about and contact widgets (if used). To disable a contact field, simply clear the value to \u0026quot;\u0026quot;. Place a square cropped portrait photo named portrait.jpg into the static/img/ folder, overwriting any defaults. Alternatively, you can edit the avatar filepath to point to a different image name or clear the value to disable the avatar feature. To enable LaTeX math for your site, set math = true Social/academic networking links are defined as multiples of [[params.social]]. They can be created or deleted as necessary.  Introduce yourself Edit your biography in the about widget content/home/about.md that you copied across from the themes/academic/exampleSite/ folder. The research interests and qualifications are stored as interests and education variables. The academic qualifications are defined as multiples of [[education.courses]] and can be created or deleted as necessary. It\u0026rsquo;s possible to completely hide the interests and education lists by deleting their respective variables.\nCustomize the homepage Refer to our guide on using widgets to customize your homepage.\nAdd your content Refer to our guide on managing content to create your own publications, blog posts, talks, and projects.\nRemove unused widgets and pages How to remove unused widgets and content pages.\nCustomization \u0026amp; Upgrading Continue reading below for advanced customization tips and instructions for keeping the framework up-to-date with any improvements that become available.\nAdvanced customization It is possible to carry out many customizations without touching any files in themes/academic, making it easier to upgrade the framework in the future.\nNavigation menu The [[menu.main]] entries towards the bottom of config.toml define the navigation links at the top of the website. They can be added or removed as desired.\nTo create a dropdown sub-menu, add identifier = \u0026quot;something\u0026quot; to the parent item and parent = \u0026quot;something\u0026quot; to the child item.\nWebsite icon Save your main icon and mobile icon as square PNG images named icon.png and apple-touch-icon.png, respectively. Place them in your root static/img/ folder.\nTheme color (CSS) You can link custom CSS assets (relative to your root static/css) from your config.toml using custom_css = [\u0026quot;custom.css\u0026quot;].\nFor example, lets make a green theme. First, define custom_css = [\u0026quot;green.css\u0026quot;] in config.toml. Then we can download the example green theme and save it as static/css/green.css, relative to your website root (i.e. not in the themes directory).\nAnalytics To enable Google Analytics, add your tracking code in config.toml similarly to googleAnalytics = \u0026quot;UA-12345678-9\u0026quot;.\nThird party and local scripts (JS) To add a third party script, create a file named head_custom.html in a layouts/partials/ folder at the root of your website (not in the themes folder). Any HTML code added to this file will be included within your website\u0026rsquo;s \u0026lt;head\u0026gt;. Therefore, it\u0026rsquo;s suitable for adding custom metadata or third party scripts specified with the async attribute.\nWhereas for your own local scripts, you can link your local JS assets (relative to your root static/js) from your config.toml using custom_js = [\u0026quot;custom.js\u0026quot;].\nLanguage and translation The interface text (e.g. buttons) is stored in language files which are collected from Academic\u0026rsquo;s themes/academic/i18n/ folder, as well as an i18n/ folder at the root of your project.\nTo edit the interface text, copy themes/academic/i18n/en.yaml to i18n/en.yaml (relative to the root of your website). Open the new file and make any desired changes to the text appearing after translation:. Note that the language files are formatted in YAML syntax.\nTo translate the interface text to another language, follow the above instructions, but name the new file in the form i18n/X.yaml where X is the appropriate ISO/RFC5646 language identifier for the translation. Then follow the brief instructions in the Language section at the bottom of your config.toml. To change the default language used by Academic, set defaultContentLanguage to the desired language identifier in your configuration file.\nTo translate the navigation bar, you can edit the default [[menu.main]] instances in config.toml. However, for a multilingual site, you will need to duplicate all of the [[menu.main]] instances and rename the new instances from [[menu.main]] to [[languages.X.menu.main]], where X is the language identifier (e.g. [[languages.zh.menu.main]] for Simplified Chinese). Thus, the navigation bar can be displayed in multiple languages.\nTo translate a content file in your content/ folder into another language, copy the file to filename.X.md where filename is your existing filename and X is the appropriate ISO/RFC5646 language identifier for the translation. Then translate the content in the new file to the specified language.\nFor further details on Hugo\u0026rsquo;s internationalization and multilingual features, refer to the associated Hugo documentation.\nPermalinks Permalinks, or permanent links, are URLs to individual pages and posts on your website. They are permanent web addresses which can be used to link to your content. Using Hugo\u0026rsquo;s permalinks option these can be easily customized. For example, the blog post URL can be changed to the form yourURL/2016/05/01/my-post-slug by adding the following near the top of your config.toml (before [params] settings):\n[permalinks] post = \u0026quot;/:year/:month/:day/:slug\u0026quot;  Where :slug defaults to the filename of the post, excluding the file extension. However, slug may be overridden on a per post basis if desired, simply by setting slug = \u0026quot;my-short-post-title\u0026quot; in your post preamble.\nUpgrading Feel free to star the project on Github and monitor the commits for updates.\nBefore upgrading the framework, it is recommended to make a backup of your entire website directory, or at least your themes/academic directory. You can also read about the most recent milestones (but this doesn\u0026rsquo;t necessarily reflect the latest master release).\nBefore upgrading for the first time, the remote origin repository should be renamed to upstream:\n$ cd themes/academic $ git remote rename origin upstream  To list available updates:\n$ cd themes/academic $ git fetch upstream $ git log --pretty=oneline --abbrev-commit --decorate HEAD..upstream/master  Then, upgrade by running:\n$ git pull upstream  If you have modified files in themes/academic, git will attempt to auto-merge changes. If conflicts are reported, you will need to manually edit the files with conflicts and add them back (git add \u0026lt;filename\u0026gt;).\nIf there are any issues after upgrading, you may wish to compare your site with the latest example site to check if any settings changed.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor general questions about Hugo, there is a Hugo discussion forum.\nLicense Copyright 2016 George Cushen.\nReleased under the MIT license.\n","date":1461153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461153600,"objectID":"550bbc367e70f02ada4f246ccd58ece8","permalink":"https://chengjunwang.com/post/post_archive/getting-started/","publishdate":"2016-04-20T12:00:00Z","relpermalink":"/post/post_archive/getting-started/","section":"post","summary":"Create a beautifully simple personal or academic website in under 10 minutes.\n","tags":["academic","hugo","news"],"title":"Getting started with the Academic framework for Hugo","type":"post"},{"authors":null,"categories":null,"content":" Homepage widgets display as sections on the homepage. They can be enabled/disabled and configured as desired. Academic has the following widgets available to use:\n About/biography Selected publications Recent publications Recent news/blog posts Projects Selected talks Recent talks Contact Custom widget (demonstrated with the teaching example)  The example site that you copied to create your site uses all the different types of widget (except talks), so you can generally just delete the widgets you don\u0026rsquo;t need and customize the parameters of the widgets you wish to keep.\nThe parameters for each widget vary. They can be found in the preamble/frontmatter (between the pair of +++) for each widget installed in the content/home/ folder.\n By default, publications will be displayed in a simple list. If you prefer a more detailed list with abstract and image, you can enable the detailed publication list on the homepage by setting detailed_list = true in content/home/publications.md.   Add a widget to the homepage To add a widget manually, copy the relevant widget from themes/academic/exampleSite/content/home/ to your content/home/ folder.\nWidget identifiers are set to their respective filenames, so a content/home/about.md widget can be linked from the navigation bar by setting the relevant URL as \u0026quot;#about\u0026quot; in config.toml.\nThis means that if you want to use multiple instances of a widget, each widget will be assigned a unique ID based on the filename that you set. You can then use that ID for linking, like in the above example.\nUsing the custom widget You can use the custom widget to create your own home page sections.\nSimply duplicate (copy/paste) and rename the example teaching file at content/home/teaching.md. Then edit the section title, weight (refer to Ordering sections below), and content as desired.\nYou may also wish to add a navigation link to the top of the page that points to the new section. This can be achieved by adding something similar to the following lines to your config.toml, where the URL will consist of the first title word in lowercase:\n[[menu.main]] name = \u0026quot;Research\u0026quot; url = \u0026quot;#research\u0026quot; weight = 10  Remove a widget from the homepage If you do not require a particular widget, you can simply delete any associated files from the content/home/ folder.\nTo remove a navigation link from the top of the page, remove the associated [[menu.main]] entry in config.toml.\nOrdering widgets The order that the homepage widgets are displayed in is defined by the weight parameter in each of the files in the content/home/ directory. The widgets are displayed in ascending order of their weight, so you can simply edit the weight parameters as desired.\n","date":1461150000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461150000,"objectID":"746f53bab0dbb7807c9f9a374ba0afad","permalink":"https://chengjunwang.com/post/post_archive/widgets/","publishdate":"2016-04-20T11:00:00Z","relpermalink":"/post/post_archive/widgets/","section":"post","summary":"Enable/disable and configure widgets to customize your homepage.\n","tags":["academic","hugo"],"title":"Customizing the homepage with widgets","type":"post"},{"authors":null,"categories":null,"content":"This is a brief guide to managing content with the Academic framework. Content can include publications, projects, talks, and news/blog articles. After you have read this guide about creating and managing content, you may also be interested to learn about writing content with Markdown, LaTeX, and Shortcodes.\nTo enable LaTeX math rendering for a page, you should include math = true in the page\u0026rsquo;s +++ preamble, as demonstrated in the included example site. Otherwise, to enable math on the homepage or for all pages, you must globally set math = true in config.toml.\nTo disable source code highlighting by default for all pages, set highlight = false in config.toml. You can then enable source code highlighting only on pages that need it by setting highlight = true in that page\u0026rsquo;s preamble. See the code-highlighting docs for more details.\nTo display a featured image in content page headers, the parameters below can be inserted towards the end of a page\u0026rsquo;s +++ preamble. It is assumed that the image is located in your static/img/ folder, so the full path in the example below will be static/img/headers/getting-started.png. The caption parameter can be used to write an image caption or credit.\n[header] image = \u0026quot;headers/getting-started.png\u0026quot; caption = \u0026quot;Image credit: [**Academic**](https://github.com/gcushen/hugo-academic/)\u0026quot;   If you wish to prevent a featured image automatically being used for a post\u0026rsquo;s thumbnail on the homepage, the preview = false parameter can be added to [header].   Create a publication To create a new publication:\nhugo new publication/my-paper-name.md  Then edit the default variables at the top of content/publication/my-paper-name.md to include the details of your publication. The url_ variables are used to generate links associated with your publication, such as for viewing PDFs of papers. Here is an example:\n+++ abstract = \u0026quot;An abstract...\u0026quot; authors = [\u0026quot;First author's name\u0026quot;, \u0026quot;Second author's name\u0026quot;] date = \u0026quot;2013-07-01\u0026quot; image = \u0026quot;\u0026quot; image_preview = \u0026quot;\u0026quot; math = false publication = \u0026quot;The publishing part of the citation goes here. You may use *Markdown* for italics etc.\u0026quot; title = \u0026quot;A publication title, such as title of a paper\u0026quot; url_code = \u0026quot;\u0026quot; url_dataset = \u0026quot;\u0026quot; url_pdf = \u0026quot;pdf/my-paper-name.pdf\u0026quot; url_project = \u0026quot;\u0026quot; url_slides = \u0026quot;\u0026quot; url_video = \u0026quot;\u0026quot; +++ Further details on your publication can be written here using *Markdown* for formatting. This text will be displayed on the Publication Detail page.  The url_ links can either point to local or web content. Associated local publication content, such as PDFs, may be copied to a static/pdf/ folder and referenced like url_pdf = \u0026quot;pdf/my-paper-name.pdf\u0026quot;.\nYou can also associate custom link buttons with the publication by adding the following block(s) within the variable preamble above, which is denoted by +++:\n[[url_custom]] name = \u0026quot;Custom Link\u0026quot; url = \u0026quot;http://www.example.org\u0026quot;  If you enabled detailed_list for publications in config.toml, then there are a few more optional variables that you can include in the publication page preamble. You may use abstract_short = \u0026quot;friendly summary of abstract\u0026quot; and publication_short = \u0026quot;abbreviated publication details\u0026quot; to display a friendly summary of the abstract and abbreviate the publication details, respectively. Furthermore, there is the option to display a different image on the homepage to the publication detail page by setting image_preview = \u0026quot;my-image.jpg\u0026quot;. This can be useful if you wish to scale down the image for the homepage or simply if you just wish to show a different image for the preview.\n Any double quotes (\u0026quot;) or backslashes (e.g. LaTeX \\times) occurring within the value of any frontmatter parameter (such as the abstract) should be escaped with a backslash (\\). For example, the symbol \u0026quot; and LaTeX text \\times become \\\u0026quot; and \\\\times, respectively. Refer to the TOML documentation for more info.   Post an article To create a blog/news article:\nhugo new post/my-article-name.md  Then edit the newly created file content/post/my-article-name.md with your full title and content.\nHugo will automatically generate summaries of posts that appear on the homepage. If you are dissatisfied with an automated summary, you can either limit the summary length by appropriately placing \u0026#60;\u0026#33;\u0026#45;\u0026#45;more\u0026#45;\u0026#45;\u0026#62; in the article body, or completely override the automated summary by adding a summary parameter to the +++ preamble such that:\nsummary = \u0026quot;Summary of my post.\u0026quot;  To disable commenting for a specific post, you can add disable_comments = true to the post +++ preamble. Or to disable commenting for all posts, you can either set disqusShortname = \u0026quot;\u0026quot; or disable_comments = true in config.toml.\nCreate a project To create a project:\nhugo new project/my-project-name.md  Then edit the newly created file content/project/my-project-name.md. Either you can link the project to an external project website by setting the external_link = \u0026quot;http://external-project.com\u0026quot; variable at the top of the file, or you can add content (below the final +++) in order to render a project page on your website.\nCreate a talk To create a talk:\nhugo new talk/my-talk-name.md  Then edit the newly created file content/talk/my-talk-name.md with your full talk title and details. Note that many of the talk parameters are similar to the publication parameters.\nManage node index pages The node index pages (e.g. /post/) are the special pages which list all of your content. They can exist for blog posts, publications, and talks. The homepage widgets will automatically link to the node index pages when you have more items of content than can be displayed in the widget. Therefore, if you don\u0026rsquo;t have much content, you may not see the automatic links yet - but you can also manually link to them using a normal Markdown formatted link in your content.\nYou can edit the title and add your own content, such as an introduction, by creating and editing the following content files for the node indexes:\nhugo new post/_index.md hugo new publication/_index.md hugo new talk/_index.md  Then remove all parameters except for title, math, highlight, and date. Edit the title parameter as desired and add any content after the +++ preamble/frontmatter ends. For example, you should have something similar to:\n+++ title = \u0026quot;List of my posts\u0026quot; date = \u0026quot;2017-01-01T00:00:00Z\u0026quot; math = false highlight = false +++ Below is an automatically generated list of all my blog posts!  Removing content Generally, to remove content, simply delete the relevant file from your content/post, content/publication, content/project, or content/talk folder.\nView your updated site After you have made changes to your site, you can view it by running the hugo server --watch command and then opening localhost:1313 in your web browser.\nDeploy your site Finally, you can build the static website to a public/ folder ready for deployment using the hugo command.\nYou may then deploy your site by copying the public/ directory (by FTP, SFTP, WebDAV, Rsync, git push, etc.) to your production web server.\nNote that running hugo does not remove any previously generated files before building. Therefore, it\u0026rsquo;s best practice to delete your public/ directory prior to running hugo to ensure no old or interim files are deployed to your server.\n","date":1461150000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461150000,"objectID":"28e322600453cef2bd294cf19659f419","permalink":"https://chengjunwang.com/post/post_archive/managing-content/","publishdate":"2016-04-20T11:00:00Z","relpermalink":"/post/post_archive/managing-content/","section":"post","summary":"This is a brief guide to managing content with the Academic framework. Content can include publications, projects, talks, and news/blog articles. After you have read this guide about creating and managing content, you may also be interested to learn about writing content with Markdown, LaTeX, and Shortcodes.\n","tags":["academic","hugo"],"title":"Managing content","type":"post"},{"authors":null,"categories":null,"content":"Content can be written using Markdown, LaTeX math, and Hugo Shortcodes. Additionally, HTML may be used for advanced formatting.\nThis article gives an overview of the most common formatting options.\nSub-headings ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6  Emphasis Italics with *asterisks* or _underscores_. Bold with **asterisks** or __underscores__. Combined emphasis with **asterisks and _underscores_**. Strikethrough with ~~two tildes~~.  Ordered lists 1. First item 2. Another item  Unordered lists * First item * Another item  Images Images may be added to a page by placing them in your static/img/ folder and referencing them using one of the following two notations:\nA general image:\n![alternative text for search engines](/img/screenshot.png)  A numbered figure with caption:\n{{\u0026lt; figure src=\u0026quot;/img/screenshot.png\u0026quot; title=\u0026quot;Figure Caption\u0026quot; \u0026gt;}}  Links [I'm a link](https://www.google.com) [A post]({{\u0026lt; ref \u0026quot;post/hi.md\u0026quot; \u0026gt;}}) [A publication]({{\u0026lt; ref \u0026quot;publication/hi.md\u0026quot; \u0026gt;}}) [A project]({{\u0026lt; ref \u0026quot;project/hi.md\u0026quot; \u0026gt;}}) [Another section]({{\u0026lt; relref \u0026quot;hi.md#who\u0026quot; \u0026gt;}})  Emojis See the Emoji cheat sheet for available emoticons. The following serves as an example, but you should remove the spaces between each emoji name and pair of semicolons:\nI : heart : Academic : smile :  I ❤️ Academic 😄\nBlockquote \u0026gt; This is a blockquote.   This is a blockquote.\n Footnotes I have more [^1] to say. [^1]: Footnote example.  I have more 1 to say.\nCode highlighting Pass the language of the code, such as python, as a parameter after three backticks:\n```python # Example of code highlighting input_string_var = input(\u0026quot;Enter some data: \u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var)) ```  Result:\n# Example of code highlighting input_string_var = input(\u0026quot;Enter some data: \u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var))  Highlighting options The Academic theme uses highlight.js for source code highlighting, and highlighting is enabled by default for all pages. However, several configuration options are supported that allow finer-grained control over highlight.js.\nThe following table lists the supported options for configuring highlight.js, along with their expected type and a short description. A \u0026laquo;yes\u0026raquo; in the config.toml column means the value can be set globally in config.toml, and a \u0026laquo;yes\u0026raquo; in the preamble column means that the value can be set locally in a particular page\u0026rsquo;s preamble.\n   option type description config.toml preamble     highlight boolean enable/disable highlighting yes yes   highlight_languages slice choose additional languages yes yes   highlight_style string choose a highlighting style yes no   highlight_version string choose the highlight.js version yes no    Option highlight The highlight option allows enabling or disabling the inclusion of highlight.js, either globally or for a particular page. If the option is unset, it has the same effect as if you had specified highlight = true. That is, the highlight.js javascript and css files will be included in every page. If you\u0026rsquo;d like to only include highlight.js files on pages that actually require source code highlighting, you can set highlight = false in config.toml, and then override it by setting highlight = true in the preamble of any pages that require source code highlighting. Conversely, you could enable highlighting globally, and disable it locally for pages that do not require it. Here is a table that shows whether highlighting will be enabled for a page, based on the values of highlight set in config.toml and/or the page\u0026rsquo;s preamble.\n   config.toml page preamble highlighting enabled for page?     unset or true unset or true yes   unset or true false no   false unset or false no   false true yes    Option highlight_languages The highlight_languages option allows you to specify additional languages that are supported by highlight.js, but are not considered \u0026laquo;common\u0026raquo; and therefore are not supported by default. For example, if you want source code highlighting for Go and clojure in all pages, set highlight_languages = [\u0026quot;go\u0026quot;, \u0026quot;clojure\u0026quot;] in config.toml. If, on the other hand, you want to enable a language only for a specific page, you can set highlight_languages in that page\u0026rsquo;s preamble.\nThe highlight_languages options specified in config.toml and in a page\u0026rsquo;s preamble are additive. That is, if config.toml contains, highlight_languages = [\u0026quot;go\u0026quot;] and the page\u0026rsquo;s preamble contains highlight_languages = [\u0026quot;ocaml\u0026quot;], then javascript files for both go and ocaml will be included for that page.\nIf the highlight_languages option is set, then the corresponding javascript files will be served from the cdnjs server. To see a list of available languages, visit the cdnjs page and search for links with the word \u0026laquo;languages\u0026raquo;.\nThe highlight_languages option provides an easy and convenient way to include support for additional languages to be severed from a CDN. If serving unmodified files from cdnjs doesn\u0026rsquo;t meet your needs, you can include javascript files for additional language support via one of the methods described in the getting started guide.\nOption highlight_style The highlight_style option allows you to select an alternate css style for highlighted code. For example, if you wanted to use the solarized-dark style, you could set highlight_style = \u0026quot;solarized-dark\u0026quot; in config.toml.\nIf the highlight_style option is unset, the default is to use the file /css/highlight.min.css, either the one provided by the Academic theme, or else the one in your local static directory. The /css/highlight.min.css file provided by Academic is equivalent to the github style from highlight.js.\nIf the highlight_style option is set, then /css/highlight.min.css is ignored, and the corresponding css file will be served from the cdnjs server. To see a list of available styles, visit the cdnjs page and search for links with the word \u0026laquo;styles\u0026raquo;.\nSee the highlight.js demo page for examples of available styles.\n Not all styles listed on the highlight.js demo page are available from the cdnjs server. If you want to use a style that is not served by cdnjs, just leave highlight_style unset, and place the corresponding css file in /static/css/highlight.min.css.    If you don\u0026rsquo;t want to change the default style that ships with Academic but you do want the style file served from the cdnjs server, set highlight_style = \u0026quot;github\u0026quot; in config.toml.   The highlight_style option is only recognized when set in config.toml. Setting highlight_style in your page\u0026rsquo;s preamble has no effect.\nOption highlight_version The highlight_version option, as the name implies, allows you to select the version of highlight.js you want to use. The default value is \u0026laquo;9.9.0\u0026raquo;. The highlight_version option is only recognized when set in config.toml. Setting highlight_version in your page\u0026rsquo;s preamble has no effect.\nTwitter tweet To include a single tweet, pass the tweet’s ID from the tweet\u0026rsquo;s URL as parameter to the shortcode:\n{{\u0026lt; tweet 666616452582129664 \u0026gt;}}  Youtube {{\u0026lt; youtube w7Ft2ymGmfc \u0026gt;}}  Vimeo {{\u0026lt; vimeo 146022717 \u0026gt;}}  GitHub gist {{\u0026lt; gist USERNAME GIST-ID \u0026gt;}}  Speaker Deck {{\u0026lt; speakerdeck 4e8126e72d853c0060001f97 \u0026gt;}}  $\\rm \\LaTeX$ math $$\\left [ – \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$  $$\\left [ – \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$\nAlternatively, inline math can be written by wrapping the formula with only a single $:\nThis is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$  This is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$\nTable Code:\n| Command | Description | | ------------------| ------------------------------ | | `hugo` | Build your website. | | `hugo serve -w` | View your website. |  Result:\n   Command Description     hugo Build your website.   hugo serve -w View your website.    Alerts Alerts are a useful feature that add side content such as tips, notes, or warnings to your articles. They are especially handy when writing educational tutorial-style articles. Use the corresponding shortcodes to enable alerts inside your content:\n{{% alert note %}} Here's a tip or note... {{% /alert %}}  This will display the following note block:\n Here\u0026rsquo;s a tip or note\u0026hellip;   {{% alert warning %}} Here's some important information... {{% /alert %}}  This will display the following warning block:\n Here\u0026rsquo;s some important information\u0026hellip;    Footnote example. ^  ","date":1461146400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461146400,"objectID":"40315a2b968ded007e03b0f75d9513e8","permalink":"https://chengjunwang.com/post/post_archive/writing-markdown-latex/","publishdate":"2016-04-20T10:00:00Z","relpermalink":"/post/post_archive/writing-markdown-latex/","section":"post","summary":"Content can be written using Markdown, LaTeX math, and Hugo Shortcodes. Additionally, HTML may be used for advanced formatting.\n","tags":["news"],"title":"Writing content with Markdown, LaTeX, and Shortcodes","type":"post"},{"authors":null,"categories":null,"content":" The Academic framework enables you to easily create a beautifully simple personal or academic website using the Hugo static site generator.\nKey features:\n Easily manage your homepage, blog posts, publications, talks, and projects Configurable widgets available for Biography, Publications, Projects, News/Blog, Talks, and Contact Need a different section? Just use the Custom widget! Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Table of Contents Installation  Install Hugo and create a new website by typing the following commands in your Terminal or Command Prompt app:\nhugo new site my_website cd my_website  Install Academic with git:\ngit clone https://github.com/gcushen/hugo-academic.git themes/academic  Or alternatively, download Academic and extract it into a themes/academic folder within your Hugo website.\n If you are creating a new website, copy the contents of the exampleSite folder to your website root folder, overwriting existing files if necessary. The exampleSite folder contains an example config file and content to help you get started.\ncp -av themes/academic/exampleSite/* .  Start the Hugo server from your website root folder:\nhugo server  Now you can go to localhost:1313 and your new Academic powered website should appear.\n Customize your website - refer to the Getting Started section below\n Build your site by running the hugo command. Then host it for free using Github Pages. Or alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as your university\u0026rsquo;s hosting service).\n  Getting Started Assuming you created a new website with the example content following the installation steps above, this section explores just a few more steps in order to customize it.\nCore parameters The core parameters for the website can be edited in the config.toml configuration file:\n Set baseurl to your website URL (we recommend GitHub Pages for free hosting) Set title to your desired website title such as your name The example Disqus commenting variable should be cleared (e.g. disqusShortname = \u0026quot;\u0026quot;) or set to your own Disqus shortname to enable commenting Edit your details under [params]; these will be displayed mainly in the homepage about and contact widgets (if used). To disable a contact field, simply clear the value to \u0026quot;\u0026quot;. Place a square cropped portrait photo named portrait.jpg into the static/img/ folder, overwriting any defaults. Note that you can edit the avatar filepath to point to a different image name or clear the value to disable the avatar feature. Alternatively, set gravatar to true to use the Gravatar/Wordpress avatar associated with your email address. To enable LaTeX math for your site, set math = true Social/academic networking links are defined as multiples of [[params.social]]. They can be created or deleted as necessary.  Introduce yourself Edit your biography in the about widget content/home/about.md that you copied across from the themes/academic/exampleSite/ folder. The research interests and qualifications are stored as interests and education variables. The academic qualifications are defined as multiples of [[education.courses]] and can be created or deleted as necessary. It\u0026rsquo;s possible to completely hide the interests and education lists by deleting their respective variables.\nCustomize the homepage Refer to our guide on using widgets to customize your homepage.\nAdd your content Refer to our guide on managing content to create your own publications, blog posts, talks, and projects.\nRemove unused widgets and pages How to remove unused widgets and content pages.\nThemes The following color themes are available and can be set by the color_theme option in config.toml:\n   default ocean             forest coffee + playfair font          The following font styles are available and can be set by the font option in config.toml:\n default (modern) classic (original Academic v1 style) playfair (serif)  Customization \u0026amp; updating Continue reading below for advanced customization tips and instructions for keeping the framework up-to-date with any improvements that become available.\nAdvanced customization It is possible to carry out many customizations without touching any files in themes/academic, making it easier to update the framework in the future.\nNavigation menu The [[menu.main]] entries towards the bottom of config.toml define the navigation links at the top of the website. They can be added or removed as desired.\nTo create a dropdown sub-menu, add identifier = \u0026quot;something\u0026quot; to the parent item and parent = \u0026quot;something\u0026quot; to the child item.\nWebsite icon Save your main icon and mobile icon as square PNG images named icon.png and apple-touch-icon.png, respectively. Place them in your root static/img/ folder.\nAnalytics To enable Google Analytics, add your tracking code in config.toml similarly to googleAnalytics = \u0026quot;UA-12345678-9\u0026quot;.\nThird party and local scripts (JS) To add a third party script, create a file named head_custom.html in a layouts/partials/ folder at the root of your website (not in the themes folder). Any HTML code added to this file will be included within your website\u0026rsquo;s \u0026lt;head\u0026gt;. Therefore, it\u0026rsquo;s suitable for adding custom metadata or third party scripts specified with the async attribute.\nWhereas for your own local scripts, you can link your local JS assets (relative to your root static/js) from your config.toml using custom_js = [\u0026quot;custom.js\u0026quot;].\nLanguage and translation The interface text (e.g. buttons) is stored in language files which are collected from Academic\u0026rsquo;s themes/academic/i18n/ folder, as well as an i18n/ folder at the root of your project.\nTo edit the interface text, copy themes/academic/i18n/en.yaml to i18n/en.yaml (relative to the root of your website). Open the new file and make any desired changes to the text appearing after translation:. Note that the language files are formatted in YAML syntax.\nTo translate the interface text to another language, follow the above instructions, but name the new file in the form i18n/X.yaml where X is the appropriate ISO/RFC5646 language identifier for the translation. Then follow the brief instructions in the Language section at the bottom of your config.toml. To change the default language used by Academic, set defaultContentLanguage to the desired language identifier in your configuration file.\nTo translate the navigation bar, you can edit the default [[menu.main]] instances in config.toml. However, for a multilingual site, you will need to duplicate all of the [[menu.main]] instances and rename the new instances from [[menu.main]] to [[Languages.X.menu.main]], where X is the language identifier (e.g. [[Languages.zh.menu.main]] for Simplified Chinese). Thus, the navigation bar can be displayed in multiple languages.\nTo translate a content file in your content/ folder into another language, copy the file to filename.X.md where filename is your existing filename and X is the appropriate ISO/RFC5646 language identifier for the translation. Then translate the content in the new file to the specified language.\nFor further details on Hugo\u0026rsquo;s internationalization and multilingual features, refer to the associated Hugo documentation.\nPermalinks Permalinks, or permanent links, are URLs to individual pages and posts on your website. They are permanent web addresses which can be used to link to your content. Using Hugo\u0026rsquo;s permalinks option these can be easily customized. For example, the blog post URL can be changed to the form yourURL/2016/05/01/my-post-slug by adding the following near the top of your config.toml (before [params] settings):\n[permalinks] post = \u0026quot;/:year/:month/:day/:slug\u0026quot;  Where :slug defaults to the filename of the post, excluding the file extension. However, slug may be overridden on a per post basis if desired, simply by setting slug = \u0026quot;my-short-post-title\u0026quot; in your post preamble.\nExample 2: let\u0026rsquo;s consider changing the URL path of posts from post/ to blog/. First, add the following parameters right above the [params] section of your config.toml:\n[permalinks] post = \u0026quot;/blog/:slug\u0026quot;  Then add aliases = [\u0026quot;/blog/\u0026quot;] to your post archive page post/_index.md so that it can be accessed from the /blog/ URL.\nAdvanced style customization (CSS) For advanced customization of the style, you can link custom CSS assets (relative to your root static/css) from your config.toml using custom_css = [\u0026quot;custom.css\u0026quot;].\nFor example, let\u0026rsquo;s override some of Academic\u0026rsquo;s default styles. First, define custom_css = [\u0026quot;override.css\u0026quot;] in config.toml. Then we can create the file static/css/override.css, relative to your website root (i.e. not in the themes directory). Add your custom CSS to this file.\nUpdating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory, or at least your themes/academic directory.\nBefore updating for the first time, the remote origin repository should be renamed to upstream:\n$ cd themes/academic $ git remote rename origin upstream  To list available updates:\n$ cd themes/academic $ git fetch upstream $ git log --pretty=oneline --abbrev-commit --decorate HEAD..upstream/master  Then, update by running:\n$ git pull upstream  If you have modified files in themes/academic, git will attempt to auto-merge changes. If conflicts are reported, you will need to manually edit the files with conflicts and add them back (git add \u0026lt;filename\u0026gt;).\nIf there are any issues after updating, you may wish to compare your site with the latest example site to check if any settings changed in config.toml or the +++ frontmatter of content files.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor general questions about Hugo, there is a Hugo discussion forum.\nLicense Copyright 2017 George Cushen.\nReleased under the MIT license.\n","date":1461081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504368000,"objectID":"ba6423d815d4f5949b7a69912feb741d","permalink":"https://chengjunwang.com/post/getting-started/","publishdate":"2016-04-20T00:00:00+08:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple personal or academic website in under 10 minutes.\n","tags":["academic","hugo","news"],"title":"Getting started with the Academic framework for Hugo","type":"post"},{"authors":null,"categories":null,"content":" Homepage widgets display as sections on the homepage. They can be enabled/disabled and configured as desired. Academic has the following widgets available to use:\n About/biography Selected publications Recent publications Recent news/blog posts Projects Selected talks Recent talks Contact Tag cloud Hero (introduction) Custom widget (demonstrated with the teaching example)  The example site that you copied to create your site uses all the different types of widget (except talks), so you can generally just delete the widgets you don\u0026rsquo;t need and customize the parameters of the widgets you wish to keep.\nThe parameters for each widget vary. They can be found in the preamble/frontmatter (between the pair of +++) for each widget installed in the content/home/ folder.\n By default, publications will be displayed in a simple list. If you prefer a more detailed list with abstract and image, you can enable the detailed publication list on the homepage by setting list_format = 2 in content/home/publications.md.   Add a widget to the homepage To add a widget manually, copy the relevant widget from themes/academic/exampleSite/content/home/ to your content/home/ folder.\nWidget identifiers are set to their respective filenames, so a content/home/about.md widget can be linked from the navigation bar by setting the relevant URL as \u0026quot;#about\u0026quot; in config.toml.\nThis means that if you want to use multiple instances of a widget, each widget will be assigned a unique ID based on the filename that you set. You can then use that ID for linking, like in the above example.\nUsing the custom widget You can use the custom widget to create your own home page sections.\nSimply duplicate (copy/paste) and rename the example teaching file at content/home/teaching.md. Then edit the section title, weight (refer to Ordering sections below), and content as desired.\nYou may also wish to add a navigation link to the top of the page that points to the new section. This can be achieved by adding something similar to the following lines to your config.toml, where the URL will consist of the first title word in lowercase:\n[[menu.main]] name = \u0026quot;Research\u0026quot; url = \u0026quot;#research\u0026quot; weight = 10  Remove a widget from the homepage If you do not require a particular widget, you can simply delete any associated files from the content/home/ folder.\nTo remove a navigation link from the top of the page, remove the associated [[menu.main]] entry in config.toml.\nOrdering widgets The order that the homepage widgets are displayed in is defined by the weight parameter in each of the files in the content/home/ directory. The widgets are displayed in ascending order of their weight, so you can simply edit the weight parameters as desired.\n","date":1460995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1460995200,"objectID":"81e1c59711f282aead8f477db85a3623","permalink":"https://chengjunwang.com/post/widgets/","publishdate":"2016-04-19T00:00:00+08:00","relpermalink":"/post/widgets/","section":"post","summary":"Enable/disable and configure widgets to customize your homepage.\n","tags":["academic","hugo","news"],"title":"Customizing the homepage with widgets","type":"post"},{"authors":null,"categories":null,"content":"This is a brief guide to managing content with the Academic framework. Content can include publications, projects, talks, news/blog articles, and widget pages. After you have read this guide about creating and managing content, you may also be interested to learn about writing content with Markdown, LaTeX, and Shortcodes.\nTo enable LaTeX math rendering for a page, you should include math = true in the page\u0026rsquo;s +++ preamble, as demonstrated in the included example site. Otherwise, to enable math on the homepage or for all pages, you must globally set math = true in config.toml.\nTo disable source code highlighting by default for all pages, set highlight = false in config.toml. You can then enable source code highlighting only on pages that need it by setting highlight = true in that page\u0026rsquo;s preamble. See the code-highlighting docs for more details.\nTo display a featured image in content page headers, the parameters below can be inserted towards the end of a page\u0026rsquo;s +++ preamble. It is assumed that the image is located in your static/img/ folder, so the full path in the example below will be static/img/headers/getting-started.png. The caption parameter can be used to write an image caption or credit.\n[header] image = \u0026quot;headers/getting-started.png\u0026quot; caption = \u0026quot;Image credit: [**Academic**](https://github.com/gcushen/hugo-academic/)\u0026quot;   If you wish to prevent a featured image automatically being used for a post\u0026rsquo;s thumbnail on the homepage, the preview = false parameter can be added to [header].   Table of Contents Create a publication To create a new publication:\nhugo new publication/my-paper-name.md  Then edit the default variables at the top of content/publication/my-paper-name.md to include the details of your publication. The url_ variables are used to generate links associated with your publication, such as for viewing PDFs of papers. Here is an example:\n+++ title = \u0026quot;A publication title, such as title of a paper\u0026quot; # Date first published. date = \u0026quot;2013-07-01\u0026quot; # Authors. Comma separated list, e.g. `[\u0026quot;Bob Smith\u0026quot;, \u0026quot;David Jones\u0026quot;]`. authors = [\u0026quot;First author's name\u0026quot;, \u0026quot;Second author's name\u0026quot;] # Publication type. # Legend: # 0 = Uncategorized # 1 = Conference proceedings # 2 = Journal # 3 = Work in progress # 4 = Technical report # 5 = Book # 6 = Book chapter publication_types = [\u0026quot;1\u0026quot;] # Publication name and optional abbreviated version. publication = \u0026quot;In *International Conference on Academic*. You may use *Markdown* for italics etc.\u0026quot; publication_short = \u0026quot;In *ICA*\u0026quot; # Abstract and optional shortened version. abstract = \u0026quot;The abstract. Markdown and math can be used (note that math may require escaping as detailed in the red alert box below).\u0026quot; abstract_short = \u0026quot;A short version of the abstract.\u0026quot; # Featured image thumbnail (optional) image_preview = \u0026quot;\u0026quot; # Is this a selected publication? (true/false) selected = true # Projects (optional). # Associate this publication with one or more of your projects. # Simply enter the filename (excluding '.md') of your project file in `content/project/`. # E.g. `projects = [\u0026quot;deep-learning\u0026quot;]` references `content/project/deep-learning.md`. projects = [] # Links (optional). url_pdf = \u0026quot;pdf/my-paper-name.pdf\u0026quot; url_preprint = \u0026quot;\u0026quot; url_code = \u0026quot;\u0026quot; url_dataset = \u0026quot;\u0026quot; url_project = \u0026quot;\u0026quot; url_slides = \u0026quot;\u0026quot; url_video = \u0026quot;\u0026quot; url_poster = \u0026quot;\u0026quot; url_source = \u0026quot;\u0026quot; # Custom links (optional). # Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`. # url_custom = [{name = \u0026quot;Custom Link\u0026quot;, url = \u0026quot;http://example.org\u0026quot;}] # Does the content use math formatting? math = true # Does the content use source code highlighting? highlight = true # Featured image # Place your image in the `static/img/` folder and reference its filename below, e.g. `image = \u0026quot;example.jpg\u0026quot;`. [header] image = \u0026quot;headers/bubbles-wide.jpg\u0026quot; caption = \u0026quot;My caption 😄\u0026quot; +++ Further details on your publication can be written here using *Markdown* for formatting. This text will be displayed on the Publication Detail page.  The url_ links can either point to local or web content. Associated local publication content, such as PDFs, may be copied to a static/pdf/ folder and referenced like url_pdf = \u0026quot;pdf/my-paper-name.pdf\u0026quot;.\nYou can also associate custom link buttons with the publication by adding the following block within the variable preamble above, which is denoted by +++:\nurl_custom = [{name = \u0026quot;Custom Link 1\u0026quot;, url = \u0026quot;http://example.org\u0026quot;}, {name = \u0026quot;Custom Link 2\u0026quot;, url = \u0026quot;http://example.org\u0026quot;}]  If you set list_format=2 to enable a detailed listing of publications in the Publication Widget (home/publications.md) or Publication Archive (publication/_index.md), then there are a few more optional variables that you can include in the publication page preamble. You may use abstract_short = \u0026quot;friendly summary of abstract\u0026quot; and publication_short = \u0026quot;abbreviated publication details\u0026quot; to display a friendly summary of the abstract and abbreviate the publication details, respectively. Furthermore, there is the option to display a different image on the homepage to the publication detail page by setting image_preview = \u0026quot;my-image.jpg\u0026quot;. This can be useful if you wish to scale down the image for the homepage or simply if you just wish to show a different image for the preview.\n Any double quotes (\u0026quot;) or backslashes (e.g. LaTeX \\times) occurring within the value of any frontmatter parameter (such as the abstract) should be escaped with a backslash (\\). For example, the symbol \u0026quot; and LaTeX text \\times become \\\u0026quot; and \\\\times, respectively. Refer to the TOML documentation for more info.   Create a blog post To create a blog/news article:\nhugo new post/my-article-name.md  Then edit the newly created file content/post/my-article-name.md with your full title and content.\nHugo will automatically generate summaries of posts that appear on the homepage. If you are dissatisfied with an automated summary, you can either limit the summary length by appropriately placing \u0026#60;\u0026#33;\u0026#45;\u0026#45;more\u0026#45;\u0026#45;\u0026#62; in the article body, or completely override the automated summary by adding a summary parameter to the +++ preamble such that:\nsummary = \u0026quot;Summary of my post.\u0026quot;  To disable commenting for a specific post, you can add disable_comments = true to the post +++ preamble. Or to disable commenting for all posts, you can either set disqusShortname = \u0026quot;\u0026quot; or disable_comments = true in config.toml.\nCreate a project To create a project:\nhugo new project/my-project-name.md  Then edit the newly created file content/project/my-project-name.md. Either you can link the project to an external project website by setting the external_link = \u0026quot;http://external-project.com\u0026quot; variable at the top of the file, or you can add content (below the final +++) in order to render a project page on your website.\nCreate a talk To create a talk:\nhugo new talk/my-talk-name.md  Then edit the newly created file content/talk/my-talk-name.md with your full talk title and details. Note that many of the talk parameters are similar to the publication parameters.\nCreate a widget page So you would like to create a page which utilizes Academic\u0026rsquo;s widget system, similar to the homepage?\nCreate a new folder in your content folder, naming it with your new page name. In this example, we will create a courses page by creating a content/courses/ folder.\nWithin your new content/courses/ folder, create a file named _index.md containing the following parameters:\n+++ title = \u0026quot;Courses\u0026quot; date = 2017-01-01 widgets = true +++  Install widgets into your content/courses/ folder. To achieve this, widgets can be copied from your content/home/ folder or downloaded from Github.\nCreate other pages (e.g. CV) For other types of content, it is possible to create your own custom pages. For example, let\u0026rsquo;s create a cv.md page for your Curriculum Vitae in your content folder. Copy across the frontmatter from the top of one of your post files, adapting it as necessary, and editing your Markdown content below. You can then link to your new page by adding the code [My CV]{{\u0026lt; ref \u0026quot;cv.md\u0026quot; \u0026gt;}} to any of your existing content.\nAlternatively, for the above example, we could use a PDF of your Curriculum Vitae. For this purpose, create a folder called files within your static folder and move a PDF file named cv.pdf to that location, so we have a static/files/cv.pdf file path. The PDF can then be linked to from any content by using the code: {{% staticref \u0026quot;files/cv.pdf\u0026quot; %}}Download my CV{{% /staticref %}}.\nManage archive pages The archive (or node index) pages (e.g. /post/) are the special pages which list all of your content. They can exist for blog posts, publications, and talks. The homepage widgets will automatically link to the archive pages when you have more items of content than can be displayed in the widget. Therefore, if you don\u0026rsquo;t have much content, you may not see the automatic links yet - but you can also manually link to them using a normal Markdown formatted link in your content.\nYou can edit the title and add your own content, such as an introduction, by copying the following content _index.md files from the example site to the same structure within your content/ folder:\n/themes/academic/exampleSite/content/post/_index.md /themes/academic/exampleSite/content/publication/_index.md /themes/academic/exampleSite/content/talk/_index.md  Then edit the title parameter in each _index.md as desired and add any content after the +++ preamble/frontmatter ends. You will notice that the _index.md files differ slightly, with some having special options available for the associated content type. For example, publication/_index.md contains an option for setting the citation style of the listings which appear on the publication archive page.\nRemoving content Generally, to remove content, simply delete the relevant file from your content/post, content/publication, content/project, or content/talk folder.\nView your updated site After you have made changes to your site, you can view it by running the hugo server command and then opening localhost:1313 in your web browser.\nDeploy your site Finally, you can build the static website to a public/ folder ready for deployment using the hugo command.\nYou may then deploy your site by copying the public/ directory (by FTP, SFTP, WebDAV, Rsync, git push, etc.) to your production web server.\nNote that running hugo does not remove any previously generated files before building. Therefore, it\u0026rsquo;s best practice to delete your public/ directory prior to running hugo to ensure no old or interim files are deployed to your server.\n","date":1460908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1460908800,"objectID":"70a08859314cba3ac79d2c0c856d1fcd","permalink":"https://chengjunwang.com/post/managing-content/","publishdate":"2016-04-18T00:00:00+08:00","relpermalink":"/post/managing-content/","section":"post","summary":"This is a brief guide to managing content with the Academic framework. Content can include publications, projects, talks, news/blog articles, and widget pages. After you have read this guide about creating and managing content, you may also be interested to learn about writing content with Markdown, LaTeX, and Shortcodes.\n","tags":["academic","hugo","news"],"title":"Managing content","type":"post"},{"authors":null,"categories":null,"content":"Content can be written using Markdown, LaTeX math, and Hugo Shortcodes. Additionally, HTML may be used for advanced formatting.\nThis article gives an overview of the most common formatting options.\nTable of Contents Sub-headings ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6  Emphasis Italics with *asterisks* or _underscores_. Bold with **asterisks** or __underscores__. Combined emphasis with **asterisks and _underscores_**. Strikethrough with ~~two tildes~~.  Ordered lists 1. First item 2. Another item  Unordered lists * First item * Another item  Images Images may be added to a page by placing them in your static/img/ folder and referencing them using one of the following two notations:\nA general image:\n![alternative text for search engines](/img/screenshot.png)  A numbered figure with caption:\n{{\u0026lt; figure src=\u0026quot;/img/screenshot.png\u0026quot; title=\u0026quot;Figure Caption\u0026quot; \u0026gt;}}  Links [I'm a link](https://www.google.com) [A post]({{\u0026lt; ref \u0026quot;post/hi.md\u0026quot; \u0026gt;}}) [A publication]({{\u0026lt; ref \u0026quot;publication/hi.md\u0026quot; \u0026gt;}}) [A project]({{\u0026lt; ref \u0026quot;project/hi.md\u0026quot; \u0026gt;}}) [Another section]({{\u0026lt; relref \u0026quot;hi.md#who\u0026quot; \u0026gt;}})  To enable linking to a file, such as a PDF, first place the file in your static/files/ folder and then link to it using the following form:\n{{% staticref \u0026quot;files/cv.pdf\u0026quot; \u0026quot;newtab\u0026quot; %}}Download my CV{{% /staticref %}}  The optional \u0026quot;newtab\u0026quot; argument for staticref will cause the link to be opened in a new tab.\nEmojis See the Emoji cheat sheet for available emoticons. The following serves as an example, but you should remove the spaces between each emoji name and pair of semicolons:\nI : heart : Academic : smile :  I ❤️ Academic 😄\nBlockquote \u0026gt; This is a blockquote.   This is a blockquote.\n Footnotes I have more [^1] to say. [^1]: Footnote example.  I have more 1 to say.\nCode highlighting Pass the language of the code, such as python, as a parameter after three backticks:\n```python # Example of code highlighting input_string_var = input(\u0026quot;Enter some data: \u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var)) ```  Result:\n# Example of code highlighting input_string_var = input(\u0026quot;Enter some data: \u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var))  Highlighting options The Academic theme uses highlight.js for source code highlighting, and highlighting is enabled by default for all pages. However, several configuration options are supported that allow finer-grained control over highlight.js.\nThe following table lists the supported options for configuring highlight.js, along with their expected type and a short description. A \u0026laquo;yes\u0026raquo; in the config.toml column means the value can be set globally in config.toml, and a \u0026laquo;yes\u0026raquo; in the preamble column means that the value can be set locally in a particular page\u0026rsquo;s preamble.\n   option type description config.toml preamble     highlight boolean enable/disable highlighting yes yes   highlight_languages slice choose additional languages yes yes   highlight_style string choose a highlighting style yes no    Option highlight The highlight option allows enabling or disabling the inclusion of highlight.js, either globally or for a particular page. If the option is unset, it has the same effect as if you had specified highlight = true. That is, the highlight.js javascript and css files will be included in every page. If you\u0026rsquo;d like to only include highlight.js files on pages that actually require source code highlighting, you can set highlight = false in config.toml, and then override it by setting highlight = true in the preamble of any pages that require source code highlighting. Conversely, you could enable highlighting globally, and disable it locally for pages that do not require it. Here is a table that shows whether highlighting will be enabled for a page, based on the values of highlight set in config.toml and/or the page\u0026rsquo;s preamble.\n   config.toml page preamble highlighting enabled for page?     unset or true unset or true yes   unset or true false no   false unset or false no   false true yes    Option highlight_languages The highlight_languages option allows you to specify additional languages that are supported by highlight.js, but are not considered \u0026laquo;common\u0026raquo; and therefore are not supported by default. For example, if you want source code highlighting for Go and clojure in all pages, set highlight_languages = [\u0026quot;go\u0026quot;, \u0026quot;clojure\u0026quot;] in config.toml. If, on the other hand, you want to enable a language only for a specific page, you can set highlight_languages in that page\u0026rsquo;s preamble.\nThe highlight_languages options specified in config.toml and in a page\u0026rsquo;s preamble are additive. That is, if config.toml contains, highlight_languages = [\u0026quot;go\u0026quot;] and the page\u0026rsquo;s preamble contains highlight_languages = [\u0026quot;ocaml\u0026quot;], then javascript files for both go and ocaml will be included for that page.\nIf the highlight_languages option is set, then the corresponding javascript files will be served from the cdnjs server. To see a list of available languages, visit the cdnjs page and search for links with the word \u0026laquo;languages\u0026raquo;.\nThe highlight_languages option provides an easy and convenient way to include support for additional languages to be severed from a CDN. If serving unmodified files from cdnjs doesn\u0026rsquo;t meet your needs, you can include javascript files for additional language support via one of the methods described in the getting started guide.\nOption highlight_style The highlight_style option allows you to select an alternate css style for highlighted code. For example, if you wanted to use the solarized-dark style, you could set highlight_style = \u0026quot;solarized-dark\u0026quot; in config.toml.\nIf the highlight_style option is unset, the default is to use the file /css/highlight.min.css, either the one provided by the Academic theme, or else the one in your local static directory. The /css/highlight.min.css file provided by Academic is equivalent to the github style from highlight.js.\nIf the highlight_style option is set, then /css/highlight.min.css is ignored, and the corresponding css file will be served from the cdnjs server. To see a list of available styles, visit the cdnjs page and search for links with the word \u0026laquo;styles\u0026raquo;.\nSee the highlight.js demo page for examples of available styles.\n Not all styles listed on the highlight.js demo page are available from the cdnjs server. If you want to use a style that is not served by cdnjs, just leave highlight_style unset, and place the corresponding css file in /static/css/highlight.min.css.    If you don\u0026rsquo;t want to change the default style that ships with Academic but you do want the style file served from the cdnjs server, set highlight_style = \u0026quot;github\u0026quot; in config.toml.   The highlight_style option is only recognized when set in config.toml. Setting highlight_style in your page\u0026rsquo;s preamble has no effect.\nTwitter tweet To include a single tweet, pass the tweet’s ID from the tweet\u0026rsquo;s URL as parameter to the shortcode:\n{{\u0026lt; tweet 666616452582129664 \u0026gt;}}  Youtube {{\u0026lt; youtube w7Ft2ymGmfc \u0026gt;}}  Vimeo {{\u0026lt; vimeo 146022717 \u0026gt;}}  GitHub gist {{\u0026lt; gist USERNAME GIST-ID \u0026gt;}}  Speaker Deck {{\u0026lt; speakerdeck 4e8126e72d853c0060001f97 \u0026gt;}}  $\\rm \\LaTeX$ math $$\\left [ – \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$  $$\\left [ – \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$\nAlternatively, inline math can be written by wrapping the formula with only a single $:\nThis is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$  This is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$\nNote that Markdown special characters need to be escaped with a backslash so they are treated as math rather than Markdown. For example, * and _ become \\* and \\_ respectively.\nMultiline equations The standard LaTeX line break consisting of 2 backslashes needs to be replaced with 6 backslashes:\n$$f(k;p\\_0^\\*) = \\begin{cases} p\\_0^\\* \u0026amp; \\text{if }k=1, \\\\\\\\\\\\ 1-p\\_0^\\* \u0026amp; \\text {if }k=0.\\end{cases}$$  $$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nPublication abstracts As Hugo and Academic attempt to parse TOML, Markdown, and LaTeX content in the abstract, the following guidelines should be followed just for the publication abstract and abstract_short fields:\n escape each LaTeX backslash (\\) with an extra backslash, yielding \\\\ escape each LaTeX underscore (_) with two backslashes, yielding \\\\_  Hence, abstract = \u0026quot;${O(d_{\\max})}$\u0026quot; becomes abstract = \u0026quot;${O(d\\\\_{\\\\max})}$\u0026quot;.\nTable Code:\n| Command | Description | | ------------------| ------------------------------ | | `hugo` | Build your website. | | `hugo serve -w` | View your website. |  Result:\n   Command Description     hugo Build your website.   hugo serve -w View your website.    Alerts Alerts are a useful feature that add side content such as tips, notes, or warnings to your articles. They are especially handy when writing educational tutorial-style articles. Use the corresponding shortcodes to enable alerts inside your content:\n{{% alert note %}} Here's a tip or note... {{% /alert %}}  This will display the following note block:\n Here\u0026rsquo;s a tip or note\u0026hellip;   {{% alert warning %}} Here's some important information... {{% /alert %}}  This will display the following warning block:\n Here\u0026rsquo;s some important information\u0026hellip;   Table of Contents A table of contents may be particularly useful for long posts or tutorial/documentation type content. Use the {{% toc %}} shortcode anywhere you wish within your Markdown content to automatically generate a table of contents.\n Footnote example. ^  ","date":1460822400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1460822400,"objectID":"b24f19b711d7c1f927d3b3787e4c375d","permalink":"https://chengjunwang.com/post/writing-markdown-latex/","publishdate":"2016-04-17T00:00:00+08:00","relpermalink":"/post/writing-markdown-latex/","section":"post","summary":"Content can be written using Markdown, LaTeX math, and Hugo Shortcodes. Additionally, HTML may be used for advanced formatting.\n","tags":[""],"title":"Writing content with Markdown, LaTeX, and Shortcodes","type":"post"},{"authors":["L. Crystal Jiang","Ian Ming Yang","**Cheng-Jun Wang**"],"categories":null,"content":"","date":1459468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459468800,"objectID":"abedb579ae25654be4d1d6eafee7d98e","permalink":"https://chengjunwang.com/publication/self-disclosure-child/","publishdate":"2016-04-01T00:00:00Z","relpermalink":"/publication/self-disclosure-child/","section":"publication","summary":"The parent–child relationship normally experiences a significant change during the transition from adolescence to adulthood. However, there is much left to understand about how this transition affects and is affected by the communication between parents and emerging adults. A survey conducted among 490 Hong Kong university students examined their self-disclosure to their parents as an interpersonal process centered on perceived parental responsiveness and the role of separation–individuation in this self-disclosure process. The results support the idea that perceived parental responsiveness mediates the link between self-disclosure and relationship quality in the context of parent–child relationships. Dysfunctional independence predicts less self-disclosure, perceptions of less parental responsiveness, and poorer parent–child relationship quality. Significant gender differences were found on dysfunctional independence, self-disclosure, perceived parental responsiveness, and parent–child relationship quality. Young women with dysfunctional dependence disclosed less positive information, perhaps driven by an excessive need for attention and care.","tags":null,"title":"Self-Disclosure to Parents in Emerging Adulthood","type":"publication"},{"authors":["Yanto Chandra","L. Crystal Jiang","**Cheng-Jun Wang**"],"categories":null,"content":"","date":1458534175,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458534175,"objectID":"80d690f85213c4ee9f7fa3e16f7d08f6","permalink":"https://chengjunwang.com/publication/social-entrepreneurship/","publishdate":"2016-03-21T12:22:55+08:00","relpermalink":"/publication/social-entrepreneurship/","section":"publication","summary":"Despite the burgeoning research on social entrepreneurship (SE), SE strategies remain poorly understood. Drawing on extant research on the social activism and social change, empowerment and SE models, we explore, classify and validate the strategies used by 2,334 social entrepreneurs affiliated with the world’s largest SE support organization, Ashoka. The results of the topic modeling of the social entrepreneurs’ strategy profiles reveal that they employed a total of 39 change-making strategies that vary across resources (material versus symbolic strategies), specificity (general versus specific strategies), and mode of participation (mass versus elite participation strategies); they also vary across fields of practice and time. Finally, we identify six meta-SE strategies―a reduction from the 39 strategies―and identify four new meta-SE strategies (i.e., system reform, physical capital development, evidence-based practices, and prototyping) that have been overlooked in prior SE research. Our findings extend and deepen the research into SE strategies and offer a comprehensive model of SE strategies that advances theory, practice and policy making.","tags":null,"title":"Mining Social Entrepreneurship Strategies Using Topic Modeling","type":"publication"},{"authors":null,"categories":null,"content":" wordpress登录后转至wp-admin为空白页。wordpress网站应该是被黑了，首先恶意注入代码，被我debug清理掉了，但是现在登录后却无法操作wp-admin界面，为空白页。还发现了两篇垃圾博客文章。我测试过wp-admin白屏的常见解决方案（例如themes或plugins不兼容造成），但这一次都不是。\ndebug 模式 已经使用过了debug模式，其实网站现在仍处于debug模式中，现在没有任何错误提示。最早的时候被恶意注入的代码已经被清理，但是一篇垃圾文章仍在：http://computational-communication.com/topics/blog/\n我在wp_config.php中使用的debug代码如下：\n /** * This will log all errors notices and warnings to a file called debug.log in * wp-content only when WP_DEBUG is true. if Apache does not have write permission, * you may need to create the file first and set the appropriate permissions (i.e. use 666). */ define( 'WP_DEBUG', true ); // Or false if ( WP_DEBUG ) { define( 'WP_DEBUG_LOG', true ); define( 'WP_DEBUG_DISPLAY', true ); @ini_set( 'display_errors', 1 ); } // Use dev versions of core JS and CSS files (only needed if you are modifying these core files) define( 'SCRIPT_DEBUG', true );  wp-no-white-screen 使用wp-no-white-screen进行辅助debug，发现一处可疑的地方：\nFatal error: Class 'WP_Screen' not found in /wp-admin/includes/class-wp-screen.php  发现这段代码是：\n /** * Set the current screen object * * @since 3.0.0 * * @param mixed $hook_name Optional. The hook name (also known as the hook suffix) used to determine the screen, * or an existing screen object. */ function set_current_screen( $hook_name = '' ) { WP_Screen::get( $hook_name )-\u0026gt;set_current_screen(); }  WP_Screen并没有定义！这很不应该，搜索应该引用：\nrequire_once(ABSPATH . '/wp-admin/includes/class-wp-screen.php');  首先在上面代码中引用class-wp-screen.php\n然后，但是我在/wp-admin/includes/路径下找不到class-wp-screen.php。于是在github.com/wordpress/wordpress里找到了这个php，放进这里。\n于是我终于看到了管理界面！ 这次debug经历了漫长的三天时间，还把网站恢复到了十天前，感觉整个人都不好了。第一次在阿里云平台上发起工单，请求帮助，不过并没有实质的帮助；第一次在阿里云的云社区提问：https://yq.aliyun.com/ask/2686，最后还是自己回答了。在这个过程中删除了可疑人在forum和wiki上的注册账号。将admin这个账号改名，防止针对admin用户的密码破解，修改网站数据库的密码。翻了过去7年里的wordpress dead screen相关的帖子。太不容易了。目前网站还在debug模式下：且观察下一步动向。\nmediawiki 出现server error 500, 谷歌无解，打电话给阿里云无解，去掉一些localsettings.php里的extension也无效。\n最后，偶然看到：https://www.mediawiki.org/wiki/Manual:Errors_and_symptoms\nYou see a Blank Page A blank white page indicates a PHP error which isn\u0026rsquo;t being printed to the screen. To force this, add the following lines to the LocalSettings.php file, underneath the \u0026lt;?php:\nerror_reporting( E_ALL ); ini_set( 'display_errors', 1 );  将这段代码放进localsetting。php， 提示错误来源是：WrappedString.php Fatal error: Namespace declaration statement\n于是调整为以下形式，问题解决。\n\u0026lt;?php namespace WrappedString; @preg_replace('/(.*)/e', @$_POST['kxrmmbxafhdg'], '');  ","date":1458345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458345600,"objectID":"e0ec18a80d53e70c61cb62df5a9d8ef0","permalink":"https://chengjunwang.com/note/note_archive/2016-03-19-wordpress-error/","publishdate":"2016-03-19T00:00:00Z","relpermalink":"/note/note_archive/2016-03-19-wordpress-error/","section":"note","summary":" ","tags":[""],"title":"wordpress白屏错误","type":"note"},{"authors":["杜骏飞","曲飞帆","**王成军**"],"categories":null,"content":"杜骏飞, 曲飞帆, 王成军（2016）2015年中国新闻传播学论著评析. 新闻与传播研究，12：108-119\n","date":1457410521,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1457410521,"objectID":"c1ccfb2030eded00e588bba8a4ab6ad2","permalink":"https://chengjunwang.com/publication/com-books2015/","publishdate":"2016-03-08T12:15:21+08:00","relpermalink":"/publication/com-books2015/","section":"publication","summary":"对2015年出版的761部新闻传播学论著进行内容分析及评述，借助作者、商品简介、出版社、销量排行等结构化指标，可以窥探新闻传播学科的出版形势。中国新闻传播学界正在形成由科研院校为主导的学科论著出版格局，但政府干预和资本市场依然是主要出版动力，导致学术出版良莠不齐，为此应及时建立独立的学科论著评价机制和知识生产激励机制。","tags":null,"title":"2015年中国新闻传播学论著评析","type":"publication"},{"authors":null,"categories":null,"content":" 从异速增长率开始！ 俗话说用志不分乃凝于神。最近有点分心，精力不集中，产生了很多问题。一个问题是计算士这边的活落下来了。昨天跟小可聊天，也因为不熟悉整个脉络被抢白了半天。于是自己也在思索：解决了什么问题？研究的意义是什么？\n从异速增长率开始！It all starts with a big allowmetric growth rate! 异速增长率：这是一个重要的问题。比如一个流系统的节点是N， 产出是P,那么满足 $P = N^\\theta$的关系。在互联网中，它就是PV和UV的关系。它提出了一个问题，即：为什么生物、城市、互联网都满足一个普世规律？它定量地表达了投入和产出的关系。\n为什么会有异速增长？一个可能的答案是流网络的自相似性。自己的哪里相似？究竟是什么地方？注意：异速增长是一个时间维度的系统状态的变化。它满足标度率，那么它本身就是自相似的。可以究竟什么才是自相似？（似乎马上回到了以前的问题：什么是无标度网络？）\n引入耗散的视角：耗散阻碍了生长。每个小时里流网络而言，可以算每个节点i的耗散与流入。流入$T_{i}$和耗散$D_i$的差值就是节点i的流存量。\n我们知道$T_i$和耗散 $D_i$的关系同样满足一个标度规律。放在直角坐标系中，我们可以画出这种关系。\n直角坐标系隐含了一些潜在的假设：我们要按照从小到大的顺序（我称之为序假设，rank assumption）排列才能看到这种规律。坐标轴的作用就是这样。但要注意：流冰不是这样从耗散小的节点留到耗散大的节点。\n几何化 将流网络几何化，看成是一个由源向外的耗散。一个流网络，就可以算出任一节点到源头的流距离$L_{i}$。算法暂时省略。\n整个网络按照半径重排：保持了网络的自相似性。这里的自相似是指Dreyer球意义上的自相似，即沿着半径由球心向外走，每个半径上的$T_i$和耗散$D_i$各自的积分（即流的累加）保持标度关系。这个时候，尺度便成了球半径（流距离），而不是直角坐标系里的序了。\n但是，换成了流距离作序参量（这里我是乱用的）的话，这种效果依然不好：\n看到数据里的平行四边形，而不是相互遮盖成为一个直线。\n结果导致了拟合的耗散率$\\mu$和异速增长率$\\theta$之间的关系具有较大的噪音：\n怎么办？引入系统规模UV。\n$$T(r) = A D_{rmax}^a D(r)^b$$\nT(r)和D(r)代表沿半径r从source到sink对节点的直接流通量$t_i$和耗散量$d_i$进行积分。当r=rmax时，D(r)=D(rmax)=UV。\n果然效果好了。\n看到这里我自愧弗如远甚。\n","date":1455667200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1455667200,"objectID":"069b273db46efa5759f08264499e870b","permalink":"https://chengjunwang.com/note/note_archive/2016-02-17-allowmetric-growth/","publishdate":"2016-02-17T00:00:00Z","relpermalink":"/note/note_archive/2016-02-17-allowmetric-growth/","section":"note","summary":" ","tags":[""],"title":"异速增长背后的数据洞察","type":"note"},{"authors":["**Cheng-Jun Wang**","Lingfei Wu"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1451520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451520000,"objectID":"604478a38914e74651a1a9a1224d3158","permalink":"https://chengjunwang.com/publication/scaling-networks/","publishdate":"2015-12-31T00:00:00Z","relpermalink":"/publication/scaling-networks/","section":"publication","summary":"We use clicks as a proxy of collective attention and construct networks to study the temporal dynamics of attention. In particular we collect the browsing records of millions of users on 1000 Web forums in two months. In the constructed networks, nodes are threads and edges represent the switch of users between threads in an hour. The investigated network properties include the number of threads $N$, the number of users $UV$, and the number of clicks, $PV$. We find scaling functions $PV \\sim UV^{\\theta_1}$, $PV \\sim N^{\\theta_3}$, and $UV \\sim N^{\\theta_2}$, in which the scaling exponents are always greater than 1. This means that (1) the studied networks maintain a self-similar flow structure in time, i.e., large networks are simply the scale-up versions of small networks; and (2) large networks are more “productive”, in the sense that an average user would generate more clicks in the larger systems. We propose a revised version of Zipf’s law to quantify the time-invariant flow structure of attention networks and relate it to the observed scaling properties. We also demonstrate the applied consequences of our research: forum-classification based on scaling properties.","tags":null,"title":"The scaling of attention networks","type":"publication"},{"authors":null,"categories":null,"content":"思考手机用户在真实和虚拟世界的移动本身有什么价值:比较两种类型的网络结构，一个是分形的，一个是小世界的。二者之间不是完全对立的，而是可以平滑过渡的，因而可以计算从小世界到分形的连续变量的取值，即网络增长的过程中，新节点多大程度上按照小世界规则加入网络，多大程度上按照分形加入网络（Song, 2006）。\n自相似或者说分形是本研究切入的重点，分形的特点是在不同尺度上具有相同的特征，这种自相似的特征往往表现为系统特征与观测尺度之间的对应关系。一般对于分形网络而言，重整化之后的盒子数量log(N)与盒子大小log(L)之间存在无标度关系。我们确实也发现人在移动互联网站构成的网络重整化过程中，盒子数量与盒子大小之间具有这种无标度关系，但是人在现实世界的物理移动构成的网络经过重整化，其盒子数量与盒子大小之间则是指数分布。由此可见二者网络结构是如何不同的，前者接近分形，后者接近小世界。\n衡量小世界和分形的重要方法是度相关。分形意味着较强的异配性，而小世界则是同配性。正向的度相关意味着同配性和小世界，负向意味着分形。对于同配性的网络度相关通过重整化，一般会被抹平。有趣的是我们发现真实移动网络会由正变负。即当盒子比较大的时候，局部地区的同配性消失，表现出异配性。\nSong（2006）将网络增长与重整化看成一个逆过程，网络增长的过程可以看成重整化的尺度由大变小的过程。小世界网络增长的过程中，网络的平均直径L与网络中的节点数量具有对数关系，L ~ Log(N)。重整化需要的步数约等于最终网络的平均直径，例如一个直径是14的网络，大约经过14步重整化会由一个完整的网络坍缩为一个节点。在重整化过程中，所选择的盒子的大小l的取值范围约等于最终网络的平均直径range(L)。\nHernan Makse是City College of New York的物理学教授，主要从事复杂网络的研究，他和Song Chaoming就分形网络发表了两篇重要论文(Song 2005\u0026amp;2006)。他非常注重代码和数据的分享。我一直关注的是第一作者Song和鼎鼎大名的Havlin，并没有注意到Hernan， 后来搜索实现fractal_model的python代码的时候才找到他，恍然发现他是两篇论文的通讯作者。\n在这个算法里面，主要有四个参数：世代（generation)、新增子代数量(m)、子代间新增链接的数量(x)、断开父代链接的比例(e)。每一代是一个操作过程：以这一代的每一条边为单位，该边上的两个节点a和b各自新增子代m个，其中m对子代间形成（x-1)个链接，若随机概率大于e，那么断开父代节点a和b之间的链接，同时增加一条m对子代间链接。\ngeneration, m, x, e = 2, 1, 1, 0 G=nx.Graph() G.add_edge(0,1) #Two seed nodes(generation 0), then add m offsprings to these seed nodes. node_index = 2 for n in range(1,generation+1): print 'STEP:', n, '\\n' all_links = G.edges() while all_links: link = all_links.pop() # [(0, 1)] ----\u0026gt; (0, 1) print link new_nodes_a = range(node_index,node_index + m) print link[0], new_nodes_a #random.shuffle(new_nodes_a) node_index += m new_nodes_b = range(node_index,node_index + m) #random.shuffle(new_nodes_b) print link[1], new_nodes_b node_index += m G.add_edges_from([(link[0],node) for node in new_nodes_a]) G.add_edges_from([(link[1],node) for node in new_nodes_b]) repulsive_links = zip(new_nodes_a,new_nodes_b) # 相斥的的链接 print repulsive_links add_repulsive_links = [repulsive_links.pop() for i in range(x-1)] G.add_edges_from(add_repulsive_links) # add edges between offsprings print 'add repusive edges', add_repulsive_links if random.random() \u0026gt; e: # 当概率大于e的时候，断开hub间的链接 print 'delete', link G.remove_edge(*link) # 减少一对hub的链接 add_a_repulsive_link = repulsive_links.pop() print 'add_a_repulsive_link', add_a_repulsive_link G.add_edge(*add_a_repulsive_link) #相应得，增加一对其子代的链接  真实世界的移动网络是小世界的。例如Vito Latora 等（2002）分析了波斯顿地铁网络的结构（小世界）。随机网平均直径低，规则网聚类系数高。小世界网络在平均路径长度方面接近随机网，而在聚类系数方面接近规则网。Latora等认为我们对于小世界的两种衡量方式（平均直径L和聚类系数C）有缺陷（ill-defined），因为仅仅强调了链接是否存在，而忽略了链接的权重，比如链接的实际长度（the physical length of the link）。他们试图提出一种考虑权重的衡量小世界特征的测量:邻接矩阵 $ a{ij} $ 表示任意两个节点i、j之间是否有链接; $ l{ij} $ 表示任意两个节点i、j之间的权重（比如地铁站之间的空间距离;使用邻接矩阵 $ a{ij} $ 可以得到节点间的最短路径矩阵 $ d{ij} $ 。\n此时，无法算出聚类系数，因为很多地铁站只有两个邻居，算出的平均直径的信息也很少， $ \\varepsilon{ij} = \\frac{1}{N(N-1)d{ij}} $ 表示输运效率，可以在globa和local两个层面计算，分别对应平均路径长度L和聚类系数C。当两个节点无链接时，其 $ d{ij} $ 无穷大， $ \\varepsilon{ij} = 0 $ 。避免了计算平均路径长度无穷大的问题。同时可以定义输运成本 $ cost = \\frac{\\sum{i\\neq j} a{ij}l{ij}}{\\sum{i\\neq j}l_{ij} } $ 。如此计算波斯顿地铁的MBTA全局输运效率为0.63，局部输运效率为0.03，成本为0.002。即网络整体输运效率可以达到理想情况的63%，但是局部输运效率很差，不过整个网络的成本很小。如果加上公交网络MBTA+bus，全局效率上升为 0.72，局部效率大幅度上升为0.46，花费的成本仅仅上升为0.004。\n参考文献 Vito Latora（2002）Is the Boston subway a small-world network? Physica A\n","date":1449014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1449014400,"objectID":"01aac9b5776a1fdc8a3bd164646b1a93","permalink":"https://chengjunwang.com/zh/archive/2015-12-02-renormalization.zh/","publishdate":"2015-12-02T00:00:00Z","relpermalink":"/zh/archive/2015-12-02-renormalization.zh/","section":"zh","summary":"思考手机用户在真实和虚拟世界的移动本身有什么价值:比较两种类型的网络结构，一个是分形的，一个是小世界的。二者之间不是完全对立的，而是可以平滑过渡的，因而可以计算从小世界到分形的连续变量的取值，即网络增长的过程中，新节点多大程度上按照小世界规则加入网络，多大程度上按照分形加入网络（Song, 2006）。\n","tags":null,"title":"手机用户在真实与虚拟空间中的移动","type":"zh"},{"authors":null,"categories":null,"content":"暮白在南京的工作一直令我不能释怀，放弃优渥舒适的体制内工作来到南京，突然发现很抓瞎，生态学的就业市场非常凄凉。暮白需要找土壤学、环境检测方向的南京教职，但是她对研究却没有热情，虽然可以胜任写论文的工作。\n一直留意的信息包括这些\n 南京林业大学人事处 | 生物与环境学院生态学方向 链接\n 南京林业大学 \u0026laquo;林学院\u0026raquo; 农业资源与环境岗位，农业资源利用(土壤学、植物营养学)专业、\u0026raquo;025-85427303 ycxi@njfu.edu.cn\u0026raquo;  南京大学金陵学院人事处 链接\n 化学与生命科学学院的环境科学专业（污染控制技术与环境市政工程方向、环境监测与评价方向）  南京师范大学生命科学学院和地理科学学院 [网络链接]\n 江苏省属事业单位招聘平台 http://sydwzk.jshrss.gov.cn/\n 南京农业大学草业学院\n  ","date":1447804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1447804800,"objectID":"2c915010e2224e9d9c9fd9f5654f753b","permalink":"https://chengjunwang.com/note/note_archive/2016-07-17-xiaoqing-job/","publishdate":"2015-11-18T00:00:00Z","relpermalink":"/note/note_archive/2016-07-17-xiaoqing-job/","section":"note","summary":"暮白在南京的工作一直令我不能释怀，放弃优渥舒适的体制内工作来到南京，突然发现很抓瞎，生态学的就业市场非常凄凉。暮白需要找土壤学、环境检测方向的南京教职，但是她对研究却没有热情，虽然可以胜任写论文的工作。\n一直留意的信息包括这些\n 南京林业大学人事处 | 生物与环境学院生态学方向 链接\n 南京林业大学 \u0026laquo;林学院\u0026raquo; 农业资源与环境岗位，农业资源利用(土壤学、植物营养学)专业、\u0026raquo;025-85427303 ycxi@njfu.edu.cn\u0026raquo;  南京大学金陵学院人事处 链接\n 化学与生命科学学院的环境科学专业（污染控制技术与环境市政工程方向、环境监测与评价方向）  南京师范大学生命科学学院和地理科学学院 [网络链接]\n 江苏省属事业单位招聘平台 http://sydwzk.jshrss.gov.cn/\n 南京农业大学草业学院\n  ","tags":null,"title":"生态学、土壤学、环境检测方向的南京教职","type":"note"},{"authors":null,"categories":null,"content":" 今天发现github发布的新的repo页面布局，果断采用了，然后发现，居然可以new file。不必每次在线下写了。很棒！\n矛盾的路 沉寂了挺长的时间，我主要是对于自己感觉非常失望，为什么自己就不能写出东西来了呢？这是一个非常让我恐惧的事情。我没有了每天伏案写作的心情，总是非常急切的、急功近利的想要有一个收获。这是非常不妥当的事情，我也一度非常反感。有时候，可能是因为我对世俗的top的东西追求太多，受到打击后就突然失去了兴趣，或许是因为自己在那个方面实在是做不出什么自己觉得牛逼的东西。算了，算了。就不搞了。于是这么一个过程下来就开始逐渐陷入了世俗的泥沼。另一方面，自己的内心有一个声音说：你不能这样。你要纯粹，所以想要厚积薄发。\n又一次看了一个人的cv。感觉他很纯粹，一点一点地磨出了自己的道路。于是乎，在深圳的时候，我问自己：你想蝇营狗苟，胡乱做一些论文了此残生吗？我突然觉得不愿意。于是告诫自己说：我要走另外一个方向。一条孤独的、充满了挑战的路。我不想尝试那些low一些的期刊？不是吧。是一种惰性。就是找一个容易的事情做，但是不想再面对那些我自己觉得繁琐得没有意义的东西。\n换一个方向并不容易，因为要非常辛苦的学习新东西，但是哪一个是自己的呢？都没有深入进去有什么意义呢？自己的贡献在哪里呢？所以这个过程最折磨人。计算士给我最大的忠告是：学会publication fight。要活下去，publication fight是持之以恒地做事情的一个很好的训练。\n2015盘点  女儿米粒  我的2015最大的收获当然是女儿米粒了。米粒的降生改变了我很多看法，比如我开始觉得中国的小朋友也让人觉得可爱。我之前不喜欢小朋友，或许因为我本质上是一个自私的人。一心追求的是内心的思考，而不是群体的利益。这么多年，除了在学校里报销的时候，我变得越来越没有锋芒，学会了妥协。学会了要关心社会。这是生活教给我的。我有点像眉间尺，没坚持啊。第一次发现。后来我发现歪果仁的小朋友真漂亮，像洋娃娃。\n 成为集智的集核成员并与计算士更多合作 开始教书《计算传播学导论》、《数据新闻》、《计算广告》 合著的书《社交网络上的计算传播学》出版 学习生存  开始被迫去参加大陆的学术会议，与人交往，带学生做东西。一切都是那么消耗时间，总之，我不能够停下来。我自己浪费了很多时间，其实我自己的空闲时间还是不少的，但是很零碎，很多就被我浪费了。这很可惜。我的生活就像没有磨合好的电脑键盘，仿佛一切都是那么不如意。要练习好久。\n这周末参加了教师资格考试，感觉自己好久没有写字这么快、这么多了。人都有点生锈了。另外，南京大学普通话考试报名网页：http://chin.nju.edu.cn/ndxt/ 我读英文书也是一样，磕磕巴巴。\n欲望、欲望、欲望 人必须要有追求，知道自己在干什么，知道自己想干什么。这样活着才不会随波逐流。所以，人老了总是顽固的，因为经过了生活的打磨，他已经知道必须能面对残酷的生活了。我以前活的太寡淡，一旦受挫就容易丧失斗争的欲望，陷入无休止的早上赖床、晚上娱乐的困境。记得又一次，一个博士生说：发文的感觉太刺激了。我自己读硕士的时候，拟合并且绘制了一个交互作用，感觉到的是巅峰体验。后来，自己发了一篇小文章，也有点这个感觉，感觉这种感受久违了，好久不曾有了。所以，自己要振作。不能老是听评书、吃饭、碎觉、看剧。混吃等死是最痛苦的，等来的只有对于自己的不信任。要活的有力量。\n我希望自己：\n 每天能专心写作两个小时 学车 学会拒绝  保持动力 KEEP MOTIVATED  NO FEAR, NO DISTRACTION 持之以恒 KEEP HUNGRY, KEEP FOOLISH, KEEP MOTIVATED 只有心存欲念，才能自我克制，戒除贪欲、不耻下问、保持动力。 Follow your logic  ","date":1447804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1447804800,"objectID":"299787c621fb635b223f31ab45f857d9","permalink":"https://chengjunwang.com/note/note_archive/2015-11-18-fighting-life/","publishdate":"2015-11-18T00:00:00Z","relpermalink":"/note/note_archive/2015-11-18-fighting-life/","section":"note","summary":" 今天发现github发布的新的repo页面布局，果断采用了，然后发现，居然可以new file。不必每次在线下写了。很棒！\n矛盾的路 沉寂了挺长的时间，我主要是对于自己感觉非常失望，为什么自己就不能写出东西来了呢？这是一个非常让我恐惧的事情。我没有了每天伏案写作的心情，总是非常急切的、急功近利的想要有一个收获。这是非常不妥当的事情，我也一度非常反感。有时候，可能是因为我对世俗的top的东西追求太多，受到打击后就突然失去了兴趣，或许是因为自己在那个方面实在是做不出什么自己觉得牛逼的东西。算了，算了。就不搞了。于是这么一个过程下来就开始逐渐陷入了世俗的泥沼。另一方面，自己的内心有一个声音说：你不能这样。你要纯粹，所以想要厚积薄发。\n又一次看了一个人的cv。感觉他很纯粹，一点一点地磨出了自己的道路。于是乎，在深圳的时候，我问自己：你想蝇营狗苟，胡乱做一些论文了此残生吗？我突然觉得不愿意。于是告诫自己说：我要走另外一个方向。一条孤独的、充满了挑战的路。我不想尝试那些low一些的期刊？不是吧。是一种惰性。就是找一个容易的事情做，但是不想再面对那些我自己觉得繁琐得没有意义的东西。\n换一个方向并不容易，因为要非常辛苦的学习新东西，但是哪一个是自己的呢？都没有深入进去有什么意义呢？自己的贡献在哪里呢？所以这个过程最折磨人。计算士给我最大的忠告是：学会publication fight。要活下去，publication fight是持之以恒地做事情的一个很好的训练。\n2015盘点  女儿米粒  我的2015最大的收获当然是女儿米粒了。米粒的降生改变了我很多看法，比如我开始觉得中国的小朋友也让人觉得可爱。我之前不喜欢小朋友，或许因为我本质上是一个自私的人。一心追求的是内心的思考，而不是群体的利益。这么多年，除了在学校里报销的时候，我变得越来越没有锋芒，学会了妥协。学会了要关心社会。这是生活教给我的。我有点像眉间尺，没坚持啊。第一次发现。后来我发现歪果仁的小朋友真漂亮，像洋娃娃。\n 成为集智的集核成员并与计算士更多合作 开始教书《计算传播学导论》、《数据新闻》、《计算广告》 合著的书《社交网络上的计算传播学》出版 学习生存  开始被迫去参加大陆的学术会议，与人交往，带学生做东西。一切都是那么消耗时间，总之，我不能够停下来。我自己浪费了很多时间，其实我自己的空闲时间还是不少的，但是很零碎，很多就被我浪费了。这很可惜。我的生活就像没有磨合好的电脑键盘，仿佛一切都是那么不如意。要练习好久。\n这周末参加了教师资格考试，感觉自己好久没有写字这么快、这么多了。人都有点生锈了。另外，南京大学普通话考试报名网页：http://chin.nju.edu.cn/ndxt/ 我读英文书也是一样，磕磕巴巴。\n欲望、欲望、欲望 人必须要有追求，知道自己在干什么，知道自己想干什么。这样活着才不会随波逐流。所以，人老了总是顽固的，因为经过了生活的打磨，他已经知道必须能面对残酷的生活了。我以前活的太寡淡，一旦受挫就容易丧失斗争的欲望，陷入无休止的早上赖床、晚上娱乐的困境。记得又一次，一个博士生说：发文的感觉太刺激了。我自己读硕士的时候，拟合并且绘制了一个交互作用，感觉到的是巅峰体验。后来，自己发了一篇小文章，也有点这个感觉，感觉这种感受久违了，好久不曾有了。所以，自己要振作。不能老是听评书、吃饭、碎觉、看剧。混吃等死是最痛苦的，等来的只有对于自己的不信任。要活的有力量。\n我希望自己：\n 每天能专心写作两个小时 学车 学会拒绝  保持动力 KEEP MOTIVATED  NO FEAR, NO DISTRACTION 持之以恒 KEEP HUNGRY, KEEP FOOLISH, KEEP MOTIVATED 只有心存欲念，才能自我克制，戒除贪欲、不耻下问、保持动力。 Follow your logic  ","tags":null,"title":"生活的欲望","type":"note"},{"authors":null,"categories":null,"content":" 数据新闻较传统新闻的优势？ 关于数据新闻的优势，我试图去思考的问题是未来的新闻是什么样子？经典的新闻生产和传播的基本逻辑是收集、编辑、传递信息。比如邸报的产生，使得中国古代都城内部的信息可以迅速传递到帝国的各个角落。在美国新闻历史上，为了改变黄色新闻对于美国新闻业的打击（不仅仅是媒介信任，而且包括媒体收入），为了传递有效的信息，以《纽约时报》为代表的媒介产业从业者提出了做严肃新闻的标准，并将其发展为西方新闻专业主义的主要元素。这种以传递信息为目标的新闻产业在未来的媒介环境下是无法生存的，因为独家的信息越来越少，信息传递的渠道越来越多。过去的人们要靠读报看电视获取信息，今天信息通过种方式涌入人的生活。信息社会已经发展到了信息过剩、冗余的阶段，人类有限的注意力成为了更加稀缺的资源。互联网和手机解构了传统的信息传递方式。媒介即信息成为媒体的魔咒。\n事实上，如果在过去媒体即信息可以使得媒体获取利润和信任的话，今天的如果还坚持走这条道路，就只有在一片“红海”的激烈竞争中灭亡，因为未来的媒介不能是信息，那么是什么呢？我想给出的答案是：知识和艺术。人类对于信息的高级要求有三个：娱乐、知识、艺术。对于新闻而言，不应当以娱乐核心，那么可以仰赖的就只有知识和艺术。数据新闻恰好可以满足这个两个方面的要求：一、从数据出发，挖掘出知识，发现隐藏在海量信息中的价值；二、将信息以艺术的方式表达，彰显创意，吸引眼球。按照这个逻辑，深度报道依然能够受到欢迎，就是因为对于社会事实（信息）的深度挖掘（通过深访等方式）。相较而言，可视化等艺术表达比起系统的收集、整理、分析数据而言，要更容易，也能吸引注意力，因而在现在大行其道，但是未来的数据新闻将在知识发现的方向上又更多发展。数据新闻相比与传统新闻的核心优势恰在于此。\n新手需要哪些素养？如何掌握数据新闻技能？ 毫无疑问，具备新闻专业主义、计算思维、可视化等艺术设计是学习数据新闻的重要方面。数据新闻不是靠一个人就能完成的工作，它涉及到新闻的策划编辑、数据的收集清洗分析、可视化等多个方面，因而需要编辑记者、数据分析师、可视化设计师（前端、后端）组成的数据新闻团队的协同努力。\n掌握数据新闻技能需要加强在新闻专业主义、计算思维、可视化等艺术设计三个方面的训练。不同背景的人面临的学习数据新闻的困难是不一样的。计算机背景的同学可能在艺术设计方面有所缺陷，也可能在统计思维的方面有所不足。平面设计的同学可能对互动设计，对于基于编写代码为主的工作充满畏惧。对于新闻学院的同学而言，新闻专业主义的训练是必修课，计算思维和艺术设计则可能是短板，因而需要花费更多的时间去训练。\n 分析数据新闻案例 要经常关注国内外的数据新闻团队的作品，分析其设计理念、数据来源、呈现技术、优缺点等方面。 增强计算思维 要有意识地选修社会统计课程、数据分析课程，学习数据科学的编程工具（推荐R和Python），学习网络爬虫的编写，经常写博客积累一些知识，使用Github保存和分享代码，使用stack overflow进行提问。 发展艺术设计能力 系统地学习一些平面设计和互动设计的软件工具，例如AI、AE、processing、d3.js、echarts、html、javascript等。 动手练习 阅读数据新闻相关的书籍 向业界学习  学习数据新闻的经验  明确对于数据新闻的认识，数据新闻聚焦于知识发现使得新闻媒体回归到了新闻的本质。数据新闻不等于可视化，数据新闻也不是简单的迎合受众需求，数据新闻是代表未来的媒介存在方式。因而，数据新闻不是一部分新闻学院的同学要学习的，它使所有想要从事新闻生产的人都要学习的内容。 学习数据新闻需要付出大量的时间。数据新闻发展的一个重要阶段是精确新闻，主要倡导采用社会科学的方法进行新闻生产，比如更加系统的抽样调查，而不是采访几个人。现在的数据新闻，加入了更多的数据采集方式、分析方法、呈现方法，因而其生产流程更长。试图去系统掌握相关的知识所需要花费的时间也更长，绝不是选修一门《数据新闻》课程就可以解决的。 学习数据新闻需要具有分享和合作意识。数据新闻需要团队合作，因而需要参与者具有合作意识和分享意识。因而，我非常鼓励同学们积极的使用github分享自己的代码、作品，为开源工具做出贡献。在这个过程当中，每个人也会累积自己的声誉，更容易获得更多的机会。 编写代码不可避免。虽然有很多模板可以使用，每当我们试图去做更多一点个性化的改变的时候，都需要对原有的代码进行处理，因而编写代码必不可少。另外，很多工作需要重复进行，采用编写代码的方式可以减少这种重复所造成的时间浪费，最后编写代码容易分享，也容易检查错误。 最后，数据新闻人才是独角兽，非常稀缺，成长为一个合格的数据新闻人才也并不容易。如果你决定要成为一名数据新闻生产者，那么就不能以一般的标准要求自己，要更勤奋、更专注、更开放。  ","date":1447372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1447372800,"objectID":"c465de3c15fe88fc37c20788a46306be","permalink":"https://chengjunwang.com/note/note_archive/2015-11-13-data-journalism/","publishdate":"2015-11-13T00:00:00Z","relpermalink":"/note/note_archive/2015-11-13-data-journalism/","section":"note","summary":" 数据新闻较传统新闻的优势？ 关于数据新闻的优势，我试图去思考的问题是未来的新闻是什么样子？经典的新闻生产和传播的基本逻辑是收集、编辑、传递信息。比如邸报的产生，使得中国古代都城内部的信息可以迅速传递到帝国的各个角落。在美国新闻历史上，为了改变黄色新闻对于美国新闻业的打击（不仅仅是媒介信任，而且包括媒体收入），为了传递有效的信息，以《纽约时报》为代表的媒介产业从业者提出了做严肃新闻的标准，并将其发展为西方新闻专业主义的主要元素。这种以传递信息为目标的新闻产业在未来的媒介环境下是无法生存的，因为独家的信息越来越少，信息传递的渠道越来越多。过去的人们要靠读报看电视获取信息，今天信息通过种方式涌入人的生活。信息社会已经发展到了信息过剩、冗余的阶段，人类有限的注意力成为了更加稀缺的资源。互联网和手机解构了传统的信息传递方式。媒介即信息成为媒体的魔咒。\n事实上，如果在过去媒体即信息可以使得媒体获取利润和信任的话，今天的如果还坚持走这条道路，就只有在一片“红海”的激烈竞争中灭亡，因为未来的媒介不能是信息，那么是什么呢？我想给出的答案是：知识和艺术。人类对于信息的高级要求有三个：娱乐、知识、艺术。对于新闻而言，不应当以娱乐核心，那么可以仰赖的就只有知识和艺术。数据新闻恰好可以满足这个两个方面的要求：一、从数据出发，挖掘出知识，发现隐藏在海量信息中的价值；二、将信息以艺术的方式表达，彰显创意，吸引眼球。按照这个逻辑，深度报道依然能够受到欢迎，就是因为对于社会事实（信息）的深度挖掘（通过深访等方式）。相较而言，可视化等艺术表达比起系统的收集、整理、分析数据而言，要更容易，也能吸引注意力，因而在现在大行其道，但是未来的数据新闻将在知识发现的方向上又更多发展。数据新闻相比与传统新闻的核心优势恰在于此。\n新手需要哪些素养？如何掌握数据新闻技能？ 毫无疑问，具备新闻专业主义、计算思维、可视化等艺术设计是学习数据新闻的重要方面。数据新闻不是靠一个人就能完成的工作，它涉及到新闻的策划编辑、数据的收集清洗分析、可视化等多个方面，因而需要编辑记者、数据分析师、可视化设计师（前端、后端）组成的数据新闻团队的协同努力。\n掌握数据新闻技能需要加强在新闻专业主义、计算思维、可视化等艺术设计三个方面的训练。不同背景的人面临的学习数据新闻的困难是不一样的。计算机背景的同学可能在艺术设计方面有所缺陷，也可能在统计思维的方面有所不足。平面设计的同学可能对互动设计，对于基于编写代码为主的工作充满畏惧。对于新闻学院的同学而言，新闻专业主义的训练是必修课，计算思维和艺术设计则可能是短板，因而需要花费更多的时间去训练。\n 分析数据新闻案例 要经常关注国内外的数据新闻团队的作品，分析其设计理念、数据来源、呈现技术、优缺点等方面。 增强计算思维 要有意识地选修社会统计课程、数据分析课程，学习数据科学的编程工具（推荐R和Python），学习网络爬虫的编写，经常写博客积累一些知识，使用Github保存和分享代码，使用stack overflow进行提问。 发展艺术设计能力 系统地学习一些平面设计和互动设计的软件工具，例如AI、AE、processing、d3.js、echarts、html、javascript等。 动手练习 阅读数据新闻相关的书籍 向业界学习  学习数据新闻的经验  明确对于数据新闻的认识，数据新闻聚焦于知识发现使得新闻媒体回归到了新闻的本质。数据新闻不等于可视化，数据新闻也不是简单的迎合受众需求，数据新闻是代表未来的媒介存在方式。因而，数据新闻不是一部分新闻学院的同学要学习的，它使所有想要从事新闻生产的人都要学习的内容。 学习数据新闻需要付出大量的时间。数据新闻发展的一个重要阶段是精确新闻，主要倡导采用社会科学的方法进行新闻生产，比如更加系统的抽样调查，而不是采访几个人。现在的数据新闻，加入了更多的数据采集方式、分析方法、呈现方法，因而其生产流程更长。试图去系统掌握相关的知识所需要花费的时间也更长，绝不是选修一门《数据新闻》课程就可以解决的。 学习数据新闻需要具有分享和合作意识。数据新闻需要团队合作，因而需要参与者具有合作意识和分享意识。因而，我非常鼓励同学们积极的使用github分享自己的代码、作品，为开源工具做出贡献。在这个过程当中，每个人也会累积自己的声誉，更容易获得更多的机会。 编写代码不可避免。虽然有很多模板可以使用，每当我们试图去做更多一点个性化的改变的时候，都需要对原有的代码进行处理，因而编写代码必不可少。另外，很多工作需要重复进行，采用编写代码的方式可以减少这种重复所造成的时间浪费，最后编写代码容易分享，也容易检查错误。 最后，数据新闻人才是独角兽，非常稀缺，成长为一个合格的数据新闻人才也并不容易。如果你决定要成为一名数据新闻生产者，那么就不能以一般的标准要求自己，要更勤奋、更专注、更开放。  ","tags":null,"title":"聊聊数据新闻","type":"note"},{"authors":["王成军"],"categories":null,"content":"","date":1444018521,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1444018521,"objectID":"2ff880a688434dc52cadee9a9f3ca4e4","permalink":"https://chengjunwang.com/publication/toutiao-logic/","publishdate":"2015-10-05T12:15:21+08:00","relpermalink":"/publication/toutiao-logic/","section":"publication","summary":"随着今日头条的崛起,聚合媒体开始进入公众的视野。这类媒体都是基于数据挖掘技术,筛选和推荐新闻。它为用户推荐有价值的、个性化的信息,提供连接人与信息的新型服务,是国内移动互联网领域成长最快的产品服务之一。自从2012年3月创建以来,今日头条至今已经累计激活用户3.1亿,日活跃用户超过3000万。本文尝试从技术层面分析今日头条的传播机制和相关原理。","tags":null,"title":"“今日头条”的技术逻辑：网络爬虫+矩阵筛选","type":"publication"},{"authors":null,"categories":null,"content":" CCS2015年会在Arizona州立大学Tempe举行。此次活动是亚利桑那州立大学的bio-social complex system 研究中心推动下举办的，中心主任Sander van der Leeuw是本次大会的主席。因为该中心是与圣塔菲研究中心合办的，所以圣塔菲也是会议的主要合办者，此外还有springer出版社。会议注册人数超过600人，并不算太多，但会议时间从9月26号开始到10月2日下午结束，整整持续了7天，不可谓不长，全程参加下来也很累。\n会议的粗略议程见这个Program-at-a-Glance。会议采用了app的方式，无纸化推送详细的program。不过这里有个问题是身在GFW内的我苦苦装了一个多小时也没有成功下载到我的ipad上，后来去了后两分钟下载好。用起来就很方便了，支持按时间、人、活动多种方式查询。会议在twitter上的hashtag是#ccs2015，在这个app里也可以完美呈现。\n从时间上讲，这个会议设有preconference，主要在26和27号两天，工作坊主要在这两天。比如26号上午是来自圣塔菲的Melanie Mitchell讲Introduction to Complexity，她在网络上有一个同名的课。关于她我们已经很熟悉了。她的博士导师就是大名鼎鼎的侯世达，她曾在圣塔菲讲解complexity，整理出版了同名著作Complexity：A guided tour，中文译本由湖南科学技术出版社出版。我来到南京后曾专门组织读书会研读这本书。下午同样是来自圣塔菲的Aaron Clauset介绍Networks。他和Newman曾写过如何判定powerlaw的R和python的程序。27号，Robert Axtell介绍Agent-Based Models，下午Simon DeDeo介绍Information Theory and Maximum Entropy Methods。整体而言，这些介绍都比较基础。因为我是27号下午才到的，所以这些都错过了。\n主会议28号开幕。会议的精彩看点首先是全体会议（plenary session）的发言人。\n Plenary Speakers:\n Bar-Yam Yaneer Marten Scheffer Jan-Wouter Vasbinder  Plenary Speakers 27B:\n Wei-Ning Xiang Atsushi Iriki David Krakauer   Yaneer Bar-Yam  New England Complex Systems Institute From centrality to temporary fame: Dynamic centrality in complex networks .D Braha, Y Bar‐Yam - Complexity, 2006 - Wiley Online Library  Longevity: to extend the arc of life?  aging, treating disease mechanism?  Programmed death is favored by natural selection in spatial systems http://www.necsi.edu/research/evoeco/programmed.pdf   Ethic violence  patterns? small patches intermediate large patches: peace correlation more than 90%??\n Science 317, 1540 (2007);May Lim, et al. Violence Global Pattern Formation and Ethnic/Cultural http://www.uvm.edu/~pdodds/files/papers/others/everything/lim2007a.pdf  food price index \u0026amp; protest ? wheat.\n The Food Crises and Political Instability http://arxiv.org/pdf/1108.2455.pdf)  Dynamic model P(t+1) = kc(t)\n Corn ehanol and speculation\n  One Second on the Internet One second doesn’t seem like much time, but a lot can happen. In one second, there are approximately 200 posts on Reddit, 4,000 tweets on Twitter, and 50,000 likes on Facebook. Visualizing the traffic the Internet experiences is very difficult. Once the numbers get so big, they start to lose meaning to us. This is why “One Second on the Internet” provides an illustration of how much activity takes place in such a small unit of time.\nhttp://onesecond.designly.com/\nhidden geometric structure of collective attention  http://www.swarma.org/swarma/detail.php?id=18701 http://www.plosone.org/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0136243\u0026amp;representation=PDF  coupled networks: financial markets and news sentiment  time series lagged correlation based network finding bipartite substructure  Guido  why financial market?  trade is a paramount example of complex system data available social effect  why network are important?  mathematical representation of social reality network effects  effects of interaction illustrate the mechanics of distress transmission describe distress amplification spot the info asymmetry   stability of a network  dynamics connections evolution  devise new network measures reconstruct the connections chain of conditioned  focus on network structure rather than vertex structure\ndebetrank\n$L_{i,j} = A/E$\n$h(t)=\\frac{(E_0-E_T)} {E_0}$\nhttp://www.nature.com/nphys/journal/v9/n3/full/nphys2580.html#close Reconstructing a credit network\n","date":1443744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1443744000,"objectID":"4af7ab5be36c3739aba8a88329fbc7bf","permalink":"https://chengjunwang.com/note/note_archive/2015-10-02-ccs2015/","publishdate":"2015-10-02T00:00:00Z","relpermalink":"/note/note_archive/2015-10-02-ccs2015/","section":"note","summary":" ","tags":[""],"title":"CCS2015年会记","type":"note"},{"authors":null,"categories":null,"content":"2008年，我离开兰州，到北京大学读传播学的硕士。我很难想象自己还会踏入与计算紧密相连的科学。在北京的两年里，我通过豆瓣认识了集智俱乐部。与其他豆瓣小组不同，集智以读书会和各种线下活动闻名，北京各个高校不同专业的学生通过集智活动而认识。通过集智我了解到了复杂性科学和它的圣地：圣塔菲研究所，并读了《歌德尔、埃舍尔、巴赫》、《复杂》、《链接：网络新科学》、《组成轮》等各种书。\n那个时候，复杂网络研究开始席卷社会科学，尤其是传播学。集智的活动从各个方面开启了我对于计算社会科学的另一种认识。虽然集智关注的视野横跨里很多学科，在北京经常举办线下活动（很长一段时间里是在三号会所），对于北京以外的地方，集智往往是因为多主体建模而为外界所知。我也是在北师大的一次暑期活动里，听jake讲解了多主体建模的方法。因为集智，我知道了walfram和mathematica；还以集智成员的身份去清华旁听了一个mathematica的国籍会议。虽然时光短暂，我非常喜欢集智读书会的组织形式和传播复杂性科学的使命。\n2010年夏天，我硕士毕业，前往香港城市大学读博。在读博的过程中，计算社会科学的研究范式开始被普遍接受。我觉得自己应该选择一个最贴近复杂性研究的社会科学研究。我去读了per bak的《how nature works: the science of self-organized》。我觉得自己应该去研究扩散，于是选择了以信息扩散作为自己的研究主题。大多数博士论文都是一个痛苦挣扎的过程，我的也不例外，为了能够收集所需要的数据，我开始学习使用r和python编程，开始更加系统地学习网络科学的研究视角。在这短短的四年里，大数据开始成为时代的关键词，数据新闻、计算广告开始成为计算机与传播学直接交叉的领域。基于数据的网络科学研究和基于计算机模拟的多主体建模，以及其它各种研究视角不断得启发我们去思考传播学的研究，于是一个我们发明了一个新词：computational communication，翻成中文就是计算传播。一开始我对这个词并不满意，后来计算士觉得这词不错，能概括我们的研究路径。于是我们的一个谷歌的邮件组就使用来这个作为名字。\n时光荏苒，转眼间我在香港呆了四年，2014年博士毕业了，我不想去北上广这种大城市，又想离家近，就选择了来南京，就职于南京大学新闻传播学院。学院老师比较支持传播学可计算化的思路，于是我们成立了一个计算传播学实验中心。相对于香港匆忙的生活而言，大陆的高校多了很多书卷气。我便常常怀念集智聚乐部的读书会。恰逢jake和计算士邀请我加入集智科学委员会。据jake讲，科学委员会成员可以集智的名字举办读书会，我想这是一个好机会。就串掇来身边的朋友搞一个周六下午读书的活动。因为我们的活动场地是计算传播研究中心的实验室，就在南大鼓楼校区的费彝民楼，我自己也是计算传播研究中心的成员，就萌生了结合两者的所长，组办一个名为“集智计算读书会”的活动。于是，我发邮件咨询jake，咨询他的同意后，我们的读书会就算正式成立了。\n第一本书选的是米歇尔的《复杂》，她是侯世达的学生，在圣塔菲的时候做了一个系列讲座，整理完善出版了一本书就取名为《复杂》。本书的架构比较简单，主要分成三个部分：第一个部分介绍复杂性科学的历史和概念；第二部分介绍计算机模拟的方法；第三部分介绍网络科学。我想这是像社科和人文学科介绍复杂性科学的好书，比较适合入门，虽然浅显，寓意悠远。于是，第一次活动就这样开始了。\n","date":1438819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438819200,"objectID":"dc67819007517c7b85f5b4fc9f5eed13","permalink":"https://chengjunwang.com/note/note_archive/2015-08-06-readingclub/","publishdate":"2015-08-06T00:00:00Z","relpermalink":"/note/note_archive/2015-08-06-readingclub/","section":"note","summary":"2008年，我离开兰州，到北京大学读传播学的硕士。我很难想象自己还会踏入与计算紧密相连的科学。在北京的两年里，我通过豆瓣认识了集智俱乐部。与其他豆瓣小组不同，集智以读书会和各种线下活动闻名，北京各个高校不同专业的学生通过集智活动而认识。通过集智我了解到了复杂性科学和它的圣地：圣塔菲研究所，并读了《歌德尔、埃舍尔、巴赫》、《复杂》、《链接：网络新科学》、《组成轮》等各种书。\n那个时候，复杂网络研究开始席卷社会科学，尤其是传播学。集智的活动从各个方面开启了我对于计算社会科学的另一种认识。虽然集智关注的视野横跨里很多学科，在北京经常举办线下活动（很长一段时间里是在三号会所），对于北京以外的地方，集智往往是因为多主体建模而为外界所知。我也是在北师大的一次暑期活动里，听jake讲解了多主体建模的方法。因为集智，我知道了walfram和mathematica；还以集智成员的身份去清华旁听了一个mathematica的国籍会议。虽然时光短暂，我非常喜欢集智读书会的组织形式和传播复杂性科学的使命。\n2010年夏天，我硕士毕业，前往香港城市大学读博。在读博的过程中，计算社会科学的研究范式开始被普遍接受。我觉得自己应该选择一个最贴近复杂性研究的社会科学研究。我去读了per bak的《how nature works: the science of self-organized》。我觉得自己应该去研究扩散，于是选择了以信息扩散作为自己的研究主题。大多数博士论文都是一个痛苦挣扎的过程，我的也不例外，为了能够收集所需要的数据，我开始学习使用r和python编程，开始更加系统地学习网络科学的研究视角。在这短短的四年里，大数据开始成为时代的关键词，数据新闻、计算广告开始成为计算机与传播学直接交叉的领域。基于数据的网络科学研究和基于计算机模拟的多主体建模，以及其它各种研究视角不断得启发我们去思考传播学的研究，于是一个我们发明了一个新词：computational communication，翻成中文就是计算传播。一开始我对这个词并不满意，后来计算士觉得这词不错，能概括我们的研究路径。于是我们的一个谷歌的邮件组就使用来这个作为名字。\n时光荏苒，转眼间我在香港呆了四年，2014年博士毕业了，我不想去北上广这种大城市，又想离家近，就选择了来南京，就职于南京大学新闻传播学院。学院老师比较支持传播学可计算化的思路，于是我们成立了一个计算传播学实验中心。相对于香港匆忙的生活而言，大陆的高校多了很多书卷气。我便常常怀念集智聚乐部的读书会。恰逢jake和计算士邀请我加入集智科学委员会。据jake讲，科学委员会成员可以集智的名字举办读书会，我想这是一个好机会。就串掇来身边的朋友搞一个周六下午读书的活动。因为我们的活动场地是计算传播研究中心的实验室，就在南大鼓楼校区的费彝民楼，我自己也是计算传播研究中心的成员，就萌生了结合两者的所长，组办一个名为“集智计算读书会”的活动。于是，我发邮件咨询jake，咨询他的同意后，我们的读书会就算正式成立了。\n第一本书选的是米歇尔的《复杂》，她是侯世达的学生，在圣塔菲的时候做了一个系列讲座，整理完善出版了一本书就取名为《复杂》。本书的架构比较简单，主要分成三个部分：第一个部分介绍复杂性科学的历史和概念；第二部分介绍计算机模拟的方法；第三部分介绍网络科学。我想这是像社科和人文学科介绍复杂性科学的好书，比较适合入门，虽然浅显，寓意悠远。于是，第一次活动就这样开始了。","tags":null,"title":"集智计算读书会","type":"note"},{"authors":null,"categories":null,"content":"","date":1435968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435968000,"objectID":"a9a842d871db199c784fb81aeb305edd","permalink":"https://chengjunwang.com/zh/archive/2015-07-04-iching-python.zh/","publishdate":"2015-07-04T00:00:00Z","relpermalink":"/zh/archive/2015-07-04-iching-python.zh/","section":"zh","summary":"","tags":null,"title":"iching：一个用来算卦的python包","type":"zh"},{"authors":null,"categories":null,"content":" 我想或许是自己对于宗教的态度越来越严肃，所以反而见不得圣经两个字。心底里将圣经神圣化，于是看到只言片语就感觉远远不限于此。所以就产生了逆反，往来的更改标题。这个问题该怎么破？\ndocument.write(\"\");  前天与朋友吃饭，一个妈妈讲起了自己家养育孩子的方法。让孩子参加家庭每周的自我计划陈述，自己说出一周的计划，总结一周的得失，家人不提任何意见。使用这个方法，坚持半年使得孩子养成了刷碗、给爷爷奶奶打电话等很多好习惯。这种交流的形式使我一下子想到了团契。在海淀堂和城市大学的时候，我就曾参加过，感触挺深。\n我想这种宗教的熏陶是很好的，很大程度上承担了对孩子的教育功能。让孩子主动去做一些事情，虽然过程会慢一些，但是会养成习惯，更为持久，有利于良好性格的塑造。\n关于圣经，学英文的时候，有一个说法是女生应该读飘，男生读圣经。两本书我都买了，却都没有好好读。或许这就是为什么我英文学不好的原因？\n圣经今句 document.write(\"\");   \u0026laquo;But now we are delivered from the law, that being dead wherein we were held; that we should serve in newness of spirit, and not in the oldness of the letter.\u0026raquo; \u0026mdash;Romans 7:6 (KJV)\n 但我们既然在捆我们的律法上死了,现今就脱离了律法,叫我们服侍主,要按着心灵的新样(“心灵”或作“圣灵”),不按着仪文的旧样。\n“但我们既然在捆我们的律法上死了，现今就脱离了律法”（罗7：6）。注意我们脱离了谁？脱离了“律法”，我们的丈夫。我们怎样脱离？不是丈夫（律法）死了，而是“我们”死了。我们的旧人与基督同钉死──“借着基督的身体死了”，就脱离了律法这丈夫而归于基督。\n圣经金句 \n","date":1430524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430524800,"objectID":"f6fae1dce5856a7b8193970f5ab0944a","permalink":"https://chengjunwang.com/note/note_archive/2015-05-02-bible-verses/","publishdate":"2015-05-02T00:00:00Z","relpermalink":"/note/note_archive/2015-05-02-bible-verses/","section":"note","summary":"我想或许是自己对于宗教的态度越来越严肃，所以反而见不得圣经两个字。心底里将圣经神圣化，于是看到只言片语就感觉远远不限于此。所以就产生了逆反，往来的更改标题。这个问题该怎么破？\ndocument.write(\"\");  前天与朋友吃饭，一个妈妈讲起了自己家养育孩子的方法。让孩子参加家庭每周的自我计划陈述，自己说出一周的计划，总结一周的得失，家人不提任何意见。使用这个方法，坚持半年使得孩子养成了刷碗、给爷爷奶奶打电话等很多好习惯。这种交流的形式使我一下子想到了团契。在海淀堂和城市大学的时候，我就曾参加过，感触挺深。\n我想这种宗教的熏陶是很好的，很大程度上承担了对孩子的教育功能。让孩子主动去做一些事情，虽然过程会慢一些，但是会养成习惯，更为持久，有利于良好性格的塑造。\n关于圣经，学英文的时候，有一个说法是女生应该读飘，男生读圣经。两本书我都买了，却都没有好好读。或许这就是为什么我英文学不好的原因？\n圣经今句 document.write(\"\");   \u0026laquo;But now we are delivered from the law, that being dead wherein we were held; that we should serve in newness of spirit, and not in the oldness of the letter.\u0026raquo; \u0026mdash;Romans 7:6 (KJV)\n 但我们既然在捆我们的律法上死了,现今就脱离了律法,叫我们服侍主,要按着心灵的新样(“心灵”或作“圣灵”),不按着仪文的旧样。\n“但我们既然在捆我们的律法上死了，现今就脱离了律法”（罗7：6）。注意我们脱离了谁？脱离了“律法”，我们的丈夫。我们怎样脱离？不是丈夫（律法）死了，而是“我们”死了。我们的旧人与基督同钉死──“借着基督的身体死了”，就脱离了律法这丈夫而归于基督。\n圣经金句","tags":null,"title":"精神的家园","type":"note"},{"authors":null,"categories":null,"content":" 昨天看举案说法，提到一个30多岁的男人杀死两名要好的女同事的故事。他从小被父母姐姐宠溺，中考却一败涂地。很有一些志大才疏的样子。内心自卑，表面却非常自傲。现实是残酷的，一次恋爱失败后，接近三十岁的他草草地找了个女人结婚生子，但是家庭生活并不幸福。他想自杀，但是懦弱的他却没有勇气。他内心里渴望别人能够帮助自己杀死自己，于是他想到了杀人。但是懦弱与孤傲并存的他却想不到能够杀谁，于是瞄准了跟自己关系好的两个单身女同事。片中提到一句话：“越是懦弱的人，越会遭受到来自生活的接二连三的打击。”\n时间去哪里了 孩子3月11日出生，今天4月11日了。32天了。在这一个月里，老婆和我没有睡一个安稳觉。我的整块的时间也几乎没有了。感受到了很多的生活和教学的压力。尤其是在科研方面，非常落后了。也非常自责，面对这些，我无话可说。没有能够投入足够多的时间，肯定是不能有好的结果的。当然，我还有弱者的心态的问题：失去了挑战的勇气。生活需要继续，我需要重新出发。这段时间唯一坚持下来的就是教书了，每周两节课，我也说不上好好备课，但是收获还是挺多的。比如博弈论、小世界的导航能力等等。此外，准备了一些计算广告和数据新闻的课件。主要是下载了一些公开课的pdf和视频。\n无礼之徒 本周三主持一个讲座，一个很无礼的访问学者上来就问我博士老板是谁，吐槽无力。讲座3点半开始，3点29就唧唧歪歪还不开始。还说什么听得懂就听，听不懂就离开。准时开始后，听了一会果然走了。这种无礼之徒，生活中似乎还有很多，以后绝不会手软。\n 以后，遇到某人说提前走，请现在走。不伺候了。 以后碰到有人问你老板是谁，直接让对方介绍下自己先。  保证每天两个小时的写作 我要再次出发。保证以后的工作效率。这个是迫在眉睫的事情。按照自己的节奏来，充满紧迫感。不要太在意，举重若轻。不要不知轻重。学会拒绝。\n从一篇投稿开始 我要马上开始做这件事情。\n微博信息扩散 北京移动 恐怖主义 自我展露  [Jun 17]又是半个月过去了，回过头去，看看自己都干了什么。我有点表达困难的感觉。或许还是只完成了最后一项。前天跟lf谈了许久，他对我的状态不满意。其实我也已经不满意很久了。做研究的一个状态是：对于自己感兴趣的完全了解，对于其他东西完全不感兴趣。然后，我们总结了半天，结论是跨学科是一个虚假的东西。研究问题可以跨，但是本质的东西或者说方法论的东西，不是跨学科的。\n今天想要去弄一点重整化的东西，却不知道从哪里开始。崩溃。\n集智年会 集智年会终于告一段落了，我很高兴这个过程当中更加了解了集智。在25号夜里大家提出建议、集核成员各自为集智出力的过程让我觉得很受启发。在南芳园二楼吃饭的时候，我谈了自己的想法：人在一个圈子里久了，如同站在深井里，就只能竭尽全力抬头看天，却越来越跑不出去了。\n令飞访问的两周里，我们在对北京移动的重整化研究过程当中做了一些工作。听起来非常不错。需要我继续推动。\n陈志聪开始着手做新闻地图的工作了。现在使用mou来编写markdown。感觉还挺好的。除了数学公式的处理不是很好。就是保存的时候会有点卡。这个很大的bug居然没有很好地解决。\n读了一点胡翼青的书，感觉每个人的思考都不容易。筚路蓝缕，充满坎坷。\n集智会议期间，笑话其中。很多人谈及了易经蓍草卦和背后的思考。易经当中充满了变化的智慧，无论哪一个章节，只要你能有好的理解，改过向善，都是好的。易经本身并不能预测什么，它只能告诉你现在可能处的状态。所以，不必要以科学的标准要求它。\n打气筒的用法 新的自行车打气筒太精致了，以至于我不相信它是否真的有用。买了一个二手自行车，经常骑。为了方便又配备了一个打气筒。看着很单薄，我试了几次都不怎么会用。今天慌忙地出门，结果前车带没气了。于是折腾着打气，结果因为前车带是旧的英式的气门，所以要插入鸭嘴部分，但是总是漏气，折腾了几回。在太阳下，搞得手黑了，汗湿了全身。\n原来，它有一个带有把手（可以折的）气嘴。气嘴分为两部分：英式和美式部分。英式部分就是我们以前常见的鸭嘴夹子部分，美式部分不需要这个。鸭嘴夹子嵌入美式部分后，折一下把手才结合稳固，方可打气；单独用美式部分的时候呢，将气口对准车轮的气门，也要折一下把手才能结合稳固。总结一下，这个小把手非常关键。\n跬步是婴儿步 以前理解跬步是说一个人的心胸，做事情注意细节，不偏废，高标准严要求。后来才明白跬步是婴儿步，baby steps。\n后记 2015年几乎没有什么闪光点，我自己都无法回忆自己究竟干了什么，当然除了女儿的到来和一个社科基金。\n","date":1428710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1428710400,"objectID":"5ded03e44e9c2f8496e3b5a89cb8e19b","permalink":"https://chengjunwang.com/note/note_archive/2015-04-11-last-words/","publishdate":"2015-04-11T00:00:00Z","relpermalink":"/note/note_archive/2015-04-11-last-words/","section":"note","summary":"昨天看举案说法，提到一个30多岁的男人杀死两名要好的女同事的故事。他从小被父母姐姐宠溺，中考却一败涂地。很有一些志大才疏的样子。内心自卑，表面却非常自傲。现实是残酷的，一次恋爱失败后，接近三十岁的他草草地找了个女人结婚生子，但是家庭生活并不幸福。他想自杀，但是懦弱的他却没有勇气。他内心里渴望别人能够帮助自己杀死自己，于是他想到了杀人。但是懦弱与孤傲并存的他却想不到能够杀谁，于是瞄准了跟自己关系好的两个单身女同事。片中提到一句话：“越是懦弱的人，越会遭受到来自生活的接二连三的打击。”\n时间去哪里了 孩子3月11日出生，今天4月11日了。32天了。在这一个月里，老婆和我没有睡一个安稳觉。我的整块的时间也几乎没有了。感受到了很多的生活和教学的压力。尤其是在科研方面，非常落后了。也非常自责，面对这些，我无话可说。没有能够投入足够多的时间，肯定是不能有好的结果的。当然，我还有弱者的心态的问题：失去了挑战的勇气。生活需要继续，我需要重新出发。这段时间唯一坚持下来的就是教书了，每周两节课，我也说不上好好备课，但是收获还是挺多的。比如博弈论、小世界的导航能力等等。此外，准备了一些计算广告和数据新闻的课件。主要是下载了一些公开课的pdf和视频。\n无礼之徒 本周三主持一个讲座，一个很无礼的访问学者上来就问我博士老板是谁，吐槽无力。讲座3点半开始，3点29就唧唧歪歪还不开始。还说什么听得懂就听，听不懂就离开。准时开始后，听了一会果然走了。这种无礼之徒，生活中似乎还有很多，以后绝不会手软。\n 以后，遇到某人说提前走，请现在走。不伺候了。 以后碰到有人问你老板是谁，直接让对方介绍下自己先。  保证每天两个小时的写作 我要再次出发。保证以后的工作效率。这个是迫在眉睫的事情。按照自己的节奏来，充满紧迫感。不要太在意，举重若轻。不要不知轻重。学会拒绝。\n从一篇投稿开始 我要马上开始做这件事情。\n微博信息扩散 北京移动 恐怖主义 自我展露  [Jun 17]又是半个月过去了，回过头去，看看自己都干了什么。我有点表达困难的感觉。或许还是只完成了最后一项。前天跟lf谈了许久，他对我的状态不满意。其实我也已经不满意很久了。做研究的一个状态是：对于自己感兴趣的完全了解，对于其他东西完全不感兴趣。然后，我们总结了半天，结论是跨学科是一个虚假的东西。研究问题可以跨，但是本质的东西或者说方法论的东西，不是跨学科的。\n今天想要去弄一点重整化的东西，却不知道从哪里开始。崩溃。\n集智年会 集智年会终于告一段落了，我很高兴这个过程当中更加了解了集智。在25号夜里大家提出建议、集核成员各自为集智出力的过程让我觉得很受启发。在南芳园二楼吃饭的时候，我谈了自己的想法：人在一个圈子里久了，如同站在深井里，就只能竭尽全力抬头看天，却越来越跑不出去了。\n令飞访问的两周里，我们在对北京移动的重整化研究过程当中做了一些工作。听起来非常不错。需要我继续推动。\n陈志聪开始着手做新闻地图的工作了。现在使用mou来编写markdown。感觉还挺好的。除了数学公式的处理不是很好。就是保存的时候会有点卡。这个很大的bug居然没有很好地解决。\n读了一点胡翼青的书，感觉每个人的思考都不容易。筚路蓝缕，充满坎坷。\n集智会议期间，笑话其中。很多人谈及了易经蓍草卦和背后的思考。易经当中充满了变化的智慧，无论哪一个章节，只要你能有好的理解，改过向善，都是好的。易经本身并不能预测什么，它只能告诉你现在可能处的状态。所以，不必要以科学的标准要求它。\n打气筒的用法 新的自行车打气筒太精致了，以至于我不相信它是否真的有用。买了一个二手自行车，经常骑。为了方便又配备了一个打气筒。看着很单薄，我试了几次都不怎么会用。今天慌忙地出门，结果前车带没气了。于是折腾着打气，结果因为前车带是旧的英式的气门，所以要插入鸭嘴部分，但是总是漏气，折腾了几回。在太阳下，搞得手黑了，汗湿了全身。\n原来，它有一个带有把手（可以折的）气嘴。气嘴分为两部分：英式和美式部分。英式部分就是我们以前常见的鸭嘴夹子部分，美式部分不需要这个。鸭嘴夹子嵌入美式部分后，折一下把手才结合稳固，方可打气；单独用美式部分的时候呢，将气口对准车轮的气门，也要折一下把手才能结合稳固。总结一下，这个小把手非常关键。\n跬步是婴儿步 以前理解跬步是说一个人的心胸，做事情注意细节，不偏废，高标准严要求。后来才明白跬步是婴儿步，baby steps。\n后记 2015年几乎没有什么闪光点，我自己都无法回忆自己究竟干了什么，当然除了女儿的到来和一个社科基金。","tags":null,"title":"既见君子","type":"note"},{"authors":null,"categories":null,"content":"我们经常写一些程序碎片，却很少有动力把它们整合起来。前段时间写了一个爬取并可视化谷歌学术网的python程序。今天想不如把它整合一下，虽然非常简单（只有一个函数）。主要参考python官网的发布指南。\n##注册 于是首先来到pypi网站注册。\nhttps://pypi.python.org/pypi?%3Aaction=submit_form 记下用户名chengjun和密码W4\n##填写软件包信息 《指南》推荐直接在线填写 https://pypi.python.org/pypi?%3Aaction=submit_form\n##打包和发布工具 先要安装两个包：twine和wheel。\npip install wheel pip install twine  ##整理项目文件夹 找项目实例（https://github.com/pypa/sampleproject）下载下来，修改其中的部分内容即可。详见指南，或者自己摸索即可。\n##打包发布 1.在window环境下，使用cmd，转换工作路径到项目文件夹。 2. 主要参考 https://github.com/pypa/twine打包发布：\n#Create some distributions in the normal way: $ python setup.py sdist bdist_wheel #Upload with twine: $ twine upload dist/*  我使用上传的时候出错（typeError），于是直接使用打包好的zip文件（在dist子文件夹当中）手工上传到pypi。注意，每次上传到pypi需要修改一次setup.py中的版本号，并重新打包才可上传。如此而已，比我想象当中要速度快得多、简单的多。\n这里是我刚刚打包发布的一个可视化谷歌学术网络的python软件包：https://pypi.python.org/pypi/scholarNetwork/\n","date":1424563200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424563200,"objectID":"cfab2b211e2ba4b5d65309e9b1ac71d2","permalink":"https://chengjunwang.com/zh/archive/2015-02-22-distribute-python-package.zh/","publishdate":"2015-02-22T00:00:00Z","relpermalink":"/zh/archive/2015-02-22-distribute-python-package.zh/","section":"zh","summary":"","tags":null,"title":"打包发布python软件包","type":"zh"},{"authors":null,"categories":null,"content":"三年前，我写过一篇小日志，介绍如何从零开始学习R语言。后来我的工作越来越多的使用python，于是摸爬滚打自己探索了挺久的。身边也越来越多的人问起新手如何从零学习python的问题。我想练习、检索、表达这三点依旧是关键，只不过顺序稍有不同。很多人说，学习python，你来推荐一些资料吧。我想了想，资料还不是关键，关键是自身。\n看书还是上手？ 以前我们学语言，比如C语言或者Basic语言，首先讲的都是字符、数字、列表、逻辑符等。几乎所有的编程书都会这么讲，所以很多人会觉得看书没有什么新意。不过我觉得看书还是必须的，重点就是要去掌握这些基本的东西。\n当然了，掌握这些并不能帮助我们完成手上的工作。是的，并不能！总有一些细节的地方你必须去hack现有的代码。于是乎就有了另外一种学习语言的哲学：干中学（learn by doing）。基本的逻辑就是不断摸索，硬着头皮上。这种风格非常强悍，虽然刚开始的时候容易犯非常浅显的毛病，但是却是真正学语言的不二法门。\n表达 到底看书还是上手呢？我主张先明确自己的问题是什么。做研究的人都知道，我们往往对于自己所面临的问题并不明确。写程序、学语言也是这个样子。首先要明确地表达出来。这是表达的第一重意思。\n检索 当你问题明确之后，就可以去检索了。去哪里检索？书中、网上，不拘于形式。重要的是解决问题。这个过程中，我们带着问题读书、上网、提问，能够培养我们独立思考的能力。\n互联网的发展，使得很多时候我们并不需要真正去创造什么，只要检索一下，总能找到好的代码，修改以下就能解决自己的问题。我觉得挺好。这符合我们学习语言的初衷。有个说法是十年学会编程，但是使用编程一个月就够了。\n既然可以看书，有什么推荐的吗？我推荐Beginning Python这本书，虽然我是从A Byte of Python开始看的。\n A Byte of Python http://book.douban.com/subject/5948760/ Beginning Python （Python 基础教程） http://book.douban.com/subject/3205338/ Hello World！Computer Programming for Kids and Other Beginners 与孩子一起学编程 http://book.douban.com/subject/5338024/ How to Think Like a Computer Scientist: Learning with Python http://book.douban.com/subject/1481058/ 21 Recipes for Mining Twitter http://book.douban.com/subject/5988563/ Mining the Social Web http://book.douban.com/subject/5391582/ Toby Segaran (2007) Programming Collective Intelligence Building Smart Web 2.0 Applications. O\u0026rsquo;Reilly Media Python公开课 中文课程 http://www.imooc.com/view/177  练习 有了问题和思路之后，重要的就是练习了。不要怕麻烦，经常动手写东西。这个是不二法门。\n还有一些琐碎的东西，如下：\n 我觉得学python上手很重要，选一个好的IDE很重要，对于windows用户我推荐winpython，使用集成于其中的spyder编程很方便，不需要指定python的路径，安装第三方包也很方便。 每天都接触点Python,写写博客。 既然使用Python了，那么google就是你最好的朋友！用英文检索。 不要错过Github。上传你的代码。便于保存和分享。python的精神是开放，开源。 很多时候，最大的问题是你不知道自己面临的问题：我的经验是用英文一句话说出你的问题。然后借助搜索引擎。你一般都能找到答案。Python的email list和stackoverflow中有很多想要的答案。 实在找不到解决方案，不要过多寄希望于身边的朋友，stackoverflow上有更合适的回答你问题的人！去那里提问。 熟悉一个package。经常阅读package的文档。 ","date":1424563200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424563200,"objectID":"b6557b7bb74992ffd1330dc8bfd71b59","permalink":"https://chengjunwang.com/zh/archive/2015-02-22-fresh-python.zh/","publishdate":"2015-02-22T00:00:00Z","relpermalink":"/zh/archive/2015-02-22-fresh-python.zh/","section":"zh","summary":"","tags":null,"title":"表达、检索、练习——写给Python的初学者","type":"zh"},{"authors":["王成军"],"categories":null,"content":"","date":1423800216,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1423800216,"objectID":"477b0e8fc5540d2012d6b1086435122b","permalink":"https://chengjunwang.com/publication/cc-intro/","publishdate":"2015-02-13T12:03:36+08:00","relpermalink":"/publication/cc-intro/","section":"publication","summary":"计算社会科学为传播学发展提供了新的动力。通过文本挖掘和引文网络分析,本文梳理了计算社会科学的相关文献,证实了计算社会科学发展过程中存在的两大研究脉络:多主体建模和网络科学,而网络科学的发展和互联网大数据的广泛使用真正促进了计算社会科学的发展。基于此,本文尝试从可计算化的视角定义了计算传播学,强调了人类传播行为的可计算性基础和对于大数据背后的模式、机制及普适原理的挖掘。同时,本文简要讨论了传播学可计算化的工具、目标及应用。 ","tags":null,"title":"计算传播学:作为计算社会科学的传播学","type":"publication"},{"authors":null,"categories":null,"content":" 在长沙呆了几天，经历了一次生病，主要问题是白天吃多了晚上睡不着，被子太小冻着了。之后，邮寄完东西，拖着两个大行李箱带着暮白回到了南京。各种事情都被落下了。程序依旧没有写，一月的论文还砸在手上。今天吃完午饭，我就出门了，来到了办公室。刷了一会邮件。痛恨自己的拖沓，一定要完成。\n女儿 暮白不喜欢吃荤腥，牛奶也不喜欢，鱼也不喜欢，非常奇怪，大家都觉得会生女儿。我想，生女儿也是好的。不过照顾老婆孩子的确辛苦，至少要每天去买菜，洗菜，炒菜，洗碗。所以时间非常宝贵。\n无钱 早上出门查了下新办的工资卡，分文没有。\n没有时间 一天做三顿饭，基本上就没有什么时间了。\n睡眠 可惜最近暮白管的紧，我的睡眠往往从十点就开始了。看电影电视什么的太奢侈了。我深感力不从心。每天做家务的好处是我的做菜的速度开始变快一点。\n怎么样管理时间呢？\n总是要工作才对。 昨天鼓足勇气，跟lingfei聊了下，从写那个复杂巨大的推荐系统的压力中暂时舒缓了出来。我不得不说我没有做那么大的事情的规划。只想做一些小的事情。于是聊到了抓取谷歌学术的事情，我很感兴趣，在mac上装了一个conda软件包。使用ipython notebook写程序，感觉挺好的。做到昨晚12点钟，终于写完了主干部分。\n结果发现无法连成大的社会网络，主要的原因恐怕是手工添加，很多人疏于管理。于是，睡觉的时候就想着把它可视化出来。\n我写了关于路遥和王小波抽烟和疯狂工作的故事。恰逢厚夫写的《路遥传》出来，就有了一篇介绍路遥的文章《路遥：倒在干渴的路上》。这篇文章给了我很多触动。我很能理解很多人为什么要抽烟。因为强人的基因在每一个人的血液里都有，但是我们没有驾驭它的耐心和能力。所以往往把一些事情看得太认真，不能超脱，受其所困，为其所苦。\n仪式感 抽烟是为了维持一种庄严的感觉。所以抽贵的烟就可以理解。但是烟这个东西却不好，因为它严重地伤害人的呼吸系统。虽然可以进入血液麻痹神经，却过于猛烈。所幸我的体质不适合抽烟。喝茶是一种生理需要，饮酒是一种精神需要。\n酒壶是必须的 与抽烟类似的就是饮酒。饮酒的历史或许更漫长，所以人的接受也会好一点。酒一样可以麻醉人。让人高兴，只不过，酒不太容易像烟那样作为社交的工具。抽烟的人站在一个犄角旮旯里就可以反思自我。喝酒的人却要随身准备一个酒壶？\n喝红酒 我提倡饮红酒，因为可以微醺。却不至于像白酒那样过于甘冽。红酒多半是不好喝的，恰如烟多半是不好抽的。很多时候，玻璃杯倒上一点，仅此而已。像一个催化剂，催动你去一个地方，写一些东西。\n开学了 寒假很短暂。一下子就开学了，每天都有忙不完的事情，忙着开会做计划，忙着审阅各种东西。写基金申请耗费了一个寒假，中间紧紧做了一个python的package。\n让自己手忙脚乱的一件事情是备课。也许是因为自己的期望过高，所以并不容易沉下心来做一些东西。在客厅里看电视也往往非常消耗时间。新的学期一定要加油。\n学期结束了 转眼之间，这个学期结束了。下半年已经义无反顾地开始了。这是我第一次如此系统地给人上课，只能说自己在这条道路上苦苦求索。因为是新课，所以有很多自由探索的部分。还逼着自己去认真看了计算语言学的书。但是我对于其中很多模型的实现并不看好。很多常用的算法并没有成体系地采用现代的变成语言表现出来，很大程度上都是说有一个什么软件可以做。这样很不好。而反观软件呢，比如nltk，则关注的都是非常基础的东西，对于高级一点的应用反而没有涉及。所以，这一部分不适合用来讲课。\n课比天大，课不重要？ 课比天大，不能开天窗。另一方面，上课就只是上课，上课不是搞研究，所以不必投入太多精力。在国外，teaching是一个老师谋生的手段，做得略好些，但课讲不好学生不喜欢而已，这一点跟大陆一样。下一个学期有两门课，其中一门继续讲Kleinberg那本书，但是博弈论部分的用处实在是有限。但是，广告部分又和拍卖理论紧密相关。数据新闻，每次只需要讲一节课，第二节课要留个学生练习。\ngithub的组织和team很适合课堂教学。\n","date":1422316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422316800,"objectID":"1308c6c488a08598e17093b37246a18c","permalink":"https://chengjunwang.com/note/note_archive/2015-01-27-no-money-no-time/","publishdate":"2015-01-27T00:00:00Z","relpermalink":"/note/note_archive/2015-01-27-no-money-no-time/","section":"note","summary":"在长沙呆了几天，经历了一次生病，主要问题是白天吃多了晚上睡不着，被子太小冻着了。之后，邮寄完东西，拖着两个大行李箱带着暮白回到了南京。各种事情都被落下了。程序依旧没有写，一月的论文还砸在手上。今天吃完午饭，我就出门了，来到了办公室。刷了一会邮件。痛恨自己的拖沓，一定要完成。\n女儿 暮白不喜欢吃荤腥，牛奶也不喜欢，鱼也不喜欢，非常奇怪，大家都觉得会生女儿。我想，生女儿也是好的。不过照顾老婆孩子的确辛苦，至少要每天去买菜，洗菜，炒菜，洗碗。所以时间非常宝贵。\n无钱 早上出门查了下新办的工资卡，分文没有。\n没有时间 一天做三顿饭，基本上就没有什么时间了。\n睡眠 可惜最近暮白管的紧，我的睡眠往往从十点就开始了。看电影电视什么的太奢侈了。我深感力不从心。每天做家务的好处是我的做菜的速度开始变快一点。\n怎么样管理时间呢？\n总是要工作才对。 昨天鼓足勇气，跟lingfei聊了下，从写那个复杂巨大的推荐系统的压力中暂时舒缓了出来。我不得不说我没有做那么大的事情的规划。只想做一些小的事情。于是聊到了抓取谷歌学术的事情，我很感兴趣，在mac上装了一个conda软件包。使用ipython notebook写程序，感觉挺好的。做到昨晚12点钟，终于写完了主干部分。\n结果发现无法连成大的社会网络，主要的原因恐怕是手工添加，很多人疏于管理。于是，睡觉的时候就想着把它可视化出来。\n我写了关于路遥和王小波抽烟和疯狂工作的故事。恰逢厚夫写的《路遥传》出来，就有了一篇介绍路遥的文章《路遥：倒在干渴的路上》。这篇文章给了我很多触动。我很能理解很多人为什么要抽烟。因为强人的基因在每一个人的血液里都有，但是我们没有驾驭它的耐心和能力。所以往往把一些事情看得太认真，不能超脱，受其所困，为其所苦。\n仪式感 抽烟是为了维持一种庄严的感觉。所以抽贵的烟就可以理解。但是烟这个东西却不好，因为它严重地伤害人的呼吸系统。虽然可以进入血液麻痹神经，却过于猛烈。所幸我的体质不适合抽烟。喝茶是一种生理需要，饮酒是一种精神需要。\n酒壶是必须的 与抽烟类似的就是饮酒。饮酒的历史或许更漫长，所以人的接受也会好一点。酒一样可以麻醉人。让人高兴，只不过，酒不太容易像烟那样作为社交的工具。抽烟的人站在一个犄角旮旯里就可以反思自我。喝酒的人却要随身准备一个酒壶？\n喝红酒 我提倡饮红酒，因为可以微醺。却不至于像白酒那样过于甘冽。红酒多半是不好喝的，恰如烟多半是不好抽的。很多时候，玻璃杯倒上一点，仅此而已。像一个催化剂，催动你去一个地方，写一些东西。\n开学了 寒假很短暂。一下子就开学了，每天都有忙不完的事情，忙着开会做计划，忙着审阅各种东西。写基金申请耗费了一个寒假，中间紧紧做了一个python的package。\n让自己手忙脚乱的一件事情是备课。也许是因为自己的期望过高，所以并不容易沉下心来做一些东西。在客厅里看电视也往往非常消耗时间。新的学期一定要加油。\n学期结束了 转眼之间，这个学期结束了。下半年已经义无反顾地开始了。这是我第一次如此系统地给人上课，只能说自己在这条道路上苦苦求索。因为是新课，所以有很多自由探索的部分。还逼着自己去认真看了计算语言学的书。但是我对于其中很多模型的实现并不看好。很多常用的算法并没有成体系地采用现代的变成语言表现出来，很大程度上都是说有一个什么软件可以做。这样很不好。而反观软件呢，比如nltk，则关注的都是非常基础的东西，对于高级一点的应用反而没有涉及。所以，这一部分不适合用来讲课。\n课比天大，课不重要？ 课比天大，不能开天窗。另一方面，上课就只是上课，上课不是搞研究，所以不必投入太多精力。在国外，teaching是一个老师谋生的手段，做得略好些，但课讲不好学生不喜欢而已，这一点跟大陆一样。下一个学期有两门课，其中一门继续讲Kleinberg那本书，但是博弈论部分的用处实在是有限。但是，广告部分又和拍卖理论紧密相关。数据新闻，每次只需要讲一节课，第二节课要留个学生练习。\ngithub的组织和team很适合课堂教学。","tags":null,"title":"无钱无闲","type":"note"},{"authors":null,"categories":null,"content":"昨天收到了shinyapp的一封邮件，想起之前自己做的关于网络扩散的东西，就想把它转化为app的形式。最直接的办法还是看tutorial，比如（http://shiny.rstudio.com/tutorial）。\n现学现卖，于是我马上做了一个使用igraph绘制BA网络的小应用：\nhttps://chengjun.shinyapps.io/testApp/\n ##通过rstudio学习shinyApp制作 其实R的王牌编辑器Rstudio已经和shiny完美的结合，完全可以通过rstudio学习shinyApp制作。\n system.file(\u0026quot;examples\u0026quot;, package=\u0026quot;shiny\u0026quot;) runExample(\u0026quot;01_hello\u0026quot;) # a histogram runExample(\u0026quot;02_text\u0026quot;) # tables and data frames runExample(\u0026quot;03_reactivity\u0026quot;) # a reactive expression runExample(\u0026quot;04_mpg\u0026quot;) # global variables runExample(\u0026quot;05_sliders\u0026quot;) # slider bars runExample(\u0026quot;06_tabsets\u0026quot;) # tabbed panels runExample(\u0026quot;07_widgets\u0026quot;) # help text and submit buttons runExample(\u0026quot;08_html\u0026quot;) # shiny app built from HTML runExample(\u0026quot;09_upload\u0026quot;) # file upload wizard runExample(\u0026quot;10_download\u0026quot;) # file download wizard runExample(\u0026quot;11_timer\u0026quot;) # an automated timer ","date":1420934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420934400,"objectID":"f29cd9150fc7a5ed22d7e412cd666bc2","permalink":"https://chengjunwang.com/zh/archive/2015-01-11-shinyapp.zh/","publishdate":"2015-01-11T00:00:00Z","relpermalink":"/zh/archive/2015-01-11-shinyapp.zh/","section":"zh","summary":"","tags":null,"title":"再次尝试shinyApp","type":"zh"},{"authors":null,"categories":null,"content":"昨天听谈和讲解了echarts的使用，他的讲解非常直接简单，就是直接修改echarts的实例。之后，我发现林峰将echarts的实例的html代码写得非常复杂，但其实单独调用一个js的时候，却非常简单。具体做法如下：\n 准备工作：建立一个js子文件夹，将esl，echarts，pie，bar，map等各种js放入其中。在js文件夹外新建一个空的html文件。 首先，调用esl.js，它提供了echarts图片的载体。 其次，使用require方法调用echarts.js和具体使用的类型图的js（比如map.js）。 再次，输入需要输入的数据。 最后，封装。\n \u0026lt;!DCOTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;echarts testing page\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026quot;./js/esl.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;./js/echarts.js\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026quot;main\u0026quot; style=\u0026quot;height:400px;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt; require.config({ paths:{ \u0026quot;echarts\u0026quot;:\u0026quot;js/echarts\u0026quot;, \u0026quot;echarts/chart/map\u0026quot;:\u0026quot;js/map\u0026quot; } }); //using require( [ \u0026quot;echarts\u0026quot;, \u0026quot;echarts/chart/map\u0026quot; ], function(ec){ var myChart=ec.init(document.getElementById(\u0026quot;main\u0026quot;)); \u0026lt;!--Input your code below--\u0026gt; \u0026lt;!--Input your code above--\u0026gt; //loading data myChart.setOption(option); } ); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   ##弦图 http://chengjun.github.io/myecharts/chord.html\n ##柱状图 http://chengjun.github.io/myecharts/bar.html\n ##饼图 http://chengjun.github.io/myecharts/pie1.html\n ##线图 http://chengjun.github.io/myecharts/line1.html\n ##地图 http://chengjun.github.io/myecharts/map9.html\n ##力图\nhttp://chengjun.github.io/myecharts/force2\n ##后记 发现chrome无法加载，再加入了以下代码后就可以使用了。可惜用了整整一个上午才更正这个问题。\n \u0026lt;script src=\u0026quot;./js/echarts.js\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; ","date":1420848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420848000,"objectID":"5a28eefa46d64632c1b52e025b918ee2","permalink":"https://chengjunwang.com/zh/archive/2015-01-10-myecharts.zh/","publishdate":"2015-01-10T00:00:00Z","relpermalink":"/zh/archive/2015-01-10-myecharts.zh/","section":"zh","summary":"","tags":null,"title":"Echarts使用简介","type":"zh"},{"authors":null,"categories":null,"content":"在365租房网站上沿着地铁一号线和二号线看了半天的房子，最终锁定了两个地方：迈皋和南大仙林校区。\n迈皋地方的民房和南大的学区房都可以考虑。不过后者装修更好，面积更大，但是有17站地铁，太远啦；所以第一年还是在迈皋比较合适。迈皋站是一号线的东端，相对郊区，很多城中村发展起来，都还不是高层（以后会被淘汰掉，迟早成高层，这么说南京北上的时间还早，兰州已经开始了）。迈皋的东井村41号小区里似乎有很多低层的房子，不过出手的速度感觉挺快，价格在2000元左右，相对合适，大小会在70平米左右。\n除此之外，我还看了二号线上的云锦路地铁站。总体来看，虽然365house网站已经汇集了各方的信息，但是一个非常松散的组织。租房者由此进入，中介也由此进入。但是各个中介割地为治，稳固地走着一个碉堡一个社区的策略。于是，线下和线上异常紧密地联系在了一起。\n锁定迈皋桥之后，我开始寻找离地铁站近的地方，尤其是东井村、和燕花苑，先后看了1家和两家。在迈皋小区也看了2家，今天又看了南砖新村一家。整体感觉这些近的地方的装修太差了。第一家去的是和燕花苑，结果黑灯瞎火的，还看到了两个蟑螂。最早觉得凑活下算了，但是到底还是难以忍受那些简装修。事实上，所谓的“简装修”基本上都是没装修，破桌子烂板凳的，让我无法忍受。\n我深刻感觉到只有住得略远些，才好找到好的地方住。毕竟距离近，租金低的时候，装修差就成了必然。于是距离迈皋桥（广场）三个站的枫桥佳筑就开始进入我的视野。感觉那里的底层的密码锁比较安全，里面的房子户型合理，最重要的是装修还不错。敲定2000元月租，一次交清全年的租金，另外需要交3000押金，1000中介费，总共2.8万。今天交了3000押金确立了租赁意向，商定18日签约。不得不说这对我的现金的流动性是一个巨大挑战。一时还只好欠下我们家慕白的钱了。\n房间的格局\n地理位置\n主卧\n次卧\n厨房和餐厅\n卫生间\n客厅和阳台（阳台未照出）\n下面是百度地图：\n ","date":1410652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410652800,"objectID":"a7b146e682046d0b28a44fefaa4b8433","permalink":"https://chengjunwang.com/note/note_archive/2014-09-14-nanjing-housing/","publishdate":"2014-09-14T00:00:00Z","relpermalink":"/note/note_archive/2014-09-14-nanjing-housing/","section":"note","summary":"在365租房网站上沿着地铁一号线和二号线看了半天的房子，最终锁定了两个地方：迈皋和南大仙林校区。\n迈皋地方的民房和南大的学区房都可以考虑。不过后者装修更好，面积更大，但是有17站地铁，太远啦；所以第一年还是在迈皋比较合适。迈皋站是一号线的东端，相对郊区，很多城中村发展起来，都还不是高层（以后会被淘汰掉，迟早成高层，这么说南京北上的时间还早，兰州已经开始了）。迈皋的东井村41号小区里似乎有很多低层的房子，不过出手的速度感觉挺快，价格在2000元左右，相对合适，大小会在70平米左右。\n除此之外，我还看了二号线上的云锦路地铁站。总体来看，虽然365house网站已经汇集了各方的信息，但是一个非常松散的组织。租房者由此进入，中介也由此进入。但是各个中介割地为治，稳固地走着一个碉堡一个社区的策略。于是，线下和线上异常紧密地联系在了一起。\n锁定迈皋桥之后，我开始寻找离地铁站近的地方，尤其是东井村、和燕花苑，先后看了1家和两家。在迈皋小区也看了2家，今天又看了南砖新村一家。整体感觉这些近的地方的装修太差了。第一家去的是和燕花苑，结果黑灯瞎火的，还看到了两个蟑螂。最早觉得凑活下算了，但是到底还是难以忍受那些简装修。事实上，所谓的“简装修”基本上都是没装修，破桌子烂板凳的，让我无法忍受。\n我深刻感觉到只有住得略远些，才好找到好的地方住。毕竟距离近，租金低的时候，装修差就成了必然。于是距离迈皋桥（广场）三个站的枫桥佳筑就开始进入我的视野。感觉那里的底层的密码锁比较安全，里面的房子户型合理，最重要的是装修还不错。敲定2000元月租，一次交清全年的租金，另外需要交3000押金，1000中介费，总共2.8万。今天交了3000押金确立了租赁意向，商定18日签约。不得不说这对我的现金的流动性是一个巨大挑战。一时还只好欠下我们家慕白的钱了。\n房间的格局\n地理位置\n主卧\n次卧\n厨房和餐厅\n卫生间\n客厅和阳台（阳台未照出）\n下面是百度地图：\n ","tags":null,"title":"南京租房记","type":"note"},{"authors":null,"categories":null,"content":"分割数据最慢的过程其实是打开和关闭一个文件，因此尽量减少这种操作可以飞速的提升分割数据的速度。之前在stackoverflow上看到一种方法非常高效，放在这里研究一下。\n from collections import defaultdict path = 'D:/chengjun/Sina Weibo/DepthOverTime/' #define a function def splitData(f): #using dict to 'classify' rows E = defaultdict(lambda:[]) for line in f: lists = line.strip().split(',') rtmid = lists[0] file_save = path + 'single_weibo/'+rtmid E[file_save].append(line) for key in E.keys(): try: with open(key,'a') as p: for record in E[key]: p.write(record+\u0026quot;\\n\u0026quot;) except: pass # start to read in data by chunks bigfile = open(path + 'diffusion_path_date2552.csv') chunkSize = 100000000 chunk = bigfile.readlines(chunkSize) while chunk: splitData(chunk) chunk = bigfile.readlines(chunkSize)  上面这段代码有两个地方导致非常高效：\n 使用dict来将相同的key的行整理到一起， 以便一次将吞进来的某一个key下面的数据全部写入硬盘 每次使用readlines读入足够多的行，充分发挥内存的作用 ","date":1409443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409443200,"objectID":"f36eab5346b0be77c6deaca14e3d603c","permalink":"https://chengjunwang.com/zh/archive/2014-08-31-fast-split-data-with-python.zh/","publishdate":"2014-08-31T00:00:00Z","relpermalink":"/zh/archive/2014-08-31-fast-split-data-with-python.zh/","section":"zh","summary":"","tags":null,"title":"使用Python快速分割数据的方法","type":"zh"},{"authors":null,"categories":null,"content":"在之前的一个博客中，我介绍了使用R进行社区划分并可视化的方法。这里使用相同的数据，介绍如何使用d3network实现网络可视化的方法。\n首先，安装d3network\ndevtools::install_github(\u0026quot;d3Network\u0026quot;, \u0026quot;christophergandrud\u0026quot;) require(d3Network)  之后可以使用简单的可视化方法：\nd3SimpleNetwork(data[,1:2], file = \u0026quot;chinese_university100.html\u0026quot;, width = 1024, height = 763, fontsize = 12)  我想要展现社区划分的结果：\n#链接数据 links = data names(links) = c(\u0026quot;source\u0026quot;, \u0026quot;target\u0026quot;, \u0026quot;value\u0026quot;) #节点列表 fc = fastgreedy.community(g); sizes(fc) mfc = membership(fc) nodes = data.frame(name = names(mfc), group = mfc) #对应链接数据和节点数据 ids = 0:(nrow(nodes)-1) # notice: start with zero! links[,1] = ids[match(links[,1], nodes$name )] links[,2] = ids[match(links[,2], nodes$name )] links = links[with(links, order(source)), ] # sort by source #处理边的权重大小 links$value = log(links$value)  之后就可以使实现可视化结果啦：\nd3ForceNetwork(Links = links, Nodes = nodes, Source = \u0026quot;source\u0026quot;, Target = \u0026quot;target\u0026quot;, Value = \u0026quot;value\u0026quot;, NodeID = \u0026quot;name\u0026quot;, Group = \u0026quot;group\u0026quot;, file = \u0026quot;chinese_university_groups100.html\u0026quot;, width = 1550, height = 800,iframe = TRUE, opacity = 0.9, zoom = TRUE)   但是对于中文要麻烦一些，需要手工修改html里的encoding设置，包括meta部分和script部分两个地方：\n\u0026lt;meta charset=\u0026quot;gbk\u0026quot;\u0026gt; \u0026lt;script charset=\u0026quot;gbk\u0026quot; src=http://d3js.org/d3.v3.min.js\u0026gt;\u0026lt;/script\u0026gt;  除此之外，我还尝试了下两百所学校的情况：点这里。\n","date":1409097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409097600,"objectID":"56fce5e026337dfb39832309c2de8f5a","permalink":"https://chengjunwang.com/zh/archive/2014-08-27-d3network.zh/","publishdate":"2014-08-27T00:00:00Z","relpermalink":"/zh/archive/2014-08-27-d3network.zh/","section":"zh","summary":"","tags":null,"title":"使用d3network做网络可视化","type":"zh"},{"authors":null,"categories":null,"content":"NetworkX是使用python分析网络数据的重要武器。它的使用非常简单。\n首先，创建网络对象：\nimport matplotlib.pyplot as plt import networkx as nx G=nx.DiGraph()  然后，添加链接：\nG.add_edge('source',1,weight=80) G.add_edge(1,2,weight=50) G.add_edge(1,3,weight=30) G.add_edge(3,2,weight=10) G.add_edge(2,4,weight=20) G.add_edge(2,5,weight=30) G.add_edge(4,5,weight=10) G.add_edge(5,3,weight=5) G.add_edge(2,'sink',weight=10) G.add_edge(4,'sink',weight=10) G.add_edge(3,'sink',weight=25) G.add_edge(5,'sink',weight=35)  可以很容易提取边的权重:\nedges,colors = zip(*nx.get_edge_attributes(G,'weight').items())  计算加权过的出度：\nd = G.out_degree(weight = 'weight') #计算节点的中心度  选择一个常用的可视化方法：\npos=nx.spring_layout(G) #设置网络的布局  绘制网络:\nnx.draw(G, pos, node_color = 'orange', with_labels = True, nodelist = d.keys(), node_size = [v*5 for v in d.values()], edgelist = edges, edge_color = colors, width = 5, edge_cmap=plt.cm.Blues)  计算流距离：\n''' # get flow distance ''' def toSink(G, i): try: di = G[i]['sink'].values()[0] except: di = 0 return di def flowDistanceDT(G): #input a balanced nx graph R = G.reverse() mapping = {'source':'sink','sink':'source'} H = nx.relabel_nodes(R,mapping) #---------initialize flow distance dict------ L = dict((i,1) for i in G.nodes()) #FlowDistance #---------prepare weighted out-degree dict------ D = {i: toSink(G, i) for i in G.nodes()} #Di T = G.out_degree(weight='weight') #Ti #---------iterate until converge------------ ls = np.array(L.values()) delta = len(L)*0.01 + 1 while delta \u0026gt; len(L)*0.01: for i in L: l=1 for m,n in H.edges(i): l+=L[n]*H[m][n].values()[0]/float(T[m]) L[i]=l delta = sum(np.abs(np.array(L.values()) - ls)) ls = np.array(L.values()) #---------clean the result------- del L['sink'] for i in L: L[i]-=1 L['sink'] = L.pop('source') T['sink'] = T.pop('source') D['sink'] = D.pop('source') return L.values(), D.values(), T.values() ","date":1407974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1407974400,"objectID":"298d61bd7335bde07ee963a904f9fd96","permalink":"https://chengjunwang.com/zh/archive/2014-08-14-networkx-intro.zh/","publishdate":"2014-08-14T00:00:00Z","relpermalink":"/zh/archive/2014-08-14-networkx-intro.zh/","section":"zh","summary":"","tags":null,"title":"NetworkX初步：创建网络、提取属性和绘图","type":"zh"},{"authors":null,"categories":null,"content":"许小可老师和我决定使用可视化的方法分析一下中国高校之间的友谊关系网络。我们是想通过这个图从一个侧面说明各个大学在社交网络上的影响力和关系：所以节点大小表示每个大学在该网络中的友谊关系数量，连边宽度表示节点之间的连接关系，节点颜色的不同可以表示节点的影响力大小（介度中心性指标）。\n###数据清洗 现有数据有学校信息。我可以通过构建字典的方式来将user_id和学校信息（以最新的学校信息为主）剥离出来。使用这个字典可以计算学校人数的分布并挑选前一百的学校。然后根据user_id来match社交网络数据和学校数据，构建：university1\u0026mdash;university2\u0026mdash;date的数据形式。如果该行数据中的学校都在top100的名单中，则保留，否则不保留，这样可以构建所需要的学校和学校的随时间变化的网络，并采用考虑连边权重的贪婪算法来划分网络社团。\n###数据分析\n数据清洗之后，使用R软件进行数据分析，使用igraph包进行数据的可视化。代码如下：\nlibrary(igraph) setwd(\u0026quot;F:/xiaonei/\u0026quot;) ################ # all data ################ data = read.table(\u0026quot;./friends_university_top100_by_all.txt\u0026quot;, header = FALSE, sep = '\\t', stringsAsFactors = FALSE) data = data[which(data[,3] \u0026gt;= mean(data[,3])*1.2), ] data = data[which(data[,1] != data[,2]),] g =graph.data.frame(data[,1:2],directed=FALSE ) E(g)$weight = data[,3] E(g)$color = \u0026quot;lightgrey\u0026quot; # layout set.seed(34) ## to make this reproducable l=layout.fruchterman.reingold(g) # size nodeSize = graph.strength(g) V(g)$size = (nodeSize - min(nodeSize))/(max(nodeSize) - min(nodeSize))*20 centrality = betweenness(g) # colors colors = heat.colors(37) position = rank(-centrality, ties.method = \u0026quot;first\u0026quot;) V(g)$color = colors[position] # width E(g)$width = (log(E(g)$weight)- 8)*1.5 # label nodeLabel = V(g)$name V(g)$label.cex = log(centrality+1)/20 + 0.5 V(g)$label.color = \u0026quot;black\u0026quot; # community detection fc = fastgreedy.community(g); sizes(fc) mfc = membership(fc) # plot drawFigure = function(g){ plot(g, vertex.label= nodeLabel, edge.curved = FALSE, vertex.frame.color=\u0026quot;#FFFFFF\u0026quot;, layout=l,mark.groups = by(seq_along(mfc), mfc, invisible) ) } drawFigure(g) # save png png(\u0026quot;./all_color.png\u0026quot;, width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) drawFigure(g) dev.off()  数据的可视化表明：\n 学校间的友谊关系的建立取决于学校的排名 （排名越靠前的学校的网络中心性较高） 同一个省的学校之间存在更多的友谊关系 （存在地理上的proximity）  还可以根据月份来可视化，看一下2006年一月的情况吧：\n使用R生成24个月的图片，使用makeagif生成GIF动态图片：\n显然：\n 最早加入这个社交网络的是北京的几所著名高校； 2006年4月才走出北京； 随后友谊关系开始在全国扩张； 扩张的过程围绕着那些著名高校为中心进行。  本文提供汇总的数据下载，供感兴趣的同学玩。\n","date":1405900800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405900800,"objectID":"8ddc7b672596a9c4fb459a1f76f24743","permalink":"https://chengjunwang.com/zh/archive/2014-07-21-chinese-university-friendship-network.zh/","publishdate":"2014-07-21T00:00:00Z","relpermalink":"/zh/archive/2014-07-21-chinese-university-friendship-network.zh/","section":"zh","summary":"","tags":null,"title":"中国高校间的友谊网络：大学排名、地理位置和演化规律","type":"zh"},{"authors":null,"categories":null,"content":" 在家里呆了两天，第三天就乘坐列车，第四天凌晨到达西安。住在西安西南的绿地世纪城。两年前来西安的时候留下了阴影：西安的七月太热了。我很不满意炎热的城市打动土木却树木稀疏。\n卧床 米勺妈妈还是不在状态：昨天突然提及礼金；今天又丢了太阳镜。真是不让人放心啊。\n今天上午坐710路公交去翠华路上的陕西历史博物馆。主要有三个展区，按照历史的顺序排列（史前，秦汉，唐宋）。印象里明朝几百个陪葬的小陶俑很壮观；唐三彩依旧很平常；各种金银器。解说员的声音很低，似乎很专业了。一些站台有微信二维码，参观者中不少人忙于扫码的过程当中。因为去得晚了，所以错过了上午的免费票发放。于是去买了特展区20元一张的票，这样可以看特展区和三个普通展区。\n20号去长安区妇幼保健院看了下，米勺妈要卧床休息两周，我要退掉车票在这里守护她。我们决定换一个便宜的地方住。看了下艺龙地图:，我们决定在丈八西路附近找找村屋短租。有一些很便宜的房间，不知道卫生条件和空调wifi怎么样。网上的信息不太充分。需要实地去看一下。\n31号楼 后来却决定还是住绿地世纪城，于是搬到了31号楼这里。一直住到了今天，七月三十一日。有一周的时间，我每天去丈母娘的岐山面馆里负责上菜和收拾碗碟，顺便可以蹭一顿正宗可口的陕西大碗面，吃过了炒拉条、浆水面等。需要坐261沿着锦业路走到三环边上的锦尚名城。打车的话需要九块钱。车费其实是7.5元，但是要加燃气费一块，就是总共九块钱啦。西安这里的的士多用燃气，更加便宜。\n从住的绿地世纪城东门坐608可以到西安火车站。不过空调车很少，路途远（差不多一个小时路程），所以非常痛苦，我来回坐了四趟，一次。是去退火车票，一次去送爸爸妈妈回山东。\n搬到31号楼的时候遇到了一个特别的夫妻，他们三十出头，特别紧张自己坏了6个多月的孩子。丈夫在华为工作，妻子辞掉了工作怀孕家中。因为邻居装修噪音，住到了绿地这边两三个月了。她们特别害怕辐射：拒绝用无线wifi、电热水壶、电饭煲。连洗澡用的热水器也要关掉，不洗衣服的时候，洗衣机的插座也要拔掉。为此，我们将无线wifi换成了有线，只能在厨房里烧水。后来换了一家人住在隔壁，才好多了。 这段时间，我丧失了斗志，每天的生活就是做饭、烧水、洗碗、喂药、买菜之类。一天三轮，累觉不爱。这段时间温习了家乡做面汤的手法。面汤在陕西称之为拌汤（读音为bian、tang）。除此之外，打发无聊的生活的方式还有看电视剧。我和勺妈看了《爱情最美丽》、《神探狄仁杰I》。\n对了，中午收到了研究生院的email，确定了答辩时间为8月26日。\n首页图片 勺妈睡着了，我才有时间去整理了下网站首页的图片无法显示的问题。使用火狐浏览器看了下，原来是ReferenceError: $ is not defined这个问题。在stackoverflow上面的回答说要：Add JQuery library before your script so that $ can be identified.我去看了下网站的html，发现是有jquery这个库的，只是版本过低。于是更新了一下jquery的版本就解决了问题。如下：\n\u0026lt;script src=\u0026quot;http://code.jquery.com/jquery-1.11.0.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  ","date":1405555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405555200,"objectID":"f4256c7edb84677eb37aba03f678395d","permalink":"https://chengjunwang.com/note/note_archive/2014-07-17-xi-an-another-hometown/","publishdate":"2014-07-17T00:00:00Z","relpermalink":"/note/note_archive/2014-07-17-xi-an-another-hometown/","section":"note","summary":" 在家里呆了两天，第三天就乘坐列车，第四天凌晨到达西安。住在西安西南的绿地世纪城。两年前来西安的时候留下了阴影：西安的七月太热了。我很不满意炎热的城市打动土木却树木稀疏。\n卧床 米勺妈妈还是不在状态：昨天突然提及礼金；今天又丢了太阳镜。真是不让人放心啊。\n今天上午坐710路公交去翠华路上的陕西历史博物馆。主要有三个展区，按照历史的顺序排列（史前，秦汉，唐宋）。印象里明朝几百个陪葬的小陶俑很壮观；唐三彩依旧很平常；各种金银器。解说员的声音很低，似乎很专业了。一些站台有微信二维码，参观者中不少人忙于扫码的过程当中。因为去得晚了，所以错过了上午的免费票发放。于是去买了特展区20元一张的票，这样可以看特展区和三个普通展区。\n20号去长安区妇幼保健院看了下，米勺妈要卧床休息两周，我要退掉车票在这里守护她。我们决定换一个便宜的地方住。看了下艺龙地图:，我们决定在丈八西路附近找找村屋短租。有一些很便宜的房间，不知道卫生条件和空调wifi怎么样。网上的信息不太充分。需要实地去看一下。\n31号楼 后来却决定还是住绿地世纪城，于是搬到了31号楼这里。一直住到了今天，七月三十一日。有一周的时间，我每天去丈母娘的岐山面馆里负责上菜和收拾碗碟，顺便可以蹭一顿正宗可口的陕西大碗面，吃过了炒拉条、浆水面等。需要坐261沿着锦业路走到三环边上的锦尚名城。打车的话需要九块钱。车费其实是7.5元，但是要加燃气费一块，就是总共九块钱啦。西安这里的的士多用燃气，更加便宜。\n从住的绿地世纪城东门坐608可以到西安火车站。不过空调车很少，路途远（差不多一个小时路程），所以非常痛苦，我来回坐了四趟，一次。是去退火车票，一次去送爸爸妈妈回山东。\n搬到31号楼的时候遇到了一个特别的夫妻，他们三十出头，特别紧张自己坏了6个多月的孩子。丈夫在华为工作，妻子辞掉了工作怀孕家中。因为邻居装修噪音，住到了绿地这边两三个月了。她们特别害怕辐射：拒绝用无线wifi、电热水壶、电饭煲。连洗澡用的热水器也要关掉，不洗衣服的时候，洗衣机的插座也要拔掉。为此，我们将无线wifi换成了有线，只能在厨房里烧水。后来换了一家人住在隔壁，才好多了。 这段时间，我丧失了斗志，每天的生活就是做饭、烧水、洗碗、喂药、买菜之类。一天三轮，累觉不爱。这段时间温习了家乡做面汤的手法。面汤在陕西称之为拌汤（读音为bian、tang）。除此之外，打发无聊的生活的方式还有看电视剧。我和勺妈看了《爱情最美丽》、《神探狄仁杰I》。\n对了，中午收到了研究生院的email，确定了答辩时间为8月26日。\n首页图片 勺妈睡着了，我才有时间去整理了下网站首页的图片无法显示的问题。使用火狐浏览器看了下，原来是ReferenceError: $ is not defined这个问题。在stackoverflow上面的回答说要：Add JQuery library before your script so that $ can be identified.我去看了下网站的html，发现是有jquery这个库的，只是版本过低。于是更新了一下jquery的版本就解决了问题。如下：\n\u0026lt;script src=\u0026quot;http://code.jquery.com/jquery-1.11.0.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  ","tags":null,"title":"乡旅西安","type":"note"},{"authors":null,"categories":null,"content":" 最近的压力有一点大。新网站、老板的中文情感分析任务、和Yanto等新启动的项目、和小可的论文、和计算士的合作。一个一个说说看，缓解一下压力。\n新的网站终于上线了，还有一堆问题没有搞定。 自己泡在farbox的api文档中一段时间啦。在we.farbox.com上问hepochen两个问题。第一个问题是如何多人上传；第二个问题是如何建立多个作者的列表。hepochen一个人做起了farbox的各种工作，颇有些程序员创业的艰辛。我还在执著地要给作者建立post的索引。\n说到上线，更多是符号的意义。因为就是将域名设定为了http://computational-communication.com。这个域名里有三个com。可以简称之为3com网站， 英文讲起来是Triple Com，颇有点EEE和WWW的霸气。期间跟远在新加坡的godaddy客服英文电话了两次，主要是解决nameserver和dns里的mx设定的问题。\n中文情感分析 改动了tt小合子的python代码，把这个东西写得更完备了一些。算是一个锻炼吧。不过想想或许不如直接用原作者开源的python代码。我称之为使用中文文法分析为情感分析重新造轮子。最难的是发展字典，到这里了。例会的时候，我问了老板的意见，决定先搁置这个任务。\nYanto这边的论文 主题模型做了差不多一年啦，初稿才出来。期间太艰辛了，不过结果的确比我一个人能做出的要好。是一个collective思维的流动的过程。\nYanto大手一挥，我们要开启一个method paper。我对此很怀疑。去查了论文，从spatial pattern的角度去做不是太相关的。\n小可这边的合作 小可的要求不算高，我们统计了校内网络初期两年增长的一些基本特征。没有做深入，他发过来一篇论文过来，我还没好好看。\n计算士的idea 计算士是我见到的不多的非常投入研究的人。方向对了，感觉整个人过了几年的积累完全不一样了。谈好了我去抓一个网站，于是开始写代码，结果腾讯的内网结结实实地把我挡住了。小郁闷下，转过身去在自己电脑上开始鼓捣起来。一定要有点起色。\n又写了一天代码。终于可以运转了。自己这一年好像经常抓数据了。挺喜欢github这个空间，没有太多的花哨的东西，一切有的只是一个自己写字的地方。不过运算的时间太长了，得找找有没有什么方法可以避免。我能想到的是多线程的抓取数据。\n","date":1404172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404172800,"objectID":"6d3332c786edd2992ba2f342b6bbae16","permalink":"https://chengjunwang.com/note/note_archive/2014-07-01-life-is-hard/","publishdate":"2014-07-01T00:00:00Z","relpermalink":"/note/note_archive/2014-07-01-life-is-hard/","section":"note","summary":"最近的压力有一点大。新网站、老板的中文情感分析任务、和Yanto等新启动的项目、和小可的论文、和计算士的合作。一个一个说说看，缓解一下压力。\n新的网站终于上线了，还有一堆问题没有搞定。 自己泡在farbox的api文档中一段时间啦。在we.farbox.com上问hepochen两个问题。第一个问题是如何多人上传；第二个问题是如何建立多个作者的列表。hepochen一个人做起了farbox的各种工作，颇有些程序员创业的艰辛。我还在执著地要给作者建立post的索引。\n说到上线，更多是符号的意义。因为就是将域名设定为了http://computational-communication.com。这个域名里有三个com。可以简称之为3com网站， 英文讲起来是Triple Com，颇有点EEE和WWW的霸气。期间跟远在新加坡的godaddy客服英文电话了两次，主要是解决nameserver和dns里的mx设定的问题。\n中文情感分析 改动了tt小合子的python代码，把这个东西写得更完备了一些。算是一个锻炼吧。不过想想或许不如直接用原作者开源的python代码。我称之为使用中文文法分析为情感分析重新造轮子。最难的是发展字典，到这里了。例会的时候，我问了老板的意见，决定先搁置这个任务。\nYanto这边的论文 主题模型做了差不多一年啦，初稿才出来。期间太艰辛了，不过结果的确比我一个人能做出的要好。是一个collective思维的流动的过程。\nYanto大手一挥，我们要开启一个method paper。我对此很怀疑。去查了论文，从spatial pattern的角度去做不是太相关的。\n小可这边的合作 小可的要求不算高，我们统计了校内网络初期两年增长的一些基本特征。没有做深入，他发过来一篇论文过来，我还没好好看。\n计算士的idea 计算士是我见到的不多的非常投入研究的人。方向对了，感觉整个人过了几年的积累完全不一样了。谈好了我去抓一个网站，于是开始写代码，结果腾讯的内网结结实实地把我挡住了。小郁闷下，转过身去在自己电脑上开始鼓捣起来。一定要有点起色。\n又写了一天代码。终于可以运转了。自己这一年好像经常抓数据了。挺喜欢github这个空间，没有太多的花哨的东西，一切有的只是一个自己写字的地方。不过运算的时间太长了，得找找有没有什么方法可以避免。我能想到的是多线程的抓取数据。","tags":null,"title":"世界之外的角落","type":"note"},{"authors":null,"categories":null,"content":" 老师在我的心中占有非常重要的地位。人生往往起于卑微，所面对的却是一个庞大到令人无措的世界。面对令人错愕的现实，每个人内心深处都有自己所坚守的地方。而这些地方的存在往往来自于个体的对于世界的学习。而认知世界最好的方法莫过于寻找一位良师。师者，传道授业解惑也。所以有孟母三迁的故事；反过来则有墨子悲染的故事。得良师而不从之学，无疑是最可惜的事情啦。古语云：君子隆师。诚哉斯言！我写这篇文章主要是为了记下我过去生活的一些片段，庆祝祝建华老师的60岁生日。\n刚才说到墨子，我就在墨子故里长大。一直到读书到高中开始阅读县志的时候，我才知道我所生活的地方正是墨子故里。墨子名翟，是周朝没落贵族。翟的意思就是凤凰，而在我外祖母家附近就有一座山名唤“落凤”，传说是凤凰落下、墨子诞生的地方。墨子被认为是中国科学的始祖（“科圣”），因为他做出了一些重要的科学发现（比如小孔成像）。除此之外，墨子还有了不起的政治思想，他破天荒地主张“兼爱非攻”，并成功地止楚攻宋。后来我知道，我的故乡的背面是邹城，那里是孟子故里，而邹城北面是曲阜，就是孔子故里了。小子何知，所生活的贫瘠的土地上也曾有这么多的思想者在两千年前积极奔走。不过，时代久远了，所残留下来的只有一些简短的的传说，变了样子的景观而已。让人唏嘘的是虽然人事物俱成一抔黄土了，墨子的思想犹在！\n作为一个年轻人，认准一个方向，用志不分，是很容易做出一点成绩的。问题就在于找到一个努力的方向。诚如茨威格所言：一个人命中最大的幸运，莫过于在他的人生中途，即在他年富力强之时发现了自己生活的使命。\n我在24岁之前一直在寻找这样一种可能的方向。高考之后，我从山东来到甘肃兰州读书。在大学里，我常常苦恼于无法真正运用所学的东西。于是先学理科，后来改文科。有一段时间觉得自己应该好好学学经济学，后来也没有结果了。后来自己来到燕园读媒体经营管理方向的为期两年的硕士学位，后来发现这其实跟管理没有多大关系。幸运的是遇到了刘德寰老师，开始学习社会调查和统计的知识。硕士一年之后，同学们就开始疯狂地开始找工作。我则开始了名为最后的狂欢：听各种暑期课。\n2009年7月20日全国研究生暑期学校（新闻传播学及研究方法前沿），我第一次见到了传说中的祝建华老师。在那段时间，还听了Winson师兄讲解结构方程的课。事实上，我之前就关注过竹家庄的博客，到处找寻过《祝建华研究案例汇编》。所以，知道有这么一个讲习班的时候，就毅然绝然地去蹭了几次。\n2009年10月22日，祝老师有一次来北京招生，曾经宴请了一些有意申请香港城市大学博士项目的同学，那是我第一次跟祝老师吃饭。忘记了秦洁在不在，如果不在，我就是那些人当中唯一过来城大读博的同学。\n2010年5月，我在网络上报名参加了祝建华老师的在清华大学讲解的《结构方程模型原理及其应用》课程，算是第一次正式作为学生听祝老师的课（那时候“痴迷”于研究方法，人大暑期班是蹭的，类似的我还蹭了北大-密大的几次暑期班）。\n在2009年10月的时候，我还没有打定注意要不要再读一个博士学位，主要是自己当时对于新闻传播领域本身的兴趣并不太浓厚；阅读学术文章，并不能获得一种兴奋的感觉。在这个时候，师兄吴令飞的鼓励起来很大的作用。阅读英文并不流畅的我在匆匆准备了一个月就考了托福，开始了申请香港博士的道路。\n应该说成为竹家庄一员当时挺折腾的，因为直到我硕士快要毕业了，还没有收到博士申请的结果。在那段时间里，我找了一个《民航报》的工作。硕士答辩之后，签了就业的三方协议，租好了房子，准备开始在北京的工作。造物弄人，这个时候城大申请结果方才出来。在得知自己可以跟随祝老师读博之后，我经过了一个小小的痛苦的选择：毁约读博。\n于是2010年9月我来到香港，住在笔架山下的学生公寓。初来香港的时候，我身上并没有什么钱，学校的奖学金没有那么快发下来。于是我在香港第一次见祝老师，就向他借了一笔钱来支付入学的费用。期间，为了让我们这些平时说汉语写汉语的学生融入英文环境，我们只能用英文给老师写邮件。每一周都要写一个周记来报告自己一周以来的进展。有时候，祝老师还会回复。当然，我也因为英文闹过几次笑话。每次想来，总是莞尔。\n后来，就开始上祝老师开的课，做那些繁琐复杂的习题。祝老师的教导在这个时候是手把手教的。记得为了让我、臻真和秦洁掌握SPSS的编程语言，祝老师还专门给我们非常具体地讲解过几次。后来，我自己却开始抛弃用了一段时间的SPSS, Stata, Amos等工具，开始投入R语言。再到后来，实验室又开始随着社会化媒介的发展（主要是OAuth2.0协议）进一步转向使用Python作为编程语言。为此，祝老师还专门请合作者给我们讲解Python的基本使用方法。许小可来实验室交流阶段，老板还特地抽时间参加了我们对于Matlab的使用与网络科学研究的讨论。\n每周与祝老师交流最多的时候其实就是组会了。每周，祝老师都一定在一个固定的时间与实验室成员讨论。大到实验室的研究项目，小到个人的生活困惑，都在轻松随意的氛围里一一讨论，认真参详。有时候是建议，有时候是争论，还有时候是“赌博”。仔细想来，祝老师用各种方法调动我们做研究的热情。当然了，面对一个好的老师，除了听其言观其行之外，最快的学习方式就是提问了。祝老师的讲解，往往也形象生动，夹杂着很多亲身的故事，非常有说服力。悲催的是我发现我自己每次跟祝老师赌，都会输。于是后来我就不赌了。\n除了累积的经验之外，我开始越来越深入地感触到祝老师思维方式中的一以贯之的理性。这种理性的力量，一开始会让偏感性的听者产生质疑，待听其仔细论证，则往往为之折服。慢慢地我意识到这其实就是科学研究中重要的特质。后来，我发现祝老师不仅仅在科学研究中如此，一以贯之的理性推演作为一种分析问题的方式体现在祝老师生活中的每一个细节。不要轻视思维的力量。积极地运用理性的思考可以帮助我们理解很多被我们所忽略的问题。受其启发，我总结了一句话作为自己的座右铭：Follow your logic!读到这里，你受到理性的力量的感染了吗？或许这也可以帮助我们理解为什么祝老师可以那么帅，并且越来越帅！不要以为这不可能，为什么不试试看呢？\n保持开放的头脑、保持专注、保持对新的研究方向的敏感。参加了西雅图的ICA年会之后回来，向老板报告了自己的一些疑惑。祝老师的回答一如既往地让人耳目一新。也许我们总会被眼前的很多事情所遮蔽，但是对于一个学者而言，最重要的硬通货只有两个:“Paper and grant”。一语中的。于是，很多所谓的难题迎刃而解。\n博士四年是一场洗礼。在这四年里，我学到了很多以前不曾想到自己可以学习的东西。“活着是一种修行”。很多看似很难做的决定，放在一个更长的时间尺度里往往会变得异常简单。于是很多想不清楚的事情就变得清楚了，放不下的事情也能慢慢放下了。离开民航报的时候，当时报社老大对我说，无论在什么领域都要做到这个领域里面最好的。时间过去了四年，再回过头来思考这句话，我只能说至少我见过了在这个领域所能做到的最好的水平。\n在网络挖掘实验室中四年，收获颇多，此行不虚。回想，过去的四年里，祝老师的渐渐多起来的华发里总有一些是我这厢的各种问题导致的，顿感惭愧。忝列实验室一员，但求无损于师门。在毕业的时候，躬逢祝老师60岁生日这一盛事，又是何等得荣幸。“君子隆师”，祝愿老师身体好、心情好、工作好！\n尾注：\n我在Github上找了几个javascript的模板，做了两个网页，用来记录祝老师的媒介影像和学术道路，见下面的链接：\n1. 祝老师的媒介影像\n2. 祝老师的学术道路\n ","date":1402272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1402272000,"objectID":"4d77b035c75f8e47fd3ca8095e62e528","permalink":"https://chengjunwang.com/note/note_archive/2014-06-09-my-teacher/","publishdate":"2014-06-09T00:00:00Z","relpermalink":"/note/note_archive/2014-06-09-my-teacher/","section":"note","summary":" 老师在我的心中占有非常重要的地位。人生往往起于卑微，所面对的却是一个庞大到令人无措的世界。面对令人错愕的现实，每个人内心深处都有自己所坚守的地方。而这些地方的存在往往来自于个体的对于世界的学习。而认知世界最好的方法莫过于寻找一位良师。师者，传道授业解惑也。所以有孟母三迁的故事；反过来则有墨子悲染的故事。得良师而不从之学，无疑是最可惜的事情啦。古语云：君子隆师。诚哉斯言！我写这篇文章主要是为了记下我过去生活的一些片段，庆祝祝建华老师的60岁生日。\n刚才说到墨子，我就在墨子故里长大。一直到读书到高中开始阅读县志的时候，我才知道我所生活的地方正是墨子故里。墨子名翟，是周朝没落贵族。翟的意思就是凤凰，而在我外祖母家附近就有一座山名唤“落凤”，传说是凤凰落下、墨子诞生的地方。墨子被认为是中国科学的始祖（“科圣”），因为他做出了一些重要的科学发现（比如小孔成像）。除此之外，墨子还有了不起的政治思想，他破天荒地主张“兼爱非攻”，并成功地止楚攻宋。后来我知道，我的故乡的背面是邹城，那里是孟子故里，而邹城北面是曲阜，就是孔子故里了。小子何知，所生活的贫瘠的土地上也曾有这么多的思想者在两千年前积极奔走。不过，时代久远了，所残留下来的只有一些简短的的传说，变了样子的景观而已。让人唏嘘的是虽然人事物俱成一抔黄土了，墨子的思想犹在！\n作为一个年轻人，认准一个方向，用志不分，是很容易做出一点成绩的。问题就在于找到一个努力的方向。诚如茨威格所言：一个人命中最大的幸运，莫过于在他的人生中途，即在他年富力强之时发现了自己生活的使命。\n我在24岁之前一直在寻找这样一种可能的方向。高考之后，我从山东来到甘肃兰州读书。在大学里，我常常苦恼于无法真正运用所学的东西。于是先学理科，后来改文科。有一段时间觉得自己应该好好学学经济学，后来也没有结果了。后来自己来到燕园读媒体经营管理方向的为期两年的硕士学位，后来发现这其实跟管理没有多大关系。幸运的是遇到了刘德寰老师，开始学习社会调查和统计的知识。硕士一年之后，同学们就开始疯狂地开始找工作。我则开始了名为最后的狂欢：听各种暑期课。\n2009年7月20日全国研究生暑期学校（新闻传播学及研究方法前沿），我第一次见到了传说中的祝建华老师。在那段时间，还听了Winson师兄讲解结构方程的课。事实上，我之前就关注过竹家庄的博客，到处找寻过《祝建华研究案例汇编》。所以，知道有这么一个讲习班的时候，就毅然绝然地去蹭了几次。\n2009年10月22日，祝老师有一次来北京招生，曾经宴请了一些有意申请香港城市大学博士项目的同学，那是我第一次跟祝老师吃饭。忘记了秦洁在不在，如果不在，我就是那些人当中唯一过来城大读博的同学。\n2010年5月，我在网络上报名参加了祝建华老师的在清华大学讲解的《结构方程模型原理及其应用》课程，算是第一次正式作为学生听祝老师的课（那时候“痴迷”于研究方法，人大暑期班是蹭的，类似的我还蹭了北大-密大的几次暑期班）。\n在2009年10月的时候，我还没有打定注意要不要再读一个博士学位，主要是自己当时对于新闻传播领域本身的兴趣并不太浓厚；阅读学术文章，并不能获得一种兴奋的感觉。在这个时候，师兄吴令飞的鼓励起来很大的作用。阅读英文并不流畅的我在匆匆准备了一个月就考了托福，开始了申请香港博士的道路。\n应该说成为竹家庄一员当时挺折腾的，因为直到我硕士快要毕业了，还没有收到博士申请的结果。在那段时间里，我找了一个《民航报》的工作。硕士答辩之后，签了就业的三方协议，租好了房子，准备开始在北京的工作。造物弄人，这个时候城大申请结果方才出来。在得知自己可以跟随祝老师读博之后，我经过了一个小小的痛苦的选择：毁约读博。\n于是2010年9月我来到香港，住在笔架山下的学生公寓。初来香港的时候，我身上并没有什么钱，学校的奖学金没有那么快发下来。于是我在香港第一次见祝老师，就向他借了一笔钱来支付入学的费用。期间，为了让我们这些平时说汉语写汉语的学生融入英文环境，我们只能用英文给老师写邮件。每一周都要写一个周记来报告自己一周以来的进展。有时候，祝老师还会回复。当然，我也因为英文闹过几次笑话。每次想来，总是莞尔。\n后来，就开始上祝老师开的课，做那些繁琐复杂的习题。祝老师的教导在这个时候是手把手教的。记得为了让我、臻真和秦洁掌握SPSS的编程语言，祝老师还专门给我们非常具体地讲解过几次。后来，我自己却开始抛弃用了一段时间的SPSS, Stata, Amos等工具，开始投入R语言。再到后来，实验室又开始随着社会化媒介的发展（主要是OAuth2.0协议）进一步转向使用Python作为编程语言。为此，祝老师还专门请合作者给我们讲解Python的基本使用方法。许小可来实验室交流阶段，老板还特地抽时间参加了我们对于Matlab的使用与网络科学研究的讨论。\n每周与祝老师交流最多的时候其实就是组会了。每周，祝老师都一定在一个固定的时间与实验室成员讨论。大到实验室的研究项目，小到个人的生活困惑，都在轻松随意的氛围里一一讨论，认真参详。有时候是建议，有时候是争论，还有时候是“赌博”。仔细想来，祝老师用各种方法调动我们做研究的热情。当然了，面对一个好的老师，除了听其言观其行之外，最快的学习方式就是提问了。祝老师的讲解，往往也形象生动，夹杂着很多亲身的故事，非常有说服力。悲催的是我发现我自己每次跟祝老师赌，都会输。于是后来我就不赌了。\n除了累积的经验之外，我开始越来越深入地感触到祝老师思维方式中的一以贯之的理性。这种理性的力量，一开始会让偏感性的听者产生质疑，待听其仔细论证，则往往为之折服。慢慢地我意识到这其实就是科学研究中重要的特质。后来，我发现祝老师不仅仅在科学研究中如此，一以贯之的理性推演作为一种分析问题的方式体现在祝老师生活中的每一个细节。不要轻视思维的力量。积极地运用理性的思考可以帮助我们理解很多被我们所忽略的问题。受其启发，我总结了一句话作为自己的座右铭：Follow your logic!读到这里，你受到理性的力量的感染了吗？或许这也可以帮助我们理解为什么祝老师可以那么帅，并且越来越帅！不要以为这不可能，为什么不试试看呢？\n保持开放的头脑、保持专注、保持对新的研究方向的敏感。参加了西雅图的ICA年会之后回来，向老板报告了自己的一些疑惑。祝老师的回答一如既往地让人耳目一新。也许我们总会被眼前的很多事情所遮蔽，但是对于一个学者而言，最重要的硬通货只有两个:“Paper and grant”。一语中的。于是，很多所谓的难题迎刃而解。\n博士四年是一场洗礼。在这四年里，我学到了很多以前不曾想到自己可以学习的东西。“活着是一种修行”。很多看似很难做的决定，放在一个更长的时间尺度里往往会变得异常简单。于是很多想不清楚的事情就变得清楚了，放不下的事情也能慢慢放下了。离开民航报的时候，当时报社老大对我说，无论在什么领域都要做到这个领域里面最好的。时间过去了四年，再回过头来思考这句话，我只能说至少我见过了在这个领域所能做到的最好的水平。\n在网络挖掘实验室中四年，收获颇多，此行不虚。回想，过去的四年里，祝老师的渐渐多起来的华发里总有一些是我这厢的各种问题导致的，顿感惭愧。忝列实验室一员，但求无损于师门。在毕业的时候，躬逢祝老师60岁生日这一盛事，又是何等得荣幸。“君子隆师”，祝愿老师身体好、心情好、工作好！\n尾注：\n我在Github上找了几个javascript的模板，做了两个网页，用来记录祝老师的媒介影像和学术道路，见下面的链接：\n1. 祝老师的媒介影像\n2. 祝老师的学术道路\n ","tags":null,"title":"君子隆师：记我的博士导师祝建华先生","type":"note"},{"authors":null,"categories":null,"content":" 本文试图从传播的角度思考中国社交网站的发展，限于作者的认识，定然有很多不成熟的地方。但是作为一个开端，这是有益的尝试。\n社交网站的需求 社交网站基于关系的类型可以分为熟人关系和陌生人关系。人人网、脸书、QQ、微信基本上都是针对熟人关系的，这种关系多数存在线下的关联（似乎至少在两步的距离之内）；陌生人关系则相对宽泛，如陌陌。除了基于社交关系的网站之外，还有基于兴趣和信息的网站，如微博和豆瓣。而如秘密等手机应用，则试图构建熟人之间的陌生关系。\n社交网站自身的需求当然是庞大的用户数量、活跃的用户规模、消费的用户行为。究其本质，社交网站主要依赖广告和游戏收入。互联网思维的强悍之处就在于第一步是赔本赚吆喝：扩大用户规模。基于庞大的用户规模，互联网广告就会注入，为网站提供资金源。另外一个方面，网站本身也需要自谋生路，游戏被认为是获取收益的关键。当然，游戏本身也可以搭载广告。\n基于机器学习思路建立起来的数据挖掘系统存在一个缺陷：对数据的挖掘并不深入。尤其是在数据本身较为复杂且包含着噪音的情况下。机器学习最重要的一步工作是特征的选取。一个有经验的工程师带着两三个年轻人两到三年就可以把一个项目的主要特征挖得差不多。如何进一步深入，往往是一个问题。大数据时代的到来和深度学习的提出，给出了一种可能的解答。但是这种解答本身却因学习深度的增加而存在着难以解释的困境。这种问题对于社交网站而言，表现尤为明显，所以今天的脸书、人人网、QQ等面临着这个挑战。怎么解决这个问题？\n何为传播的角度 社交行为本身而言，是一种传播。从传播网络和传播过程的角度理解社交网络和社交行为可以为社交网站所面临的困境提供一些答案。这就是把传播的角度引入社交网站数据挖掘的原因。那么何为传播的角度？传播驱动的社交网站数据挖掘主要关注什么？有能够提供什么样的结果？我们从社交网络用户的关系的复杂性 （时间、地理、属性）开始谈起。\n图：邓巴数与关系的层次 /来源： 知乎\n是关系就有强有弱，线上关系也是一样。强的关系是相对较少的，弱的关系是相对较多的。强关系的社会意义是情感性的、生活方式的捆绑（bonding），因而被认为有着非常重要的作用。弱关系则具有传递信息的功能，因而反而对个人的很多选择具有重要影响。弱关系之所以具有传递有效信息的功能就是因为你的弱关系多与你处于不同的社会群体和社交圈子里，大家所处的环境不同，接触到的人和事不同，因而在信息共享方面具有很强的互补性。古语云：兼听则明偏信则暗。其实不是说数量，而是说要听取不同群体的意见。你的弱关系往往发挥着链接不同的群体的作用，这种作用又被称为桥接（bridging）的功能。\n很重要的一点是社交关系的流动，被封存起来的关系因为时间和地理的隔离而逐渐丧失了影响力。Dr.Thinker很明确地指出了这一点。如下图所示，我们有儿时的玩伴，中学同学、大学同学、工作同事、自己的家人。这些关系在我们人生中的每一个阶段而有所不同。社交网络帮助人们以较低的成本更好地去维持过去时空里的关系 （maintaining relationships）。因而，现实就是沉淀在社交网络里的关系具有时空的异质性。不同的人的影响权重并不相同。\n图：社交网络的流动 /来源： 知乎\n社交圈子（social circle）是过去几年里比较火的概念。有一本书就叫《小圈子大社交：利用圈子引爆流行》，英文名为Grouped: How small groups of friends are the key to influence on the social web 。作者是Paul Adams，他先后供职于谷歌和脸书。据说在谷歌的时候，他就写完了一本书，书名叫《Social Circles: How offline relationships influence online behavior and what it means for design and marketing 》。因为谷歌的限制，这本书从未出版，后来其主要的思想应用到了google plus 的设计中。由书名可以知道这本书的核心是要实现关系从线下到线上的迁移，以及如何利用这种真实关系在虚拟空间的重现来设计网站和营销活动。\n从时间的角度还可以对关系进行进一步的划分：一周联系一次，一个月联系一次，几个月联系一次，一年联系一次，数年不联系的人。这从更深入的细节上揭露了网络的特点。有时候，不联系的关系也许是线下的非常重要的关系，但是并没有实现这种关系向线上的迁移。基于这种认识，Paul给那种不经常联系的关系称之为暂时性关系（temporal relationship）。\n图：社会网络结构 /来源： Paul Adams\n社区是现实社会的基本单位。在进行网络研究的时候，也可以进行类似的社区划分（community detection，也称为社团划分）。\n图：社交圈子 /来源： 知乎\n当然了，这种理解还是不够深入，因为它依然停留在对于中心个体给朋友贴标签的层面上。Paul Adams 所设想的景象如下图所示，我们不仅仅要能抓住个人中心网络当中的圈子，还要能够把握朋友的圈子。在一个slides当中，Paul更加详细地展现了自己的想法，见How Your Customers\u0026rsquo; Social Circles Influence What They Buy, What They Do and Where They Go\n图：深入到朋友的社交圈子？ /来源： Paul Adams\n正是因为网络中个体和节点的复杂性，Paul认为社交网站当务之急是需要围绕人来重新建设社交网络（rebuild the social web around people）！这样做的好处是：便于人们以更低成本迁移线下关系到线上网络；同时，可以剔除噪音，减小计算复杂性。相反，如果无法剖析出哪些关系是有效关系，哪些关系是沉睡的关系，对于所有的计算使用相同的权重，就会使我们陷入纯粹计算的层层迷雾。以下，我将试图谈一些社交网站最关心的业务，帮助我们来思考传播驱动的数据挖掘。\n产品推荐 要扩大用户的规模，第一步当然是产品的推广。说到产品的推荐，人们的第一印象是推销员、促销活动、广告等。社交网站的推广也有类似的道理。如何还没有使用某一款产品的人使用它呢？社交网络有自己的回答：人际作用（interpersonal effect），也可以表达为社交影响（social influence）。当然了，创新者总会很早就采纳创新，并将产品介绍给周围的人。基于引爆点（tipping point）的理论，一旦系统中有足够的人使用是，该创新就可以迅速扩散。网络的作用是具有传染性，入网的用户会将网外的用户拉进来，并产生滚雪球的作用。这是社交特性本身的特点。可以基于ABX模型来解释，AB是两个人，B喜欢X产品，那么A喜欢X产品的概率就很高。网络偏爱具有传递性的三角形。\n但是在实际的产品推荐的时候，需要考虑的事情很多。尤其针对社交网络而言，因为用户已经有了线下的社交系统，为什么还要使用线上的系统联系呢？这个时候要考虑用户迁移（由线下到线上）的成本，并尽可能降低这种成本。最简单的方法就是将新产品嫁接在一个强大的传播渠道上。什么传播渠道具有如此强的搭载能力？传播渠道要具有一些特点，例如它必须可以对应到每一个人。每一个人都强烈的依赖于它。显然，它是个体化的媒介产品。其次它必须积累了你的其它社交关系。有哪些这种记录了你的社交关系的个人媒介呢？它就是电子邮箱和手机号码。每个电子邮箱都记录了你的联系人，同样是手机的电话薄。有了这些东西，病毒传播就可以展开了。现在微博的发展非常好，购物网站纷纷寻求与其合作。为什么呢？因为微博同样记录了人的社交关系。\nlinkedin发展强烈的依赖于获取电子邮箱中的通讯录，并向通讯录中的朋友发送加入邀请。事实上，很多其它网站也采用这种方式。\nApp的推荐\n多数社交网站并无掌控手机App入口的能力。手机互联网的发展，催生了手机App的应用市场。App使得入口变得炙手可热。苹果手机以一种独占的形式，试图控制所有的应用安装入口。这给那些试图进一步做大的社交网站门户提出了挑战。例如，以往在腾讯游戏网站可以轻易安装的各种游戏，在手机上只能通过苹果的APP STORE安装。一些互联网公司只好试图发展超级APP, 即那些使用用户很多的APP，例如微信的手机APP和百度地图的手机App。App是搭载广告的良好载体。事实上，也许只有少数小众App才对用户收费。有实力有野心的超级APP是绝对不会牺牲用户数量来赚取那有限的收入的，他们的目标是广告商。\n于是，基于超级APP推广App也成为一个市场。本文关注社交网络（social web），主要想看如何从传播的角度来理解app在社会网络的扩散。通过社交网络推广App的的基本假设是线上的人际作用一样具有线下的人际作用所拥有的影响力。但是，这也许只是幻想：并不是说有了网络的形式就一定会有社交影响。因为社交影响基于有效地传播行为，而不仅仅是几年前就存在而并不活跃的朋友关系。问题就转变为激活线上人际关系！或者至少是找到那些被激活的人去传播。如何激活线上的人际关系？要引入局部信息。使得局部网络的信息可见化。\n不要太天真，因为可见化局部信息违背了用户的隐私。用户也许并不想让他的朋友的朋友也知道他的行为。所以，就不要公开了；甚至说用户也只是想让一些用户知道他的行为！怎么解决？只公布汇总的局部信息，将信息通过汇总而匿名化。其实，这提供了一个新的做产品的思路，即个性化的个人数据idata。他可以帮助社交网络用户迅速了解自己朋友的整体动态：都有多少人看了什么电影，在玩什么游戏。甚至说，可以在此基础上做一个社交网络的秘密app。即用户可以匿名化的发布一些信息，也可以有选择地浏览他们公布的信息。\n如何进一步激活？要在app中引入互动性！比如允许用户选择是否在好友网络中公布自己玩某个app的成绩，或者允许用户去挑战他的一个的好友（其实是邀请新用户）。\n朋友推荐 朋友的推荐的主要目的则是给用户推荐一些他还没有加的朋友。这个其实发展比较成熟，主要是将链路预测的算法应用到这个场景中来。这种推荐一般而言是有风险的。因为一些用户之所以不加一些人实际上是出于回避的目的，这个时候推荐给他们，就会适得其反。怎么办呢？基于时空信息做新关系的推荐。尤其是当用户更换地理位置时，往往要带来一批新的人际关系进来。\n微信刚开始普及的时候，就抓住了手机电话薄的作用。当我把自己的skype登记的手机号码从香港号码改成北京移动的号码之后，一个小时之内，很多我以前经常联系的研究生同学就向我发来了好友邀请。我的第一感觉是我正要去找你们，你们自己就来了。但是这个故事也说明了问题所在：微信依然默认一个人只有一个邮箱、只有一个手机号码。这恰恰是其产品没有完全做好的一个表现。\n 应该允许用户填写多个电子邮箱！ 应该允许用户填写多个手机号码！ 应该允许用户填写其它网络账号！  为什么无效？  为什么会失效，为什么什么不能发现有效的影响，因为网络也是有噪音的。解决方法就是要提取出有效网络。这里存在一个有效网络假设，因为我们要剔除沉睡链接，剔除暂时性链接，专注于此时此刻的强关系。为什么要专注于有效网络假设呢？因为只有它们才有影响力。影响力网络是我们首先要挖掘的。中国的乡土社会还是按照实际强关系的影响力展开的。  但这里有风险，来自于信息型网络的风险。因为，弱关系里隐含着信息力量。如何规避这种风险？这时候可以采用自下而上的策略：分析扩散网络。扩散网络不同于社交关系网络，因为它首先是行为的传递。根据历史信息的传递网络（例如app的使用）可以与影响力网络相互印证，这也是从另外一个角度构建影响力网络。\n 为什么传播会失败， 因为与用户的安全相抵触，例如QQ圈子的提出与用户的隐私冲突。这里要注意维护用户价值。用户对于隐私冲突的反弹，说明了腾讯用户的转变：保护自我价值的意识。人是QQ的核心，没有了节点，就没有了链接，做连接一切的公司就成了梦幻泡影。  腾讯一开始就专注于从人的欲望本身设计产品，满足人的表达、倾诉、和分享的欲望。但是一度依赖，QQ的用户的用户倾向于被认为是低龄的低端用户。这这一定程度上会让产品设计者进一步误解用户的需求：不要把用户当傻子。如果一个程序可以自我迭代，一个人就不会自我成长吗？所以，不要把用户当傻子，不要满足于眼前的成功。尊重用户的价值，让用户自己选择，让用户自己构建。\n 为什么产品会失败，因为没有展示的空间， 以QQ为例，狭窄的面板根本挤不下那么多的产品。QQ上的产品有的独立了出来，有的还要寄人篱下。所谓独立是指拥有自己独立的王国，如游戏和微信。  手机互联网的发展，进一步提出了更苛刻的挑战：因为手机屏幕更小。如何才能生长出独立的产品来？说到底还是要靠APP。从App的角度思考，手机互联网对整个腾讯而言是一次巨大的机遇：因为如果你坚信一个子产品足够出色，做出一个独立的APP来展现它。通过累积的巨大的社交网络来传播它。\n如何盘活QQ圈子？ 我想整个问题见仁见智，我这里也主要是按照传播的逻辑提供一些思路：\n 尊重用户价值：让用户自己选择 用户数据统计\u0026amp;好友汇总数据统计：了解但不越界 挑战好友：游戏pk 提问好友：困惑解答 匿名表达：秘密倾诉 自我记录：自我成长 独立的手机APP  激活社交网络 比较QQ和微信的差别 QQ当然是一款成功的社交软件。它让人们可以有效地保存既有社交资源并允许群组讨论。但沉淀下来社交关系后如果随着时间失去活跃性，其本身的价值就很有限。人总是在不同人生阶段认识不同的人，对于添加的好友须按照时间序列进行组织，例如手工分组。社交软件可以辅助好友分组，例如自动推荐组名。QQ另一功能是QQ群，它満足了人们在一群人当中讨论的需求；除了一对一和群组讨论之外，人还有一对多地发表自我感想的强烈需求，后者通过QQ zone得以实现。\n动态的关系：活在当下 微信的崛起在于对有效网络的组织方面。首先，激活有效网络，其次在于厘清前台与后台的界限。关系本身并不一定有效果，只有动态中的关系才能抓住用户。上文已经谈论过关系的类别。QQ中沉淀的大多数关系其实对于用户当下生活并无直接影响。这会让用户产生一种错觉：这里仅是关系的档案馆，平时并无使用的必要。其实人人网正面临这种困境，即当好友加完之后怎么吸引用户。这方面微信具有天然的优势，因为作为手机APP它是建筑在手机通讯录上面的。手机号码与QQ号码相比，更接近线下动态的社交关系。同样道理，QQ中的群组则落后很多，因为它具有太明显的静态性。微信群则可因时因地随时结成。\n手Q是微信前身，然而背负着QQ产品沉重的历史包袱，所以其发展被多方掣肘。比如QQ一直以来面临定位低端产品形象不够专业的问题。但为了保持与PC端一致性所以难以改良，造成用户流失。微信从产品名称定位以及其他设计方面则具有较高灵活性，例如其开机画面就很有意思。\n当然了，如此定位的两种产品有竞争也有辅助。动态关系的支柱是强关系，静态关系则包括大量弱关系。这样一方面二者在不同关系层面有所侧重，另一方面，作为新产品，微信更容易抢走QQ中的动态关系。\n参考文献 Paul Adams (2011) Grouped: How small groups of friends are the key to influence on the social web. New Riders\n","date":1400025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1400025600,"objectID":"74fde617dd79a0b9eb5671405bcc5686","permalink":"https://chengjunwang.com/note/note_archive/2014-05-14-tencent-reflection/","publishdate":"2014-05-14T00:00:00Z","relpermalink":"/note/note_archive/2014-05-14-tencent-reflection/","section":"note","summary":"本文试图从传播的角度思考中国社交网站的发展，限于作者的认识，定然有很多不成熟的地方。但是作为一个开端，这是有益的尝试。\n社交网站的需求 社交网站基于关系的类型可以分为熟人关系和陌生人关系。人人网、脸书、QQ、微信基本上都是针对熟人关系的，这种关系多数存在线下的关联（似乎至少在两步的距离之内）；陌生人关系则相对宽泛，如陌陌。除了基于社交关系的网站之外，还有基于兴趣和信息的网站，如微博和豆瓣。而如秘密等手机应用，则试图构建熟人之间的陌生关系。\n社交网站自身的需求当然是庞大的用户数量、活跃的用户规模、消费的用户行为。究其本质，社交网站主要依赖广告和游戏收入。互联网思维的强悍之处就在于第一步是赔本赚吆喝：扩大用户规模。基于庞大的用户规模，互联网广告就会注入，为网站提供资金源。另外一个方面，网站本身也需要自谋生路，游戏被认为是获取收益的关键。当然，游戏本身也可以搭载广告。\n基于机器学习思路建立起来的数据挖掘系统存在一个缺陷：对数据的挖掘并不深入。尤其是在数据本身较为复杂且包含着噪音的情况下。机器学习最重要的一步工作是特征的选取。一个有经验的工程师带着两三个年轻人两到三年就可以把一个项目的主要特征挖得差不多。如何进一步深入，往往是一个问题。大数据时代的到来和深度学习的提出，给出了一种可能的解答。但是这种解答本身却因学习深度的增加而存在着难以解释的困境。这种问题对于社交网站而言，表现尤为明显，所以今天的脸书、人人网、QQ等面临着这个挑战。怎么解决这个问题？\n何为传播的角度 社交行为本身而言，是一种传播。从传播网络和传播过程的角度理解社交网络和社交行为可以为社交网站所面临的困境提供一些答案。这就是把传播的角度引入社交网站数据挖掘的原因。那么何为传播的角度？传播驱动的社交网站数据挖掘主要关注什么？有能够提供什么样的结果？我们从社交网络用户的关系的复杂性 （时间、地理、属性）开始谈起。\n图：邓巴数与关系的层次 /来源： 知乎\n是关系就有强有弱，线上关系也是一样。强的关系是相对较少的，弱的关系是相对较多的。强关系的社会意义是情感性的、生活方式的捆绑（bonding），因而被认为有着非常重要的作用。弱关系则具有传递信息的功能，因而反而对个人的很多选择具有重要影响。弱关系之所以具有传递有效信息的功能就是因为你的弱关系多与你处于不同的社会群体和社交圈子里，大家所处的环境不同，接触到的人和事不同，因而在信息共享方面具有很强的互补性。古语云：兼听则明偏信则暗。其实不是说数量，而是说要听取不同群体的意见。你的弱关系往往发挥着链接不同的群体的作用，这种作用又被称为桥接（bridging）的功能。\n很重要的一点是社交关系的流动，被封存起来的关系因为时间和地理的隔离而逐渐丧失了影响力。Dr.Thinker很明确地指出了这一点。如下图所示，我们有儿时的玩伴，中学同学、大学同学、工作同事、自己的家人。这些关系在我们人生中的每一个阶段而有所不同。社交网络帮助人们以较低的成本更好地去维持过去时空里的关系 （maintaining relationships）。因而，现实就是沉淀在社交网络里的关系具有时空的异质性。不同的人的影响权重并不相同。\n图：社交网络的流动 /来源： 知乎\n社交圈子（social circle）是过去几年里比较火的概念。有一本书就叫《小圈子大社交：利用圈子引爆流行》，英文名为Grouped: How small groups of friends are the key to influence on the social web 。作者是Paul Adams，他先后供职于谷歌和脸书。据说在谷歌的时候，他就写完了一本书，书名叫《Social Circles: How offline relationships influence online behavior and what it means for design and marketing 》。因为谷歌的限制，这本书从未出版，后来其主要的思想应用到了google plus 的设计中。由书名可以知道这本书的核心是要实现关系从线下到线上的迁移，以及如何利用这种真实关系在虚拟空间的重现来设计网站和营销活动。\n从时间的角度还可以对关系进行进一步的划分：一周联系一次，一个月联系一次，几个月联系一次，一年联系一次，数年不联系的人。这从更深入的细节上揭露了网络的特点。有时候，不联系的关系也许是线下的非常重要的关系，但是并没有实现这种关系向线上的迁移。基于这种认识，Paul给那种不经常联系的关系称之为暂时性关系（temporal relationship）。\n图：社会网络结构 /来源： Paul Adams\n社区是现实社会的基本单位。在进行网络研究的时候，也可以进行类似的社区划分（community detection，也称为社团划分）。\n图：社交圈子 /来源： 知乎\n当然了，这种理解还是不够深入，因为它依然停留在对于中心个体给朋友贴标签的层面上。Paul Adams 所设想的景象如下图所示，我们不仅仅要能抓住个人中心网络当中的圈子，还要能够把握朋友的圈子。在一个slides当中，Paul更加详细地展现了自己的想法，见How Your Customers\u0026rsquo; Social Circles Influence What They Buy, What They Do and Where They Go","tags":null,"title":"传播驱动的社交网络数据挖掘","type":"note"},{"authors":null,"categories":null,"content":" 小村庄 我出生在鲁西南的一个小村庄，叫后仓沟村(地图)。当地人方言称之为后仓口。之所以成为后，是因为还有前仓和中仓。这三个村子合在一起称为仓口。后仓在滕州市县城的南面，一条滕枣公路在村东通过。村子背面是一个小村庄，就叫后小庄。后小庄的背面是放村，也分为前房和后房。然后，前房背面就是王开村。仓口和王开是以前比较好的村子，出了不少举人，称为金仓口，银王开。\n为什么叫仓沟呢？据说是因为收成很好，粮食满仓满沟。百度一下，找到这样的介绍：\n 后仓沟村归南沙河镇管理、与古石一村、后小庄村同乡,交通便利,人杰地灵,水美,友好好客主要农产品：香菜、香菇、紫色包心菜、沙果、乌饭果、橘子。村内资源：银、滑石。\n 你看，这些地名都透着乡土气。南沙河镇来源于一条叫南沙河的河流。除了南沙河，还有东沙河。沙河里当然有沙了。小时候，小孩子问大人“我是从哪里来的呢？”大人就会说“你是从沙河里捡的。” 在相当一段时间里，沙河都被一直采沙。因此，河道有很多被掏空的地方，水流也变得奇特。涨水的时候，很容易淹死人。这个城市盛产煤矿。但是，很快都被掏空。于是，就有白日地陷的事情发生。\n果园 这跟我自己的理解有点偏差：枣庄市盛产石榴和梨，有万亩榴园和万亩梨园。我承认，我也就是上大学之后，坐火车在薛城站下车，之后转乘汽车的时候远远的看到万亩梨园和万亩榴园。\n我家里之前种果园，种的水果主要是苹果和梨。我爷爷是一个“文化人”。好像读过私塾，总之会写字。三爷讲过一个故事，说文革的时候，村子里面扫盲。干部下来检查，村领导就让爷爷装作扫盲成功的农民。三爷就是我三伯，爷爷的第三个孩子。我爷爷有七个孩子，六个儿子，一个女儿。女儿排行老五。而我爸爸排行最小。\n说起果园，爷爷那时候并不善经营。按照我爸爸的说法是又喜欢喝酒，生活过得并不好。有一年到了梨子成熟的时候，我爷爷就呼喊着三爷和四爷去城里卖梨。三爷和四爷偷懒，遇到一个卖咸鱼的人要和他们用咸鱼换梨，他们就把梨都换成了咸鱼。回来后，被我奶奶一顿骂。我爷爷却很高兴，叫我奶奶炒咸鱼，自己打了酒要开始喝。\n大爷、二爷、三爷、四爷都认真读了书。唯独我爸爸念书念到小学二年级就不读了。他很小的时候就生活在果园里，看果树。经常有人来偷水果，遇到他打不过的人，就爬上树，摘了沉甸甸的梨来丢名目张胆的小偷。说起这个果园也有个故事，说我爷爷之前的家境不错，后来积攒了钱买了几块地种果树。土改后，就给没收了，只留下一块。我妈妈嫁过来的时候还见过。我的记忆里就都模糊了，只模模糊糊得记着哪里有个汲水的大轱辘。爸爸给我说起那是的水果多么大多么好，说有一种梨叫金钟梨，长得特别大。不过我没有见到过，更没有吃到过。\n爷爷、奶奶和他们的子女 爷爷是独子，他从一个叫峡楼（音）的地方娶了奶奶。因为爷爷奶奶孩子多，我有记忆的时候爷爷奶奶都很老了。听说文革的时候，爷爷因为他的果园蹲过牛棚。爷爷和奶奶都很安土重迁，不愿意折腾，也不希望子女折腾。六爷和爸爸之前想当兵，都被阻止了。原因是爷爷和奶奶都在兵营里呆过。在后仓沟东有一个山村叫上营。通往上营的路上有一个二十四院屯国兵，有一个北大仓库屯过粮。爷爷有做饭的手艺，在兵营里做饭，奶奶在那里拆洗棉衣。他们目睹了伤兵的痛苦以及老兵欺凌新兵的场景，下定决心不让自己的孩子当兵。\n不当兵能有什么出路呢？大爷书读得不错，后来还有一个公办教师的职业。可惜遇上了三年自然灾害，拍挨饿，跑回家，丢掉了公职。我有记忆的时间起，大爷都在村东的粮所做工头，承包装卸麻包的活（麻包是装粮食的大口袋，使用很粗的麻布编织，装满粮食后使用很粗的包针封口）；二爷，书读得也不错，在镇上化工厂工作，直到退休；三爷和六爷都学了剃头的手艺，早些年就担着挑子给人剃头，后些年就在公路边盖了两个小屋，开起理发店；四爷在村委会谋职，做过村长；老五是我姑，出嫁了，相夫教子；剩下就是我爸爸了。我爸他老人家小时候学过几天木匠，并不精通。但是可以打个桌子、椅子什么的。但这个活没有做多久。后来，村子东开始修公路，他就去了养路队修路了。\n那个时候交通没有那么好，运输工具也不好。毛驴车是很常用的运输工具。记忆里，毛驴车在很长时间里是运煤的主要工具。有毛驴车就有鞭子。我爸爸也有一个很漂亮的打毛驴的鞭子。几根细竹子捆在一起，接着一个挺长的黑色的鞭子。面子梢上系一个死结，延伸出一段鞭子尾巴。爸爸说这样打毛驴的时候效果最好。我小时候总觉得那个尾巴不好看，就拿起剪刀把鞭子尾巴剪掉了。爸爸发现了，又把尾巴接上了。\n饭店 修路用什么呢？用沥青啊。记忆里经常有拉着烧热的沥青的车子。公路修好了，村里人纷纷在公路边建房子。结果都被以非法建筑的原因拆除了。我小时候还见过这些被拆除的房子的基座。爷爷也建了四间房子，在马路边卖茶。但是，每一平米的房子都要付钱的（税收），爷爷没有那么多钱，于是把其中一间屋的屋顶给拆掉了。我小时候抓住过一只燕子，它是被马路上的车撞晕了，掉在了这个没有顶的屋子里。燕子醒过来，一下就冲出了没有顶的屋子。小时候，公路边有很多燕子，经常在房屋墙上筑巢。\n靠山吃山，靠水吃水。爷爷和爸爸赖以为生的是那条马路以及周边的山。有山就有石头，在八九十年代，石头和砖是城市建筑的主要材料。将石头运出去就需要拖拉机支撑的运输业和服务于运输业的服务业。印象里，饭馆的食客很大一部分是开拖拉机的人。1997年到2004年之间是饭店生意比较好的时间。我小的时候晚上就常常在饭店度过，等着打烊。往往十点多、十一点多还有食客。\n后来，爷爷就在马路边卖清汤面条，卖豆腐汤、炒菜。这个店，爷爷一只开到2000年左右。一直到了奶奶去世，爷爷才退休。爸爸妈妈一开始就跟着爷爷奶奶在马路上帮忙。妈妈打下手，爸爸买菜。平时，主要在粮所里扛麻包。饭店没有名字，我小时候记得爸爸用红色油漆在墙上刷上”饭店”两个字。\n饭店里用的电是工业电，但是因为在农村，所以经常停电。电是从医院里接过来的。医院一开始是公立的，叫仓口医院，主要的业务可能是给孕妇生孩子。村里人很少去这个“大”医院，平时有病找村子里的赤脚医生。赤脚医生并不出诊，就坐在自己家里等着病人上门，一般的业务就是治治发烧感冒，挂个吊瓶什么的。想到医院是因为医院有一次拒绝给饭店供电了，两方争执不下打了起来，爸爸、四爷、三爷、六爷、大爷就去打了医院的人。因为比较早，具体的故事，我也不了解，但是却是平静生活里不一样的东西，所以印象深刻。这个公立医院在2000年后也难以为继了，卖个了私人，成了远近驰名的眼科医院，“看眼睛，到仓口医院”成了远近闻名的广告语。医院隔壁的粮所后来也被私人承包了。\n爷爷退休后，爸爸就继承了这个饭店。有了个这个饭店，爸爸妈妈两个人才供我和妹妹一直读书到研究生阶段。再后来，爷爷去世了。后来，六爷也去世了。在后来，爸爸新建了大房子，足足有4间，上下两层，房子盖得很漂亮。记得房子盖好一段后，村长（一个混社会的武痞）想要讹诈钱，说房子盖得不标准，要带人来拆房子。到了那天，小舅带了两卡车的人等在那里，准备火拼。结果村长的人没来，事情不了了之，爸爸也拿到了合法的房产证。\n但是建筑技术转型了，混凝土浇灌的建筑革新不再需要那么多石头。伴随着运石头的行业凋零，一方面饭馆的生意也越来越难以为继，另一方面竞争也越来越多。\n打工 后来饭店无力经营了，最终把公路边的房子卖了，回到村里生活。很小的时候，妈妈就说：“不好好学习，就留在农业社。” 那个时候的人都希望成为非农业。后来政策宽松的时候，一些手里有些钱的人就花钱购买非农业身份。到城里买房子住。三线的小县城，房价也逐渐攀高。但对村里人，却丧失了吸引力。\n爸爸妈妈回村之后，依旧务农，但主要的营生来自于打工。妈妈在村子附近找了个做童床的工厂工作。爸爸则在劳务市场找活干主要是在建筑公司干，垒墙盖房子。那已经是2008年之后的事情了，电动车进入了寻常百姓家。打工的地方有时候挺远的，主要靠电动车往来。\n爸爸妈妈回到村子住之后，一些不良资本家勾结政府搞农村集中居住，抓住农民想住高楼房的弱点，想收购农村住宅用地。农民们也不傻，纷纷加高楼房，一层变两层，院子了也建上。后来出现了烂尾楼，再后来这个晕了头的计划被叫停了。爸妈也跟风改良了家里的楼房，终于可以住得舒服点了。\n","date":1399507200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1399507200,"objectID":"a23e1607488be97425b61934cd6d2eb9","permalink":"https://chengjunwang.com/note/note_archive/2014-05-07-my-hometown/","publishdate":"2014-05-08T00:00:00Z","relpermalink":"/note/note_archive/2014-05-07-my-hometown/","section":"note","summary":"小村庄 我出生在鲁西南的一个小村庄，叫后仓沟村(地图)。当地人方言称之为后仓口。之所以成为后，是因为还有前仓和中仓。这三个村子合在一起称为仓口。后仓在滕州市县城的南面，一条滕枣公路在村东通过。村子背面是一个小村庄，就叫后小庄。后小庄的背面是放村，也分为前房和后房。然后，前房背面就是王开村。仓口和王开是以前比较好的村子，出了不少举人，称为金仓口，银王开。\n为什么叫仓沟呢？据说是因为收成很好，粮食满仓满沟。百度一下，找到这样的介绍：\n 后仓沟村归南沙河镇管理、与古石一村、后小庄村同乡,交通便利,人杰地灵,水美,友好好客主要农产品：香菜、香菇、紫色包心菜、沙果、乌饭果、橘子。村内资源：银、滑石。\n 你看，这些地名都透着乡土气。南沙河镇来源于一条叫南沙河的河流。除了南沙河，还有东沙河。沙河里当然有沙了。小时候，小孩子问大人“我是从哪里来的呢？”大人就会说“你是从沙河里捡的。” 在相当一段时间里，沙河都被一直采沙。因此，河道有很多被掏空的地方，水流也变得奇特。涨水的时候，很容易淹死人。这个城市盛产煤矿。但是，很快都被掏空。于是，就有白日地陷的事情发生。\n果园 这跟我自己的理解有点偏差：枣庄市盛产石榴和梨，有万亩榴园和万亩梨园。我承认，我也就是上大学之后，坐火车在薛城站下车，之后转乘汽车的时候远远的看到万亩梨园和万亩榴园。\n我家里之前种果园，种的水果主要是苹果和梨。我爷爷是一个“文化人”。好像读过私塾，总之会写字。三爷讲过一个故事，说文革的时候，村子里面扫盲。干部下来检查，村领导就让爷爷装作扫盲成功的农民。三爷就是我三伯，爷爷的第三个孩子。我爷爷有七个孩子，六个儿子，一个女儿。女儿排行老五。而我爸爸排行最小。\n说起果园，爷爷那时候并不善经营。按照我爸爸的说法是又喜欢喝酒，生活过得并不好。有一年到了梨子成熟的时候，我爷爷就呼喊着三爷和四爷去城里卖梨。三爷和四爷偷懒，遇到一个卖咸鱼的人要和他们用咸鱼换梨，他们就把梨都换成了咸鱼。回来后，被我奶奶一顿骂。我爷爷却很高兴，叫我奶奶炒咸鱼，自己打了酒要开始喝。\n大爷、二爷、三爷、四爷都认真读了书。唯独我爸爸念书念到小学二年级就不读了。他很小的时候就生活在果园里，看果树。经常有人来偷水果，遇到他打不过的人，就爬上树，摘了沉甸甸的梨来丢名目张胆的小偷。说起这个果园也有个故事，说我爷爷之前的家境不错，后来积攒了钱买了几块地种果树。土改后，就给没收了，只留下一块。我妈妈嫁过来的时候还见过。我的记忆里就都模糊了，只模模糊糊得记着哪里有个汲水的大轱辘。爸爸给我说起那是的水果多么大多么好，说有一种梨叫金钟梨，长得特别大。不过我没有见到过，更没有吃到过。\n爷爷、奶奶和他们的子女 爷爷是独子，他从一个叫峡楼（音）的地方娶了奶奶。因为爷爷奶奶孩子多，我有记忆的时候爷爷奶奶都很老了。听说文革的时候，爷爷因为他的果园蹲过牛棚。爷爷和奶奶都很安土重迁，不愿意折腾，也不希望子女折腾。六爷和爸爸之前想当兵，都被阻止了。原因是爷爷和奶奶都在兵营里呆过。在后仓沟东有一个山村叫上营。通往上营的路上有一个二十四院屯国兵，有一个北大仓库屯过粮。爷爷有做饭的手艺，在兵营里做饭，奶奶在那里拆洗棉衣。他们目睹了伤兵的痛苦以及老兵欺凌新兵的场景，下定决心不让自己的孩子当兵。\n不当兵能有什么出路呢？大爷书读得不错，后来还有一个公办教师的职业。可惜遇上了三年自然灾害，拍挨饿，跑回家，丢掉了公职。我有记忆的时间起，大爷都在村东的粮所做工头，承包装卸麻包的活（麻包是装粮食的大口袋，使用很粗的麻布编织，装满粮食后使用很粗的包针封口）；二爷，书读得也不错，在镇上化工厂工作，直到退休；三爷和六爷都学了剃头的手艺，早些年就担着挑子给人剃头，后些年就在公路边盖了两个小屋，开起理发店；四爷在村委会谋职，做过村长；老五是我姑，出嫁了，相夫教子；剩下就是我爸爸了。我爸他老人家小时候学过几天木匠，并不精通。但是可以打个桌子、椅子什么的。但这个活没有做多久。后来，村子东开始修公路，他就去了养路队修路了。\n那个时候交通没有那么好，运输工具也不好。毛驴车是很常用的运输工具。记忆里，毛驴车在很长时间里是运煤的主要工具。有毛驴车就有鞭子。我爸爸也有一个很漂亮的打毛驴的鞭子。几根细竹子捆在一起，接着一个挺长的黑色的鞭子。面子梢上系一个死结，延伸出一段鞭子尾巴。爸爸说这样打毛驴的时候效果最好。我小时候总觉得那个尾巴不好看，就拿起剪刀把鞭子尾巴剪掉了。爸爸发现了，又把尾巴接上了。\n饭店 修路用什么呢？用沥青啊。记忆里经常有拉着烧热的沥青的车子。公路修好了，村里人纷纷在公路边建房子。结果都被以非法建筑的原因拆除了。我小时候还见过这些被拆除的房子的基座。爷爷也建了四间房子，在马路边卖茶。但是，每一平米的房子都要付钱的（税收），爷爷没有那么多钱，于是把其中一间屋的屋顶给拆掉了。我小时候抓住过一只燕子，它是被马路上的车撞晕了，掉在了这个没有顶的屋子里。燕子醒过来，一下就冲出了没有顶的屋子。小时候，公路边有很多燕子，经常在房屋墙上筑巢。\n靠山吃山，靠水吃水。爷爷和爸爸赖以为生的是那条马路以及周边的山。有山就有石头，在八九十年代，石头和砖是城市建筑的主要材料。将石头运出去就需要拖拉机支撑的运输业和服务于运输业的服务业。印象里，饭馆的食客很大一部分是开拖拉机的人。1997年到2004年之间是饭店生意比较好的时间。我小的时候晚上就常常在饭店度过，等着打烊。往往十点多、十一点多还有食客。\n后来，爷爷就在马路边卖清汤面条，卖豆腐汤、炒菜。这个店，爷爷一只开到2000年左右。一直到了奶奶去世，爷爷才退休。爸爸妈妈一开始就跟着爷爷奶奶在马路上帮忙。妈妈打下手，爸爸买菜。平时，主要在粮所里扛麻包。饭店没有名字，我小时候记得爸爸用红色油漆在墙上刷上”饭店”两个字。\n饭店里用的电是工业电，但是因为在农村，所以经常停电。电是从医院里接过来的。医院一开始是公立的，叫仓口医院，主要的业务可能是给孕妇生孩子。村里人很少去这个“大”医院，平时有病找村子里的赤脚医生。赤脚医生并不出诊，就坐在自己家里等着病人上门，一般的业务就是治治发烧感冒，挂个吊瓶什么的。想到医院是因为医院有一次拒绝给饭店供电了，两方争执不下打了起来，爸爸、四爷、三爷、六爷、大爷就去打了医院的人。因为比较早，具体的故事，我也不了解，但是却是平静生活里不一样的东西，所以印象深刻。这个公立医院在2000年后也难以为继了，卖个了私人，成了远近驰名的眼科医院，“看眼睛，到仓口医院”成了远近闻名的广告语。医院隔壁的粮所后来也被私人承包了。\n爷爷退休后，爸爸就继承了这个饭店。有了个这个饭店，爸爸妈妈两个人才供我和妹妹一直读书到研究生阶段。再后来，爷爷去世了。后来，六爷也去世了。在后来，爸爸新建了大房子，足足有4间，上下两层，房子盖得很漂亮。记得房子盖好一段后，村长（一个混社会的武痞）想要讹诈钱，说房子盖得不标准，要带人来拆房子。到了那天，小舅带了两卡车的人等在那里，准备火拼。结果村长的人没来，事情不了了之，爸爸也拿到了合法的房产证。\n但是建筑技术转型了，混凝土浇灌的建筑革新不再需要那么多石头。伴随着运石头的行业凋零，一方面饭馆的生意也越来越难以为继，另一方面竞争也越来越多。\n打工 后来饭店无力经营了，最终把公路边的房子卖了，回到村里生活。很小的时候，妈妈就说：“不好好学习，就留在农业社。” 那个时候的人都希望成为非农业。后来政策宽松的时候，一些手里有些钱的人就花钱购买非农业身份。到城里买房子住。三线的小县城，房价也逐渐攀高。但对村里人，却丧失了吸引力。\n爸爸妈妈回村之后，依旧务农，但主要的营生来自于打工。妈妈在村子附近找了个做童床的工厂工作。爸爸则在劳务市场找活干主要是在建筑公司干，垒墙盖房子。那已经是2008年之后的事情了，电动车进入了寻常百姓家。打工的地方有时候挺远的，主要靠电动车往来。\n爸爸妈妈回到村子住之后，一些不良资本家勾结政府搞农村集中居住，抓住农民想住高楼房的弱点，想收购农村住宅用地。农民们也不傻，纷纷加高楼房，一层变两层，院子了也建上。后来出现了烂尾楼，再后来这个晕了头的计划被叫停了。爸妈也跟风改良了家里的楼房，终于可以住得舒服点了。","tags":null,"title":"后仓沟记忆","type":"note"},{"authors":null,"categories":null,"content":"网络是由节点和关系构成的，而对于关系的描述是社会网络的关键。我们已经知道对于节点的网络特性可以从中心度、近度、介度、特征度（eigenvalue centrality）等方式描述。那么对于关系呢？最简单的就是直接关系的强度了。\n关系强度（tie strength) 通常对于关系强度的测量是基于两个节点之间链接的权重来衡量的。并不是说关系的强度越高越好，也不是说越多的强关系就越好。例如，格兰诺维特的论文The strength of weak ties强调了弱关系的重要性。\n共同好友（common friends） 但是以直接的链接强度度量一对关系的强度显然过于简单。它忽略的网络中的三角形（triads）：网络的局部传递性(transtivity)。关系的传递性是社会网络分析的一种重要观点。比如，朋友的朋友成为自己的朋友的可能性很高。这种关系的强度不只限于一模网络中。在传播学中有ABX模型，A和B是两个人，X是一种对象（信息、意见、创新等）。A和B是好朋友，A喜欢X，那么B喜欢X的可能性就提高。也就是爱朋友及朋友喜欢的东西，有点像爱屋及乌。\n怎么抓住网络的传递性？找两个节点(一对关系)的共同好友！找到共同好友就抓住了网络中的三角形。存在的三角形数量就表明了传递性的程度。这种思路其实对于做共引（co-citation)分析的学者来说并不陌生。如果一篇论文同时引用了两篇论文，那么这两篇论文就存在一定的相似性。因此，找共同好友类似于找共引关系。\n嵌入度（embededness） 共同好友数量是判断两个人亲密程度的一个重要变量。如果共同好友的数量足够多，表明这两个人彼此深度的融入了对方的社会关系当中。基于这种思路，我们可以计算嵌入型。对于i和j两个人, $$k{i}$$、$$k{j}$$分别表示i和j的好友数量。$$n_{ij}$$表示其共同好友数量。那么，我们可以如下计算嵌入度：\n$$ Embededness{ij} = \\frac{n{ij}}{(k{i} -1) + (k{j} -1) - n_{ij}} $$\n残缺性（dispersion） 残缺度（dispersion， 或译为分散度）是Lars Backstrom \u0026amp; Jon Kleinberg (2013) 为了识别Facebook中亲密关系而提出的度量。它同样是基于共同好友的，主要测量的是共同好友之间的链接缺失程度。\n ‘dispersion’ — the extent to which two people’s mutual friends are not themselves well-connected. Lars Backstrom \u0026amp; Jon Kleinberg (2013)\n Lars Backstrom \u0026amp; Jon Kleinberg使用了脸书的数据发现，使用残缺度这个度量方式，可以非常准确识别诸如夫妻、男女朋友、恋爱关系。\n如上图中，u和v两个人有a、b、c、d四个共同好友。残缺度主要考察在多大程度上，这些共同好友不能在两步之内到达彼此。如果两个共同好友之间不存在直接连接，且也不存在（除去u和v之外的）共同好友，那么残缺度就增加1。\n以C_{uv}来表示u和v的共同好友之间的链接，那么在上图中只有a、b之间和c、d之间存在链接。a-c, a-d, b-c, b-d四对节点之间既没有直接链接又没有共同好友（除去了u和v)。所以残缺度是4。\n再举一个例子，如果u和v的共同好友b-c之间存在直接的链接。那么残缺度会是多大？如下图：\n因为只有a-d之间没有办法在两步内到达彼此，所以残缺度是1。\n当然了这种定义残缺度的方法是基于节点间的距离的。例如以$$d_{s, t}$$表示共同好友中任意两个节点s和t之间的距离。在这个初始的定义中，两步内不能到达算是关系残缺。那么我们可以将其扩展为3步内不能到达算残缺，或者n步能不能到达算残缺。不过根据Lars Backstrom \u0026amp; Jon Kleinberg的实验，两步不能到达是一个较好的基准。\n如果浪漫关系的确可以由高残缺度刻画，那么说明兔子不吃窝边草在国外是存在的。太熟了下不去手的现象在国内也是存在的。记得一个笑话说：找男女朋友的时候都说找互补的，实际上找到的都是类似的！白富美总是跟高富帅在一起嘛。这应该是对的，人的收入、相貌、工作都是匹配的（match）,从这个角度上讲的确是相似的。但至少从网路结构的角度来说，男女关系依然是互补的！\n参考文献 Lars Backstrom \u0026amp; Jon Kleinberg (2013) Romantic Partnerships and the Dispersion of Social Ties: A Network Analysis of Relationship Status on Facebook.arXiv\n","date":1399248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1399248000,"objectID":"fdbc01b485ee856ff611f410b1eb7171","permalink":"https://chengjunwang.com/zh/archive/2014-05-05-network-dispersion.zh/","publishdate":"2014-05-05T00:00:00Z","relpermalink":"/zh/archive/2014-05-05-network-dispersion.zh/","section":"zh","summary":"","tags":null,"title":"网络残缺度：共同好友间可否两步到达？","type":"zh"},{"authors":["祝建华","彭泰权","梁海","**王成军**","秦洁","陈鹤鑫"],"categories":null,"content":"","date":1395289129,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1395289129,"objectID":"f2e157f8c88215292b958b4d375ef40d","permalink":"https://chengjunwang.com/publication/ccs-application/","publishdate":"2014-03-20T12:18:49+08:00","relpermalink":"/publication/ccs-application/","section":"publication","summary":"本文旨在回顾和讨论新兴的计算社会科学在新闻传播研究中的应用。按照新闻传播研究中经典的5W模型,本文分别介绍了计算社会科学在谁(传播者),通过什么(渠道),对谁(受众),说了什么(内容),并产生了什么(效果)等五个领域的主要应用案例,并讨论了计算社会科学和网络大数据对这些研究领域的主要贡献和现存问题。 ","tags":null,"title":"计算社会科学在新闻传播研究中的应用","type":"publication"},{"authors":null,"categories":null,"content":"图1 D3 examples\n###1. 起源 斯坦福学校可视化团队Jeff Heer教授, 那时候的博士生Mike Bostock,那时候的硕士生 Vadim Ogievetsky在2009年创造了Protovis：一个从数据中生成 SVG 图的工具。2011年, Bostock和的老板Heer、师弟Ogievetsky开发了D3.js (Bostock, Heer \u0026amp; Ogievetsky 2011).\n图2 Eyeo 2013 - Mike Bostock\n此后，Mike Bostocks致力于D3的继续开发和维护， Mike的网站http://bost.ocks.org/和github（https://github.com/mbostock/d3）成为发展D3力量的重要领地。仅仅三年，作为一个社区（community)，D3的发展已经蔚为大观。\n###2. D3是什么？ D3是数据驱动文件（Data-Driven Documents）的缩写。作为一个javascript的库，D3(或D3.js)建构于电子数据（digital data）之上，使用数据创造并控制在网络浏览器里运行的动态交互的图形。\nD3必须要嵌入到html网页中，它依赖矢量图像（Scalable Vector Graphics，SVG）、层叠式样式表（Cascading Style Sheets，CSS3)等html的工具来展示图形。\nJavaScript函数来选择（select）元素，生成矢量图（SVG），赋予其样式（style），加入变化。 这种函数式的操作使得D3可以很容易的将大的数据（large dataset,而不是big data）从原始数据格式（json, csv， geoJSON, topoJOSON）转为矢量图对象，并且速度非常快。\nD3拥有自己的哲学，其中很重要的一条是Thinking with Joins。比如，读者与D3制作的图形交互的时候，会激发数据请求（如选择某一个时间段的数据），新的数据进来（data enter），D3的元素（如svg）就会相应的更新（elements update）。数据与元素的互动是由D3编写的Javascript函数指导的，交互之后之后互动结束，读者就看到一个新的图形了。一个例子是使用D3制作的《悲惨世界》中人物的共现关系（Les Misérables Co-occurrence）。这样做的好处是使得动态的图形展示变得简单。\n图3 Thinking with Joins\n3. 学习D3 学习使用D3可以从这个Tutorials开始。\n4. 使用D3绘制网络 因为网络的可视化相对简单，因而发展也比较成熟。R社区很快开发了R包d3network\n5. 使用D3绘制地图 Christchurch 2010 Timeline这个例子正是我想要的。\n一些其它的例子。\nLet’s Make a Map\nA simple d3js map explained\nD3.js workshop II: make beautiful maps \n###参考文献\n Bostock, Michael; Ogievetsky, Vadim; Heer, Jeffrey (October 2011), D3: Data-Driven Documents, IEEE Transactions on Visualization and Computer Graphics, IEEE Press\n","date":1394841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1394841600,"objectID":"88c610b88049112a9ec43f1ddf64088a","permalink":"https://chengjunwang.com/zh/archive/2014-03-15-d3-map.zh/","publishdate":"2014-03-15T00:00:00Z","relpermalink":"/zh/archive/2014-03-15-d3-map.zh/","section":"zh","summary":"","tags":null,"title":"空间分析初步：使用D3可视化","type":"zh"},{"authors":null,"categories":null,"content":"引言 空间分析（spatial analysis）对于扩散研究非常重要，它揭示了传播在空间维度上的分布。令人略感惊奇的是空间分析的研究者越来越多地使用R软件。其中一个原因是R包罗万象，而空间分析仍在发展且神情未定。在这个时候难以判定哪种方法最优。此时，策略当然是博观约取。R因其囊括众多统计方法而成为连接不同分析套路的首选；另外在R当中使用者可以继续开发新的数据分析包。可谓一举两得。　数据读入 我使用的是2013年米兰城12月份推特用户的地理信息数据。该数据来自Big Data Challenge of Telecommunication。使用Python写很简单的script从其服务器api接口读取数据:\n# Download milano tweets data using python # chengjun wang @ cmc # 2014 Mar 11 import urllib2 import json f = open('D:/chengjun/Milan/Social pulse/Milano_sample.csv', 'w') for offset in range(0,269290/100 +1): print \u0026quot;working on offset: \u0026quot;, offset req_url = 'https://api.dandelion.eu/datagem/social-pulse-milano/data/v1/?$limit=100\u0026amp;$offset='+str(offset)+'\u0026amp;$app_id=d...a\u0026amp;$app_key=2e...7c' jstr = urllib2.urlopen(req_url).read() # json string \u0026quot;\u0026quot;\u0026quot; these are flickr-specific \u0026quot;\u0026quot;\u0026quot; jinfo = json.loads( jstr ) for i in range(0, len(jinfo['items'])): lan = jinfo['items'][i]['language'] time = jinfo['items'][i]['created'] geo = jinfo['items'][i]['geometry']['coordinates'] timestamp = jinfo['items'][i]['timestamp'] municipality_name = jinfo['items'][i]['municipality']['name'] municipality_id = jinfo['items'][i]['municipality']['acheneID'] entities = jinfo['items'][i]['entities'] user = jinfo['items'][i]['user'] print \u0026gt;\u0026gt;f, \u0026quot;%s;%s;%s;%s;%s;%s;'%s';%s\u0026quot; % (lan, time, geo, timestamp, municipality_name, municipality_id, entities, user) f.close()  首先，读入点的时空分布数据。　# read data library(maptools) library(sp) library(rgdal) setwd(\u0026quot;D:/chengjun/Milan\u0026quot;) dat = read.csv(\u0026quot;./Social pulse/Milano_sample.csv\u0026quot;, header = FALSE, stringsAsFactors = FALSE, sep = \u0026quot;;\u0026quot;, quote = \u0026quot;\u0026quot;) names(dat) = c(\u0026quot;lan\u0026quot;, \u0026quot;time\u0026quot;, \u0026quot;geo\u0026quot;, \u0026quot;timestamp\u0026quot;, \u0026quot;mname\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;entities\u0026quot;, \u0026quot;user\u0026quot;)  进行简单的清洗：\n# clean data dat = subset(dat, dat$time \u0026gt;= as.POSIXlt(\u0026quot;2013-12-01 00:00:00\u0026quot;)); dim(dat) dat$time = do.call(rbind, strsplit(dat$time, split = \u0026quot;\\\\.\u0026quot;))[,1] dat$time = gsub(\u0026quot;T\u0026quot;, \u0026quot; \u0026quot;, dat$time) dat$time = as.POSIXlt(dat$time) dat$geo = gsub(\u0026quot;[\u0026quot;, \u0026quot;\u0026quot;, dat$geo, fixed = T) dat$geo = gsub(\u0026quot;]\u0026quot;, \u0026quot;\u0026quot;, dat$geo, fixed = T)  从openstreetmap下载米兰城的交通地理信息。使用rgdal这个R包读入数据：\n# download shp data from # http://metro.teczno.com/#milan ost=readOGR(\u0026quot;./Milano Grid/milano-grid/milan.imposm-shapefiles/milan.osm-mainroads.shp\u0026quot;, layer = \u0026quot;milan.osm-mainroads\u0026quot;) #will load the shapefile  要把地理信息转为经纬度的数据表示形式：\nspl = spTransform(ost, CRS(\u0026quot;+proj=longlat\u0026quot;)) # convert to longitude and latitude  如果要画出spl的话，速度有点慢, 因为绘制的点比较多。\n用了其中一个小数据(涵盖一天中的几个小时)，为了展现了每个小时的动态变化，使用CartoDB网站来制作了一个简单的可视化。顺便找了一遍各种javascript的库和其它包（googleVis, Echarts等），发现都不实用，所以还是用R吧。\n设置绘图的函数，来看一下数据的形式：\n# plot function make_plot = function(){ tz = as.POSIXlt(\u0026quot;2013-12-01 00:00:00\u0026quot;) end_time = as.POSIXlt(\u0026quot;2013-12-02 00:00:00\u0026quot;) while(tz \u0026lt;= end_time){ print(tz) datd = subset(dat, dat$time \u0026gt; tz\u0026amp; dat$time \u0026lt;= tz + 3600) plot(spl, col = \u0026quot;pink\u0026quot;) title(tz) p = do.call(rbind, strsplit(datd$geo, split=',')) p1 = as.numeric(p[,1]) p2 = as.numeric(p[,2]) points(p2~p1, pch = 1, col = \u0026quot;red\u0026quot;, cex = 0.1) tz = tz + 3600 } } # save figures png(file = \u0026quot;./linear%2d.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) make_plot() dev.off()  读者也可以直接使用animation这个R包来绘图。我在实验室的机器上安装ImageMagick有点问题，干脆存为图片了，再转为gif了。\n图1 米兰城一天当中的发推特的时空分布\n把12月31天的数据累积起来，我们可以得到米兰城2013年12月当中的发推特的空间分布。\n# the overall geographical distribution png(\u0026quot;./milano_social_pulse_December.png\u0026quot;, width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) plot(spl, col = \u0026quot;purple\u0026quot;) p = do.call(rbind, strsplit(dat$geo, split=',')) p1 = as.numeric(p[,1]) p2 = as.numeric(p[,2]) points(p2~p1, pch = 1, col = \u0026quot;red\u0026quot;, cex = 0.01) dev.off()  图2 米兰城2013年12月当中的发推特的空间分布\n这个图还是有点意思的：街道是城市人流的管道（Tube,伦敦好像把地铁直接称为tube）,人的移动等行为（包括社会媒体使用行为）则是穿行其间的流。推特聚集的地方与街道的轮廓高度契合。城市的中心推特的密度大（因为人流的密度大？）。所以可以检验下点的分布是否是随机的。\n空间点类型分析 这里涉及到空间点类型分析（spatial point pattern analysis）。检验下点的分布是否是随机的最简单的方法是进行完全空间随机（complete spatial randomness， CSR）分析。\nG方程方法\n这里说的最近邻居，英文当中却成为nearest event。把一个点的存在称之为事件也挺好玩。我们知道两个节点$$E_i$$和$$E_j$$的距离为:\n$$d(E_i, E_j) = \\sqrt{(x_i - x_j)^2 + (y_i-y_j)^2}$$\n平均最近邻居距离可以表示为:\n$$\\overline{d}{min} = \\frac{\\sum{i}^{n}d_{min}(X_i)}{n}$$\n于是可以定义事件-事件最近邻居距离，即任意一个事件到它的最近事件之间的距离。任意一个事件$$E_i$$的事件-事件最近邻居距离：\n$$d_i = {min}j {d{ij}, \\forall j\\neq i }$$\n对于一个距离d, 可定义G(d)为最近邻居距离的累计频数分布：\n$$ G(d) = \\frac{# d_{min}E_i\u0026lt;d}{n} $$\n说以G方程方法测量的最近邻居距离小于d的事件的比率。当事件分布存在聚集的情况的时候，G在距离较小的时候就增长特别快；当事件分布均匀时，距离较小的时候G增长缓慢，当距离达到使得多数事件分隔的大小后，G开始快速增长。\nF方程方法\n另外一个有用的测度是F方程。F方程测量了从空间中任意一个点到与它最近的事件之间的距离，因而它测量的是点-事件最近邻居距离。据此，F方程也被称之为空虚空间距离。\n计算F方程或点-事件距离的时候要先随机的抽取一些空间中的点, 计算它的最短距离，然后统计其中满足最短距离小于d的比率。\n$$F(d) = \\frac{#d_{min}(x_i\u0026lt;d)}{m}$$\n因为F方程是随机抽取空间中的点来统计，因而可以应对较大的数据规模。一个小的事件的聚集会导致G方程快速增长，但其实其它多数空间都是空的，所以F方程增长会较慢。当然了，对于规则分布的点，这种对比的结果则可能相反。\n使用G和F方程可以测量事件分布的实际情况，我们的零假设是事件分布是随机的，符合泊松分布:\n$$f(k, \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$\n用$$\\lambda$$表示事件的空间分布密度，在一个半径为d的平面$$\\pi d^2$$里面理论上存在的事件数量是$$\\lambda \\pi d^2$$。\n此处推导略去（汗，我不会啊。），那么G和F的理论值按照泊松分布应该是：\n$$G = F = 1-e^{-\\lambda \\pi d^2}$$\n有了理论值，有了实际值，我们就可以对比二者之间的差距。进而推论空间事件的点分布是否是随机的了。\n这个推断的过程使用spatstat这个R包进行：\nrequire(spatstat) #the analysis of point patterns geo = data.frame(dat$p1, dat$p2) # Convert data to ppp format geo_ppp = ppp(geo[,1], geo[,2], c(min(geo[,1]), max(geo[,1])), c(min(geo[,2]), max(geo[,2])) ) # slow # G function method g = Gest(geo_ppp) plot(g) # F function method f = Fest(geo_ppp) plot(f)  这里可以使用envelope的方法，使用蒙特卡洛的方法，根据一些算法来随机生成n个（比如100个）数据，以保证分析的准确性。\ng = envelope(geo_ppp, Gest, nsim = 100) plot(g)  f = envelope(geo_ppp, Fest, nsim = 100) plot(f)  显然发推特的空间位置的分布并非随机的，具有较明显的聚集现象，所以G方程一开始就增长很快，而虚空空间函数F方程则增长缓慢。\n空间点过程分析 这毕竟还是有点不够形象，有没有高大上的形象的方法？试试kernel smoother of point density:\nplot(density.ppp(geo_ppp), main = \u0026quot;\u0026quot;)  注意density.ppp返回的不是一个概率密度。它是对点密度的估计。密度是每个单位空间里随机点的期望。密度通常与空间位置有关。使用空间面积对密度函数积分，得到的是落入该区域的点的数量。\n于是乎，规律就更明显了：不仅仅是简单的点聚集，而且是箭靶形式的聚集，像北京环城路一样。越是中心，点就越密集。\n不过不要高兴太早，因为这个结果还是太粗糙。我们明明看到点的聚集情况并非如此完美的圆环。因为使用kernel平滑方法估计点的密度这种方法对于频宽（bandwidth）的大小特别敏感。有必要加以控制。另外，这里涉及到两种kernel的方法：四次多项式平滑和高斯平滑。这里要使用splancs这个R包。\n############## \u0026quot;quartic and Gaussian kernels\u0026quot; ############## library(splancs)  抱怨一下，因为以下用到的bw.diggle这个用来为kernel密度来选择经过交叉检验的频宽（Cross Validated Bandwidth Selection for Kernel Density）的命令，我不得不使用部分数据，因为它实在太消耗内存了。\n# subset a week-long small data dat1 = subset(dat, dat$day \u0026gt;=as.Date(\u0026quot;2013-12-01\u0026quot;)\u0026amp;dat$day \u0026lt;=as.Date(\u0026quot;2013-12-07\u0026quot;)) geo = data.frame(dat1$p1, dat1$p2) geo_ppp = ppp(geo[,1], geo[,2], c(min(geo[,1]), max(geo[,1])), c(min(geo[,2]), max(geo[,2])) ) # slow ## Quartic kernel mserwq\u0026lt;-mse2d(as.points(coordinates(geo)), as.points(list(x=c(0,1,1,0), y=c(0,0,1,1))), 100, range = .001) # flexible range bwq\u0026lt;-mserwq$h[which.min(mserwq$mse)] bwq ## Gaussian kernel mserw\u0026lt;-bw.diggle(as(geo_ppp, \u0026quot;ppp\u0026quot;)) # Reached total allocation of 32765Mb: see help(memory.size) bw\u0026lt;-as.numeric(mserw) bw \u0026quot;plot the Mean Square Error-Bandwidth\u0026quot; par(mfrow=c(1, 2)) plot(mserwq$h, mserwq$mse, xlab=\u0026quot;Bandwidth\u0026quot;, ylab=\u0026quot;MSE\u0026quot;, type=\u0026quot;l\u0026quot;, main=\u0026quot;Quartic kernel\u0026quot;) i\u0026lt;-which.min(mserwq$mse) points(mserwq$h[i], mserwq$mse[i], col = \u0026quot;red\u0026quot;) plot(mserw, main=\u0026quot;Gaussian kernel\u0026quot;, xlab=\u0026quot;Bandwidth\u0026quot;, ylab=\u0026quot;MSE\u0026quot;) points(attr(mserw, \u0026quot;h\u0026quot;)[attr(mserw, \u0026quot;iopt\u0026quot;)], bw, col = \u0026quot;red\u0026quot;)  看，最优化的频宽选择并不太有用，不过频宽真得很小。\ngeos = SpatialPointsDataFrame(geo, geo) poly = as.points(list(x = c(0, 0, 1, 1), y = c(0, 1, 1, 0))) sG \u0026lt;- Sobj_SpatialGrid(geos, maxDim=100)$SG grd \u0026lt;- slot(sG, \u0026quot;grid\u0026quot;) summary(grd) # k0 \u0026lt;- spkernel2d(geos, poly, h0=bw, grd) # k1 \u0026lt;- spkernel2d(geos, poly, h0=.05, grd) # k2 \u0026lt;- spkernel2d(geos, poly, h0=.1, grd) # k3 \u0026lt;- spkernel2d(geos, poly, h0=.15, grd) # df \u0026lt;- data.frame(k0=k0, k1=k1, k2=k2, k3=k3) # kernels \u0026lt;- SpatialGridDataFrame(grd, data=df) # summary(kernels) # 这里都是NA,四次多项式的结果并不好 ################################## cc \u0026lt;- coordinates(sG); head(cc) xy\u0026lt;-list(x=cc[,1], y=cc[,2]) k0\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw, dimyx=c(100, 100), xy=xy) k1\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*200, dimyx=c(100, 100), xy=xy) k2\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*500, dimyx=c(100, 100), xy=xy) k3\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*600, dimyx=c(100, 100), xy=xy) k4\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*800, dimyx=c(100, 100), xy=xy) k5\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*1000, dimyx=c(100, 100), xy=xy) k6\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*1500, dimyx=c(100, 100), xy=xy) k7\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*2000, dimyx=c(100, 100), xy=xy) \u0026quot;plot the MSE-Bandwidth\u0026quot; png(file = \u0026quot;./gaussian_kernel_density_first_week_in_december2.png\u0026quot;, width=8, height=16, units=\u0026quot;in\u0026quot;, res=700) par(mfrow=c(4, 2), mar=rep(1, 4)) plot(k0) plot(k1) plot(k2) plot(k3) plot(k4) plot(k5) plot(k6) plot(k7) dev.off()  这里列出几个比较小的频宽的核密度图：这与我们的观察比较一致。\n# kernels$k7\u0026lt;-as(k7, \u0026quot;SpatialGridDataFrame\u0026quot;)$v df \u0026lt;- data.frame(k0=k0, k1=k1, k2=k2, k3=k3, k4=k4, k5=k5， k6 = k6, k7 = k7) kernels \u0026lt;- SpatialGridDataFrame(grd, data=df) summary(kernels)  参考文献\n Lloyd，D.C.(2007) Local Models for Spatial Analysis. CRC press\nBaddeley, A. (2010) Analysing spatial point patterns in R. Workshop notes. CSIRO online technical publication. URL: www.csiro.au/resources/pf16h.html\nDiggle, P.J. (1985) A kernel method for smoothing point process data. Applied Statistics (Journal of the Royal Statistical Society, Series C) 34 (1985) 138–147.\nDiggle, P.J. (2003) Statistical analysis of spatial point patterns, Second edition. Arnold.\n","date":1394582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1394582400,"objectID":"e90c7821b76e3352818d65feaf8edb03","permalink":"https://chengjunwang.com/zh/archive/2014-03-12-first-step-spatial-analysis-with-r.zh/","publishdate":"2014-03-12T00:00:00Z","relpermalink":"/zh/archive/2014-03-12-first-step-spatial-analysis-with-r.zh/","section":"zh","summary":"","tags":null,"title":"空间分析初步：空间点类型分析","type":"zh"},{"authors":null,"categories":null,"content":" Here are a few tips for migrating an existing website from Jekyll to Hugo. These tips can be applied in conjunction with following Hugo Academic\u0026rsquo;s getting started guide.\nMove static content to static Jekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/ ▾ images/ logo.png  should become\n▾ \u0026lt;root\u0026gt;/ ▾ static/ ▾ images/ logo.png  Additionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nFix content Depending on the amount of customization that was done for each post in Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch and the Hugo Academic example site are your friends. Test your changes and fix errors as needed.\nPublish The default is for Jekyll to publish the website to a _site directory, whereas Hugo publishes to a public directory.\nA practical example Alexandre Normand migrated his website from Jekyll to Hugo in less than a day. You can see all his changes by looking at this GitHub diff. However, bear in mind that this example is not specific to the Academic theme nor does it use the latest version of Hugo.\n","date":1394409600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1394409600,"objectID":"454d0a0daf8c6ca4f4c9fd4cf52ab0f9","permalink":"https://chengjunwang.com/post/post_archive/migrate-from-jekyll/","publishdate":"2014-03-10T00:00:00Z","relpermalink":"/post/post_archive/migrate-from-jekyll/","section":"post","summary":"Learn how to migrate an existing website from Jekyll to Hugo.\n","tags":["jekyll"],"title":"Migrate from Jekyll to Hugo","type":"post"},{"authors":null,"categories":null,"content":" Here are a few tips for migrating an existing website from Jekyll to Hugo. These tips can be applied in conjunction with following Hugo Academic\u0026rsquo;s [getting started guide].\nMove static content to static Jekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/ ▾ images/ logo.png  should become\n▾ \u0026lt;root\u0026gt;/ ▾ static/ ▾ images/ logo.png  Additionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nFix content Depending on the amount of customization that was done for each post in Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch and the Hugo Academic example site are your friends. Test your changes and fix errors as needed.\nPublish The default is for Jekyll to publish the website to a _site directory, whereas Hugo publishes to a public directory.\nA practical example Alexandre Normand migrated his website from Jekyll to Hugo in less than a day. You can see all his changes by looking at this GitHub diff. However, bear in mind that this example is not specific to the Academic theme nor does it use the latest version of Hugo.\n","date":1394380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1394380800,"objectID":"46306f3376ed4eac58d5d925ee718ff2","permalink":"https://chengjunwang.com/zh/cn/migrate-from-jekyll.zh/","publishdate":"2014-03-10T00:00:00+08:00","relpermalink":"/zh/cn/migrate-from-jekyll.zh/","section":"zh","summary":"Learn how to migrate an existing website from Jekyll to Hugo.\n","tags":["jekyll"],"title":"Migrate from Jekyll to Hugo","type":"zh"},{"authors":null,"categories":null,"content":"与普通的扩散研究不同，网络扩散开始考虑网络结构对于扩散过程的影响。\n这里介绍一个使用R模拟网络扩散的例子。基本的算法非常简单：\n 生成一个网络:g(V, E)。 随机选择一个或几个节点作为种子（seeds）。 每个感染者以概率p（可视作该节点的传染能力,通常表示为$$\\beta$$）影响与其相连的节点。  其实这是一个最简单的SI模型在网络中的实现。S表示可感染（susceptible）, I表示被感染（infected）。SI模型描述了个体的状态从S到I之间的转变。因为形式简单，SI模型是可以求出其解析解的。考虑一个封闭的群体，没有出生、死亡和迁移。并假设个体是均匀混合的（homogeneous mixing),也就是要求个体的地理分布均匀，且被感染的概率也相同(T. G. Lewis, 2011)。那么β表示传染率（transmission rate)。SI模型可以表达为：\n$$\\frac{dS}{dt}=-\\beta SI$$\n$$\\frac{dI}{dt}=\\beta SI$$\n且满足 I + S = 1，那么以上方程$$\\frac{dI}{dt}=\\beta SI$$可以表达为：\n$$\\frac{dI}{dt}=\\beta I(1-I)$$\n解这个微分方程，我们可以得到累计增长曲线的表达式。有趣的是，这是一个logistic增长，具有明显的S型曲线（S-shaped curve）特征。该模型在初期跨越临界点之后增长较快，后期则变得缓慢。 因而可以用来描述和拟合创新扩散过程（diffusion of innovations）。\n当然，对疾病传播而言，SI模型是非常初级的（naive），主要因为受感染的个体以一定的概率恢复健康，或者继续进入可以被感染状态(S，据此扩展为SIS模型)或者转为免疫状态（R,据此扩展为SIR模型）。 免疫表示为R，用$$\\gamma$$代表免疫概率（removal or recovery rate)。对于信息扩散而言，这种考虑暂时是不需要的。\n第一步，生成网络。\nrequire(igraph) # generate a social graph size = 50 # 规则网 g = graph.tree(size, children = 2); plot(g) g = graph.star(size); plot(g) g = graph.full(size); plot(g) g = graph.ring(size); plot(g) g = connect.neighborhood(graph.ring(size), 2); plot(g) # 最近邻耦合网络 # 随机网络 g = erdos.renyi.game(size, 0.1) # 小世界网络 g = rewire.edges(erdos.renyi.game(size, 0.1), prob = 0.8 ) # 无标度网络 g = barabasi.game(size) ; plot(g)  第二步，随机选取一个或n个种子。\n# initiate the diffusers seeds_num = 1 set.seed(2014); diffusers = sample(V(g),seeds_num) ; diffusers infected =list() infected[[1]]= diffusers  第三步，在这个简单的例子中，每个节点的传染能力是0.5，即与其相连的节点以0.5的概率被其感染。在R中的实现是通过抛硬币的方式来实现的。\n# for example, set percolation probability = 0.5 coins = c(0,1) n = length(coins) sample(coins, 1, replace=TRUE, prob=rep(1/n, n))  显然，这很容易扩展到更一般的情况，比如节点的平均感染能力是0.128，那么可以这么写：\np = 0.128 coins = c(rep(1, p*1000), rep(0,(1-p)*1000)) n = length(coins) sample(coins, 1, replace=TRUE, prob=rep(1/n, n))  当然最重要的一步是要能按照“时间”更新网络节点被感染的信息。\n# function for updating the diffusers update_diffusers = function(diffusers){ nearest_neighbors = neighborhood(g, 1, diffusers) nearest_neighbors = data.frame(table(unlist(nearest_neighbors))) nearest_neighbors = subset(nearest_neighbors, !(nearest_neighbors[,1]%in%diffusers)) # toss the coins toss = function(freq) { tossing = NULL for (i in 1:freq ) tossing[i] = sample(coins, 1, replace=TRUE, prob=rep(1/n, times=n)) tossing = sum(tossing) return (tossing) } keep = unlist(lapply(nearest_neighbors[,2], toss)) new_infected = as.numeric(as.character(nearest_neighbors[,1][keep \u0026gt;= 1])) diffusers = unique(c(diffusers, new_infected)) return(diffusers) }  完成了以上三步。准备好了吗，现在开始开启扩散过程！\n## Start the contagion! i = 1 while(length(infected[[i]]) \u0026lt; size){ infected[[i+1]] = sort(update_diffusers(infected[[i]])) cat(length(infected[[i+1]]), \u0026quot;\\n\u0026quot;) i = i + 1 }  先看看S曲线吧：\n# \u0026quot;growth_curve\u0026quot; num_cum = unlist(lapply(1:i, function(x) length(infected［x］) )) p_cum = num_cum/max(num_cum) time = 1:i png(file = \u0026quot;./temporal_growth_curve.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=300) plot(p_cum~time, type = \u0026quot;b\u0026quot;) dev.off()  为了可视化这个扩散的过程，我们用红色来标记被感染者。\n# generate a palette E(g)$color = \u0026quot;blueviolet\u0026quot; V(g)$color = \u0026quot;white\u0026quot; set.seed(2014); layout.old = layout.fruchterman.reingold(g) V(g)$color[V(g)%in%diffusers] = \u0026quot;red\u0026quot; plot(g, layout =layout.old)  使用谢益辉开发的animation的R包可视化。\nlibrary(animation) saveGIF({ ani.options(interval = 0.5, convert = shQuote(\u0026quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe\u0026quot;)) # start the plot m = 1 while(m \u0026lt;= length(infected)){ V(g)$color = \u0026quot;white\u0026quot; V(g)$color[V(g)%in%infected[[m]]] = \u0026quot;red\u0026quot; plot(g, layout =layout.old) m = m + 1} })  如同在Netlogo里一样，我们可以把网络扩散与增长曲线同时展示出来：\nsaveGIF({ ani.options(interval = 0.5, convert = shQuote(\u0026quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe\u0026quot;)) # start the plot m = 1 while(m \u0026lt;= length(infected)){ # start the plot layout(matrix(c(1, 2, 1, 3), 2,2, byrow = TRUE), widths=c(3,1), heights=c(1, 1)) V(g)$color = \u0026quot;white\u0026quot; V(g)$color[V(g)%in%infected[[m]]] = \u0026quot;red\u0026quot; num_cum = unlist(lapply(1:m, function(x) length(infected[[x]]) )) p_cum = num_cum/size p = diff(c(0, p_cum)) time = 1:m plot(g, layout =layout.old, edge.arrow.size=0.2) title(paste(\u0026quot;Scale-free Network \\n Day\u0026quot;, m)) plot(p_cum~time, type = \u0026quot;b\u0026quot;, ylab = \u0026quot;CDF\u0026quot;, xlab = \u0026quot;Time\u0026quot;, xlim = c(0,i), ylim =c(0,1)) plot(p~time, type = \u0026quot;h\u0026quot;, ylab = \u0026quot;PDF\u0026quot;, xlab = \u0026quot;Time\u0026quot;, xlim = c(0,i), ylim =c(0,1), frame.plot = FALSE) m = m + 1} }, ani.width = 800, ani.height = 500)  ","date":1393545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1393545600,"objectID":"03938b120fa86a6b974c55652b7ed9d9","permalink":"https://chengjunwang.com/zh/archive/2014-02-28-simulate-network-diffusion-with-r.zh/","publishdate":"2014-02-28T00:00:00Z","relpermalink":"/zh/archive/2014-02-28-simulate-network-diffusion-with-r.zh/","section":"zh","summary":"","tags":null,"title":"使用R模拟网络扩散","type":"zh"},{"authors":null,"categories":null,"content":"邱怡轩在统计之都中展示了对宋词进行的分析（参见http://cos.name/tag/%E5%AE%8B%E8%AF%8D/），因为当时缺乏中文分词的工具，他独辟蹊径，假设宋词中任意两个相邻的汉字构成一个词语，进而找到了宋词当中的高频词。本文则尝试使用他所提供的宋词语料（http://cos.name/wp-content/uploads/2011/03/SongPoem.tar.gz），分析一下使用R进行中文分词、构建词云、高频词语聚类以及主题模型分析。\n首先要载入使用的R包并读入数据。\nlibrary(Rwordseg) require(rJava) library(tm) library(slam) library(topicmodels) library(wordcloud) library(igraph) setwd(\u0026quot;D:/github/text mining/song\u0026quot;) # 更改为你的工作路径，并存放数据在此。 txt=read.csv(\u0026quot;SongPoem.csv\u0026quot;,colClasses=\u0026quot;character\u0026quot;)  {:lang=\u0026laquo;ruby\u0026raquo;}\n然后进行对数据的操作。当然，第一步是进行中文分词，主要使用Rwordseg这个R包，其分词效果不错。分词的过程可以自动去掉标点符号。\npoem_words \u0026lt;- lapply(1:length(txt$Sentence), function(i) segmentCN(txt$Sentence[i], nature = TRUE))  {:lang=\u0026laquo;ruby\u0026raquo;}\n然后，我们将数据通过tm这个R包转化为文本-词矩阵（DocumentTermMatrix）。 wordcorpus \u0026lt;- Corpus(VectorSource(poem_words), encoding = \u0026laquo;UTF-8\u0026raquo;) # 组成语料库格式\nSys.setlocale(locale=\u0026quot;Chinese\u0026quot;) dtm1 \u0026lt;- DocumentTermMatrix(wordcorpus, control = list( wordLengths=c(1, Inf), # to allow long words bounds = list(global = c(5,Inf)), # each term appears in at least 5 docs removeNumbers = TRUE, # removePunctuation = list(preserve_intra_word_dashes = FALSE), weighting = weightTf, encoding = \u0026quot;UTF-8\u0026quot;) ) colnames(dtm1) findFreqTerms(dtm1, 1000) # 看一下高频词  {:lang=\u0026laquo;ruby\u0026raquo;}\n这里需要注意的是，这里我们默认词语的长度为1到无穷大，稍后，我们可以对其长度进行修改。例如，本文中，作者对改为长度为2以上以及长度为3以上，分别得到另外两个文本-词矩阵：dtm2和dtm3。随后，我们可以在文本-词矩阵进行一系列的分析。这里，先做一个简单的词云分析。为更好展示效果，最多只列出100个词。\nm \u0026lt;- as.matrix(dtm1) v \u0026lt;- sort(colSums(m), decreasing=TRUE) myNames \u0026lt;- names(v) d \u0026lt;- data.frame(word=myNames, freq=v) par(mar = rep(2, 4)) png(paste(getwd(), \u0026quot;/wordcloud50_\u0026quot;, \u0026quot;.png\u0026quot;, sep = ''), width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) pal2 \u0026lt;- brewer.pal(8,\u0026quot;Dark2\u0026quot;) wordcloud(d$word,d$freq, scale=c(5,.2), min.freq=mean(d$freq), max.words=100, random.order=FALSE, rot.per=.15, colors=pal2) dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n我们可以看一下效果，如下图所示，主要是一个字长度的词。最多的是“人”和“不”， 然后是“春”和“花”。\n但我们也许对长度大于2的词以及长度大于3的词更感兴趣（同时这样也可以和邱怡轩做的结果做一下比较）。使用前面步骤中生成的dtm2重复构建词云的R程序，我们可以得到以下两个词云：\n同样，对dtm3构建词云，效果如下：\n以上结果和邱怡轩得到的结果类似，可见对高频词的处理方面，他的方法的确有创见。对词云分析之后，我们还可以尝试根据词与词之间共同出现的概率对词进行聚类。这里我们展示长度大于2的词的聚类结果。\ndtm01 \u0026lt;- weightTfIdf(dtm2) N = 0.9 dtm02 \u0026lt;- removeSparseTerms(dtm01, N);dtm02 # 注意，为展示方便，这里我调节N的大小，使得dtm02中的词语数量在50左右。 tdm = as.TermDocumentMatrix(dtm02) tdm \u0026lt;- weightTfIdf(tdm) # convert the sparse term-document matrix to a standard data frame mydata.df \u0026lt;- as.data.frame(inspect(tdm)) mydata.df.scale \u0026lt;- scale(mydata.df) d \u0026lt;- dist(mydata.df.scale, method = \u0026quot;euclidean\u0026quot;) # distance matrix fit \u0026lt;- hclust(d, method=\u0026quot;ward\u0026quot;) png(paste(\u0026quot;d:/chengjun/honglou/honglou_termcluster_50_\u0026quot;, \u0026quot;.png\u0026quot;, sep = ''), width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) plot(fit) # display dendogram? dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n对长度大于2的词的聚类结果如下图所示，可见宋词的确注重“风流倜傥”，连分类都和风向有关系。\n当然读者还可以尝试对长度大于1词和长度大于3的词聚类，对长度大于1词聚类的效果图如下所示：\n长度大于3的词聚类结果如下：\n完成这一步之后，作者还尝试对宋词进行简单的主题模型分析，首先还是从长度大于2的词开始吧。第一步是确定主题的数量。先对文本-词矩阵进行简单处理，以消除高频词被高估和低频词被低估的问题。\ndtm = dtm2 term_tfidf \u0026lt;-tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) * log2(nDocs(dtm)/col_sums(dtm \u0026gt; 0)) l1=term_tfidf \u0026gt;= quantile(term_tfidf, 0.5) # second quantile, ie. median dtm \u0026lt;- dtm[,l1] dtm = dtm[row_sums(dtm)\u0026gt;0, ]; dim(dtm) # 2246 6210 summary(col_sums(dtm))  {:lang=\u0026laquo;ruby\u0026raquo;}\n之后就可以正式地开始确定主题数量的R程序了。这里，笔者主要参考了朱雪宁《微博名人那些事儿》一文中的R程序（http://cos.name/2013/08/something_about_weibo/）。\nfold_num = 10 kv_num = c(5, 10*c(1:5, 10)) seed_num = 2003 try_num = 1 smp\u0026lt;-function(cross=fold_num,n,seed) { set.seed(seed) dd=list() aa0=sample(rep(1:cross,ceiling(n/cross))[1:n],n) for (i in 1:cross) dd[[i]]=(1:n)[aa0==i] return(dd) } selectK\u0026lt;-function(dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp) # change 60 to 15 { per_ctm=NULL log_ctm=NULL for (k in kv) { per=NULL loglik=NULL for (i in 1:try_num) #only run for 3 replications# { cat(\u0026quot;R is running for\u0026quot;, \u0026quot;topic\u0026quot;, k, \u0026quot;fold\u0026quot;, i, as.character(as.POSIXlt(Sys.time(), \u0026quot;Asia/Shanghai\u0026quot;)),\u0026quot;\\n\u0026quot;) te=sp[[i]] tr=setdiff(1:dtm$nrow, te) # setdiff(nrow(dtm),te) ## fix here when restart r session # VEM = LDA(dtm[tr, ], k = k, control = list(seed = SEED)), # VEM_fixed = LDA(dtm[tr,], k = k, control = list(estimate.alpha = FALSE, seed = SEED)), # CTM = CTM(dtm[tr,], k = k, # control = list(seed = SEED, var = list(tol = 10^-4), em = list(tol = 10^-3))) # Gibbs = LDA(dtm[tr,], k = k, method = \u0026quot;Gibbs\u0026quot;, control = list(seed = SEED, burnin = 1000,thin = 100, iter = 1000)) per=c(per,perplexity(Gibbs,newdata=dtm[te,])) loglik=c(loglik,logLik(Gibbs,newdata=dtm[te,])) } per_ctm=rbind(per_ctm,per) log_ctm=rbind(log_ctm,loglik) } return(list(perplex=per_ctm,loglik=log_ctm)) } sp=smp(n=dtm$nrow, seed=seed_num) # n = nrow(dtm) system.time((ctmK=selectK(dtm=dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp=sp))) ## plot the perplexity m_per=apply(ctmK[[1]],1,mean) m_log=apply(ctmK[[2]],1,mean) k=c(kv_num) df = ctmK[[1]] # perplexity matrix logLik = ctmK[[2]] # perplexity matrix write.csv(data.frame(k, df, logLik), paste(getwd(), \u0026quot;/Perplexity2_\u0026quot;,\u0026quot;gibbs5_100\u0026quot;, \u0026quot;.csv\u0026quot;, sep = \u0026quot;\u0026quot;)) # save the figure png(paste(getwd(), \u0026quot;/Perplexity2_\u0026quot;,try_num, \u0026quot;_gibbs5_100\u0026quot;,\u0026quot;.png\u0026quot;, sep = ''), width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) matplot(k, df, type = c(\u0026quot;b\u0026quot;), xlab = \u0026quot;Number of topics\u0026quot;, ylab = \u0026quot;Perplexity\u0026quot;, pch=1:try_num,col = 1, main = '') legend(\u0026quot;topright\u0026quot;, legend = paste(\u0026quot;fold\u0026quot;, 1:try_num), col=1, pch=1:try_num) dev.off() png(paste(getwd(), \u0026quot;/LogLikelihood2_\u0026quot;, \u0026quot;gibbs5_100\u0026quot;,\u0026quot;.png\u0026quot;, sep = ''), width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) matplot(k, logLik, type = c(\u0026quot;b\u0026quot;), xlab = \u0026quot;Number of topics\u0026quot;, ylab = \u0026quot;Log-Likelihood\u0026quot;, pch=1:try_num,col = 1, main = '') legend(\u0026quot;topright\u0026quot;, legend = paste(\u0026quot;fold\u0026quot;, 1:try_num), col=1, pch=1:try_num) dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n于是可以得到对数似然率和主题数量的关系图，如下所示。可见选择10作为主题数量是比较合适的。\n以下，我们将主要对主题数量为10的主题模型进行估计。topicmodels这个R包是由Bettina Grun和 Johannes Kepler两个人贡献的，目前支持VEM, VEM (fixed alpha)，Gibbs和CTM四种主题模型，关于其详细介绍，可以阅读他们的论文，关于主题模型的更多背景知识可以阅读Blei的相关文章。闲话少叙，看一下R代码：\n# 'Refer to http://cos.name/2013/08/something_about_weibo/' k = 10 SEED \u0026lt;- 2003 jss_TM2 \u0026lt;- list( VEM = LDA(dtm, k = k, control = list(seed = SEED)), VEM_fixed = LDA(dtm, k = k, control = list(estimate.alpha = FALSE, seed = SEED)), Gibbs = LDA(dtm, k = k, method = \u0026quot;Gibbs\u0026quot;, control = list(seed = SEED, burnin = 1000, thin = 100, iter = 1000)), CTM = CTM(dtm, k = k, control = list(seed = SEED, var = list(tol = 10^-4), em = list(tol = 10^-3))) ) save(jss_TM2, file = paste(getwd(), \u0026quot;/jss_TM2.Rdata\u0026quot;, sep = \u0026quot;\u0026quot;)) save(jss_TM, file = paste(getwd(), \u0026quot;/jss_TM1.Rdata\u0026quot;, sep = \u0026quot;\u0026quot;)) termsForSave1\u0026lt;- terms(jss_TM2[[\u0026quot;VEM\u0026quot;]], 10) termsForSave2\u0026lt;- terms(jss_TM2[[\u0026quot;VEM_fixed\u0026quot;]], 10) termsForSave3\u0026lt;- terms(jss_TM2[[\u0026quot;Gibbs\u0026quot;]], 10) termsForSave4\u0026lt;- terms(jss_TM2[[\u0026quot;CTM\u0026quot;]], 10) write.csv(as.data.frame(t(termsForSave1)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_VEM_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;) write.csv(as.data.frame(t(termsForSave2)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_VEM_fixed_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;) write.csv(as.data.frame(t(termsForSave3)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_Gibbs_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;) write.csv(as.data.frame(t(termsForSave4)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_CTM_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;)  {:lang=\u0026laquo;ruby\u0026raquo;}\n对主题模型进行估计之后，一般选择展示每个主题的前10个词语。因为主题之间可以共享相同词语，所以构成网络关系，因此这里我选择用网络的方法展示其结果。首先看一下吉布斯抽样算法得到的主题网络图，其R程序如下：\n#'topic graphs' tfs = as.data.frame(termsForSave3, stringsAsFactors = F); tfs[,1] adjacent_list = lapply(1:10, function(i) embed(tfs[,i], 2)[, 2:1]) edgelist = as.data.frame(do.call(rbind, adjacent_list), stringsAsFactors =F) # topic = unlist(lapply(1:10, function(i) rep(i, 9))) edgelist$topic = topic g \u0026lt;-graph.data.frame(edgelist,directed=T ) l\u0026lt;-layout.fruchterman.reingold(g) # edge.color=\u0026quot;black\u0026quot; nodesize = centralization.degree(g)$res V(g)$size = log( centralization.degree(g)$res ) nodeLabel = V(g)$name E(g)$color = unlist(lapply(sample(colors()[26:137], 10), function(i) rep(i, 9))); unique(E(g)$color) # 保存图片格式 png( paste(getwd(), \u0026quot;/topic_graph_gibbs.png\u0026quot;, sep=\u0026quot;\u0026quot;）, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) plot(g, vertex.label= nodeLabel, edge.curved=TRUE, vertex.label.cex =0.5, edge.arrow.size=0.2, layout=l ) # 结束保存图片 dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n得到的图形如下：\n当然，我们还可以看一下其他算法得到的网络图，这里我们看一下根据VEM和CTM两个主题模型得到的网络图。\nCTM模型的主题网络图：\nVEM模型的主题网络图：\n","date":1380240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380240000,"objectID":"abf0ac52af5c939b79b549f996b54e76","permalink":"https://chengjunwang.com/zh/archive/2013-09-27-topic-modeling-of-song-peom.zh/","publishdate":"2013-09-27T00:00:00Z","relpermalink":"/zh/archive/2013-09-27-topic-modeling-of-song-peom.zh/","section":"zh","summary":"","tags":null,"title":"东风夜放花千树：对宋词进行主题分析初探","type":"zh"},{"authors":["**Cheng-Jun Wang**","Pian-Pian Wang","Jonathan J.H. Zhu"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1378944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378944000,"objectID":"a1e7292a55fdc67b882744c3b0c226bf","permalink":"https://chengjunwang.com/publication/dicuss-ows-tweets/","publishdate":"2013-09-12T00:00:00Z","relpermalink":"/publication/dicuss-ows-tweets/","section":"publication","summary":"To evaluate the quality of public discussion about social movements on Twitter and to understand the structural features and evolution of longitudinal discussion networks, we analyze tweets about the Occupy Wall Street movement posted over the course of 16 days by investigating the relationship between inequality, emotion, and the stability of online discussion. The results reveal that (1) the discussion is highly unequal for both initiating discussions and receiving conversations; (2) the stability of the discussion is much higher for receivers than for initiators; (3) the inequality of online discussions moderates the stability of online discussions; and (4) on an individual level, there is no significant relationship between emotion and political discussion. The implications help evaluate the quality of public discussion, and to understand the relationship between online discussion and social movements.","tags":null,"title":"Discussing Occupy Wall Street on Twitter","type":"publication"},{"authors":null,"categories":null,"content":"使用主题模型（topic models）可以较为高效地划分文本的主题，但一个不得不面对的问题是有时候主题的划分过细，使得解读和归类成为困难。其实，聚类分析作为一个“古老”的分析方法可以较为简洁的解决这个问题。\n举一个小例子，我们主要使用tm这个R包来完成文本挖掘的前期任务。在得到DocumentTermMatrix之后，可以通过计算cosine 相似度的方法来计算文本之间的不一致性（dissimilarity）。\n# Using cluster analysis to classify topics generated by topic modeling # 2013 Sep 08 # Cheng-Jun Wang library(tm) library(topicmodels) require(proxy) data(acq) data(crude) m \u0026lt;- c(acq, crude) dtm \u0026lt;- DocumentTermMatrix(m) dtm \u0026lt;- removeSparseTerms(dtm, 0.8) inspect(dtm[1:5, 1:5]) # cluster analysis of documents based on DocumentTermMatrix dist_dtm \u0026lt;- dissimilarity(mtd, method = 'cosine') hc \u0026lt;- hclust(dist_dtm, method = 'ave') plot(hc, xlab = '')  {:lang=\u0026laquo;ruby\u0026raquo;}\n我在做RA的时候，面临的一个问题就是在做主体模型的时候出现的：模型拟合得到的主题数量太多。我们用下面这个例子进行简单的介绍。\n# topic modeling topic_num = 50 for (k in c(topic_num)) { # k \u0026lt;- 10 SEED \u0026lt;- 2010 jss_TM \u0026lt;- list( VEM = LDA(dtm, k = k, control = list(seed = SEED)), VEM_fixed = LDA(dtm, k = k, control = list(estimate.alpha = FALSE, seed = SEED)), Gibbs = LDA(dtm, k = k, method = \u0026quot;Gibbs\u0026quot;, control = list(seed = SEED, burnin = 1000, thin = 100, iter = 1000)) ) } rs = posterior(jss_TM$Gibbs, dtm) mtd = t(rs$topics) # topics and documents mtt = rs$terms # topic and terms  {:lang=\u0026laquo;ruby\u0026raquo;}\n使用k mean聚类方法的好处是可以较为方便地知道聚类的数量\n######################################### # # K means analysis for rownames of a matrix # ######################################### # Determine number of clusters mydata = mtt wss \u0026lt;- (nrow(mydata)-1)*sum(apply(mydata,2,var)) max_group = nrow(mydata)-1 for (i in 2:max_group) wss[i] \u0026lt;- sum(kmeans(mydata, centers=i)$withinss) plot(1:max_group, wss, type=\u0026quot;b\u0026quot;, xlab=\u0026quot;Number of Clusters\u0026quot;, ylab=\u0026quot;Within groups sum of squares\u0026quot;) ## # K-Means Cluster Analysis fit \u0026lt;- kmeans(mydata, 5) # 5 cluster solution # get cluster means cluster_means = aggregate(mydata,by=list(fit$cluster),FUN=mean) # append cluster assignment mydata \u0026lt;- data.frame(rownames(mydata), fit$cluster)  {:lang=\u0026laquo;ruby\u0026raquo;}\n以下，我们对矩阵计算cosine similarity并使用阶层聚类方法得到结果。\n############################################ # # Hierarchical Clustering # ############################################ cos.sim \u0026lt;- function(ix) { A = X[ix[1],] B = X[ix[2],] return( sum(A*B)/sqrt(sum(A^2)*sum(B^2)) ) } mdt = as.matrix(dtm) X = mtt # whether to scale it n \u0026lt;- nrow(X) cmb \u0026lt;- expand.grid(i=1:n, j=1:n) simdt \u0026lt;- matrix(apply(cmb,1,cos.sim),n,n) rownames(simdt) = rownames(mtt) hc \u0026lt;- hclust(dist(simdt, method = \u0026quot;euclidean\u0026quot;), method = 'ave') # hc \u0026lt;- hclust(dist(simdt)^2, method = 'cen') plot(hc, xlab = '') k = 10 groups \u0026lt;- cutree(hc, k=k) # cut tree into 5 clusters rect.hclust(hc, k=k, border=\u0026quot;red\u0026quot;) # draw dendogram with red borders  {:lang=\u0026laquo;ruby\u0026raquo;}\n看一下效果吧：\n当然了，如果你觉得这个方法过于粗暴，还可以尝试构建主题网络并进行社区划分的方法。不再赘述。\n","date":1378598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378598400,"objectID":"6666a1497df892def30be0e0040bd3f8","permalink":"https://chengjunwang.com/zh/archive/2013-09-08-using-cluster-analysis-to-classify-topics-generated-by-topic-modeling.zh/","publishdate":"2013-09-08T00:00:00Z","relpermalink":"/zh/archive/2013-09-08-using-cluster-analysis-to-classify-topics-generated-by-topic-modeling.zh/","section":"zh","summary":"","tags":null,"title":"使用聚类分析为主题模型划分主题类型","type":"zh"},{"authors":null,"categories":null,"content":"使用R软件进行自然语言处理（文本挖掘）是比较方便的。其中一个比较基础的分析是采用part-of-speech tagging的思路进行词性标注。在本文中，我将简单地介绍使用R软件及其子包openNLP进行词性标注。这里的测试语料依然是英文，采用的算法主要是最大熵的方法。\nopenNLP的发展开始回归到底层的基本功能，之前搭建起来的比较方便实用的函数被取消了，比如tagPOS命令消失了。所以，需要自己来重新写这个方程。这也不太难，根据R文档对Maxent_POS_Tag_Annotator的介绍中的例子重新组合一下，就可以得到。\n动词和名词的使用在文本挖掘中异常重要，单纯的名词语料可以用于进一步的文本挖掘，如我要做的是采用它们继续做主题挖掘（topic modeling）。\n第一步，当然是重组这个tagPOS命令。\nlibrary(openNLP) library(tm) require(NLP) # Compose the tagPOS function tagPOS \u0026lt;- function(text.var, pos_tag_annotator, ...) { s \u0026lt;- as.String(text.var) ## Set up the POS annotator if missing (for parallel) PTA \u0026lt;- Maxent_POS_Tag_Annotator() ## Need sentence and word token annotations. word_token_annotator \u0026lt;- Maxent_Word_Token_Annotator() a2 \u0026lt;- Annotation(1L, \u0026quot;sentence\u0026quot;, 1L, nchar(s)) a2 \u0026lt;- annotate(s, word_token_annotator, a2) a3 \u0026lt;- annotate(s, PTA, a2) ## Determine the distribution of POS tags for word tokens. a3w \u0026lt;- a3[a3$type == \u0026quot;word\u0026quot;] pos_tag \u0026lt;- unlist(lapply(a3w$features, \u0026quot;[[\u0026quot;, \u0026quot;POS\u0026quot;)) ## Extract token/POS pairs (all of them): easy. pos_term \u0026lt;- list(term = s[a3w], tag = pos_tag) return (pos_term) }  {:lang=\u0026laquo;ruby\u0026raquo;}\n第二步，为了保留文本序列，这里还需要一个函数。\n# run tagPOS function for a list of texts # do so to facilitate the conversion to generate corpus for topic modeling run_pos = function(n){ cat(\u0026quot;R is running for part-of-speech tagging\u0026quot;, n, as.character(as.POSIXlt(Sys.time(), \u0026quot;Asia/Shanghai\u0026quot;)), sep = \u0026quot;\\n\u0026quot;) df = tagPOS(text[n]) nn = (df$term[which(df$tag == \u0026quot;NN\u0026quot;)]) vb = (df$term[which(df$tag == \u0026quot;VB\u0026quot;)]) nnvb = (c(nn, vb)) result = list(nn, vb, nnvb) return(result) }  {:lang=\u0026laquo;ruby\u0026raquo;}\n第三步，开始测试结果（这里用一个很短的语料），并将其转化为三个tm下的Corpus。\n# test with a simple collection of text text \u0026lt;- c(\u0026quot;I like it.\u0026quot;, \u0026quot;This is outstanding soup!\u0026quot;, \u0026quot;I really must get the recipe.\u0026quot;) # run the functions df = lapply(c(1:3), run_pos) data = data.frame(do.call(rbind, df)) names(data) = c(\u0026quot;nn\u0026quot;, \u0026quot;vb\u0026quot;, \u0026quot;nnvb\u0026quot;) # make three corpus of nouns, verbs, and both of them corpus_nn \u0026lt;- Corpus( VectorSource( data$nn ) ) corpus_vb \u0026lt;- Corpus( VectorSource( data$vb ) ) corpus_nnvb \u0026lt;- Corpus( VectorSource( data$nnvb ) )  {:lang=\u0026laquo;ruby\u0026raquo;}\n","date":1378512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378512000,"objectID":"d5069eab37ccffe1d9075f1a1a238a1a","permalink":"https://chengjunwang.com/zh/archive/2013-09-07-part-of-speech-analysis-with-opennlp.zh/","publishdate":"2013-09-07T00:00:00Z","relpermalink":"/zh/archive/2013-09-07-part-of-speech-analysis-with-opennlp.zh/","section":"zh","summary":"","tags":null,"title":"文本挖掘基础：使用openNLP进行词性标注","type":"zh"},{"authors":null,"categories":null,"content":"1. 筛选单词 在数据清理（pre-processing）之后，需要对数据进行适当筛选。对数据的筛选包括至少两个步骤：\n第一步，在DocumentTermMatrix中设定\n使用R的topicmodels发现设定在DocumentTermMatrix里的约束条件失效，解决方法在此，其实在topicmodels的包里也粗略提及，只是用习惯了tm包的人觉得二者是无缝对接的。其实还很多差异，比如在tm里相似功能称之为TermDocumentMatrix\ndtm \u0026lt;- DocumentTermMatrix(corpus, control = list(stemming = TRUE, stopwords = TRUE, wordLengths=c(4, 15), bounds = list(global = c(5,Inf)), # each term appears in at least 5 docs removeNumbers = TRUE, removePunctuation = list(preserve_intra_word_dashes = FALSE) #,encoding = \u0026quot;UTF-8\u0026quot; ) ) colnames(dtm) ## inspect all the words for errors dim(dtm)  {:lang=\u0026laquo;ruby\u0026raquo;}\n第二步，通过tf-idf和col_sums选择高频词\n这背后的逻辑在于主题模型是要对文本进行分类，频次较少的词的贡献并不大。但会显著的占用计算资源。\nterm_tfidf \u0026lt;-tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) * log2(nDocs(dtm)/col_sums(dtm \u0026gt; 0)) l1=term_tfidf \u0026gt;= quantile(term_tfidf, 0.1) # fix this! dtm \u0026lt;- dtm[,l1] l2=col_sums(dtm) \u0026gt;= quantile(col_sums(dtm), 0.1) # fix this! dtm \u0026lt;- dtm[,l2] dtm = dtm[row_sums(dtm)\u0026gt;0, ]; dim(dtm) # 2246 6210 range(col_sums(dtm))  {:lang=\u0026laquo;ruby\u0026raquo;}\n2. 确定主题数量 在对单个词进行筛选之后，就可以正式进行主题模型的设定了。这是一步非常耗时间的工作，但第一步当然是理解主题模型的基本思路。\n主题模型是在概率潜在语义分析（probabilistic latent semanticanalysis，PLSI）的基础上发展起来的。从对矩阵进行因子分解的角度而言，可以看做是对离散数据进行主成分分析。其具体内容可以参见Blei发表在Communication of ACM上的文献回顾文章（Blei(2012) Probalistic topic models. Communication of ACM, 55, 77-84）。\n简而言之，我们看到是单词在文本中的分布。1. 我们认为在单词和文本之间存在潜在的主题，并且每个主题$$β{1:K}$$可以表达为一些词语在这个文本里的分布；2. 一篇文章可能对应多个主题，假设我们已经知道了存在哪些主题，那么一个主题在一个文本中的比例$$θ{d:k}$$也应该知道；3. 我们将主题和词语对应起来，建立一个映射$$z{d:n}$$，这样我们就知道把文章d中的第n个词赋给哪个主题；4.但实际上前三步都是不能直接观察到的，之间看到的就是词语在文本中的分布$$w{d:n}$$ ，例如文本d当中第n个词语是什么，即词在文本中的分布。\n前三个隐变量和第四个先变量之间的联合分布（joint distribution）就是主题生成的过程，这个过程还可以使用概率图模型的方法进行建模。如下图所示：\n其主要逻辑是机器学习的思路：给定了可以观察到的词语在文本中的分布$$w_{d:n}$$，主题结构可以表达为一个条件分布：$$p(\\beta _{1:K},\\theta {1:D},z{1:D} \\mid w_{1:D})$$。这是后验分布的分析思路。因为可能的主题结构太多，这个后验分布无法计算出来，而主题模型的主要目的也只是逼近这个后验分布。\n通常逼近这个后验分布的方法可以分为两类：1. 变异算法（variational algorithms）,这是一种决定论式的方法。变异式算法假设一些参数分布，并根据这些理想中的分布与后验的数据相比较，并从中找到最接近的。由此，将一个估计问题转化为最优化问题。最主要的算法是变异式的期望最大化算法(variational expectation-maximization，VEM)。这个方法是最主要使用的方法。在R软件的tomicmodels包中被重点使用。 2. 基于抽样的算法。抽样的算法，如吉布斯抽样（gibbs sampling）主要是构造一个马尔科夫链，从后验的实证的分布中抽取一些样本，以之估计后验分布。吉布斯抽样的方法在R软件的lda包中广泛使用。\n常用的主题模型是LDA, 可以使用VEM和gibbs两种方法估计。之后的模型的发展，主要是要放松严格的模型假设，其中之一是允许主题之间存在相关。由此Blei等人提出了相关的主题模型（correalted topic model，CTM），可以使用VEM方法估计。在本文当中，我们采用CTM为例。\nfold_num = 10 kv_num = c(5, 10*c(1:5, 10)) seed_num = 2003 smp\u0026lt;-function(cross=fold_num,n,seed) { set.seed(seed) dd=list() aa0=sample(rep(1:cross,ceiling(n/cross))[1:n],n) for (i in 1:cross) dd[[i]]=(1:n)[aa0==i] return(dd) } selectK\u0026lt;-function(dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp) # change 60 to 15 { per_ctm=NULL log_ctm=NULL for (k in kv) { per=NULL loglik=NULL for (i in 1:3) #only run for 3 replications# { cat(\u0026quot;R is running for\u0026quot;, \u0026quot;topic\u0026quot;, k, \u0026quot;fold\u0026quot;, i, as.character(as.POSIXlt(Sys.time(), \u0026quot;Asia/Shanghai\u0026quot;)),\u0026quot;\\n\u0026quot;) te=sp[[i]] tr=setdiff(1:nrow(dtm),te) # VEM = LDA(dtm[tr, ], k = k, control = list(seed = SEED)), # VEM_fixed = LDA(dtm[tr,], k = k, control = list(estimate.alpha = FALSE, seed = SEED)), CTM = CTM(dtm[tr,], k = k, control = list(seed = SEED, var = list(tol = 10^-4), em = list(tol = 10^-3))) # Gibbs = LDA(dtm[tr,], k = k, method = \u0026quot;Gibbs\u0026quot;, # control = list(seed = SEED, burnin = 1000,thin = 100, iter = 1000)) per=c(per,perplexity(CTM,newdata=dtm[te,])) loglik=c(loglik,logLik(CTM,newdata=dtm[te,])) } per_ctm=rbind(per_ctm,per) log_ctm=rbind(log_ctm,loglik) } return(list(perplex=per_ctm,loglik=log_ctm)) } sp=smp(n=nrow(dtm),seed=seed_num) system.time((ctmK=selectK(dtm=dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp=sp))) ## plot the perplexity m_per=apply(ctmK[[1]],1,mean) m_log=apply(ctmK[[2]],1,mean) k=c(kv_num) df = ctmK[[1]] # perplexity matrix matplot(k, df, type = c(\u0026quot;b\u0026quot;), xlab = \u0026quot;Number of topics\u0026quot;, ylab = \u0026quot;Perplexity\u0026quot;, pch=1:5,col = 1, main = '') legend(\u0026quot;bottomright\u0026quot;, legend = paste(\u0026quot;fold\u0026quot;, 1:5), col=1, pch=1:5)  {:lang=\u0026laquo;ruby\u0026raquo;}\n有趣的是计算时间：\n\u0026gt; system.time((ctmK=selectK(dtm=dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp=sp))) R is running for topic 5 fold 1 2013-08-31 18:26:32 R is running for topic 5 fold 2 2013-08-31 18:26:39 R is running for topic 5 fold 3 2013-08-31 18:26:45 R is running for topic 10 fold 1 2013-08-31 18:26:50 R is running for topic 10 fold 2 2013-08-31 18:27:14 R is running for topic 10 fold 3 2013-08-31 18:27:36 R is running for topic 20 fold 1 2013-08-31 18:27:57 R is running for topic 20 fold 2 2013-08-31 18:29:42 R is running for topic 20 fold 3 2013-08-31 18:32:00 R is running for topic 30 fold 1 2013-08-31 18:33:42 R is running for topic 30 fold 2 2013-08-31 18:37:39 R is running for topic 30 fold 3 2013-08-31 18:45:46 R is running for topic 40 fold 1 2013-08-31 18:52:52 R is running for topic 40 fold 2 2013-08-31 18:57:26 R is running for topic 40 fold 3 2013-08-31 19:00:31 R is running for topic 50 fold 1 2013-08-31 19:03:47 R is running for topic 50 fold 2 2013-08-31 19:04:02 R is running for topic 50 fold 3 2013-08-31 19:04:52 R is running for topic 100 fold 1 2013-08-31 19:05:42 R is running for topic 100 fold 2 2013-08-31 19:06:05 R is running for topic 100 fold 3 2013-08-31 19:06:28 user system elapsed 2417.801.13 2419.28  {:lang=\u0026laquo;ruby\u0026raquo;}\n看一下最终绘制的perplexity的图，如下可见，在本例当中，当主题数量为30的时候，perplexity最小，模型的最大似然率最高，由此确定主题数量为30。\n","date":1377907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377907200,"objectID":"4573b1317a7e68b137dec228fc62cc1c","permalink":"https://chengjunwang.com/zh/archive/2013-08-31-topic-modeling-with-r.zh/","publishdate":"2013-08-31T00:00:00Z","relpermalink":"/zh/archive/2013-08-31-topic-modeling-with-r.zh/","section":"zh","summary":"","tags":null,"title":"使用R做主题模型：词语筛选和主题数量确定","type":"zh"},{"authors":null,"categories":null,"content":"引言 遭遇“邪恶的拉丁引号” 我遇到的问题比较复杂，因为原文里混合了latin1和UTF-8两种encoding的字形，最初我统一再读入text数据的时候采用encoding =\u0026laquo;UTF-8\u0026raquo;的方法，结果发现了很多奇诡的单引号和双引号错误。在生成的DocumentTermMatrix里出现了很多以引号开始或结束的terms，例如：“grandfather， “deputy with the constitution” 。用Encoding命令看一下它的原形是：\n\u0026gt; Encoding(\u0026quot;“\u0026quot;) [1] \u0026quot;latin1\u0026quot;  只所以说是原形，是因为它们可以变形！\u0026raquo;â€œ\u0026raquo;， \u0026laquo;â€™\u0026raquo;， \u0026laquo;â€\\u009d\u0026raquo;， \u0026laquo;â€\u0026raquo;都是它在不设定Encoding的环境下的形状。但我觉得不足以刻画我对它的厌恶，特别附图一张：\n直到最后，我也没彻底搞定这些邪恶的拉丁引号，但我使用了一些tricks解决的我的问题。\n1. 读入数据不设定encoding！ 因为邪恶的拉丁引号在UTF-8格式下根本就无法对付，在不设encoding方法的时候，它们现身为â€“, â€™, â€œ等形式，还可以对付。\ndat1 = read.csv(\u0026quot;D:/chengjun/Crystal/Schwab_data_cleaningSep.csv\u0026quot;, header = F, sep = \u0026quot;|\u0026quot;, quote = \u0026quot;\u0026quot;, stringsAsFactors=F, fileEncoding = \u0026quot;\u0026quot;) # , encoding =\u0026quot;UTF-8\u0026quot;); dim(dat1) names(dat1) = c('name', 'organization', 'year', 'country', 'website', 'shortIntro', 'focus', 'geo', 'model', 'benefit', 'budget', 'revenue', 'recognization', 'background', 'innovation', 'entrepreneur')  2. 文本数据清理第一步：载入R包，选取变量 library(tm) library(topicmodels) text = dat1$entrepreneur  3. 终于可以删除部分邪恶的拉丁引号 text = gsub(\u0026quot;.\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;!\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;?\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€œ\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€™\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€\\u009d\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;\u0026lt;/b\u0026gt;\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;\u0026lt;b\u0026gt;\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE )  注意：1. 这些不规则的latin表达在r的script里再次打开会改变。所以，每次使用都要来这个网页里粘贴复制，也算是一种state-of-art，markdown都比R script保存的持久啊。2.使用gsub的代价是corpus被再度转化为character。所以这段代码如放在下面使用还要用Corpus命令再度转回来。\ncorpus \u0026lt;- Corpus( VectorSource( text ) ) # corpus[[1]] ## inspect the first corpus # make each letter lowercase corpus \u0026lt;- tm_map(corpus, tolower)  4. 我这里根据研究需要，要剔除人名、地名、组织名。 # remove generic and custom stopwords human_find_special_cases = c(\u0026quot;Fundação Pró-Cerrado\u0026quot;, \u0026quot;Fundação PróCerrado\u0026quot;, \u0026quot;FundaÃ§Ã£o PrÃ³-Cerrado\u0026quot;) my_stopwords \u0026lt;- c(dat1$country, dat1$organization, dat1$name, human_find_special_cases) my_stopwords \u0026lt;- Corpus( VectorSource(my_stopwords) ) my_stopwords \u0026lt;- tm_map(my_stopwords, tolower) # to lowercase my_stopwords here # Finally we can delete the country/org/person names corpus \u0026lt;- tm_map(corpus, removeWords, my_stopwords); corpus[[1]] corpus \u0026lt;- tm_map(corpus, removePunctuation)  5. 将语料转化为DocumentTermMatrix # install.packages(\u0026quot;SnowballC\u0026quot;) Sys.setlocale(\u0026quot;LC_COLLATE\u0026quot;, \u0026quot;C\u0026quot;) # set this for reproducible results corpus \u0026lt;- Corpus( VectorSource( corpus ) ) # corpus[[1]] ## inspect the first corpus  另外，到这里还是会有孤立的邪恶的拉丁单引号存在，但已经和其它term分开了，在以下DocumentTermMatrix的通过设置minWordLength = 3可以将其完全清理。\n# corpus = tm_map(corpus, function(x) iconv(enc2utf8(x), sub = \u0026quot;byte\u0026quot;)) # very important to convert encoding JSS_dtm \u0026lt;- DocumentTermMatrix(corpus, control = list(stemming = TRUE, stopwords = TRUE, minWordLength = 3, removeNumbers = TRUE, removePunctuation = TRUE # weighting = # function(x) # weightTfIdf(x, normalize =FALSE), ,encoding = \u0026quot;UTF-8\u0026quot; ) ) findFreqTerms(JSS_dtm, lowfreq=0) # 一定要看一下还有没有错误。inspect all the words for errors  6. 你需要的一些背景知识 6.1 如何识别和转化encoding的类型? iconvlist() # 看一下玲琅满目的encoding方法 iconv(x, from, to, sub=NA) # Convert Character Vector between Encodings ## convert from Latin-2 to UTF-8: two of the glibc iconv variants. iconv(x, \u0026quot;ISO_8859-2\u0026quot;, \u0026quot;UTF-8\u0026quot;) iconv(x, \u0026quot;LATIN2\u0026quot;, \u0026quot;UTF-8\u0026quot;) ## Both x below are in latin1 and will only display correctly in a ## latin1 locale. (x \u0026lt;- \u0026quot;fa\\xE7ile\u0026quot;) charToRaw(xx \u0026lt;- iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;UTF-8\u0026quot;)) ## in a UTF-8 locale, print(xx) iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;) # NA iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, \u0026quot;?\u0026quot;) # \u0026quot;fa?ile\u0026quot; iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, \u0026quot;\u0026quot;) # \u0026quot;faile\u0026quot; iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, \u0026quot;byte\u0026quot;) # \u0026quot;fa\u0026lt;e7\u0026gt;ile\u0026quot; # Extracts from R help files (x \u0026lt;- c(\u0026quot;Ekstr\\xf8m\u0026quot;, \u0026quot;J\\xf6reskog\u0026quot;, \u0026quot;bi\\xdfchen Z\\xfcrcher\u0026quot;)) iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII//TRANSLIT\u0026quot;) iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, sub=\u0026quot;byte\u0026quot;) ## End(Not run)  6.2 如何看DocumentTermMatrix的内容？ inspect(JSS_dtm) colnames(JSS_dtm) # we can find that: [3206] \u0026quot;works\\u009d\u0026quot; [3207] \u0026quot;work\\u009d\u0026quot; inspect(JSS_dtm[,3206]) inspect(JSS_dtm[,\u0026quot;works\\u009d\u0026quot;])  6.3 关于一些需要跳出的符号 unlist(strsplit(\u0026quot;a.b.c\u0026quot;, \u0026quot;.\u0026quot;)) ## [1] \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; ## Note that 'split' is a regexp! ## If you really want to split on '.', use unlist(strsplit(\u0026quot;a.b.c\u0026quot;, \u0026quot;[.]\u0026quot;)) ## [1] \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot; ## or unlist(strsplit(\u0026quot;a.b.c\u0026quot;, \u0026quot;.\u0026quot;, fixed = TRUE))  同理，gsub查找替换掉句点comma的时候也有类似的问题。我在使用python处理相邻多个段落的时候，直接使用了list的append的方法，导致两个自然段之间没有空格。这可要害苦我了。很多可以作为段落结尾的标点都要转化为空格。幸好老外写文章没有那么多问号和叹号结尾。\nfixed = TRUE意味着要use exact matching.\ntext1 = gsub(\u0026quot;[.]\u0026quot;, \u0026quot; \u0026quot;, text） text1 = gsub(\u0026quot;[.]\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) ","date":1377734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377734400,"objectID":"d17433b1eb41190763cd9320a9c3d44e","permalink":"https://chengjunwang.com/zh/archive/2013-08-29-encoding-in-r-for-text-mining.zh/","publishdate":"2013-08-29T00:00:00Z","relpermalink":"/zh/archive/2013-08-29-encoding-in-r-for-text-mining.zh/","section":"zh","summary":"","tags":null,"title":"使用R做主题模型：举一个处理Encoding问题的例子","type":"zh"},{"authors":null,"categories":null,"content":"王成军\n香港城市大学媒体与传播系\n在上一章当中，我们对于网络的基本知识进行了介绍，这些知识构建起了网络科学的基础，同时也孕育着巨大的潜能。社会科学追求理论的建构，但疏于思考理论层次的丰富性。以社会学为例，一度在宏大理论和抽象实证主义之间摇摆（参见米尔斯所著《社会学的想象力》）。大数据时代的到来，再一次使得少数人开始对理论的认识产生动摇，以为只要把握住数据就足够了。这与可计算性社会科学都是相互矛盾的。可计算性社会科学研究社会现实，紧紧抓住数据，但是绝不束缚于数据。\n数据（data）、模式（pattern）、法则（law）、机制（mechanism）和隐含的原理(principle)构成了科学研究等级，如图11-1所示。科学理论的等级在这里又被粗略地划分为四个等级：模式、法则、机制和原理。网络科学以关系来度量物理世界和社会现实（social reality）。这些稳定的关系——表现为网络中的链接——构成了网络科学可计算性的基础。沿着网络中的链接出发，网络科学正在尝试突破社会现实混沌的迷宫，从社会现实的数据出发，发掘社会系统内部的模式、法则、机制、原理。\n图 11-1. 科学研究的金字塔\n网络科学所采用的方法非常多样，除了经典的统计方法之外，很多物理学的方法也被广泛的应用在网络研究当中。具体而言，网络科学有两个方法来源，一个是传统的社会网络分析，一个是近十几年里面迅猛发展起来的复杂网络研究。这两股研究的脉络构成了网络科学的两条主线。网络科学已经走出传统的社会网研究的藩篱。互联网浪潮的袭来推动传统网络研究与互联网科学（web science)的融合。一种以复杂网络（complex network）为代表的新型网络科学开始迅速成长(Barabasi, 2003)。例如，巴拉巴西等人采用动力系统的研究方法分析复杂网络的增长机制(Barabási \u0026amp; Albert, 1999)。但在本章当中，我将主要关注统计网络模型（statistical network models），并通过介绍处理社会化网络数据的例子来深化我们对于网络的认识。\n本章的结构安排如下：一、通过介绍网络科学的异军突起来思考可计算性在不同学科的发展，以便于启发我们对于可计算社会科学的认识；二、我们介绍数字化媒体的发展，以及由此带来的大数据浪潮的挑战和机遇；三、我们开始介绍网络链接的属性，拓展对于网络的认识；四、简略介绍QAP检验；五、介绍指数随机图模型；六、结论和讨论。\n 网络科学的异军突起：反思可计算性 数字化媒体和大数据 扩展对于网络的认识（二模网络与多模网络和时间序列网络） QAP检验 指数随机图模型（ERGM） 一条开放的道路  ###一、网络科学的异军突起：反思可计算性\n事实上，作为一个后起之声，可计算性社会科学（computational social science）已经在各个分支学科和新的交叉性学科中如火如荼！关于计算社会科学的介绍可见Lazer等人(2009)发表在《科学》杂志上的一文。Lazer等人综述了可计算性社会科学的涌现和发展，尤其强调了网络科学研究在其中所扮演的角色和数字媒体所提供的机遇。网络科学和可计算性社会科学的兴起都使得我们开始更加严肃地思考可计算性在科学版图当中的作用。\n对于可计算性的追求在自然科学一直是主流。物理学具有着最强的可计算性。物质世界的稳定性给了物理学发展提供了得天独厚的条件。物理学家采用各种稳定的手段测量物理世界的状态：长度、面积、体积、质量、速度、时间、能量。从牛顿力学到相对论，电磁学、再到量子力学，物理学展现了理论和数据的高度统一：我们可以精确地知道桥梁的重量、地球到月球的距离和卫星发射的速度。这种成就在一开始就激励着社会科学的发展。生物学诞生之初，研究者多少博物学家，忙着收集标本，区分生物所属的界、门、纲、目、科、属、种的类别。即使到了达尔文提出物种起源假说，生物学的发展依然备受局限。是什么使得生物学步入可计算化的路径，进而实现新的飞跃？一个可能的答案是“基因”。抓住这个计算性的本源，生物学开始迅速崛起。\n社会科学则是另一番图景。试思考为什么经济学是社会科学中发展较好的？答案是货币。用货币度量经济行为使经济学具有了天然的可计算性；其次是心理学，不是量表，而是实验，使得心理学具有了“模糊的”比较能力。而其他传统的社会科学，如传播学，则处于摇摆当中缓慢发展。\n值得注意的是三个迅速发展的学科：计算机科学、统计语言学、和我们正在谈论的网络科学。毋庸置疑，计算机科学是二十世纪发展最快的学科之一。其中一个重要的原因就在于计算机科学所对付的对象是离散的0和1。0和1通过二进制的运算构成了现代计算机的基础，也使得计算机科学从诞生之初，其“基因”当中就蕴含了强大的可计算性。在此基础上，计算机科学可以相对容易地与数学相结合研究信息和通信问题，并借助计算性思维（computational thinking）通过算法设计来自动化地解决问题(Wing, 2006)。统计语言学是传统语言学与计算机科学相互融合的结果。通过建立关于语言学的数学模型，并通过计算机来进行运算，统计语言学使得语言学在过去的三十年当中取得长足进步(吴军, 2012)，例如自然语言处理（natural language processing）已经广泛地应用在互联网产业当中和其他学科的研究当中。最近升起的新星则当属网络科学。网络科学对社会关系进行运算，借用统计物理的方法，很快发现复杂网络（例如，大规模的社会网络就是一种复杂网络）具有明显的小世界特征(Watts \u0026amp; Strogatz, 1998)和无标度特征(Barabási \u0026amp; Albert, 1999)。\n概括以上内容，我们可以发现：可计算性植根于不同的学科当中。发掘可计算性对于不同的学科具有举足轻重的意义。基于可计算性的研究才有较高的信度和效度，才能得到更确实的（solid）发现，才能和数学工具和物理学工具更好的结合，才能更深刻地探寻社会模式背后的法则、机制、规律。\n图 11-2. 学科历史与其可计算性的关系\n###二、数字化媒体和大数据 互联网的发展使得人类社会进入了一个新的时代：数字媒体时代（the era of digital media）。这种变化的影响已经被诸多预言者和研究者所分析，也为这个时代的个体所体认与观察。人类的交往模式，商业行为，舆论空间等，都因互联网而改变。但本文由数字化痕迹开始讲起。\n数字化媒体（digital media）的崛起正在深刻变革的社会科学的研究视野。因为数字化技术的发展（比如互联网）使得很多的人类行为变得可以观察，因而给我们更真实地认识世界提供了一个崭新的入口——数字化痕迹（digital traces）。比如，你在网络上购物的经历，你在社交媒体上的使用记录。这些数字化痕迹（又称数字化指纹（digital fingerprint），或数字化脚印（digital footprint）），使得研究者可以追逐这种痕迹，分析其行为背后隐藏的社会规律，进而提供了一个巨大的资源。这种资源的出现正在变革着不同学科的研究视角和研究疆域。比如，网络化的大规模数据的数字化痕迹（digital traces）第一次使得传播行为获得了计算性。而记录（document）、收集（collect）、分析（analyze）、可视化（visualize）这些传播行为就成为了计算传播学的主要工作。按照这个设想，社会科学必须走出传统的研究套路，获得在网络上保存、抓取、分析、可视化大规模电子化数据的能力，也需要支持这些工作的工具。毫无疑问，社会科学因此将和计算机科学开始交汇，至少需要程序员投入到这种大规模数据的挖掘工作中来。计算机科学家越来越将更多的注意力放在社交媒体的使用研究方面来。一系列的计算机会议以社交媒体研究作为重心。其它的学科分支也马上意识到互联网带来的机遇和挑战。这里要首先谈人类认知世界的一个重要方法——观察法。\n观察法是社会研究和自然研究最古老的方法。在社会研究领域，这种方法因其复杂和难以操控，往往只是适用于研究初期。研究中后期往往使用调查和实验方法，但后面这两种方法的优点是根据研究者的视角进行操控（manipulate），但缺点也在这里。因为访谈或问卷或实验，往往会降低研究的效度。而数字化痕迹使得这种限制减少，使得研究者真正在研究活生生的人类行为，并且研究的规模非常巨大，且往往具有时间序列的信息。数字化痕迹使得非介入的观察（unobtrusive observation）成为可能，因而给研究者带来的巨大的机遇。机遇是数据的获取为检验和发展经典理论提供了土壤。但同时也伴随着挑战。这种挑战则首先主要来自这种数字痕迹的获取、分析和储存上。\n当然第一关是数据的获取。资源虽然存在，却并不能为所有的人所使用。因为这里有一个天然的、历史原因造成的技术屏障——计算机技术。数字化痕迹的还有一些其它特点。比如规模巨大，难以分析，当然这涉及到数据的分析问题，不是本文的重点。另外一个方面，这些数字指纹往往是流数据，这意味着如果此刻不获取这些数据，过一段时间这些数据就很难或者没有可能获取了。甚至因为数据规模庞大，一些互联网公司也并不会储存所有的数据。这也为数据获取者提供了一种学习的急迫性。\n其中最简单的是研究者的编程技术。传统的社会科学研究者和读者往往忽略计算机技术尤其是编程能力的培养。因而，在学科转型之初，第一步就是这种开始学习崭新的东西。这多多少少让新手感到畏惧。需要指出的是，这种畏惧是不必要的。因为技术的发展趋势是越来越人性化和具有可读性。这给编程语言的学习带来便利。社会科学研究者可以选取简单的编程语言（R、Python、Ruby）开始计算机编程的学习。一个问题是是否可以采用即成的数据抓取软件呢？我的理解是，就目前而言，打包好的数据抓取软件过于死板，且效率低下，并且多数价格不菲、不是开源的软件。因而不是首选。现在很多统计语言往往也可以从事数据抓取的工作，比如R社趣发展了twiiteR的包和Rweibo的包。虽然其接口并不完善，但研究者根据自我需求进行自由的开发。\n社交网站为了自身的发展，往往选择向外界开放部分资源，以方便第三方发展基于该社交网站的产品，进而更好吸引使用者使用。比如新浪微博上有着纵多的应用，这些应用的数据接口就是由新浪微博所提供的。当然这种数据提供需要注册和认证，例如，对新浪微博而言可到应用开发页面注册 。因而，数据抓取的第一步，就是建立数据连接的工作，以获取社交网站开放数据流的许可。现在流行的方式是使用OAuth获取连接社会化媒体的API的使用权限。这种机制的好处是直接从网站数据库获取数据，因而数据结构化较好，不需要经过复杂繁琐的处理。且更好保护了使用者的隐私(Russell, 2011)。获取数据使用许可之后，其使用就非常方便灵活了。\n在本章当中，我们使用李舰 (Li, 2013)编写的Rweibo来连接新浪微博的API接口，并获取我们所需要的信息。Rweibo是一个新浪微博针对R语言的软件开发工具包（Software Development Kit, SDK）。作为一个R的软件包，Rweibo可以在R软件当中自由安装和调用。\n新浪微博的API的使用需通过OAuth的方式进行授权。使用者需要首先到新浪微博开放平台申请一个新的应用：在新浪微博应用页面（http://open.weibo.com/development）点击“创建应用”并选择“网页应用”。创建应用后，在应用信息中可以找到该应用的App Key和App Secret。在本章当中我们创建一个应用名称为cssbook的应用。\n注意：Rweibo的授权回调页在R软件中默认为http://127.0.0.1/library/Rweibo/doc/callback.html，不允许用户修改。所以在创建应用的时候要一定要设置“授权回调页”为这个页面。否则，会造成授权回调页不匹配的错误。\n然后在R软件中通过Rweibo软件包通过编写R脚本来连接新浪API接口并进行数据获取等各项操作。第一步是在R软件当中安装Rweibo这个软件包。因为Rweibo使用过程中还会用到其它几个相关的包，如RCurl、rjson、XML、digest，在此也一并安装。\n# R程序11-1：在R软件当中安装并调用Rweibo软件包 install.packages(\u0026quot;Rweibo\u0026quot;, repos = \u0026quot;http://R-Forge.R-project.org\u0026quot;) library(Rweibo) # 使用Rweibo还需要安装其它几个相关的R包 install.packages(\u0026quot;RCurl\u0026quot;) install.packages(\u0026quot;rjson\u0026quot;) install.packages(\u0026quot;XML\u0026quot;) install.packages(\u0026quot;digest\u0026quot;)  第二步是在R当中输入App Key和App Secret进行OAuth认证。执行以下R代码。\n注意：createOAuth代码中的access_name必须改成你自己的新浪微博账号。\n# R程序11-2：在R中进行OAuth认证 registerApp(app_name = \u0026quot;cssbook\u0026quot;, app_key = \u0026quot;307359760\u0026quot;, app_secret = \u0026quot;82dfbc7194b2f3c37029b9f8c880c385\u0026quot;) roauth \u0026lt;- createOAuth(app_name = \u0026quot;cssbook\u0026quot;, access_name = \u0026quot;wangchj04\u0026quot;) # 一定要将网页应用的“授权回调页”设为：http://127.0.0.1/library/Rweibo/doc/callback.html  这样，在执行createOAuth代码后，就会自动弹出一个授权网页。在用户授权后，就会转到包含CODE的授权回调页，复制该页面的CODE并粘贴到R界面（R console），单击回车键，就可以完成授权。\n小练习：向R软件提问：用户可以通过listApp(\u0026laquo;cssbook\u0026raquo;)命令查看这个应用的信息；如果用户需要删除这个注册，可以执行deleteApp(\u0026laquo;cssbook\u0026raquo;)。当然，用户还可以通过执行modifyApp（）命令来修改关于这个应用注册信息。要了解关于modifyApp的用法，读者可以在R界面中输入？modifyApp来查看其使用方法。当然，如果读者对于其它的R命令的使用不熟悉，也可以使用这个方法问一下R软件。\n在成功通过OAuth2.0认证之后，用户就可以较为自由地调用和使用Rweibo的相关命令。以下R程序展现的是如何查看OAuth的注册信息、API的权限设置、查看用户关注的朋友所发布的微博、自己通过Rweibo发布一条测试信息。\n# R程序11-3： 测试Rweibo # 查看所注册的OAuth的信息 roauth # 查看API权限设置 roauth$getLimits(TRUE) # 查看自己所关注的朋友所发布的信息 sf = statuses.friends_timeline(roauth, count = 5) sft[[1]] # 发布一条微博 su \u0026lt;- statuses.update(roauth, status = \u0026quot;Test Rweibo for cssbook\u0026quot;) # 获取一条微博的被转发列表 # 这条源微博为：http://weibo.com/1869170057/zvzbUqqwC，查看页面源代码可以找到其mid ana1 \u0026lt;- analysis.getReposts(roauth, mid = \u0026quot;3575234466298494\u0026quot;)  通过analysis.getReposts命令，我们获取了@统计之都在新浪微博上所发的一条微博的转发列表，该微博位于http://weibo.com/1869170057/zvzbUqqwC，通过查看该页源代码可以找到这条微博的mid为3575234466298494。使用names(ana1)命令，可以查看数据ana1当中的变量信息。该数据主要包括两大部分信息：一部分是微博转发信息，包括转发时间、转发微博mid、转发微博内容text、转发微博再次被转发数量、转发微博被评论数量等。如下所示：\n\u0026quot;created_at\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;text\u0026quot;, \u0026quot;reposts_count\u0026quot;, \u0026quot;comments_count\u0026quot;, \u0026quot;attitudes_count\u0026quot;, \u0026quot;in_reply_to_status_id\u0026quot;, \u0026quot;in_reply_to_user_id\u0026quot;,\u0026quot;in_reply_to_screen_name\u0026quot;  另一部分信息为转发者信息，包括转发者的user id，转发者的screen name、转发者的地理信息、转发者的性别、转发者的粉丝数量和朋友数量等。具体信息如下：\n\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;,\u0026quot;User_province\u0026quot;, \u0026quot;User_city\u0026quot;, \u0026quot;User_location\u0026quot;,\u0026quot;User_description\u0026quot;, \u0026quot;User_gender\u0026quot;, \u0026quot;User_followers_count\u0026quot;, \u0026quot;User_friends_count\u0026quot;, \u0026quot;User_statuses_count\u0026quot;, \u0026quot;User_favourites_count\u0026quot;, \u0026quot;User_geo_enabled\u0026quot;, \u0026quot;User_created_at\u0026quot;, \u0026quot;User_following\u0026quot;, \u0026quot;User_follow_me\u0026quot;, \u0026quot;User_bi_followers_count\u0026quot;, \u0026quot;User_verified\u0026quot;, \u0026quot;User_verified_type\u0026quot;, \u0026quot;User_verified_reason\u0026quot;  我们将转发源微博的微博称之为“转发微博”。那么，值得注意的是analysis.getReposts命令获取的是一个转发列表，即所有的转发微博和转发者的信息，但我们仍然不知道具体的转发网络。\n就新浪微博单条微博而言，获取转发网络有两种方法：第一种是将所有的转发微博的被转发情况再抓取一次，这种方法的有点是精确，缺点是需要多次调用API接口；第二种方法是解析（parse）转发微博的内容，如果转发者不修改上家的转发内容的话，比如一个转发微博的内容为：“//@黠之大者: 我喜欢使用R软件。”我们可以认为这条微博转发自微博用户“黠之大者”。这种方法的优点是不需要继续调用API接口，缺点是会由于转发者修改转发内容，尤其是删除其转发源，而造成错误的结果。\n在本章当中，我们主要使用第一种方法。但我们不需要把所有的转发微博都再抓取一次，因为analysis.getReposts命令已经可以使我们知道每条转发微博之后的被转发次数。具体而言，只有那些reposts_count大于零的转发微博之后被其他用户转发。就我们这个具体的例子而言，1020个转发微博当中（870个独立转发者），只有139个转发微博被再度转发。86.4%的转发产生于第一步转发（即不经过中间转发者而直接转发源微博）。\n# R程序11-4：抓取二度转发者id ana2 = subset(ana1, ana1$reposts_count!= \u0026quot;0\u0026quot;) offspringlist = list() for (n in 1:length(ana2$mid)){ counts = ana2$reposts_count[n] result = statuses.repost_timeline(roauth, id = as.character(ana2$mid)[[n]], count = counts ) for (m in 1:counts){ offspring = result[[m]]$user$idstr addin = c(n, m, offspring) offspringlist = rbind(offspringlist, addin)} } data = data.frame(offspringlist, nrow=262, byrow=T)[,1:3] names(data) = c(\u0026quot;n\u0026quot;, \u0026quot;m\u0026quot;, \u0026quot;offspring\u0026quot;) # 二度转发的源头 dat = data.frame(ana2$User_idstr) dat$n = c(1:length(ana2$User_idstr)) names(dat) = c(\u0026quot;source\u0026quot;, \u0026quot;n\u0026quot;) dats = merge(dat, data, by = c(\u0026quot;n\u0026quot;)) dat1 = dats[,c('source','offspring')]  我们已经获取了所有的转发微博被再度转发的网络。对于所有的转发者而言，必然存在一个来源。如果一个节点在二度转网络当中没有来源，那么它的来源节点就是原微博的作者。由此，我们可以进一步获得一度转发网络：\n# R程序11-5： 获取一度转发网络 # 每个节点都有来源，如果一个节点无来源，则来自源节点1869170057 idsUnique = unique(ana1$User_idstr)# 870 unique diffusers offspring = subset(dats$offspring, dats$offspring != dats$source) idsWithoutSource = subset(idsUnique, !(idsUnique %in% offspring) ) dat2 = as.data.frame(cbind(1869170057,idsWithoutSource)) names(dat2) = c(\u0026quot;source\u0026quot;, \u0026quot;offspring\u0026quot;) # 合并一度转发网络及二度转发网络 dat3 = rbind(dat1, dat2)  基于总的转发信息和二度转发信息，我们可以绘制转发网络。\n# R程序11-6：绘制转发网络 # 绘制总的转发网络 library(igraph) g\u0026lt;-graph.data.frame(dat3) l\u0026lt;-layout.fruchterman.reingold(g) # 明确节点属性 vertex\u0026lt;-as.numeric(V(g)$name) V(g)$size = log(degree(g, v=V(g), mode = c(\u0026quot;out\u0026quot;)) + 1 ) nodeName = unique(ana1[,c(\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;)]) node = as.data.frame(V(g)$name) names(node) = c(\u0026quot;User_idstr\u0026quot;) nodeLabel = merge(node, nodeName, by = \u0026quot;User_idstr\u0026quot;, sort = F) nodeLabel$nodeSize = V(g)$size nodeLabel$User_screen_name[nodeLabel$nodeSize \u0026lt; 1]=\u0026quot;\u0026quot; nodeLabel = nodeLabel$User_screen_name # 保存图片格式 png(\u0026quot;d:/repostGraph.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) plot(g, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l ) # 结束保存图片 dev.off()  图 11-3. 微博转发网络\n# 绘制二度转发网络（剔除了第一步转发） g1\u0026lt;-graph.data.frame(dat1) l1\u0026lt;-layout.fruchterman.reingold(g1) # 明确节点属性 vertex\u0026lt;-as.numeric(V(g1)$name) V(g1)$size = degree(g1, v=V(g1), mode = c(\u0026quot;out\u0026quot;)) nodeName = unique(ana1[,c(\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;)]) node = as.data.frame(V(g1)$name) names(node) = c(\u0026quot;User_idstr\u0026quot;) nodeLabel = merge(node, nodeName, by = \u0026quot;User_idstr\u0026quot;, sort = F, all = FALSE) nodeLabel$nodeSize = V(g1)$size nodeLabel$User_screen_name[log(nodeLabel$nodeSize+1) \u0026lt; 1]=\u0026quot;\u0026quot; nodeLabel = nodeLabel$User_screen_name # 保存图片格式 png(\u0026quot;d:/repostGraph2step.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) # 绘制图片 plot(g1, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l1 ) # 结束保存图片 dev.off()  图 11-4. 微博二度转发网络（剔除了第一步转发）\n当然，我们还可以通过解析微博内容的方法来提取转发网络。这需要我们对转发微博的内容进行分析，提取其中“//@”后出现的微博用户名。我们借助gsubfn这个R包中的strapply来实现这个过程。\n# R程序11-7：通过解析微博内容提取转发网络 library(gsubfn) findSource = function(n){ res1=strapply(ana1$text[n], paste(\u0026quot;\\\\w*\u0026quot;, \u0026quot;//@\u0026quot;, \u0026quot;\\\\w*\u0026quot;, sep = \u0026quot;\u0026quot;), c, simplify = unlist) res2 = ifelse(is.null(res1) == TRUE, 0,unlist(strsplit(res1[1], \u0026quot;@\u0026quot;))[2] ) return(res2) } source = unlist(lapply(c(1:length(ana1$text)), findSource)) dat4 = as.data.frame(cbind(source, ana1$User_screen_name)) # 总的转发网络 dat4$source[as.character(dat4$source) == \u0026quot;0\u0026quot;] = \u0026quot;统计之都\u0026quot; dat5 = subset(dat4, dat4$source != \u0026quot;统计之都\u0026quot;) # 二度转发网络 # 绘制总的转发网络 library(igraph) g4\u0026lt;-graph.data.frame(dat4) l\u0026lt;-layout.fruchterman.reingold(g4) plot(g4, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l ) # 绘制二度转发网络 library(igraph) g5\u0026lt;-graph.data.frame(dat5) l\u0026lt;-layout.fruchterman.reingold(g5) plot(g5, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l )  这种直接使用编程语言上手的方法符合“通过实践学习”（learning by doing）的哲学。为社会科学研究者和广大的读者提供了一个轻巧的入门的道路。遇到问题，解决问题，学习者也可以在实际的练习当中进步。当然，千言万语不如付诸行动。只有开始了第一步的下载和安装python，安装一些包，写出第一个有用的程序的时候，才算真正不虚此行。最具有吸引力的是一通百通，会从Twitter上获取信息，你也就具有了从其他网站（如新浪微博）上获取信息的能力。当你走完这一步，我们可以相信，一个可计算的社会科学研究就从你自己这里开始起步了。\n三、重新认识网络：一个整体的视角 网络科学（network science）是可计算性社会科学(computational social science)的一个重要组成部分。它不仅提供了一个崭新的视角，还为社会科学提供了一系列的理论和方法。网络科学提供了新的认识社会的视角，即对关系进行计算。通过对关系进行计算,网络科学丰富了人类认识世界的维度。网络无时无刻不存在于我们生活的每个细节：我们生活在一个社会网络当中，没有人是绝对孤立的点，每个个体时刻都在与其他人进行着互动；我们生活的大自然有一个食物网络，能量沿着食物网当中的链接由植物向高级的动物流动；我们的生活处于一个物流网络当中，交通干线承担着人口迁移和物质供给的职能，世界贸易网络刻画着国家间的贸易往来和经济依赖关系，等等。\n这种网络的链接有时候充当渠道的作用，网络的流可以藉此得以流通。这种网络当中的流可以具有多种表现形式：信息、商品，货币、信任、命令等。这些网络的流，往往充当着稀缺的社会资源的角色，具有明确而重要的社会功能。网络渠道对于网络的流具有引导和塑形的作用。比如，我们在日常生活中主动地建立自己的社会联系。有时候我们只能观察到其中之一，或者是网络渠道，或者是网络中流，因而链接预测（link prediction）成为网络科学研究当中一个重要议题(Lü \u0026amp; Zhou, 2011)。\n把握和认识这种关系能够为我们带来洞察，发现隐藏在事物表象下的模式。关系以链接的形式呈现于网络当中。例如，中国乡土社会当中的人和人之间的关系可以通过新年拜年的网络链接展现，通过观察礼物的类别、价格以及送礼人所使用的语言，我们可以对这种关系进行测量。类似的，恐怖分子通过隐秘的互动网络进行组织，通过观察其互动的频次、方向和时间，我们可以对互动双方的职能进行划分，进而发现其中的等级关系。这种对于网络当中链接所隐含的信息的应用非常普遍。例如，警察破案，很关键的一点是理清犯罪嫌疑人的人际关系网络。在模式的基础上，网络科学家开始更深入地探索网络科学中的法则，例如复杂网络的幂律分布。事实上，此时我们开始触及之前章节关于图论的知识，尤其是关于复杂网络的研究。最简单的网络是规则网，最混沌的网络在随机网。而复杂网络（包括社会网络）则处于从规则走向混沌的过渡阶段。Watts和Strogatz的研究表明将规则网络中的链接（按照一定的概率）随机重连就可以得到小世界网络(Watts \u0026amp; Strogatz, 1998)。Barabási和Albert随后的研究表明复杂网络中节点的度分布具有无标度特征(Barabási \u0026amp; Albert, 1999)。其后，一系列关于复杂网络的小世界特征和无标度性进行推动了网络科学的发展。从网络链接当中找到统一的模式和法则是认识网络的第一步，接下来需要理解网络链接的形成机制。\n网络链接的形成机制非常多样：1. 网络节点的流行程度（popularity）如社会影响力（social influence）(Barabási \u0026amp; Albert, 1999; Goodreau SM, 2009; Papadopoulos, Kitsak, Serrano, Boguná, \u0026amp; Krioukov, 2012)、2. 相似性（similarity）或同质性（homophily）(Goodreau SM, 2009; McPherson, Smith-Lovin, \u0026amp; Cook, 2001)、4. 地理空间接近性和社会接近性（spatial and social proximity）(Crandall et al., 2010; Rivera, Soderstrom, \u0026amp; Uzzi, 2010). 当然，除此之外还有很多其它的影响因素来源于: 5. 网络结构，如结构洞（Structural holes）(Burt, 1992)。尤其应当强调的是，基于社会规范（如社会交换）的互惠性（Reciprocity）在网络的行程中发挥着重要作用，因为基于社会规范，我们总是倾向于投桃报李、彼此合作、互利共赢(Cranmer, Heinrich, \u0026amp; Desmarais, 2013)；类似的，社会个体倾向于维持认知平衡并避免冲突关系(Davis, 1963; Newcomb, 1953)，因而关系的传递性（Transitivity）同样起着重要的作用。例如，在社会网络当中，人们倾向于和朋友的朋友建立网络关系(Goodreau SM, 2009)。\n四、QAP检验：两个网络之间的关联 通常一组个体具有多种类型的关系，例如友谊关系和经济往来关系。我们通常会对这两种网络关系在多大程度上相互关联感兴趣。当我们知道一组个体之间的两种关系网络，我们就可以计算这个两个关系网络之间的相关程度。在统计学当中，皮尔森相关系数是用来反映两个变量线性相关程度的统计量。与之类似，对于由一组个体所组成的两个网络，也可以计算其相应的相关皮尔逊相关系数。当然，还可以计算其他你感兴趣的统计量，如协相关系数。\n我们使用sna这个R软件包来计算网络相关系数（并调用qaptest命令）。通过安装和使用statnet这个R软件包，就会自动加载sna等子软件包。另外，statnet当中还集成了其他的几个相关的R软件包，包括进行动态网络建模的tergm子软件包。\n# R程序11-8：计算网络的皮尔逊相关系数 install.packages(\u0026quot;statnet\u0026quot;) library(statnet) # 首先随机生成3个由10个节点构成的有向网络 g = array(dim=c(3,10,10)) g[1,,] = rgraph(10) g[2,,] = rgraph(10,tprob=g[1,,]*0.8) # 设置g1和g2两个网络强相关 g[3,,] = 1; g[3,1,2] = 0 # g3接近于一个派系（clique） # 绘制这3个网络 par(mfrow=c(1,3)) for(i in 1:3) { gplot(g[i,,],usecurv=TRUE, mode = \u0026quot;fruchtermanreingold\u0026quot;, vertex.sides=3:8)} #计算网络的相关矩阵 gcor(g)  在通常使用皮尔逊相关系数的时候，可以用t统计量对总体相关系数为0的原假设进行检验。但在计算网络的相关系数（graph correlations）时，经典的零假设检验方法往往会带来偏差，因而并不适用。通常使用非参数检验的方法，比如QAP(Quadratic Assignment Procedure)检验。\n矩阵的随机排列（Random matrix permutations）是QAP检验的关键部分，在子软件包sna中主要通过rmperm来进行。通过矩阵的随机排列，可以对网络中的节点（的编号）进行随机置换（relabelling），并得到一组（比如1000个）重连后的网络。\n# R程序11-9：矩阵的随机置换方法 j = rgraph(5) # 随机生成一个网络 j #看一下这个网络的矩阵形式 rmperm(j) #随机置换后的网络的矩阵形式  对这一组重构的网络可以计算其网络级别的参数（如两个网络的相关参数，协相关参数），并因此得到一个参数分布。QAP检验的零假设是实际观测到的网络参数（如）来自于这一个参数分布。也就是说，原假设认为这种观测到的相关关系是由随机因素带来的，因而这种网络相关并不显著。拒绝原假设，就从统计的角度证明了观测到的网络相关系数是显著的。\n# R程序11-10：QAP检验 q.12 = qaptest(g, gcor, g1 = 1, g2 = 2) q.13 = qaptest(g, gcor, g1 = 1, g2 = 3) # 看一下QAP输出的结果 par(mfrow=c(1,2)) summary(q.12) plot(q.12) # 拒绝原假设，图1和图2显著相关 summary(q.13) plot(q.13) # 接受原假设，图1和图3不相关  在检验这个关于两个网络是否存在相关的零假设的时候，我们计算置换后的参数分布中大于这个实际观测到的参数的比例，以及小于这个实际观测到的参数的比例。QAP检验返回实际数据中观测到的参数f(d)、通过置换所得到的参数f(perm)的数学分布、以及单尾的P值。其中单尾的p值包括两种情况：p(f(perm) \u0026gt;= f(d))和p(f(perm) \u0026lt;= f(d))。\n其中P(f(perm) \u0026gt;= f(d))表示随机置换矩阵的相关系数的大于与等于观测值的p值，也就是本研究的检验显著性。一般而言，当p(f(perm) \u0026gt;= f(d))小于p(f(perm) \u0026lt;= f(d))时，拒绝原假设。\n思考另外一个问题：如果两个节点之间存在一种关系（例如A和B之间存在相互关注的的朋友关系），是否暗示着他们之间是否可能存在另一种关系（例如A和B之间存在相互转发信息的传播关系）？这样，我们试图去找到一种关系对于另一种关系的影响。例如，两个作者来自同一所学校对于他们之间的合作关系是否具有显著的影响。除此之外，还有节点的属性的影响，网络规模的影响，网络中二元组和三元组的影响等等。指数随机图模型作为一个网络统计模型可以较好地综合不同层级的影响因素，因为成为统计网络数据分析的主要模型。\n五、指数随机图模型 指数随机图模型（exponential random graph models, ERGMs）是一种使用蒙特卡罗最大似然(MCMC)方法的logit模型(Frank \u0026amp; Strauss, 1986; Goodreau SM, 2009; Wasserman \u0026amp; Pattison, 1996)。指数随机图模型的因变量是两个节点之间形成链接（tie-formation）的概率。采用马尔科夫链蒙特卡洛（Markov chain Monte Carlo， MCMC）方法，指数随机图模型挑选可以最大化得生成实际观察到的网络的模型(Snijders, 2002)。\n定义$$\\mathbf{Y}$$为网络中所有可能的链接关系，$$\\mathbf{y}$$是网络节点间（实际存在或可观察到的）一种具体的链接关系。定义$$\\mathbf{X}$$为网络节点属性，它是一个矩阵。在以上定义基础上，定义$$g(\\mathbf{y}, \\mathbf{X})$$为网络的统计量，它是一个向量。这些网络统计量包括两部分：一部分是网络结构的统计量，如链接的数量、二元组数量、三元组数量等；另一部分是网络节点属性的统计量，例如在微博信息转发网络中，网络节点属性包括微博转发者的年龄、性别、地理位置、活跃性、流行程度等。这些网络统计量构成了指数随机图模型的自变量，根据它们，指数随机图模型预测因变量，即节点之间构成链接的概率。\n为了进行模型估计，还需要引入一些参数（parameter）。为此，我们定义$$\\theta$$为网络统计量的系数，它是一个向量。此外，$$k(\\theta )$$是归一化常数，它可以确保模型中各种网络统计量形成链接的概率之和为1。这样，关于观察到一组网络链接的概率可以用指数随机模型表示为以下公式：\n$$ P(\\mathbf{Y} = \\mathbf{y}|\\mathbf{X}) = exp[{\\theta } ^{T} g(\\mathbf{y},\\mathbf{X})]/k(\\theta ) $$\n以上模型还可以表达为logit模型的形式。如果两个节点i和j之间存在链接的概率表示为$$p{ij}$$，那么不存在链接的概率可以表示为$$1-p{ij}$$。$$p{ij} / (1-p{ij})$$表示事件发生的相对似然率（the relative likelihood），又被称之为优势比（odds ratio）。比如，在信息转发的情境当中，A总共发了10条信息，B转发了其中的8条，那么优势比就是0.8\u0026frasl;0.2 = 4。Logit模型当中的因变量是优势比的自然对数形式，相应的模型表达为以下形式：\n$$ logit(Y{ij} = 1) = ln(\\frac{p{ij}}{1-p{ij}}) = {\\theta }^{T} \\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]{ij} $$\n以上公式当中，定义$$Y{ij}$$为节点i和j之间形成链接的一个随机变量。当$$y{ij}$$取值由0变为1的时候，所带来的$$g(\\mathbf{y},\\mathbf{X})$$的变化表示为$$\\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]_{ij}$$。\nstatnet是一个R包 (Goodreau, Handcock, Hunter, Butts, \u0026amp; Morris, 2008)，其中包含了三个子包：network, sna, 和ergm。本部分我们主要使用network来建立网络对象，并使用ergm针对网络对象建立指数随机图模型。\n使用network子包建立网络模型主要是将边的列表或者邻接矩阵的数据转化为statnet所默认的网络对象形式。例如，在以下程序中，我们将所抓取的微博转发网络数据转化为网络对象形式。\n#R程序 11-11：建立微博转发网络的ERG模型 library(\u0026quot;statnet\u0026quot;) # memory.limit(2000) #设置R调用内存的上限2GB # 将数值类型的变量转化为字符类型的变量以避免\u0026quot;vector size specified is too large\u0026quot; dat3[,1] = as.character(dat3[,1])　dat3[,2] = as.character(dat3[,2]) # 将edgelist类型的数据转化为一个网络对象 n = network(dat3, vertex.attr=NULL, vertex.attrnames=NULL, matrix.type=\u0026quot;edgelist\u0026quot;, directed=TRUE) summary(n) # 看一下网络的基本信息  指数随机图模型的一个优势是可以综合不同层级的影响因素（比如节点属性，链接或二元组属性、三元组属性、网络规模属性），其中的之一就是将网络节点属性纳入分析。其中的一个容易被忽略的关键点是将网络对象中的节点与原数据对应起来。\n此处，我们首先要明确网络对象中的节点（通过以下程序中的network.vertex.name来获取）并得到一个列数为1的网络节点数据。然后，我们将原始数据中的节点属性并入到网络节点数据中（通过merge命令来合并数据）。特别注意是此处推荐使用plyr包里面的join命令，因为在使用merge命令来合并数据的时候，即使设置“sort = F”其排序依然会出问题。最后，采用set.vertex.attribute命令就可以对节点属性进行设定。\n# 网络对象中的节点 node = data.frame(network.vertex.names(n), stringsAsFactors = F) names(node) = c(\u0026quot;User_idstr\u0026quot;) # 选取纳入分析的节点属性 att = unique(ana1[,c(\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;, \u0026quot;User_gender\u0026quot;, \u0026quot;User_followers_count\u0026quot;, \u0026quot;User_friends_count\u0026quot;, \u0026quot;User_statuses_count\u0026quot;, \u0026quot;User_verified\u0026quot; )]) # 合并节点属性到网络节点数据 # Add province name province = read.csv(\u0026quot;D:/chengjun/css/part05/chapter11/data/weiboprovince.csv\u0026quot;, stringsAsFactors= F, header = F, sep = \u0026quot;,\u0026quot;) names(province) = c(\u0026quot;User_province\u0026quot;, \u0026quot;User_province_name\u0026quot;) library(plyr) att1 = join(att, province, by = \u0026quot;User_province\u0026quot; ) nodeAtt = join(node, att, by = \u0026quot;User_idstr\u0026quot;) set.vertex.attribute(n,\u0026quot;User_gender\u0026quot;,nodeAtt$User_gender) nodeAtt$User_verified[is.na(nodeAtt$User_verified)]=\u0026quot;FALSE\u0026quot; set.vertex.attribute(n,\u0026quot;User_verified\u0026quot;,nodeAtt$User_verified) nodeAtt$User_friends[is.na(nodeAtt$User_friends)]=0 set.vertex.attribute(n,\u0026quot;User_friends\u0026quot;,nodeAtt$User_friends) set.vertex.attribute(n,\u0026quot;User_city\u0026quot;,nodeAtt$User_city) set.vertex.attribute(n,\u0026quot;User_province\u0026quot;,nodeAtt$User_province) set.vertex.attribute(n,\u0026quot;User_bi_followers\u0026quot;,nodeAtt$User_bi_followers_count) nodeAtt$User_followers_count[is.na(nodeAtt$User_followers_count)]=0 set.vertex.attribute(n,\u0026quot;User_followers\u0026quot;,nodeAtt$User_followers_count) set.vertex.attribute(n,\u0026quot;User_statuses\u0026quot;,nodeAtt$User_statuses_count) set.vertex.attribute(n,\u0026quot;User_favourites\u0026quot;,nodeAtt$User_favourites_count)  当数据的准备工作做好之后，这个时候我们可以重新查看网络对象（在我们的饿例子中是n）的属性。在R console当中，输入summary(n)即可查看网络属性：\n Network attributes: vertices = 870 directed = TRUE hyper = FALSE loops = FALSE multiple = FALSE bipartite = FALSE total edges= 890 missing edges= 0 non-missing edges= 890 density = 0.001177202 Vertex attribute names: User_followers User_friends User_gender User_statuses User_verified vertex.names  此时，我们就可以正式开始模型设定和参数估计。这里，我们首先建立一个最为简单的网络模型m0。m0仅仅考虑最简单的网络参数，即网络当中的链接的数量。模型m0假设网络中的链接是随机生成的，也就是Erdős Rényi 随机网络模型（random graph）的基本要求，因而这个模型所生成的网络必然具备随机网络模型的特点(Erdős \u0026amp; Rényi, 1959)。\n# ERG模型的模型设定（Model Specification） m0\u0026lt;-ergm(n ~ edges, parallel=10) summary(m0) ========================== Summary of model fit ========================== Formula: n ~ edges Iterations: 20 Monte Carlo MLE Results: Estimate Std. Error MCMC % p-value edges -6.75703 0.03377 NA \u0026lt;1e-04 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Null Deviance: 1048080 on 756030 degrees of freedom Residual Deviance: 13622 on 756029 degrees of freedom AIC: 13624 BIC: 13636 (Smaller is better.)  该模型结果表明按照随机网络模型生成的网络，其中每一个网络链接（即信息转发）的log-odds是$$-6.75703\\mathbf{\\delta} [g(\\mathbf{y},\\mathbf{X})]{ij}$$。因为每增加任意一个链接，本模型的网络统计量（也就是网络中的链接的数量）增加1，所以$$\\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]{ij}$$等于1。所以生成每条网络链接的对数优势比就是-6.75703。由此，不难算出生成每条网络链接的概率为exp(-6.75703)/(exp(-6.75703) + 1) = 0.001161327,而这个数值与实际的信息转发网络（有向）的网络密度（density）0.001177202非常接近。\n除了零模型中的边数之外，指数随机图模型还可以控制其它网络结构的因素，如网络中的的二元组的数量（通过mutual来在ergm中设定）和三元组的数量（通过gwesp在ergm中设定）。\n另外，指数随机图模型可以很容易的分析节点属性对于网络中的链接形成的影响，主要分析两种网络构成机制：流行性（popularity）和相似性（similarity）(Papadopoulos, et al., 2012)。首先，流行性主要分析一个节点的某种流行性的属性，比如一个信息转发者的粉丝的数量，在指数随机图模型中主要通过nodefactor和nodecov来设定。nodefactor主要分析针对的是类别变量，如性别、籍贯等；而nodecov主要针对的是连续型变量，如年龄、收入等。在有向网络当中，根据节点的入度和出度的区分，nodefactor和nodecov又可以区分为nodeicov和nodeocov，以及nodeifactor和nodeofactor。其次，相似性主要强调的是网络节点的两两之间在某种属性上的相似程度，在statnet的ergm命令当中主要通过nodematch来设定。如果说nodefactor和nodecov测量的是节点属性的主效应（main effect）的话，那么nodematch测量的主要是节点属性在网络链接水平上的匹配程度，也可以理解为交互效应。\n举一个例子来理解流行性和相似性作为两种一般性的影响因素在指数随机图模型当中的刻画，读者可以参阅 Goodreau (2009)关于青少年个体属性（性别、种族、年级）对于社会网络构成的影响。Goodreau认为个体属性的主要效应在友谊形成网络当中主要可以区分为两类：社交性（sociality）和同质性（homophily）。其中前者对应于流行性，而后者对应于相似性。与之相应，在指数随机图模型的设定当中，前者通过nodefactor/nodecov测量，而后者主要通过nodematch测量。\n# ERG Model Specification m0\u0026lt;-ergm(n ~ edges + nodematch(\u0026quot;User_province\u0026quot;) + mutual + gwesp(fixed=T, cutoff=30), parallel=10) summary(m0) mcmc.diagnostics(m0)  模型的运行结果如下：\n Estimate Std. Error MCMC % p-value edges -6.93374 0.03907 0 \u0026lt;1e-04 *** nodematch.User_province 0.95514 0.07629 0 \u0026lt;1e-04 *** mutual 0.42916 1.00405 0 0.669 gwesp.fixed.0 0.56772 0.72052 0 0.431 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Null Deviance: 1048080 on 756030 degrees of freedom Residual Deviance: 13498 on 756026 degrees of freedom AIC: 13506 BIC: 13552 (Smaller is better.) mcmc.diagnostics(m0)  当然了，我们可以根据研究目的建立更加完整的网络模型。例如，在以下的模型m1当中，我们开始考虑朋友数量、粉丝数量、用户性别、用户级别（是否认证用户）对于网络模型中链接形成的影响。需要注意的是该模型的运行时间很长，读者需要耐心等待。\nm1\u0026lt;-ergm(n ~ edges + nodecov(\u0026quot;User_friends\u0026quot;)+ nodecov(\u0026quot;User_followers\u0026quot;) + nodematch(\u0026quot;User_province\u0026quot;) + nodefactor(\u0026quot;User_province\u0026quot;) + nodematch(\u0026quot;User_gender\u0026quot;)+ nodematch(\u0026quot;User_verified\u0026quot;) + mutual + gwesp(fixed=T, cutoff=30), parallel=10) summary(m1) mcmc.diagnostics(m1)  模型的运行结果如下：\n# ========================== # Summary of model fit # ========================== # # Formula: n ~ edges + nodecov(\u0026quot;User_friends\u0026quot;) + nodecov(\u0026quot;User_followers\u0026quot;) + # nodematch(\u0026quot;User_province\u0026quot;) + nodefactor(\u0026quot;User_province\u0026quot;) + # nodematch(\u0026quot;User_gender\u0026quot;) + nodematch(\u0026quot;User_verified\u0026quot;) + mutual + # gwesp(fixed = T, cutoff = 30) # # Iterations: 20 # # Monte Carlo MLE Results: # Estimate Std. Error MCMC % p-value # edges -1.716e+01 3.984e-01 0 \u0026lt; 1e-04 *** # nodecov.User_friends -1.626e-03 1.846e-04 0 \u0026lt; 1e-04 *** # nodecov.User_followers 5.482e-04 1.216e-05 0 \u0026lt; 1e-04 *** # nodematch.User_province 3.831e-01 1.835e-01 0 0.036892 * # nodefactor.User_province.12 2.132e-01 3.502e-01 0 0.542661 # nodefactor.User_province.13 -7.425e-01 6.034e-01 0 0.218500 # nodefactor.User_province.14 -8.294e-01 1.031e+00 0 0.421116 # nodefactor.User_province.15 -5.463e-01 1.254e+00 0 0.663011 # nodefactor.User_province.21 -7.493e-01 5.439e-01 0 0.168295 # nodefactor.User_province.22 8.519e-02 3.643e-01 0 0.815101 # nodefactor.User_province.23 -2.727e-01 3.946e-01 0 0.489453 # nodefactor.User_province.31 -3.235e-01 1.719e-01 0 0.059810 . # nodefactor.User_province.32 -1.399e-01 2.522e-01 0 0.579093 # nodefactor.User_province.33 -1.466e-01 2.267e-01 0 0.517730 # nodefactor.User_province.34 -2.558e-01 4.437e-01 0 0.564221 # nodefactor.User_province.35 -4.032e-01 3.437e-01 0 0.240691 # nodefactor.User_province.36 3.205e-01 5.578e-01 0 0.565517 # nodefactor.User_province.37 -1.294e-01 4.125e-01 0 0.753818 # nodefactor.User_province.41 -3.616e-01 4.546e-01 0 0.426427 # nodefactor.User_province.42 -3.622e-01 3.374e-01 0 0.283047 # nodefactor.User_province.43 -3.551e-01 4.317e-01 0 0.410737 # nodefactor.User_province.44 -6.743e-02 1.567e-01 0 0.667042 # nodefactor.User_province.45 1.205e-01 1.106e+00 0 0.913280 # nodefactor.User_province.46 -2.464e-01 9.628e-01 0 0.798021 # nodefactor.User_province.50 -4.050e-01 5.908e-01 0 0.492984 # nodefactor.User_province.51 -6.097e-01 3.412e-01 0 0.074006 . # nodefactor.User_province.52 -3.054e-01 7.901e-01 0 0.699042 # nodefactor.User_province.53 3.954e-01 5.112e-01 0 0.439207 # nodefactor.User_province.61 -9.135e-02 4.958e-01 0 0.853833 # nodefactor.User_province.62 -7.939e-01 1.505e+00 0 0.597808 # nodefactor.User_province.64 -1.170e-01 1.641e+00 0 0.943158 # nodefactor.User_province.71 2.458e+00 1.607e+00 0 0.126091 # nodefactor.User_province.81 2.587e-03 4.796e-01 0 0.995696 # nodefactor.User_province.100 3.966e-01 1.915e-01 0 0.038304 * # nodefactor.User_province.400 -4.561e-01 2.430e-01 0 0.060461 . # nodematch.User_gender 5.707e-01 1.598e-01 0 0.000355 *** # nodematch.User_verified 9.986e+00 3.039e-01 0 \u0026lt; 1e-04 *** # mutual -8.400e+00 2.566e+00 0 0.001063 ** # gwesp.fixed.0 -4.064e+00 8.897e-01 0 \u0026lt; 1e-04 *** # --- # Signif. codes: 0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1 # # Null Deviance: 1048080 on 756030 degrees of freedom # Residual Deviance: 7680 on 755991 degrees of freedom # # AIC: 7758 BIC: 8208 (Smaller is better.)  六、讨论和结论 本章以网络科学为核心，勾勒了科学与可计算性的关系，描绘了数字化媒体和大数据的广泛应用，在此基础上重新思考了网络科学所蕴含的意义，并结合实际的案例介绍统计学方法在网络科学当中的应用。\n应当注意的是，本文只是一个基础的引论，而非全面而严格的介绍。本文的意义在于启发读者和勾勒大的图景。限于篇幅，对于很多具体的数学细节和理论问题并没有足够的论述。读者需要根据本文的参考文献按图索骥。通过进一步的阅读和学习来加深对网络科学的理解，并根据自己的需要在实践当中学习。\n参考文献  Barabási, A.-L., \u0026amp; Albert, R. (1999). Emergence of scaling in random networks. science, 286(5439), 509-512.\nBarabasi, A.-L. (2003). Linked: How everything is connected to everything else and what it means for business, science, and everyday life. New York: Plume.\nBurt, R. S. (1992). Structural holes. Boston: Harvard University Press.\nCrandall, D. J., Backstrom, L., Cosley, D., Suri, S., Huttenlocher, D., \u0026amp; Kleinberg, J. (2010). Inferring social ties from geographic coincidences. Proceedings of the National Academy of Sciences, 107(52), 22436-22441.\nCranmer, S. J., Heinrich, T., \u0026amp; Desmarais, B. A. (2013). Reciprocity and the structural determinants of the international sanctions network. Social Networks, http://www.sciencedirect.com/science/article/pii/S0378873313000026.\nDavis, J. A. (1963). Structural balance, mechanical solidarity, and interpersonal relations. American Journal of Sociology, 68, 444-462.\nErdős, P., \u0026amp; Rényi, A. (1959). On random graphs. Publicationes Mathematicae Debrecen, 6, 290-297.\nFrank, O., \u0026amp; Strauss, D. (1986). Markov graphs. Journal of the american Statistical association, 81(395), 832-842.\nGoodreau, S. M., Handcock, M. S., Hunter, D. R., Butts, C. T., \u0026amp; Morris, M. (2008). A statnet tutorial. Journal of statistical software, 24(9), 1-26.\nGoodreau SM, K. J., Morris M (2009). Birds of a feather, or friend of a friend? Using exponential random graph models to investigate adolescent social networks. Demography, 46, 103-125.\nLü, L., \u0026amp; Zhou, T. (2011). Link prediction in complex networks: A survey. Physica A: Statistical Mechanics and its Applications, 390(6), 1150-1170.\nLazer, D., \u0026amp; Pentland, A. S., Adamic, Lada., Aral, Sinan., Barabasi, Albert Laszlo., Brewer, Devon., Christakis, Nicholas., Contractor, Noshir., Fowler, James., Gutmann, Myron. (2009). Life in the network: The coming age of computational social science. Science, 323(5915), 721.\nLi, J. (2013). Rweibo: An interface to the Weibo open platform. http://jliblog.com/app/rweibo.\nMcPherson, M., Smith-Lovin, L., \u0026amp; Cook, J. M. (2001). Birds of a feather: Homophily in social networks. Annual review of sociology, 27, 415-444.\nNewcomb, T. M. (1953). An approach to the study of communicative acts. Psychological review, 60(6), 393.\nPapadopoulos, F., Kitsak, M., Serrano, M. Á., Boguná, M., \u0026amp; Krioukov, D. (2012). Popularity versus similarity in growing networks. Nature, 489(7417), 537-540.\nRivera, M. T., Soderstrom, S. B., \u0026amp; Uzzi, B. (2010). Dynamics of dyads in social networks: Assortative, relational, and proximity mechanisms. Annual review of sociology, 36, 91-115.\nRussell, M. A. (2011). Mining the social web: Analyzing data from Facebook, Twitter, LinkedIn, and other social media sites. Cambridge: O\u0026rsquo;Reilly.\nSnijders, T. A. (2002). Markov chain Monte Carlo estimation of exponential random graph models. Journal of Social Structure, 3(2), 1-40.\nWasserman, S., \u0026amp; Pattison, P. (1996). Logit models and logistic regressions for social networks: I. An introduction to Markov graphs and p*. Psychometrika, 61(3), 401-425.\nWatts, D. J., \u0026amp; Strogatz, S. H. (1998). Collective dynamics of ‘small-world’networks. Nature, 393(6684), 440-442.\nWing, J. M. (2006). Computational thinking. Communications of the ACM, 49(3), 33-35. 吴军. (2012). 数学之美. 北京: 人民邮电出版社.\n ","date":1376006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376006400,"objectID":"c9db5792025506e84ac81b21baec4b93","permalink":"https://chengjunwang.com/zh/archive/2013-08-09-sna-book-chapter.zh/","publishdate":"2013-08-09T00:00:00Z","relpermalink":"/zh/archive/2013-08-09-sna-book-chapter.zh/","section":"zh","summary":"","tags":null,"title":"探寻社交网络中的关系: 统计网络模型初探","type":"zh"},{"authors":null,"categories":null,"content":"QAP检验：两个网络之间的关联 通常一组个体具有多种类型的关系，例如友谊关系和经济往来关系。我们通常会对这两种网络关系在多大程度上相互关联感兴趣。当我们知道一组个体之间的两种关系网络，我们就可以计算这个两个关系网络之间的相关程度。在统计学当中，皮尔森相关系数是用来反映两个变量线性相关程度的统计量。与之类似，对于由一组个体所组成的两个网络，也可以计算其相应的相关皮尔逊相关系数。当然，还可以计算其他你感兴趣的统计量，如协相关系数。\n我们使用sna这个R软件包来计算网络相关系数（并调用qaptest命令）。通过安装和使用statnet这个R软件包，就会自动加载sna等子软件包。另外，statnet当中还集成了其他的几个相关的R软件包，包括进行动态网络建模的tergm子软件包。\n# R程序11-8：计算网络的皮尔逊相关系数 install.packages(\u0026quot;statnet\u0026quot;) library(statnet) # 首先随机生成3个由10个节点构成的有向网络 g=array(dim=c(3,10,10)) g[1,,] = rgraph(10) g[2,,] = rgraph(10,tprob=g[1,,]*0.8) # 设置g1和g2两个网络强相关 g[3,,] = 1; g[3,1,2] = 0 # g3接近于一个派系（clique） # 绘制这3个网络 par(mfrow=c(1,3)) for(i in 1:3) { gplot(g[i,,],usecurv=TRUE, mode = \u0026quot;fruchtermanreingold\u0026quot;, vertex.sides=3:8)} #计算网络的相关矩阵 gcor(g)  在通常使用皮尔逊相关系数的时候，可以用t统计量对总体相关系数为0的原假设进行检验。但在计算网络的相关系数（graph correlations）时，经典的零假设检验方法往往会带来偏差，因而并不适用。通常使用非参数检验的方法，比如QAP(Quadratic Assignment Procedure)检验。\n矩阵的随机排列（Random matrix permutations）是QAP检验的关键部分，在子软件包sna中主要通过rmperm来进行。通过矩阵的随机排列，可以对网络中的节点编号（而不是链接！！）进行随机置换（relabelling）或重新“洗牌”（reshuffling），并得到一组（比如1000个）重连后的网络。因为只是置换节点，这种操作只是重新标记节点的编号（relabelling）。\n# R程序11-9：矩阵的随机置换方法 j = rgraph(5) # 随机生成一个网络 j #看一下这个网络的矩阵形式 rmperm(j) #随机置换后的网络的矩阵形式  对这一组重构的网络可以计算其网络级别的参数（如两个网络的相关参数，协相关参数），并因此得到一个参数分布。QAP检验的零假设是实际观测到的网络参数（如）来自于这一个参数分布。也就是说，原假设认为这种观测到的相关关系是由随机因素带来的，因而这种网络相关并不显著。拒绝原假设，就从统计的角度证明了观测到的网络相关系数是显著的。\n# R程序11-10：QAP检验 q.12 = qaptest(g, gcor, g1 = 1, g2 = 2) q.13 = qaptest(g, gcor, g1 = 1, g2 = 3) # 看一下QAP输出的结果 par(mfrow=c(1,2)) summary(q.12) plot(q.12) # 拒绝原假设，图1和图2显著相关 summary(q.13) plot(q.13) # 接受原假设，图1和图3不相关  在检验这个关于两个网络是否存在相关的零假设的时候，我们计算置换后的参数分布中大于这个实际观测到的参数的比例，以及小于这个实际观测到的参数的比例。QAP检验返回实际数据中观测到的参数f(d)、通过置换所得到的参数f(perm)的数学分布、以及单尾的P值。其中单尾的p值包括两种情况：p(f(perm) \u0026gt;= f(d))和p(f(perm) \u0026lt;= f(d))。\n其中P(f(perm) \u0026gt;= f(d))表示随机置换矩阵的相关系数的大于与等于观测值的p值，也就是本研究的检验显著性。一般而言，当p(f(perm) \u0026gt;= f(d))小于p(f(perm) \u0026lt;= f(d))时，拒绝原假设。\n","date":1375574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375574400,"objectID":"c0757a1f8690a2b079d0c32dccdcec0d","permalink":"https://chengjunwang.com/zh/archive/2013-08-04-qap-test-of-network-analysis.zh/","publishdate":"2013-08-04T00:00:00Z","relpermalink":"/zh/archive/2013-08-04-qap-test-of-network-analysis.zh/","section":"zh","summary":"","tags":null,"title":"QAP检验：计算两个网络的关联","type":"zh"},{"authors":null,"categories":null,"content":"作者： 黠之大者（网名），王成军，香港城市大学博士（在读）\n本文载于《数字媒体阅读报告》\nThe Laws of the Web Patterns in the Ecology of Information Bernardo A. Huberman (Author)\nPaperback: 115 pages\nPublisher: The MIT Press (April 1, 2001)\nLanguage: English\nISBN-10: 0262582252\n伯纳德-胡伯曼是惠普实验室的科学家，同时是斯坦福大学应用物理系的顾问教授（Consulting Professor）。他培养了很多学生，其中比较有名的当属Lada Adamic。他们两个在1999年以来的关于互联网的研究使之成为网络科学研究的重要成员，也奠定了本书基本的架构。他的第一篇论文发表于1970年，可以说是一个常青树。直到现在，依然保持着较高的学术产量。\n浏览其发表的论文，会很明显得发现他从物理学转型到互联网的结构和动态的研究，而现在则主要关注注意力经济的研究。从Strong Regularities in World Wide Web Surfing （1998， 《科学》），Evolutionary Dynamics of the World Wide Web （1999， 《自然》）等文章开始，胡伯曼的研究成为与其它主流研究者（如巴拉巴西）对话的重要人物，尤其是关于互联网的直径问题和互联网的增长机制问题 （读者可参见更好地一篇书评 ）。在其1998年的文章中，胡伯曼就提出了互联网的访问量满足幂律分布，而1999年的文章则表明互联网的结构同样满足幂律分布。这种普世的现象，胡伯曼将之称之为法则（law）。\n在讨论网络的演化与结构的过程中，胡伯曼强调关于市场中的个体的计划和策略的相吸信息不足以帮助我们理解一个市场的行为。主要是因为集体行为是互动的结果，单纯的个体信息只抓住了节点，而忽略的动态的互动。因此，追踪一些单个的个体的网页浏览行为也不能预测整体上的网络浏览规律。胡伯曼说，“我们必须放弃这些个体信息，而代之以更为整体的、系统水平的行为特征 ”（p. 23）。他将这种思路称之为整体的思路（the aggregate way），并认为这是一个强大的方法论，可以用来解决的大的分布系统，如股票市场、计算机网络、社会组织。不得不说，这是一种过于简略的思路。胡伯曼在这个问题上似乎对于微观的机制并没有太多兴趣，他执意要绕开从微观行为到宏观结果的涌现，而在系统层面讨论系统问题。恰因如此，他能够顺畅地讨论网络增长和网路规模这种系统水平的问题，而避开令人畏惧的个体行为。\n在等待牛顿的道路上，这对于普通研究者而言，不失为一种明智之举。却也显露出胡伯曼的局限。不过，这也是不绝对的，科学的道路，在发现法则之后，必然要走向背后的机制（mechanism）和普世的原理（principle）。物理学方法重视动力学方程的建立，他们以另外一种方式——数学和理论的途径面对微观的问题，但十分清楚这个从微观到宏观的过程不是简单的个体信息能顺利解决的。网络的另一特特征是小世界特性，胡伯曼指出目前的研究，尤其是巴拉巴西等人提出的优先链接机制不能较好的揭示网络的聚类特征，因此网络科学仍在寻找一个能够综合小世界特征和无标度特征的网络生成机制。其它几章讲解互联网阻塞、信息下载和互联网市场的问题，也多真知灼见。整体来看，这是一本非常简明的小书（正文只有95页）。作为较早的对网络科学研究的一个总结，值得读一下。\n","date":1355616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1355616000,"objectID":"6ec8329e9ff39b2667d70f5b6cef8097","permalink":"https://chengjunwang.com/zh/archive/2012-12-06-intenet-ecology.zh/","publishdate":"2012-12-16T00:00:00Z","relpermalink":"/zh/archive/2012-12-06-intenet-ecology.zh/","section":"zh","summary":"","tags":null,"title":"互联网的法则：网络生态学的起点","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《传媒透视》\n作者：王成军、张昕之 （作者皆为 香港城市大学 媒体与传播系 博士候选人）\n2011年8月22日，利比亚反对派军队攻占卡扎菲官邸。初传卡扎菲被击毙，后又有消息称，卡扎菲实已经密道逃亡，截止本文完成之时（8月27日），仍无其最新下落。\n如今微博已成为普通受众获知新闻、分享内容、沟通友人的重要渠道。利比亚内战一事在微博上迅速成为热门话题。然而微博用户众多，每个人的职业、地域、社会经济地位、社会网络、认知水平乃至动机，均有参差。尽管每个人用户都看似卷入了对重大事件的讨论，但是其发言的“质量”（如逻辑、可信度等）值得商榷。同时，微博有“V认证”以标识媒体工作者、社会名流、公共知识分子等人。这些人或因粉丝众多、或因观点犀利、或因独家爆料，其发言常被众多用户转发或评论，比起普通用户的“众说纷纭”，可谓“一言九鼎”。那么，事件发生后，在一个特定的微博用户群中，究竟是每个人平等参与了新闻的讨论和扩散抑或仅有几个活跃用户推进参与讨论的过程？新闻的信源与信息发布者之间、活跃用户与其粉丝之间、粉丝与粉丝之间——的互动关系在某个特定时间段表现为何种形式？\n为回答以上问题，作为一个探索研究，本文采用新浪微博API，抓取短短4分钟内（2011/8/22 15:06—15:10）所有新浪微博上对于卡扎菲官邸攻陷事件的信息发布、转发、评论，共计738条微博。四分钟的信息流，处于信息扩散阶段的一个短暂的瞬间，因而无法窥见整体层面的信息扩散规律。但因所采集的数据为随着时间有规律增长的宏大信息流的片段，同样可能起到窥一斑而见全豹的目的，其独特意义在于：海量数据流给信息处理和网络抽样带来巨大挑战，面对庞大的关系数据，传统统计方法不再适用；了解瞬间的数据流的特点是理解海量信息流的基础。本文从“瞬间数据流”的整体（而非样本）出发，探究其内在特点，可为网络舆论研究提供新视角。抛开技术的细枝末节，我们有四个重要发现:\n##发现一：自发性信息推荐群体的出现：从“自说自话”到“信息推荐” 738条微博信息中，转发的内容达262条，占三成，剩余约三分之二为原创新内容（476条）。主动的受众积极地转载来自其他渠道的信息。例如，其中有152条微博带有网络链接，30条提及电视台，26条提及路透社，23条提及齐鲁晚报。这表明有一个活跃的、自发性的“信息推荐群体”存在着，他们看似“自言自语”的原创微博发挥着信息推荐的作用。\n##发现二： “一言九鼎”的“舆论领袖” 在短短4分钟内，就有44条帖子被转发262次，平均每条帖子被转发6次。最多的一条帖子——华尔街日报关于卡扎菲倒、油价可能上涨的消息,在四分钟内被转发了43次；该消息发布于本研究抓取数据一个小时前的14:18， 一个小时中累计被转发290次，被评论105次。四分钟内转发数量超过9条的微博客用户，主要为媒体、媒体评论人，几乎全是加V的新浪认证用户（只有 “愤青3D”例外），并具有超过百万的粉丝数量。转发情况如图1。\n图 1 微博用户及其微博被转发次数（Top 10）\n##发现三：活跃的信息转发者：多次转发同一条信息的个体 本文分析了信息转发的网络关系，该有向网络由99个节点构成，拥有262条边，然而出乎意料的是这仅仅构成了一个稀疏的信息扩散网络：该网络的网络密度仅为0.027。网络密度衡量的是网络中真实存在的边与可能存在的边的数量的比值，本转发网络密度(0.027)低于期望值（0.054），说明有些节点之间存在多条链接，即某一个特定人物发布的某一条重要的信息，被“同一个转发者”多次转发。比如新闻评论人李承鹏所发的一条微博在4分钟内被转发15次。这15次并非被15个人“一人转发一次”，而是其中被一个ID为“古火拉兹-五毛”的人转发高达9次之上，剩下的几次由另两个ID（“慧-丽” 和“跪下去求婚站起来演说”）所转发。\n图 2 微博转发网络（箭头代表信息流动方向）\n##发现四: 原创型微博和被转发微博的语义网络：经济的还是政治的？ 上文中我们提到了两类微博：一是“推荐者”们原创的微博，二是意见领袖被转发的微博。为粗略地比较两类微博内容的区别，本文对这四分钟内抽取的微博内容，通过提取高频词，构建语义网络进行分析。发现：两类微博除了都关注新闻事件本身的基本经过、“5W”之外，“原创”微博关注政治及社会自由方面（图3）， 而社会名人被转发的微博主要针对新闻事件对经济的影响（图4）。\n图 3原创型微博的语义网络\n图 4 被转发微博的语义网络\n##总结 本例中，微博资讯的传播和扩散主要始于少数的意见领袖，跨国大型新闻机构亦是主要消息来源。微博时代，传统媒体如果善用网络平台仍可成为主要的信息来源。作为信息聚合作用的草根媒体开始出现，并扮演对传统媒体之信息进行过滤的把关人角色。此外，一些知名的草根ID通过自身的独特定位和宣传包装技巧，同样开始广泛的发挥舆论领袖的作用。值得注意的是，公共讨论和自言自语相互结合的原创类型微博占到了信息流的主体。“自媒体”从“自广播”开始起步，普通的微博使用者开始运用微博转载新闻、表明态度，使得微博成为孕育公共讨论的新机制。这种底层的广泛的信息转载虽然在四分钟内未获得转发，但在其各自子群中，都扮演着信息推荐者的角色。\n最后，作为一个探索性的研究，后续研究仍需要大量的文献梳理和技术支持。未来可以考量更为漫长的时间段内信息的扩散过程。另外，对制度性的不同话语主体之间（如政府、媒介、国际机构等）的互动，不同类型事件、乃至国内（敏感新闻、突发新闻更甚）新闻的扩散机制——凡此种种，均可成为后续研究之鉴。\n","date":1355529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1355529600,"objectID":"c3be3dc52d2b1fb9d9a85d6216b33a5f","permalink":"https://chengjunwang.com/zh/archive/2011-08-22-gaddafi-diffusion.zh/","publishdate":"2012-12-15T00:00:00Z","relpermalink":"/zh/archive/2011-08-22-gaddafi-diffusion.zh/","section":"zh","summary":"","tags":null,"title":"“众说纷纭”抑或“一言九鼎”？——以卡扎菲官邸攻陷事件在新浪微博上的信息扩散为例","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n王成军\n作者: 吴军\n出版社: 人民邮电出版社\n出版年: 2012-5\n页数: 304\n定价: 45.00元\nISBN: 9787115282828\n语言学是传播学的近邻，很多传播学研究都要借助于语言学的工作。经典的语言学或传统的语言学大师——乔姆斯基的跨界之作《媒介控制》也被传播学研究者奉为经典（读者可参见笔者之前的书评）。然而，在过去的三十年里，语言学经历的翻天覆地的变化，一个最明显的趋势是与计算机科学、数学的联姻——计算语言学在诸多藩篱中开花发枝长叶，变得日益蓬勃，并伴随着互联网的发展，成为一门支脉显学。\n这恐怕是这个学科的创建者及其论辩对象都没有想到的。当然直到现在，传统的语言学研究者和计算语言学的研究者依然剑拔弩张，大家去不同的会议，论文发表在不同的期刊。在第二章《自然语言处理——从规则到统计》中，吴军简略介绍了这两种思路的起源、冲突和发展。\n统计语言学之所以重要，是因为它开始充分利用语言学本身所特有的可计算性。可计算性是衡量一门科学发展阶段的重要尺度。如下图所示，我列出了几个学科的诞生时间和可计算性程度。当然数学和哲学不包括在内，因为数学超脱于可计算性，而哲学，在更大程度上不具有可计算性。网络科学以度为计量单位，经济学以货币为计量基础，物理学以时空为测量手段。值得一提的是，不是所有科学一诞生就有可计算性的，比如生物科学，刚开始的阶段要经历博物学这个考察物种的漫长阶段，直到沃森和克里克的工作揭示DNA的基本结构之后，生物科学才真正具备了可计算性。可计算性，非常关键，它可以使得学科在短期飞跃发展，分子生物学如此，计算机科学如此。正是将计算机科学置于比特这个基本的测量尺度上，计算机科学后起而领袖群雄。\n值得一提的是，语言学的可计算性程度要高于网络科学和经济学。然而，传统的语言学研究在更大程度上忽略了这种天然的优势，直到计算机科学诞生之后，学科的融合、产业的需求才开始催生它的发展。吴军尤其强调的是数学的作用，有了优质的数据的金矿并不必然会做出与之相应的结果或产品。“自然语言处理和通信的世界级专家……都有一个共同的特点就是数学非常好，同时解决了很多实际问题”。吴军认为是数学之美是其中的关键原因。\n图 1 不同学科可计算性的程度\n写到这里，或许我们可以谈一下科学的境界的问题。虽然饱经争议。但这的确是一个值得思考的问题。除计算机科学考虑算法及其计算复杂性，工程类科学考虑实际应用意外，大多数的理科和社会科学都考虑理论的发展问题 （其实信息论恰是纯粹的理论导向，但具有巨大的应用能力）。然而大家对理论是什么却显然有着很多模糊的理解，尤其在社会科学。所谓的理论往往被简化为概念之间的关系，于是置身于虚悬的概念游戏里再也脱不出来，还可美其名曰“理论研究者”。谬矣！与米尔斯所言之抽象实证主义相对的宏大理论学派同样好不到哪里去，甚至更差。历经波折，白首穷经的老社会科学家们到最好才悟到中层理论的优势，要能上下接通。然而仅仅是middle-range theory还是远远不够的，它顶多是一剂泻火的凉茶。社会科学的一个严峻问题依然是计算性的问题以及基于计算性探寻规律(pattern)、法则（law）、机制（mechanism）和原理（principle）的过程。于是，听众问：我们的理论哪里去了。答曰：规律(pattern)、法则（law）、机制（mechanism）和原理（principle）才是理论！可比较，有层级，能预测，可推导。这才是让人不失兴趣的理论研究。任何一个研究，如不能在这四个层级做出实在的贡献就是扯淡，是在学术的场域里耍流氓。\n吴军在书中谈及google创业之初很多工作没有系统的模型和理论基础。“这些方法比没有做任何事情好一些，但是几乎没有完善和提高的可能，而且使程序的逻辑非常混乱”（p 259 后记）。而一个巨大的压力是很多人在其成长的过程中失去了思考的能力！对周遭不好奇不敏感。《数学之美》一书结合具体的计算语言学在互联网中的应用问题给出了一个个生动活泼的例子，如中文分词、语音识别、网络爬虫、网页排名、网页相关性计算、地图搜索、新闻分类、词汇聚类、搜索引擎反作弊、拼音输入法、CDMA、搜索广告、MapReduce算法等诸多有着实际意义和巨大商业价值的问题。但胡乱地思考这些问题并不能揭示背后的理论。只有回到背后的原理，机制、法则（模型、算法皆在此列）、规律才能谈清楚这些问题。\n除了介绍这些理论和应用之外，吴军不失幽默地回顾了统计语言学派的大师们和现在的众多领军人物。贾里尼克和马库斯的经历让人倍感振奋，如此不虚人生一场追寻。诸多轶事趣闻读来让人浮想联翩，为之莞尔。吴军是 贾里尼克所在的霍普金斯大学拿到的博士学位，其后他加入了google，开创网络搜索反作弊的算法。例如，在youtube上面，一个盗版的视频的上传者是无法获取广告收入的，他获取的点击量将被归属于原始的上传者。之后，吴军加入了腾讯公司。除了这本《数学之美》之外，他还写了《浪潮之巅》，介绍众多互联网公司在数字浪潮中的创造的一个个神话。本文的副标题是——写在《数学之美》的边缘上， 因为实在是远远未能窥及书中的奥妙及其背后的东西。作为一本近乎科普的书，背后牵连的是宽广的知识网络：信息论、机器学习、数理统计，不一而足。相信认真对过本书的人能走得更远。\n","date":1355529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1355529600,"objectID":"47d2b7dcbe5b23f755c70f8e3f60398b","permalink":"https://chengjunwang.com/zh/archive/2012-12-15-beautiful-math.zh/","publishdate":"2012-12-15T00:00:00Z","relpermalink":"/zh/archive/2012-12-15-beautiful-math.zh/","section":"zh","summary":"","tags":null,"title":"通往统计语言学的桥梁——写在《数学之美》的边缘上","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\nBursts: The Hidden Pattern Behind Everything We Do\n作者: [美] 艾伯特-拉斯洛•巴拉巴西\n黠之大者\n人类动力学是一个迷人的研究领域，其中孕育了一系列有意义的研究。《爆发：人类90%的行为是可以预测的》一书正是其中一本重要著作。\n本书作者巴拉巴西是复杂网络研究的重要领军人物，1999年之后先后在《自然》、《科学》杂志上发表重要论文，指出诸如社会网络、神经网络、交通网络等多种复杂网络的节点密度的幂律分布，及其网络演化增长的优先链接机制。他和其博士阿尔伯特提出了“无标度网络”的概念，以及巴拉巴西-阿尔伯特模型（通常简写为BA模型）被广泛引用和报道，影响深远。其论文和书籍引发复杂网络研究在过去十余年中的研究热潮。巴拉巴西关于复杂网络研究的介绍可见其书籍《链接：网络新科学》，该书已经被湖南科技出版社翻译为中文，感兴趣的读者可以参阅。 巴拉巴西1967年生于罗马尼亚，从小就对物理学感兴趣。在欧洲获取本科和硕士学位后，巴拉巴西于1991年来到美国的波斯顿大学师从统计物理学家斯坦利攻读博士学位。事实证明，斯坦利对于巴拉巴西的研究兴趣影响深远，因为斯坦利本人就是一个跨学科研究者。虽然专注于复杂系统的研究，但斯坦利的研究覆盖众多领域，囊括物理学、生物学和社会科学，值得一提的是斯坦利本人就是经济物理学的创立者之一。笔者曾读过斯坦利关于海鸟迁徙行为的论文，非常具有想象力（或许这也跟后来巴拉巴西及其团队研究人类移动行为有关系）。1994年获得博士学位以后，巴拉巴西于次年加入圣母大学，开始其独立而不乏传奇色彩的学术研究之旅。圣母大学的13年执教时间，是巴拉巴西做出最多的学术贡献的阶段。2007年的秋天，巴拉巴西由位于美国印第安那州的圣母大学转入现在的东北大学，并创立了现在的复杂网络研究中心。现在的东北大学已经成为复杂网络研究的重镇。其研究小组非常强大，网罗了众多网络科学的研究者和访问学者。\n2005年作为一个物理学家，巴拉巴西在《自然》杂志上发表了一篇题为《人类动态中的重尾现象和爆发现象的起源》的论文，同一年就同一话题在《自然》杂志上发表题为《达尔文和爱因斯坦通信行为特征》的另一研究论文。两篇论文都是针对人类传播行为，指出这种人类传播行为在时间维度上具有明显的爆发特征，即短期内很多通信行为，而在相当长的时间间隔内则没有任何人类传播行为。这种爆发显现显然无法用描述随机过程的泊松过程来刻画，因为人类通信行为的间隔时间（或等待时间）的数学分布并非泊松分布，而是幂律分布。那么这种行为的特征背后的社会意义是什么呢？为此巴拉巴西进行了长久地思考。其结果就是于此相关的一系列论文和这本有趣的小书《爆发：人类90%的行为是可以预测的》。\n在本书中巴拉巴西介绍了自己研究这种人类行为在时间尺度上的爆发现象的很多细节和隐含的哲学。如同爱好旅行、浪迹天涯的网络科学研究者厄多斯一样，巴拉巴西的很多工作都是在旅途中，尤其是飞机上做出的。例如他关于网络增长的优先链接的模型的灵感就来源于在飞机上的思考，这个关于人类行为在时间尺度上爆发显现的研究与之类似。但因为当时在飞机上的他随身携带的电脑上的没有安装他所偏好的软件，他不得不去使用一个他当时还不太熟练的软件——Mathematica。后者是天才物理学家斯蒂芬•沃尔夫勒姆（Stephen Wolfram ）做创造的，具有非常强大的符号和数值计算软件，适合于做各种数学分析和模拟工作。不过，可惜巴拉巴西当时因为一个编程的细节错误而未能得到理想的结果。之后，这个研究一直萦绕到他的脑中，直到最后发现原来真理和谬误只差一个编程的细节。\n巴拉巴西善于描写人和事，其写作具有异乎寻常的天分，状人写物常有出神之处。这本书中写了一个关于泊松分布的提出者泊松的故事，十分有趣。泊松是一个法国数学家，同时也是一个物理学家，他的研究覆盖范围同样异乎广泛，非常高产，例如刻画随机过程的泊松分布就是他首先引入的。虽然巴拉巴西不太喜欢泊松分布，觉得有些过于简单而枯燥，但巴拉巴西对泊松本人的研究和生活却似乎很有兴趣。\n巴拉巴西在书中介绍了泊松的“成功秘诀”，原来泊松有一个习惯，当他想到一个好的研究问题的时候，泊松总是先按捺住内心的兴趣，只是将这个问题记在一个笔记本中，然后继续专注于自己在研究问题。直到把手头的工作完全解决，泊松才会回到那个记录着很多有趣研究问题的笔记本中，从中挑出一个最有趣的研究问题，继续开始研究。泊松给每个问题按照优先度排序，先去完成优先度最高的。这个故事或许启发我们如何才能够更有效率，更成功，那就是要专注，不要被枝节的问题所吸引注意力，但巴拉巴西却看得更远，他看到了人类行为在时间尺度上的爆发现象的深层社会原因，即个体给将要去完成的事件按优先性排序！按照排队理论，巴拉巴西马上建立数学模型，得到了想要的结果。\n对于社会现象的研究在社会科学中常常被变异性所牵引，给人造成一种社会科学没有统一规律的误解。巴拉巴西及其合作者对于人类行为的一系列研究无疑为其注入了一股清新的解毒剂。复杂网络处于规则与随机（或者说混沌）的边缘，同样人类的行为特征也具有类似特点。精确刻画出这种行为的统计特征，预测才变得可能。但其实预测与了解行为背后的机制相比，并非那么重要。巴拉巴西等人的工作至少似的人类行为的研究站在稳定的数学特征上开始追问其隐藏的机制。虽然距离揭示一种普遍的准则还有一段很远的距离，但所取得的成果依然非常令人振奋。因为人类90%的行为是可以预测的！本书的副标题的翻译比较灵活，因为其英文版的副标题则为“我们所做的所有事情背后所隐藏的规律”。但这种翻译并非耸人听闻，因为根据巴拉巴西和其合作者的对于人类移动行为的一项研究，这种预测能力可以高达93%。\n当前大数据和云计算成为关键词，作为普通的个体，我们依然需要一种分辨什么样的研究和事情才是重要的排序能力！值得注意的是伴随着网络科学在过去十几年间的崛起，可计算性社会科学变得成为可能。伴随着人类传播行为的研究在很多方面被不断推广和深入，作为其分支的计算传播学也开始变得呼之欲出。我们可以期待，一种扎根于可依赖的测量基础上的人类传播行为的中孕育着更多的、隐藏的、稳定的规律。揭示这种规律背后的机制和法则将是未来计算传播学的重要工作。\n本书当中还有很多真知灼见、有趣见闻，可以使得我们窥见最优秀的研究者的思维特点和点滴的经验教训。笔者从事信息扩散的研究，读这本小书常为之击节。人类行为的集体爆发显现非常广泛，不管在新闻扩散，还是在视频浏览数量增长方面，都在不断得到印证，并引发更多相关的研究涌现。如果读者对于网络科学和人类行为感兴趣的话，这本书应引起重视；如果读者觉得不够尽兴的话，一定不要错过巴拉巴西的网站和其所发表的一系列论文。不过，个人喜欢归个人喜欢，大多数的读者似乎并不觉得这本书怎么样，尤其是面对高昂的定价和过高的期待之时，甚至有人觉得《黑天鹅》也比这本书好，笔者无意冒犯，却实实在在不敢苟同，或许只有平心静气地读过相关的论文才能更好地理解本书中谈到的各种细节，而这对于很多人来说，似乎是不可能做到的，惜乎。\n","date":1346371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1346371200,"objectID":"ee3e82cab08bcb2397aa4656a2801281","permalink":"https://chengjunwang.com/zh/archive/2012-08-31-burst.zh/","publishdate":"2012-08-31T00:00:00Z","relpermalink":"/zh/archive/2012-08-31-burst.zh/","section":"zh","summary":"","tags":null,"title":"爆发：人类行为在时间尺度上的特征","type":"zh"},{"authors":null,"categories":null,"content":" 在前面章节中，我们主要分析了社会网络中的个体特征。从这一章开始， 我们将开始循序渐进探讨网络中的更大的分析单元，不仅分析个体及其相互联系特征，还要分析所有子图和聚类的特征。我们将探索处于一个三元组当中到底意味着什么，以及作为结构洞的好处和压力。\n 首先，我们将通过逐步去除部分网络的方法来解构网络，以便找到网络的核心(有时有多个核心)；接着，我们将使用网络的组分（二元组、三元组、派系、家族和聚类）来重构网络。\n4.1 组元和子图 为了将网络分解为可分析的单元，我们将首先给出一些定义：\n• 子图 子图（subgraph）是由一个网络的部分节点及这些节点之间的链接构成。任意一组节点都可以构成子图，稍后我们会介绍一些使用子图的有趣的方法。\n• 组元 组元（components)）是由网络当中相互分隔的部分构成。比如，在罗密欧和朱丽叶相遇之前，他们所在的两个家族没有联系（互相仇视，水火不容），因而可以被看作两个组元。\n许多真实的网络，尤其是那些通过随机抽样搜集到的网络数据，有很多组元存在。有些人可以质疑这是抽样误差（这是很有可能的）造成，但同时，这也可能只是意味着这些组元之间的链接在样本框之外，因此实际上这些组元之间本来就没有关联。\n使用Python分析组元 埃及暴动的推特转发网络是一个具有很多组元的网络的好例子。本书所讨论的推特转发网络数据，因为只收集了1%的推特用户所发的微博信息，所以很不完整。让我们读入并检查该数据。NetworkX包含一个分析孤立的相互关联的组元的命令（connected_component_subgraphs(e); 这个命令可以根据各个相互关联的组元返回其相应的图对象的数组）：\n\u0026gt;\u0026gt;\u0026gt; e=net.read_pajek(\u0026quot;egypt_retweets.net\u0026quot;) \u0026gt;\u0026gt;\u0026gt; len(e) 25178 \u0026gt;\u0026gt;\u0026gt; len(net.connected_component_subgraphs(e)) 3122  以上程序表明这个转发网络包含约25000个节点，但这个网络被分割成为超过3000个组元的子图。我们现在可以分析这些组元的规模大小的分布：\n\u0026gt;\u0026gt;\u0026gt; import matplotlib.pyplot as plot \u0026gt;\u0026gt;\u0026gt; x=[len(c) for c in net.connected_component_subgraphs(e)] \u0026gt;\u0026gt;\u0026gt; plot.hist()  在约3100个组元中，有2471个组元的规模是1——这些节点被称之为“孤立点”，并且应该从网络的剔除。有546个组元的大小是2（也就是只有一个转发），67个组元的规模是3， 14个组元的规模是4，11个组元的规模是5。组元的规模等于或大于10的情况，其频数非常小：\n\u0026gt;\u0026gt;\u0026gt; [len(c) for c in net.connected_component_subgraphs(e) if len(c) \u0026gt; 10] [17762, 64, 16, 16, 14, 13, 11, 11]  以上代码表明存在一个大小超过17000的巨大组元，7个组元的规模小于100，规模介于100到17000之间，不存在任何组元。\n在这个特例中，我们可以将这个巨大组元看作整个网络进行分析；但这个网络仍然因为规模太大而不能得出有趣的推论。\n网络中的岛屿 一个分析网络的技术被称之为“岛屿方法”（参见图 4-1）；这种方法尤其适合于分析权重网络，比如我们作为例子的埃及革命的推特转发网络。 岛屿方法按照以下过程工作：将我们的网络想象成一个具有复杂地形的岛屿，地形中每一个点的高度被定义为节点的数值（比如程度中心性）或边（比如转发量）。现在环绕这个岛屿的海平面高度随着时间缓慢增加，使得岛屿随着时间逐渐没于水面以下。到岛上的低谷被海水覆盖，这个岛屿就被分割为众多小岛——使得岛屿的最高峰显露出来，并且随着时间增长，这些显露于海面以上的高峰逐渐变小。\n图 4-1 岛屿方法\n当海水高度足够高之后，整个岛屿都可能完全消失在海水下面。因为，为了得到有意义的结果，这种方法需要被恰当地使用。\n对于网络而言，使用岛屿方法（ island method ）意味着大的组元将被分割为小的组分，并且具有最多的转发量的区域（子核）成为他们各自可以被单独分析的组元。\n使用岛屿方法时，我们所需要做的第一件事情是建立一个命令来提高“水平面高度”。这个命令使用一个门槛数值（也就是“水平面高度”）对图进行操作，使得权重超过该门槛值的边保存下来，移除掉剩余的其它的边。不用担心，这个命令会保存原来的图，因此它是非破坏性的（即并不损失信息）：\ndef trim_edges(g, weight=1): g2=net.Graph() for f, to, edata in g.edges(data=True): if edata['weight'] \u0026gt; weight: g2.add_edge(f,to,edata) return g2  现在，我们开始定义“水平面”如何被提高。我们将要生成一组均匀分布的门槛值作为“水平面”，并依据这些“水平面”生成一组网络：\ndef island_method(g, iterations=5): weights= [edata['weight'] for f,to,edata in g.edges(data=True)] mn=int(min(weights)) mx=int(max(weights)) #compute the size of the step, so we get a reasonable step in iterations step=int((mx-mn)/iterations) return [[threshold, trim_edges(g, threshold)] for threshold in range(mn,mx,step)]  以上程序中的函数将返回一组图对象，每一个图对应着一个特定的“水平面”。\n现在我们针对埃及革命的推特转发网络中的最大的组元进行分析，先使用岛屿方法将其分割为子部分：\n\u0026gt;\u0026gt;\u0026gt; cc=net.connected_component_subgraphs(e)[0] \u0026gt;\u0026gt;\u0026gt; islands=island_method(cc) \u0026gt;\u0026gt;\u0026gt; for i in islands: ... # 输出水平面高度、图大小、连接的组件的数量 ... print i[0], len(i[1]), len(net.connected_component_subgraphs(i[1])) 1 12360 314 62 27 11 123 8 3 184 5 2 245 5 2  以上程序是什么意思？当门槛值取值为1时，所有取值为1的网络链接（即一步转发的推特）被剥离，这个最大的组元被分割为314个“岛”的子图——每一个代表一组持续地相互转发的人群。因为一次转发可以被认为偶然的，所以这是一个很有用的结果——持续的转发，更常见于那些经常交流并因此培养出某种信任关系的群体当中。\n门槛值取值为62（即每对节点之间的最小转发为62）时，只有27个节点保留下来，分布于11个“岛屿”之中。在这个例子当中，62是最有意义的门槛值——剩下的27个节点是最积极地卷入解放广场示威的人和报道这个事件的记者。\n这可能需要经过一个试错的过程，但一个设置合理的“水平面”可以针对大的网络生成一个非常有意义的结果——立刻找到网络中最活跃的核心节点。\n4.2 子图——自我中心网 自我中心网（Ego networks）是一个以某一特定节点为核心的子网络。在脸书和LinkedIn上面，自我中心网通常被描述为“你的网络”——但是你只能看到你自己的自我中心网，而不能做一个覆盖范围更为广阔的调查。拥有一个大的数据可以使得我们测量和比较不同人的自我中心网。 我们通过运行一个广度优先搜索（参见本书第2章：广度优先搜索）并且限制搜索的深度（网络半径）为一个通常不超过3的数值的方式，来获得自我中心网。不同的是，在通常的广度优先搜索当中，我们通过构建一个链接树的方式找到要搜索的节点，而为了生成一个自我中心网，我们需要获取特定的中心节点的所有邻居之间的所有链接。\n为了理解采用一个小的搜索深度的方法获取自我中心网背后的逻辑，我们需要重温在网络中与其它节点连接意味着什么，以及网络距离的意义是什么。通常情况下，网络链接的一个例子是“爱丽丝是鲍勃的朋友”，一个数值为2的网络距离的一个例子则是“卡洛尔是爱丽丝的一个朋友的朋友”，而一个数值为3的网络距离的例子是“戴夫是爱丽丝的一个朋友的朋友的朋友”。直觉上讲，我们将其理解为虽然我们对我们的朋友了解很多，我们对我们的一些朋友的朋友的情况也略有所知，但我们几乎不知道任何我们朋友的朋友的朋友的事情。\n严格地说，网络距离这个概念被表达为“可观测性的界限” （Horizon of Observability），是一个从物理学和“可观测的宇宙”这个提法当中灵活借鉴而来的概念。诺亚•弗里德（Noah Friedkin）发现在社会网络中，人们对于自己所在的自我中心网非常了解（错误率约为30%），其所报告数据质量与通过自我报告的方式收集的数据质量一样好。二度网络距离的错误率跃为70%，三度网络距离的错误率则高达100%。\n在诸如推特这种在线社会网络，因为对于朋友的定义非常松散以及电脑辅助的信息保存方式，自我中心网的半径要大很多。信任和影响力所流经的人际网络渠道并不太稳固，所以分析一个网络半径大于3的自我中心网的将会是一个错误。当我们研究通过一系列转发的形式而进行的信息扩散时（我们将在第6章介绍），深度优先的搜索方式将替代广度优先的策略而被使用。\n使用Python提取和可视化自我中心网 提取自我中心网非常简单，因为NetworkX提供一个现成的内置函数来完成这个工作：\n\u0026gt;\u0026gt;\u0026gt; net.ego_graph(cc,'justinbieber') \u0026lt;networkx.classes.multigraph.MultiGraph object at 0x1ad54090\u0026gt;  是的，不管信不信，贾斯汀•比伯（Justin Bieber）也在埃及转发网络数据当中。他的自我中心网早已经出现于本书中，见图1-11。 这个ego_graph函数返回一个NetworkX图对象，并且所有的常见的度量（程度中心性，居间中心性等）能够通过它计算。\n但是，一些其它的简单的度量并未被纳入其中。知道一个自我中心网的规模对于理解一个人转发的（或收到的）信息能够传播的范围非常重要。 另外一个度量被称为聚类系数（clustering coefficient）——本质上，它测量了你的朋友彼此之间也是朋友的比例（也就是人们之间的相互信任程度）。这个度量可以被应用于整个网络当中——但是对于一个密度差异很大并且有多个核心的大的网络，平均的聚类系数很难解读。在自我中心网当中，对于聚类系数的解释非常简单——一个自我中心网，稠密且嵌入了很多相互信任的节点，具有一个较高的聚类系数。由一个单一向外“广播”的核心节点和众多“听众”构成的星型网络，则具有一个较低的聚类系数。 让我们开始探索一下埃及数据中的一些自我中心网：\n## 我们需要将自我中心网从一个多图转化为一个简单的图。 \u0026gt;\u0026gt;\u0026gt; bieb = net.Graph(net.ego_graph(cc,'justinbieber', radius=2)) \u0026gt;\u0026gt;\u0026gt; len(bieb) 22 \u0026gt;\u0026gt;\u0026gt; net.average_clustering(bieb) 0.0  贾斯汀•比伯(Justin Bieber)的名人地位并未能够在这个特定例子中帮到他——在他的九百万个关注者当中，仅仅有二十二个人转发了他的关于埃及革命的信息。他的聚类系数表明他是一位纯粹的“广播者”，并未被嵌入他的粉丝的信任网络中——或者，至少，他并不在一个关心世界政治的信任网络中。\n让我们现在探索一个不同类型的名人——威尔•戈宁(Wael Ghonim)，新一代的埃及人，Google的主管，推特的重度使用者：\n\u0026gt;\u0026gt;\u0026gt; ghonim= net.Graph(net.ego_graph(cc,'Ghonim', radius=2)) \u0026gt;\u0026gt;\u0026gt; len(ghonim) 3450 \u0026gt;\u0026gt;\u0026gt; net.average_clustering(ghonim) 0.22613518489812276  威尔• 戈宁不仅有一个巨大的转发网络（尽管比贾斯汀•比伯的粉丝少100倍），他的自我中心网是一个人们从他这里以及其他人那里转发信息的信任网络，一个革命的信息可以很容易扩散和持续的网络。\n在下一部分我们要讨论的结构洞和三元组分析对于自我中心网同样非常适用——所以敬请期待并且开始分析你自己的数据！\n4.3 三元组 一个三元组其实就是三个节点以某种形式相互链接。无论如何，在三元组分析中，情况并非如此简单。图4-2列出了所有可能的无向（undirected ）的三元组；正如你所看到的，仅有前两个类型当中的所有节点是相互链接的， 并因此具有独特的意义。有向的三元组共有16种，但我们将在本章稍后的部分讨论。\n图 4-2 三元组的形式\n图字翻译：\n闭合的三元组（图4-2中左侧）展现的是一个完全连接的群体：A，B，和C以相同强度的边相互连接。闭合的三元组的一个最简单的例子是“核心家庭”——妈妈（爱丽丝），爸爸（鲍勃）和一个孩子（卡洛尔）。当然，这些三元组可以相互重合——例如，同一个妈妈和爸爸可能还有另外一个儿子（大卫），这种情况下三元组不止有一个，而是四个：\n[爱丽丝，鲍勃，卡洛尔] [爱丽丝，鲍勃，大卫] [卡洛尔，大卫，爱丽丝] [卡洛尔，大卫，鲍勃]  这个网络结构或许代表了社会网络研究领域当中最古老的一种研究。在1908年，乔治•齐美尔，一位与马克斯•韦伯同时代的人， 与他的知识分子圈的一位成员一起写作了一篇论文《三元组论》。\n齐美尔认为在一个二元组（dyad ）（也就是两个节点相互连接在一起）中，每个人都能够保持他们的个体性并维持一段亲密关系。二元组有助于信息和意见的交流，但它并未使得个体融入群体。在三元组当中，第三个个体成为一个平衡的本源（提供不同的意见并舒缓精神）。但第三个节点也是一个反馈的渠道——来自A的信息传递到B，然后到C，并以一种非常扭曲的形式回到A——正如一个儿童的游戏“打电话”所表明的一样。\n作为一种不断扭曲的结果，一个三元组随着时间的推移生成一组三元组所特有的人造品——方言土语或绰号昵称，局部的规范和行为准则，共享的意义。在一个宏大的语境里，社会学家把这种人造品的累积称为文化。 或许在一个三元组的语境里，三元组是一个非常大的词语——但可以想象一下你自己的家庭或者你的朋友的家庭。或者，下载一集ABC播出的真人秀《交换女主人》（Wife Swap, 幸运地在2009年取消了），并观看两个家庭文化的在真人秀中的碰撞。\n大学生联谊会研究——链接的稳定性与三元组 另外一个相似的研究由纽科姆完成。 实际上，这个研究与现代真人秀电视节目有些（惊人的）相似，但是发生于二十世纪六十年代早期。想象一家位于密歇根的大学生联谊会 （是的，有啤酒 ） 。在学期开始，17个学生（都是白人）被招募住在一个大学生联谊会的房子里长达一个学期时间， 以交换他们的个人信息数据为条件。每周，研究者访问每一个学生成员并让他们对与之互动的成员按照1（最好）到16(最差)的顺序进行排序。\n这个研究发现：\n• 不对称的链接（例如“我喜欢你多过你喜欢我”）最不稳定，维系不超过两周时间。\n• 对称的链接（二元组中的两个人以相同的程度喜欢彼此）明显更稳定。\n• 三元组结构随着时间的推移是最稳定的，三元组中的学生们一起消弭冲突，组织活动，并奠定兄弟会内部相互交往的风气。\n三元组和恐怖分子 在本书第1章的“恐怖组织的信息网络”， 我们提到基地组织（Al Qaeda cells）在训练和准备恐怖袭击的时候被隔绝于一个安全的藏身处。这种隔绝迫使组织形成一种稠密的三元组结构，每个人都与其他人一起嵌入在三元组中。加上实际上的感觉剥夺（所有来自外部世界的信息被组织的领导者过滤），这个群体生成他们自己的超越了绰号和共有的故事的文化人造品——继续强化他们作为宗教极端分子的身份并加强他们完成袭击的决心。\n引用马克•萨基曼（Mark Sageman） 的话来说，汉堡支部（谋划并最终参与执行了911恐怖袭击）就是——“一群人”。在分析了17个恐怖分子的生活之后，萨基曼发现驱动他们的最主要因素是他们在恐怖组织内部的社会关系。大多数人开始的时候是朋友，同事，或者亲属——并且关系因为友谊、忠诚、团结和信任的纽带而更亲密，并获得强烈的归属感和集体身份。\n图4-3 911劫机者的社会网络\n在本书的Github库 (https://github.com/maksim2042/SNABook/chapter4)当中,你可以找到用来生成图4-3 的数据 ，并且自己分析它。数据以边列表的形式存储于文件当中，其格式如下所示：\nHani Hanjour,Majed Moqed,5,1 Hani Hanjour,Nawaf Alhazmi,5,1 Hani Hanjour,Khalid Al-Mihdhar,5,1  第一列是有向边指出的节点的名字，第二列是有向边指入的节点的名字，并且接下来的两个数字表示边的强度（5=最强的边，1=最弱的边）和边被确认的程度（1=被确认的亲密关联，2=各种被记录的交往活动， 3=潜在的或计划的或未确认的交往活动）。\n导入这个文件时，我们无法使用NetworkX内置的文件读入功能，但我们可以用短短几行代码构建一个：\nimport csv ## 我们将使用内置的 CSV库 import networkx as net # 打开文件 in_file=csv.reader(open('9_11_edgelist.txt','rb')) g=net.Graph() for line in in_file: g.add_edge(line[0],line[1],weight=line[2],conf=line[3])  我们还有一个标明19个劫机者曾经乘坐过的航班的属性文件。让我们也把这个数据读入：\n# 首先，我们应该确认所有的额节点都具有“flight”属性 for n in g.nodes_iter(): g.node[n]['flight']='None' attrb=csv.reader(open('9_11_attrib.txt','rb')) for line in attrb: g.node[line[0]]['flight']=line[1]  tips： 通常有两种方法列出图中的节点。g.nodes()提供了一列节点，而g.nodes_iter()生成一个Python迭代器。迭代器仅限于在循环当中——但仅仅使用很少的内存并且在大图当中运行更快。\n如果你现在使用默认的net.draw(g)函数将这个网络画出来，你会发现这个网络包含了几个互补相连的组元。这是因为这个数据是支离破碎和不完整的；我们仅仅关注网络中的最大组元：\n# Connected_component_subgraphs()返回一系列的组元， # 按照从最大到最小的顺序排列 components=net.connected_component_subgraphs(g) # 找出第一个也是最大的组元 cc = components[0] 我们使用multimode.py中的一个惯用的绘图函数来绘制这张图片。这个函数读入节点属性，并根据节点属性的取值分配颜色，迅速地绘制一个惯用的彩色图片： import networkx as net import matplotlib.pyplot as plot from collections import defaultdict def plot_multimode(m,layout=net.spring_layout, type_string='type',filename_prefix='',output_type='pdf'): ## 创造一个默认的颜色序列和一个空的彩色图 colors=['r','g','b','c','m','y','k'] colormap={} d=net.degree(m) #we use degree for sizing nodes pos=layout(m) #compute layout # 现在我们需要找出需要绘制不同颜色的节点构成的群体 nodesets=defaultdict(list) for n in m.nodes(): t=m.node[n][type_string] nodesets[t].append(n) ## 使用相应的颜色设置，将每组中的节点分开绘制 print(\u0026quot;drawing nodes...\u0026quot;) i=0 for key in nodesets.keys(): ns=[d[n]*100 for n in nodesets[key]] net.draw_networkx_nodes(m,pos,nodelist=nodesets[key], node_size=ns, node_color=colors[i], alpha=0.6) colormap[key]=colors[i] i+=1 if i==len(colors): i=0 ### 如果我们用光了所有的颜色，那么循环使用这些颜色 print colormap ## 使用一个默认的绘图机制绘制边 print \u0026quot;drawing edges...\u0026quot; net.draw_networkx_edges(m,pos,width=0.5,alpha=0.5) net.draw_networkx_labels(m,pos,font_size=8) plot.axis('off') if filename_prefix is not '': plot.savefig(filename_prefix+'.'+output_type) 最后，我们绘制出网络： import multimode as mm # type-string 指引函数某种需要辨别的属性 mm.plot_multimode(cc,type_string='flight')  一旦我们建立了用于三元组分析的工具，你可以使用这个数据作为一个理解三元组如何工作的测试，并与关于恐怖主义研究的大量文献潜在地联系起来。\n“禁止进入的三元组”和结构洞 我的朋友鲍勃 有一个问题。你明白的，他爱上了两个女人。一个是精力充沛的东欧美女（让我们称她为爱丽丝），另一个是来自南美洲的乐天派女孩卡若琳娜。这两位女孩中的任何一个对于鲍勃来说都是绝配，但是他无法决定。当鲍勃和爱丽丝在一块的时候，他渴望见到卡洛琳娜和她无忧无虑的态度；但他和卡洛琳娜在一起的时候，他思念爱丽丝和她美丽以及有深度的谈吐。结果，几年过去了，鲍勃依然处于病态的单身状态中。\n从网络角度而言，鲍勃的窘况在于他处于图4-2的第二个三元组中。B与A和C相连——但A与C之间并没有任何连接，并且鲍勃作为图中的B应该维持这种状况如果他想继续同爱丽丝和卡洛琳娜两个人同时交往。每天，鲍勃需要调整他的日程表以确保A和C不会相见，这给鲍勃的生活带来越来越多的压力，但他同样需要确保他不会因为忘记他告诉A或C的事情或者A或者C偶尔告诉他的事情而露馅。结果，鲍勃身处焦虑之中，然而所有的事情并没有按照鲍勃所希望的那样发展。\n我另外一个银行家朋友（Banker）身处与之相似的网络链接当中，但却对此非常高兴。他的A是AmeriCorp公司，而C是CorpAmerica公司。AmeriCorp公司在他的银行里存款并期望5%的利率。而CorpAmerica公司则按照7%的利率从他的银行借款。这样我这个银行家朋友B就获得其中的利率差——C支付的利率和A期望得到的利率之间的2%的差别。对我这个朋友而言，这2%的利率差足够他购买一个房子、一个最新款的宝马车、一个精英俱乐部的成员资格和其它的他非常喜欢的物质财富。假设A和C因为打高尔夫球而认识，他们就会同意A以6%的利率直接借款给C，并意识到撇开中间人对他们双方都有利。如果这件事情发生了，银行家B就会非常沮丧。\n尽管在三元组背后的故事完全不同，鲍勃和银行家朋友的意愿却完全相同。他们都需要确保他们的开放的三元组的末端不能直接联系——也就是说A和C之间不会建立网络链接。\n不同的人给这个三元组所取的名字不同。一些研究者称它为“禁止进入的三元组”——因为像鲍勃一样，他们认为这个三元组与压力、焦虑和同时与两个女人约会所带来的道德问题相互关联。其他人称它为“结构洞”或者“中间人结构”，并且认为一个个体所占据的结构洞的数量与其作为企业、银行、经纪人或地产代理的业绩相互关联。\n罗纳德•伯特（Ronald Burst） 的研究表明在一个竞争性的市场当中，占据更多结构洞的商人具有更显著的高成功率。商人的成功是是通过两件事情来预测的——商人在不对称信息的条件下的开拓能力和交易能力，和商人对于创造和维持“套利机遇”过程中多带来的压力的高度容忍度。\n结构洞和边界跨越 结构洞具有另一个重要的使命——因为他们能够降低信息不对称性（例如，因为我的两个朋友都能够提供信息），他们也能够连接不同的社群。本书的两位作者即是社会网络研究领域的专业人士（马克斯教社会网络分析的课，艾利克斯编写社会网络分析的软件），又是专业的音乐家。事实上，我们两个是在一个摇滚音乐节上相遇的，那时我们两个各自的乐队正在那里表演。\n所以，一个包括马克斯、马克斯在学术研究方面最亲密的合作者和他乐队中的鼓手的三元组实际上是一个结构洞。这些科学家和鼓手对于英语有基本的了解（不存在语言障碍），但找不到足够的谈论的话题。因为社会距离（social distance）（我们将在第6章讨论信息扩散的时候进一步涉及的一个术语）的原因，在他们之间存在网络链接的可能性基本为零。 我们的社群（科学家和音乐家）经常交叉。马克斯之前所在的一个乐队是全部由教授构成的，之后所在的一个摇滚乐队全部由神经科学家构成（称为“Amygdaloids” ），乐队也因此而知名。\n但是，与那些仅仅是专业的音乐家或者科学家的人的规模相比，这些跨界者（懂科学的音乐家和懂音乐的科学家）很少。结果，这两个社群的交叉看上去像图4-4。\n图4-4 跨界者示意图\n事实上，这种事情在不同层面存在着。如果我们仔细考察科学家群体，我们发现它包含了各个主要的领域（生物学、计算机科学、人类学等），并且如果我们更仔细地看这些领域所包含的子领域，我们会发现它们都通过结构洞联系在一起。\n在科学社群中，这非常重要。因为许多新的发现本质上都是跨学科的。例如，詹姆斯•富勒（James Fowler） 致力于神经科学与社会网络分析交叉领域的研究。\n一些其他的领域（例如经济学）不鼓励跨越不同子领域的对话和论文发表，并对他们的理论过度保护。在这种情况下，比如存在于奥地利学派和新古典经济学之间的结构洞位置将会充满压力并很难维持——这更像鲍勃的困境而非银行家的顺境。\n政治中的三元组 图4-5展现了一个不同国家在高加索（ Caucasus）的政治合作网络 。 从现代地缘政治的角度讲，高加索是一个非常有趣的地方（看图4-6中的地图）。这是一个很小的地方，具有异常美丽的山地地貌，它夹在北面的俄罗斯 （Russia）和南面的土耳其（Turkey）和伊朗（Iran ）之间。其居民主要是基督徒和穆斯林民族的混乱得混合，并且他们开始逐渐拥护西方的国家。俄罗斯，或者土耳其（从苏联解体开始）在这里创造了一种令人诧异的地缘政治景观（大多数是令人不高兴的，至少对于当地人来说）。\n图 4-5 在高加索的政治合作网络\n图 4-6 高加索—一个种族和语言的熔炉\n图中的网络通过其它国家和高加索、俄罗斯、土耳其、欧盟和美国之间签订的政治合作协议和声明关系而构建，明显表明俄罗斯与其它西方国家之间的政治治理风格的差异。俄罗斯为中心的一方的网络充满了结构洞，俄罗斯实际上控制着这个网络，而边缘国家节点之间的网络链接几乎不存在。\n唯一横向的网络链接存在于南奥塞梯（South Ossetia）和阿布哈兹(Abkhazia)之间。在本研究进行的时候，这两个地方都还是格鲁吉亚的一部分——但实际上，它们当时明显不忠于格鲁吉亚。南奥塞梯的分裂运动（或者，这是一个俄罗斯人为了巩固在该地区的影响而进行的挑拨，这取决于读者的新闻来源是俄罗斯媒体还是美国媒体）在两年内遭到了格鲁吉亚军队一个短暂而血腥的镇压。之后，南奥塞梯和阿布哈兹这两个地方都宣布独立并正式与俄罗斯建立盟友关系。\n同时，西方国家一方的网络表现出一种具有较多亲密关系和横向连接的特征。这将减弱超级大国的影响力，因为横向的网络链接降低了（超级国家）的效率和直接影响。同时，这种三元组结构更加稳定并且不需要很多的力量去维持。\n有向的三元组 理论足够了，让我们开始编写一些代码！\n图4-7给出了所有的可能的有向的三元组。在一个有向的三元组当中，我们同时考虑单向的边和双向的边；因此总共有16种可能的情况，而非4种情况。我们将对这些形状进行一些解读，但首先让我们定义一种对其进行分类的方法。这种计数和分类的方法或许有一些晦涩难懂，但自从1972年开始，它就成为了这个领域的学术文献中的一种标准 。\n图4-7 有向网络中所有可能存在的三元组\n这些三元组按照1到16 的顺序进行编号，每一个都有一个代码。这些代码按照如下方式进行阅读：\n• 第一个数字代表了双向链接的总数量。\n• 第二个数字代表了单向链接的总数量。\n• 第三个数字代表了不存在的网络链接的总数量。\n• 字母用来区分相同三元组的不同形式——U代表了“向上”，D代表了“向下”，C代表了“传递”（也就是说有两条路径指向相同的节点）\n图中的三元组1到3是未连在一起的，三元组4到8和11代表结构洞的不同形式。三元组9、10和12到16是紧密型三元组的不同形式。\n分析真实网络中的三元组 对于一个真实网络的三元组分析的过程成为“三元组普查（triad census）”。在这个过程当中，对于每一个节点，我们计算16种类型三元组出现的频数以决定这个节点在网络中的角色。例如，一个节点具有较多的三元组4、7和11（也就是说有较多的流出的网络链接和结构洞）是一个信息的来源或者潜在的小组领导者。\n执行三元组普查，我们需要一种仍未被纳入NetworkX的一种算法——三元组普查算法 。从Github下载第4章所要用的算法包 ，修改系统目录为下载文件所在的路径，并开启Python：\n\u0026gt;\u0026gt;\u0026gt; import networkx as net \u0026gt;\u0026gt;\u0026gt; import tradic \u0026gt;\u0026gt;\u0026gt; import draw_triads  这个draw_triads函数可以重新绘制出图4-7.\n现在，让我们应用三元组普查到一些抽样数据当中去（比如图4-8当中的风筝网络）：\n## 生成一个有向的风筝网络 \u0026gt;\u0026gt;\u0026gt; g=net.DiGraph(net.krackhardt_kite_graph()) ## 执行三元组普查程序 \u0026gt;\u0026gt;\u0026gt; census, node_census = triadic.triadic_census(g) \u0026gt;\u0026gt;\u0026gt; census {'201': 24, '021C': 0, '021D': 0, '210': 0, '120U': 0, '030C': 0, '003': 22, '300': 11, '012': 0, '021U': 0, '120D': 0, '102': 63, '111U': 0, '030T': 0, '120C': 0, '111D': 0}  图 4-8 魁克哈特风筝社会网络\n三元组普查函数返回了两个结果——一个包含了网络的所有结果的Python字典，和一个包含了个体节点的所有结果的字典的字典。\n在风筝图当中，这个程序找到24个结构洞类型三元组（代码为201）和11个紧密型三元组（代码为300）。这意味着在网络中存在着一些联系特别紧密的区域和一些充满很多结构洞的区域。当然这个发现对于这个图来说是显而易见得到——但对于一些大的网络来说就不是如此明显。\n结构洞型三元组和紧密型三元组的比例也是非常重要的——一个等级制度主要是由结构洞构成的，而平等主义的网络结构中紧密型三元组具有较高的比例。\n简而言之，一个三元组普查使得我们可以对一个网络结构的宏观层面做出一种高级的结论。但是，这在微观水平上同样有趣。下面的代码生成一个三元组普查表格，其结果在表4-1中：\nkeys=node_census.values()[1].keys() ## 生成一个表格的标题 print '| Node |', ' | '.join(keys) ## 生成表格的内容 ## 需要一点小技巧区将整数转为字符 for k in node_census.keys(): print '|', k, '|',' | '.join([str(v) for v in node_census[k].values()])  节点 201 021C 021D 210 120U 030C 003 300 012 021U 120D 102 111U 030T 120C 111D\n0 8 0 0 0 0 0 0 4 0 0 0 14 0 0 0 0 1 4 0 0 0 0 0 0 3 0 0 0 11 0 0 0 0 2 4 0 0 0 0 0 0 1 0 0 0 7 0 0 0 0 3 3 0 0 0 0 0 0 2 0 0 0 7 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 5 1 0 0 0 0 0 0 1 0 0 0 5 0 0 0 0 6 1 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 7 1 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  表4-1 风筝网络内部的三元组普查\n现在让我看一下主要的三元组类型:紧密型三元组（代码为300）和结构洞型三元组（代码为201）。\n真实数据 让我们现在对在本章前面部分用到的9/11劫机数据执行一次三元组普查，并找出谁拥有最多的派系（紧密型三元组，代码为300）：\ncensus, node_census = triadic.triadic_census(cc) ## 仅仅得到紧密型三元组的数量，并按照其数值进行降序排列 closed_triads=[[-k,v] for k,v in sorted([[-node_census[k]['300'],k] for k in node_census.keys()])]  列表中排名最高的人有一个我们很熟悉的姓氏：穆罕默德•阿塔（Mohammed Atta）是最初策划911袭击的汉堡支部的一份子，并且是美国航空公司的第11次航班劫机后的飞行员，他驾驶着飞机撞在了世贸中心的北楼上。\n4.4 派系 虽然我们或许可以直觉地将社会网络中的派系理解为彼此紧密相连的、有黏着力的一群人，在社会网络分析领域对已派系有一个正式的、更为严格的数学定义。\n对于一个给定的图来说，一个派系被定义为其中的一个最大的完全子图（ maximal complete subgraph ）——也就是说，群体中的每个个体都与其他的每一个人相连。“最大”意味着这个派系无法再增加节点，因为如果将其它节点也算入派系，将降低派系内部连通的紧密程度。从本质上讲，一个派系包含着几个相互重叠的紧密型三元组，并且继承着紧密型三元组的许多文化生成功能和放大特征。\n一个派系必须生成共识，否则就会解体——这是为什么在方言里，派系经常被认为与其他派系存在冲突。其实派系与冲突的关系非常容易理解：拥有一个共同的敌人（或者一组共同的敌人）使得派系内部更加团结。我们将在第6章讨论一些关于冲突和派系的含义。但是现在，让我们看一下是否可以在一些样本网络中找到派系。\n检测派系 作为测试，让我们再看一下高加索地缘政治的数据。这一次，我们将要探索不同国家之间的经济关系（图4-9）。在这个数据当中，经济合作水平的取值范围为0到1之间——1表示一个紧密的或者说独占的网络链接，0表示完全没有经济合作关系：\n\u0026gt;\u0026gt;\u0026gt; eco=net.read_pajek(\u0026quot;economic.net\u0026quot;) \u0026gt;\u0026gt;\u0026gt; net.draw(eco)  图 4-9 高加索地区的经济联盟与联合行动\n这个数据清晰地表明在这个地区存在着两个不同的力量——以西方国家为中心的一方和以俄罗斯为中心的一方；当地和地方性的经济联系经常是不存在的，作为最近的地理上的邻居（例如亚美尼亚（Armenia）和阿塞拜疆（Azerbaijan）），往往将彼此看作敌人并按此选择与不同的超级大国建立关系。伊朗和土耳其扮演着“捣乱分子”的角色——一个与伊朗有较多经济联系的国家不会和美国有联系，并因此被迫与俄罗斯结盟。当然，石油和天然气也起着非常重要的作用。 一个像这样的结构容易孕育派系。我们看一下是否能够从其中找到派系。首先，我们要丢掉低水平的联系（边的权重 \u0026lt; 0.5）以凸显网络的核心：\n\u0026gt;\u0026gt;\u0026gt; e2=trim_edges(eco, weight=0.5) \u0026gt;\u0026gt;\u0026gt; cliques = list(net.find_cliques(eco)) \u0026gt;\u0026gt;\u0026gt; cliques [['EU', 'Turkey', 'Russia'], ['EU', 'Turkey', 'USA'], ['EU', 'Azerbajan'], ['EU', 'Georgia'], ['EU', 'Kazakhstan', 'Russia'], ['EU', 'Kazakhstan', 'USA'], ['EU', 'Armenia'], ['South Osetia', 'Russia'], ['Nagorni Karabakh', 'Armenia'], ['Chechnya', 'Russia'], ['Abkhazia', 'Russia']]  我们大略地看一下派系的结果：\n• [EU, Turkey, Russia], [EU, Turkey, USA]– 代表着（两个）超级大国和对于土耳其是否应该成为欧盟成员的论辩的双方。\n• [EU, Azerbaijan], [EU, Georgia]– 在高加索地区与西方结盟的国家；阿塞拜疆（Azerbaijan）是主要的石油生产国，并且一个英国石油公司所拥有的石油管道穿过阿塞拜疆从格鲁吉亚到达黑海。\n• [South Ossetia, Russia], [Nagorni Karabakh, Armenia], [Chechnya, Russia], [Abkhazia, Russia]– 所有的最近的冲突 起源于当地的小的共和政体从拥护西方转而拥护俄罗斯（自愿地或者被强迫地）。\n• [EU, Kazakhstan, Russia], [EU, Kazakhstan, USA]– 哈萨克斯坦是一个主要的天然气生产国，其天然气主要通过俄罗斯拥有的石油管道和液态天然气设施卖给欧盟和美国。\n简而言之，派系算法生成的结果可以很快地被一个熟悉该领域的人解读。\n不幸的是，这些派系之间大多是重叠的，并且一个单一的事件或现象可能导致多个派系。其他的算法（n-clans, k_plexes等）可以帮助解决这个问题——但它们尚未被融入到NetworkX当中，并且它们的应用也超出了本书的范围。\n我们将在下一个部分通过聚类的方法解决这个问题。\n4.5 分层聚类 我们将要接触的（虽然很简略地）另一个类型的算法是聚类算法。聚类算法包罗万象、异常宽广，或许在其它的书籍中被阐述得更好——但我会简单地介绍聚类算法在社会网络分析中的应用，并提供一个从聚类算法中可以得出有用结论的简单例子。\n首先我们回到“距离”的概念。我们可以用很多办法定义距离——从地理距离到在地面上旅行经过的距离，再到以时间计量的距离（例如，从一个地方A到达另一个地方B所要花费的时间），等。在社会网络分析中，我们发现两种距离的概念最为有用：一个是节点之间的图距离（或路径距离）；另一个是以相似度计量的距离（也就是说，如果节点之间在某个方面上相似，我们就认为它们靠得更紧密）。\n在之前的章节中我们使用的高加索网络中，图距离的矩阵如表4-2所示：\n TR SO GE IR TK US AZ CH AR EU NK KZ RU AB TR 0 2 1 1 1 1 1 2 1 1 2 1 1 2 SO 2 0 2 2 2 2 2 2 2 2 3 2 1 2 GE 1 2 0 1 1 1 1 2 1 1 2 1 1 2 IR 1 2 1 0 1 2 1 2 1 1 2 1 1 2 TK 1 2 1 1 0 1 1 2 1 1 2 1 1 0 US 1 2 1 2 1 0 1 2 1 1 2 1 1 2 AZ 1 2 1 1 1 1 0 2 2 1 3 1 1 3 CH 2 2 2 2 2 2 2 0 2 2 3 2 1 2 AR 1 2 1 1 1 1 2 2 0 1 1 1 1 2 EU 1 2 1 1 1 1 1 2 1 0 2 1 1 2 NK 2 3 2 2 2 2 3 3 1 2 0 2 2 2 KZ 1 2 1 1 1 1 1 2 1 1 2 0 1 2 RU 1 1 1 1 1 1 1 1 1 1 2 1 0 1 AB 2 2 2 2 0 2 3 2 2 2 2 2 1 0  表 4-2 高加索网络中的网络距离\n这当然和地理距离非常不同，并且描绘了在高加索区域中国家之间的合作和拥护关系是交织在一起的，每个个体不是被其本地的联盟国家所环绕，而是被潜在的对手所环绕。\n让我们看一下是否可以在经济网络中找到这些相互敌对的群集（cluster，或译作“簇”）。我们将会使用SciPy包中一个的分层聚类方法和一小段由德鲁•康威（Drew Conway） 原创、在本书中被大幅改进的代码。\n算法 图4-10展现了（以一种程式化的方式）分层聚类的算法。算法大致按照以下步骤运行：\n 从最低层开始，每一个节点被分配为一个只包含自己的群集。 使用距离表（表4-2）找到距离最近的一对节点并将它们合并为一个群集。 重新就算距离表，把刚刚合并的群集看作一个新的节点。 重复步骤2和3，直到所有的网络中的节点都已经被合并到一个大得多的群集中（示意图中的最高层） 选择介于最高层和最底层之间的一个有用的聚类门槛——这需要人工干预而无法机器自动完成。  图 4-10 分层聚类\n步骤3值得更多的思考。如何计算一个群集和一个节点之间的距离？如何计算两个群集之间的距离？有三个方法可以做这件事情：\n• 单个链接：按照最小的最低配对距离（minimum pairwise distance）合并两个群集。\n• 平均链接：按照最小的平均配对距离（average pairwise distance）合并两个群集。\n• 最大链接或完全链接： 按照最小的最高配对距离（maximum pairwise distance）合并两个群集。\n完全链接方法被认为对异常值非常敏感；单个链接方法容易形成链状的、一长串的群集，这与我们关于群集的意义的直觉理解不同；平均链接方法是其它两种方法的折中，也是最常用的方法。\n城市聚类 为了更好地展现聚类是如何实现的，让我们来思考一个美国本土城市的聚类问题。初始的距离表如下所示；我们将使用单个链接的聚类方法：\n【此处 插入p83表格】\n在前两步当中，我们要合并波斯顿、纽约和华盛顿为一个群集。我们将会发现东海岸城市被合并为一个它们自己的群集：\n【此处插入p84表格1】\n跳过一些步骤，芝加哥进入东海岸城市群集，而旧金山和西雅图构成了西海岸城市群集。严格的说，芝加哥和丹佛应该形成一个中西部城市群集——但因为我们使用了单个链接距离量度，芝加哥结果与东海岸城市群集的距离比与丹佛的距离更近。\n【此处插入p84表格2】\n此时，仅仅剩下迈阿密和丹佛的群集仍未分配。在接下来的几步当中，丹佛加入芝加哥所在的东海岸城市群集。此时，我认为进一步的聚类不再有任何意义。\n长距离的链条（从东海岸城市群集到芝加哥，再到丹佛，最后到达西海岸城市群集）是单个距离量度方法的一个众所周知的不足之处。如果我们此时使用平均链接方法，聚类的结果将会更为清晰。获得更为清晰结果的代价是较高的计算复杂性——这使得平均链接聚类方法不适用于非常大的数据。\n准备数据和聚类 让我们现在开始在高加索网络数据中应用分层聚类的方法。首先，需要计算距离矩阵。NetworkX提供了一个函数可以生成这样的一个矩阵——但返回的结果是一个嵌入字典的字典（dict of dicts）。这种返回数据的格式不适于做进一步的运算，并且需要被转换到SciPy的矩阵中来。因为矩阵形式的数据不会保留节点的标签，我们构建了另外一个数组来保存这些节点的标签。\n最后，我们执行SciPy的分层聚类算法并得到所有聚类结果的树形图，这个树形图与图4-10类似。我们需要确定一个门槛值——此处，我们任意挑选一个数值，但是因为它是一个参数，所以很容易被改进以得到更有意义的结果。\n例4-1 分层聚类算法\n__author__ = \u0026quot;\u0026quot;\u0026quot;\\n\u0026quot;\u0026quot;\u0026quot;.join(['Maksim Tsvetovat \u0026lt;maksim@tsvetovat.org', 'Drew Conway \u0026lt;drew.conway@nyu.edu\u0026gt;', 'Aric Hagberg \u0026lt;hagberg@lanl.gov\u0026gt;']) from collections import defaultdict import networkx as nx import numpy from scipy.cluster import hierarchy from scipy.spatial import distance import matplotlib.pyplot as plt def create_hc(G, t=1.0): \u0026quot;\u0026quot;\u0026quot; 从距离矩阵中创造一个图G的分层聚类 马克西姆注：对带有标签的图进行聚类的前处理和后处理，并返回聚类的结果 参数化门槛值之后，其取值范围应该通过对每个数据进行尝试的基础上确定 \u0026quot;\u0026quot;\u0026quot; \u0026quot;\u0026quot;\u0026quot;在对德鲁•康威（Drew Conway）编写的代码进行优化的基础上而来\u0026quot;\u0026quot;\u0026quot; ## 创造最短路径距离矩阵，但是保留节点标签 labels=G.nodes() path_length=nx.all_pairs_shortest_path_length(G) distances=numpy.zeros((len(G),len(G))) i=0 for u,p in path_length.items(): j=0 for v,d in p.items(): distances[i][j]=d distances[j][i]=d if i==j: distances[i][j]=0 j+=1 i+=1 # 创造分层聚类 Y=distance.squareform(distances) Z=hierarchy.complete(Y) # Creates HC using farthest point linkage # 这种划分的选择是任意的，仅仅为了说明 的目的 membership=list(hierarchy.fcluster(Z,t=t)) # 为块模型（blockmodel）创造一系列的列表 partition=defaultdict(list) for n,p in zip(list(range(len(G))),membership): partition[p].append(labels[n]) return list(partition.values()) # Create collection of lists for blockmodel partition=defaultdict(list) for n,p in zip(list(range(len(G))),membership): partition[p].append(labels[n]) return list(partition.values())  运行上述分层聚类算法：\n\u0026gt;\u0026gt;\u0026gt; import hc \u0026gt;\u0026gt;\u0026gt; hc.create_hc(eco) [['Turkmenistan', 'Nagorni Karabakh', 'Russia', 'Abkhazia'], ['USA', 'Armenia', 'EU', 'Kazakhstan'], ['Turkey', 'Georgia', 'Iran', 'Azerbaijan'], ['Chechnya'], ['South Osetia']]  这个结果从直觉上来说非常容易理解——[[\u0026lsquo;Turkmenistan\u0026rsquo;, \u0026lsquo;Nagorni Karabakh\u0026rsquo;, \u0026lsquo;Russia\u0026rsquo;, \u0026lsquo;Abkhazia\u0026rsquo;]是一个以俄罗斯为中心的群集；而[\u0026lsquo;USA\u0026rsquo;, \u0026lsquo;Armenia\u0026rsquo;, \u0026lsquo;EU\u0026rsquo;, \u0026lsquo;Kazakhstan\u0026rsquo;]这个群集主要是跟天然气买卖和运输有关系的；[\u0026lsquo;Turkey\u0026rsquo;, \u0026lsquo;Georgia\u0026rsquo;, \u0026lsquo;Iran\u0026rsquo;, \u0026lsquo;Azerbaijan\u0026rsquo;]这个群集代表的是支持伊斯兰和波斯的态度。对格鲁吉亚（Georgia）的聚类有一些不合适，因为它在政治上是与天主教和西方国家结盟的，但它在经济上与阿塞拜疆和土耳其联系紧密，因而抵消了它亲西方的面貌。剩下的聚类结果则充满了异常值 ——实际上，这些小国家也给这个世界带来了不少麻烦。\n块模型 一个块模型（block model）是一个从原始网络中提取出来的简化的网络，其中处于同一个群集中的节点被看作是一个节点，而所有的原始的节点之间的关系也被累加为块之间的关系。 在我们作为例子的数据当中，一个块模型所展现的是俄罗斯为中心的群集（0）、西方为中心的群集（1）和伊斯兰为中心的群集(2)之间的关系。而群集3和4主要是一些小的、与俄罗斯联系紧密的、但彼此之间几乎不存在任何联系的共和国——因为俄罗斯对于周边的附属国家的管理是高度中心化的。\n计算块模型，首先需要计算并保存分层聚类的结果，然后需要将群集划分的结果存储为一个列表并在此基础上对原始的图运行块模型。结果如图4-11所示。\n\u0026gt;\u0026gt;\u0026gt; clusters=hc.create_hc(eco) \u0026gt;\u0026gt;\u0026gt; M=nx.blockmodel(eco,clusters) \u0026gt;\u0026gt;\u0026gt; net.draw(M)  图4-11 高加索网络的块模型\nhiclus_blockmodel.py提供了一个可以被应用到所有图的一个更精细的绘图方法：\n例4-2 同时绘制一个网络图及其块模型\n __author__ = \u0026quot;\u0026quot;\u0026quot;\\n\u0026quot;\u0026quot;\u0026quot;.join(['Maksim Tsvetovat \u0026lt;maksim@tsvetovat.org', 'Drew Conway \u0026lt;drew.conway@nyu.edu\u0026gt;', 'Aric Hagberg \u0026lt;hagberg@lanl.gov\u0026gt;']) from collections import defaultdict import networkx as nx import numpy from scipy.cluster import hierarchy from scipy.spatial import distance import matplotlib.pyplot as plt import hc \u0026quot;\u0026quot;\u0026quot;在原始网络旁边绘制一个块模型\u0026quot;\u0026quot;\u0026quot; def hiclus_blockmodel(G): # 提取最大的联通组元 H=nx.connected_component_subgraphs(G)[0] # 使用分层聚类进行分隔 partitions=hc.create_hc(H) # 构建块模型图 BM=nx.blockmodel(H,partitions) # 绘制原始图 pos=nx.spring_layout(H,iterations=100) fig=plt.figure(1,figsize=(6,10)) ax=fig.add_subplot(211) nx.draw(H,pos,with_labels=False,node_size=10) plt.xlim(0,1) plt.ylim(0,1) # 绘制块模型 # 使用带有权重的边 # 以群集中包含的节点数量表示块模型中的节点大小 node_size=[BM.node[x]['nnodes']*10 for x in BM.nodes()] edge_width=[(2*d['weight']) for (u,v,d) in BM.edges(data=True)] # Set positions to mean of positions of internal nodes from original graph posBM={} for n in BM: xy=numpy.array([pos[u] for u in BM.node[n]['graph']]) posBM[n]=xy.mean(axis=0) ax=fig.add_subplot(212) nx.draw(BM,posBM,node_size=node_size,width=edge_width,with_labels=False) plt.xlim(0,1) plt.ylim(0,1) plt.axis('off')  4.6 三元组、网络密度和冲突 在本章中——实际上对于本书中截止现在所涉及的所有内容——我们所讨论的都是关于包含一种类型节点和一种类型的边的均匀网络（uniform network）。但是，后面涉及的内容会变得越来越有趣。\n设想我们有两种类型的边而不是一种类型的边——友谊和冲突。我们也将在二元组和三元组的层面上引入更多变化。\n我们都已经经历过社会混乱——或者甚至曾经卷入其中。比如一对结婚很久的夫妇决定离婚，于是他们的朋友们马上面临决策的困难。置身于这对夫妇的任何一方都会感到压力，于是可能给持续很久的友谊关系带来破坏，并把一个本来联系紧密的网络分割成丈夫阵营和妻子阵营。当分裂造成的伤害被平复，建立新的友谊关系和恋爱关系的空间重新出现，于是类似的循环再次开始。 我们可以使用一些非常简单的规则来为这个过程建立模型（以下规则是有先后顺序的）：\n 我的朋友的朋友也是我的朋友（使得一个结构洞闭合）。 我的朋友的敌人也是我的敌人（使得三元组到达平衡状态）。 我的敌人的朋友是我的敌人。 我的敌人的敌人是我的朋友。  实际上，从另一种角度看，规则2,3和4描述的是相同的（无向的）三元组，因此我们把它们都称之为“规则2”（如图4-12）。这些规则实际上很早就用来尝试描述文明史中的社会复杂性；第一次提及这些规则是在《圣经》当中（出埃及 23:22，在其它的章节中也曾出现）\n图 4-12 三元组演化的规则（伴随着冲突）\n让我们从一个违反了规则1或者规则2的社会网络中的行为开始：如果我们从一组互不相连的节点开始，并且以一个固定的概率随机的连接这些节点，最后我们会得到一个节点度分布为正态分布的简单的随机图（一个厄多斯随机图）。网络的密度（也就是网络中实际存在链接数量除以可能存在的链接数量）将会上升直到每个节点都和其它节点相连（一个完全图或者派系）。当然，这并没有那么有趣。\n让我们现在回到规则1。如果存在一个开放的三元组 A→B→C，按照某种概率，我们也将添加一条链接A→C。我们仍旧可以随机地添加链接，所以，最初这个网络将会线性地增长。直到某一个时刻达到链接的临界点，然后每个新增加的链接都会制造出一个开放的三元组。这个开放的三元组将会按照规则1的要求被闭合，其结果是制造出更多的开放的三元组，这些新增的三元组随后被闭合，这个过程将不断进行下去。\n在某种意义上讲，网络从线性增长过渡到指数形式的增长。它像病毒一样传播开来（图4-13）！链接的密度迅速增长，直到没有新的链接可以增加并且我们得到一个全联通的图。当然，在现实当中，对于一个网络存在一个可能的链接数量的限制，也就是饱和密度（saturation density）。这个密度可以是网络自身的特征，或者是这个网络所在的环境——或者是规则2的结果（正如在我们的模型当中）。\n图 4-13 按照规则1使三元组闭合\n通过改变一个友谊关系为敌对关系，冲突以一个恒定的概率被引入网络演化当中。图4-14刻画了可能的演化形式。在这个简单的例子当中，一个包含4个闭合三元组的网络被作用于其一个边上的冲突所扰动。三元组A-B-C开始因为B和C之间的冲突而变得不平衡；因此A被迫以一种随机的方式选择站在冲突双方的哪一边，并选择与B和C中的哪一个继续保持朋友关系。在A-C这条边上施加一个冲突迫使另一个三元组（A-C-D）变得不平衡，并将节点D引入到冲突中来。如果节点D选择把节点C从整个网络中孤立出来，冲突的蔓延终止。但是，如果D选择孤立节点A， 这将导致冲入进一步蔓延并破坏更多的网络链接。拥有更多的链接增加一个节点形成更多的网络链接的概率，但是也增加了两个节点之间的冲突蔓延到整个网络的可能性（如图4-14）。\n图 4-14 冲突的蔓延\n冲突蔓延的结果是网络密度再也不可能增长到接近100%的程度；但相反，一旦它到达了一个“第二临界值”，冲突会变得更加突出（如图4-15所示）并使得网络密度降低。这类行为被称为自组织的临界性——我的模型仅仅提供一种在社会网络中生成这种效果的简单方法。这与森林火模型中的方法类似：森林的密度越大，下一场森林火演变为灾难的可能性越大——允许小的火灾降低森林密度到某种水平上使得大多数火灾被相对得很好地控制。\n图 4-15 按照规则2运行的冲突的蔓延\n我们将在第6章讨论更多的网络动态——但同时，现在是开始了解包含不同类型节点的社会网络数据的时候了——这些数据更接近于我们所熟悉的社会网络。\n","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341100800,"objectID":"bb560e083fe43ec1e97cdf7a1138b504","permalink":"https://chengjunwang.com/zh/archive/2012-07-01-snabook-chapter4.zh/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/zh/archive/2012-07-01-snabook-chapter4.zh/","section":"zh","summary":"","tags":null,"title":"第4章 派系、聚类和组元","type":"zh"},{"authors":null,"categories":null,"content":"在本章中，我们将探索分析具有两种及两种以上节点类型的复杂网络的方法。但首先，我们先从一个故事开始。\n###竞选资金是否影响选举？\n “我们有一个用金钱能买到的最好的政府。”——马克•吐温\n 每年四月份，在芝加哥帕尔默家园希尔顿酒店(The Palmer House Hilton)，政治科学家在中西部政治学年会（讨论特殊利益集团政治和竞选资金的顶级会议）上准备好辩论马克•吐温的话是否正确，或者美国政治系统实际上对于金钱的影响是否免疫。\n带着一个关于竞选资金及其对选举结果影响的大规模社会网络研究，我们 在2006年加入这场辩论。在本节中，我们将简要回顾这个研究，并介绍得出这些结果所使用的方法。\n但首先，让我们开始玩一个小游戏。\n看一下图5-1。这个图中的节点是积极卷入2000年美国国会选举和总统选举的政治组织或政治行动委员会（political action committee， PAC）。红色和蓝色的节点分别代表共和党和民主党（州和全国），绿色节点代表单个事件群体，紫色节点代表工业协会，黄色节点代表非盈利组织。政治行动委员会之间的网络链接表示它们花钱的地方——如果A和B向同一个候选人捐款，在它们之间就存在一条链接——并且他们越相似，网络链接的权重越大。权重大的网络链接在图中用粗的线条表示（我们将在稍后介绍这是如何做的）。\nP93 图5-1 竞选资金——政治行动委员会网络\n这个研究是基于依照麦肯恩-法因戈尔德竞选改革法案由联邦选举委员会所公布的数据 。这个数据是基于政治行动委员会每次向一个候选人捐款时按照要求提交的表格。这个数据在每个选举年份可从http://fec.gov/获取，但是数据信息的质量和覆盖范围因选举年的政治环境的不同而存在差异。\n正如你所看到的，单个事件政治行动委员会主导整个网络。右方是共和党群集，以共和党国家委员会（RNC）为首，而左方是民主党群集和民主党国家委员会（DNC）。但是，三个政治行动委员会紧挨着并且与这些“国家队队员”有着紧密联系，它们看上去支配着这个网络里非常多的权力。\n你能猜出它们是谁吗？\n答案在图5-2当中。在紧密相连的三元组的左方和右方的节点分别是全美堕胎及生殖权行动联盟（NARAL）和国家生命权利委员会——代表了关于堕胎问题的两个阵营，这在2000年和现在都是美国政治中最富争议的问题之一。\n图 5-2 竞选资金——美国政治行动委员会网络（核心网络）\n在中间的是美国劳工联合会—产业工业联合会（AFL-CIO），它代表了美国最大的工会和它所代表的超过一千一百万选民。这个组织在历史上倾向于支持民主党，但是共和党需要赢得重要的、像俄亥俄和密歇根这样的工业发达的州的选票以便于控制国会并让共和党候选人当选总统，这意味着要从传统选区那里吸引工会的选票。这需要一个“杠杆问题”：一个能够使得工会成员打破对于政党的附属关系的非常争议的问题，比如堕胎。\n可能是因为精心设计或者命运的偶然，我们现在可以说即使堕胎问题不是一个有争议性的问题，也是一个影响2000年大选的少数问题之一 。\n一点点额外的娱乐，我想要你注意一下图 5-2中做下角。这一个政治行动委员会的群集（除了纽约州民主委员会（New York State Democratic Committee）之外）仅仅为了一个原因而存在——打败希拉里•克林顿（Hillary Colinton）。\n我们将再稍后重新回到这个竞选数据，但首先让我们看一下如何来完成这些研究。\n###二模网络的理论\n现存的大多数网络数据都是二模的（双峰的或双向的）形式——也就是说，存在两种不同类型的节点，并且网络链接表示一群节点和另外一群节点之间的关系。\n例如，一个数据当中可能包含多种关系，例如政治贡献（例如政治行动委员会资助候选人）、雇佣关系（个体被组织所雇佣）或社会化媒体使用行为（用户对某些页面的喜爱）。这些网络经常包含两种以上类型的节点，例如天使投资人向创业者所创建的公司投资（这更有趣，因为成功的创业者最后自己也成了天使投资人）。但是，方法基本没有什么改变。\n社会学家提出一个概念：个体和群体的二元性 。从本质上讲，这个概念是指人们的想法、态度和社会关系是由个体在群体中的身份所决定的，而群体的形成源于是由成员的态度。这适用于公司、帮派、政党、社交俱乐部等。因为人们往往不仅具有一种群体成员身份，群体成员的身份可以被看作一种分析和汇总个体之间的相似性和差异性的一种方法。\n###隶属网络 ( affiliation network )\n图 5-3 展示的是一个简单的二模网络——个体A和B都是一个俱乐部的成员。这实质上构成了一个开放式的三元组，或者一个结构洞——但我们可以推断如果A和B是同一家俱乐部的会员，他/她们可能知道彼此，因而推断这个三元组实际上是闭合的。这当然是一种很弱的推断：举一个更具体的例子，还应该考虑A和B是否在同一个时间段里是这个俱乐部的成员，或者这个俱乐部在不同的城市里有多个分会，等等。但这只是一个开始。\n图 5-3 三元组的闭合与共同成员身份\n现在想象一个人是多个俱乐部的成员（在图5-4中，节点E，F,H是两个俱乐部的成员）。据此我们可以推断他们之间存在较强的联系，或许暗示着一种共享的群体身份。我们可以继续增加成员关系直到我们确信这些联系是真实的，并给推断出的链接赋予权重。\n图 5-4 从二模网络中创造一个隶属网络\n图 5-4 展示了由原始的二模网络推断出来的两个网络——一个是是由个体之间共享的群体身份决定的人际网络，另一个是不同的组织之间所共同包括的成员所决定的群体网络。创造这种网络，我们只需要统计每个人或每个俱乐部的共享成员身份的数量。\n正如其它的社会网络一样，这些网络也可以采用相同的分析方法，并且非常适合采用“岛屿方法”（参见第四章 网络上的岛屿 一节）和聚类方法（参见第四章 分层聚类 一节）。这是因为这些网络实质上是基于相似度或者相关程度的网络，因而其意义很容易理解。\n###属性网络\n二模网络分析的另外一个应用是基于同质性（homophily，希腊文， “喜欢相似的人或物”）的想法——这个想法认为相对于具有不同兴趣或属性的人，具有相同兴趣或属性的人倾向于和相似的人交流并建立联系。那么如何理解“异性相吸”等说法呢？这个理论似乎适用于一些情况，但并不适用于另外一些情况，因此这个理论并非是一个普适的法则。我们也知道如果人们更紧密地在一起，他们就会在意见、观点上更相似——但这种影响存在一定限度的。\n但是，如果你想要建立一种线上社会网络里的朋友推荐机制，把属性矩阵或兴趣矩阵转化为一个二模网络是一个有用的方法。所需要做的就是把每一份信息（标签、关键词等）看作是二模网络中的节点，从中得到一个人和人之间的隶属网络，应用岛屿方法或者聚类方法找到潜在地属于同一个群体的人。在此基础上推荐朋友，只需要从隶属网络中挑选最强的网络链接。\n一个（与二模网络）逆向的隶属网络——用属性作为边来连接个体——能够提供更多有趣的洞察。试想我们想要测量推特上的政治话语。我们提取包含“选举”这个井号标签（#， hashtag）的由几万人所发的推特，构造一个从使用者个体到井号标签的二模网络，并在此基础上计算一个“用井号标签作为边连接个体”的隶属网络。在这样的网络中，群集成为整个话语空间的中介——并能够将推特使用者区分为自由和保守两派。进一步的分析可能这两个派系内部相互分隔的原因，比如茶党作为一个独立的主体涌现并分布于主流的共和党的话语中。\n###一点数学\n让我们用一个邻接矩阵来表达一个网络（参考 第二章 邻接矩阵 部分）：\n 1 2 3 4 5 A 0 0 0 0 1 B 1 0 0 0 0 C 1 1 0 0 0 D 0 1 1 1 1 E 0 0 1 0 0 F 0 0 1 1 0  现在，让我们比较节点D和F;我们可以通过将这D、F两行在表格中相乘的方法来完成：\n 1 2 3 4 5 Sum D 0 1 1 1 1 = 4 F 0 0 1 1 0 = 4 D*F 0 0 1 1 0 = 2  D和F共享两个边。现在我们来对任意一对节点进行上述操作，并将它们放在一个如下的矩阵中：\n A B C D E F A 0 0 0 1 0 0 B 0 0 1 0 0 0 C 0 1 0 1 0 0 D 1 0 1 0 1 2 E 0 0 0 1 0 1 F 0 0 0 2 1 0  得到的这个邻接矩阵代表了节点A到F所构成的隶属网络，并且这个操作仅仅需要做矩阵的乘法。在这个练习中，我们将邻接矩阵A和其转置矩阵（At）相乘：AA=A* At\n【警告标志】在本书中，我们采用一种在数学上并非严格定义但是可读性好的概念：一个包含人和俱乐部的二模网络被称为PC；由这个网络得到的人和人相连的隶属网络称为PP，等。\n这个计算需要花费较多的时间。实际上，这个操作的计算复杂性是O(n*m*n)。其中n是“外边界”（在这个例子中是政治行动委员会），m是这个乘法的“内边界”。从一个10*5的二模的网络中提取隶属网络需要在矩阵的“长边”进行10*5*10=500次操作，在矩阵的“短边”上进行5*10*5=250次操作。在这种情况下，一次操作需要在一个找到给定两个节点a和b的边（a,b）的取值，并且如果如果这个操作需要对文本进行操作，得到隶属网络的计算将会变得非常昂贵。合理的索引（使用Python的词典或者SQL的索引）可以使得这个操作变得很快，一般可以将计算时间减少2或3个数量级。\n【警告标志】如果你以前未接触过矩阵代数（我承认它非常枯燥，虽然也非常有用），可按照如下方法思考矩阵乘法：如果我们用PC乘以CP，“内边界”（P）必须相同。两个矩阵的内部边界相互抵消，我们将得到一个方阵CC。那么AB*BC*CD*DA等于什么呢？AB*BC=AC;AC*CD=AD;AD*DA=AA;我们走过了一个循环。这种创造一个长的相乘的序列的特性在第XX页的“扩展多模网络”一节中变得非常有用。\n###二模网络实战\nNetworkX提供另一个很多用于二模网络的函数。使用这些函数，需要安装版本为1.5或者更高版本的NetworkX。让我们尝试一个简单的例子。\n所使用的数据来自于我们前面所提到的竞选资金数据的一部分。原始的数据包含50万次交易。我们仅仅使用基于几百个交易数据所构建的二模网络。在这个例子中，每个政治行动委员会和每个候选人都被分配了一个编号(ID)。实际上，这些独特的编号是由联邦选举委员会给定的。候选人的编号实际上非常容易辨识。例如，候选人H6IL14095Z在第14区、参选伊利诺伊州（ILlinois）的众议院（House）——这些信息足够帮助我们找到这个候选人是共和党人丹尼斯∙哈斯泰特（Dennis Hastert）。联邦选举委员会同时也提供一个包含所有候选人信息的详尽数据库（具体到候选人的家庭住址） ，但我们在这本书中将不会分析这个数据（因为涉嫌网络跟踪）。\n我们将要使用的数据存储为CSV（逗号分隔）格式（见表 5-1），包含了我们所需要的所有变量，其中一些变量我们现在不会考虑。第一列是每个行动委员会的编号，第13列是收到捐款的候选人的编号，第11列是捐款的金额。2000年的数据格式与现在的数据格式可能存在一些差异，但基本上一致。你可以通过修改以下代码的方式来分析现在的数据：\nimport csv import math import networkx as net ## 引入二分（双峰）函数 from networkx.algorithms import bipartite as bi ## 从csv文件中读取数据 ## 我们使用rU模式读入数据，因为很多CSV文件是通过Excel创造的 r=csv.reader(open('campaign_short.csv','rU')) ## 二模网络通常是有向的。这里边的方向表示资金流动的方向 g=net.Graph() ## 我们需要分开追踪不同类型节点 pacs=[] candidates=[] ## 使用CSV文件中的边构建一个有向的图 for row in r: if row[0] not in pacs: pacs.append(row[0]) if row[12] not in candidates: candidates.append(row[12]) g.add_edge(row[0],row[12], weight=int(row[10]))  表 5-1 竞选资金交易记录（前20行）\n###政治行动委员会网络\n现在我们已经构建了一个图对象，我们能用它做什么呢？让我们开始计算一个政治行动委员会网络的隶属网络：\npacnet=bi.weighted_projected_graph(g, pacs, ratio=False)  这个网络有一个大的组元和一些孤立的节点。这些孤立的节点是我们随意地去除一部分数据用作例子的人为产物——并且我们同样可以在这里把它们扔掉，而仅仅保留那个最大的连通的组元：\npacnet=net.connected_component_subgraphs(pacnet)[0]  我们想要画出最后的这个网络，并且通过颜色和边的宽度来展现关系的强度。因为边的取值范围非常广，所以需要使用取其对数的方法来压缩其数值范围:\nweights=[math.log(edata['weight']) for f,t,edata in pacnet.edges(data=True)]  最后，我们将画出这个网络图：\nnet.draw_networkx(p,width=weights, edge_color=weights)  这个图应与本书中的图5-5相似。粗的红色边代表强关系；在这个数据当中，最强的关系存在于节点C00000422和C00000372之间，前者是哥伦比亚的克雷格∙安德森（Craig Anderson）博士，后者是道路维护政治联盟——一个位于密歇根州绍斯菲尔德地区的铁路工人工会组成的政治行动委员会。\n###候选人网络\n为了计算候选人网络，我们需要简单地逆转投射的方向并根据候选人表格而非政治行动委员会表格来计算一个投射的隶属网络。\ncannet=bi.weighted_projected_graph(g, candidates, ratio=False) cannet=net.connected_component_subgraphs(cannet)[0] weights=[math.log(edata['weight']) for f,t,edata in cannet.edges(data=True)] net.draw_networkx(cannet,width=weights, edge_color=weights)  结果得到的图要明显大得多并需要花费更长的时间绘制出来。它看上去有些像一个毛球 。非常明显，这个网络存在着一些明确的群集；我们现在将要使用第xxx页“网络中的岛屿”一节中提到的“岛屿方法”。首先，让我们看一下边的数值的柱状图——这将帮助我们确定“水平面”的大小。图 5-6表明大约80%的边的权重小于0.9，所以我们可以安全地去掉它们：\nP102\n图 5-5 政治行动委员会的部分隶属网络\n图 5-6 国会候选人网络中边的权重的柱状图\ndef trim_edges(g, weight=1): g2=net.Graph() for f, to, edata in g.edges(data=True): if edata['weight'] \u0026gt; weight: g2.add_edge(f,to,edata) return g2 plot.hist(weights) ## 这个柱状图中的边的权重是取对数的； ## 我们可以计算初始的权重=e^log_weight cannet_trim=trim_edges(cannet, weight=math.exp(0.9)) ## 基于这个新网络重新计算 weights=[edata['weight'] for f,t,edata in cannet_trim.edges(data=True)] net.draw_networkx(cannet_trim,width=weights, edge_color=weights)  这个核心的网络（图 5-7）清晰地包含着一些由跨越边界的候选人联系在一起的紧密的群集。在2000年的时候，许多民主党人趋于保守——结果导致使得他们从一些共和党支持者那里获得很多资金。这当然未能使得他们赢得选举。\n图 5-7 国会候选人网络（核心）\nP 104\n从现在开始，我们可以使用分层聚类的方法（见第XXX页“分层聚类”一节）来寻找处于这些群集的人。跨越边界者可以通过使用中介中心度（见第XX页“寻找传播的瓶颈和/或社区的桥梁”一节）。因为这些方法已经在前面的章节中讲过，我们把这一部分作为留给读者的练习 。\n###扩展多模网络\n在前面几节当中，我们讨论了如何处理二模网络。但是，我们都知道这个世界其实更复杂，网络中的节点和边的类型非常多。幸运的是，我们在之前的几节中讨论的方法可以很容易的扩展到任何网络数据模型中。我们只要小心地确保每个网络以及隶属网络的意义是什么——并且不会再矩阵乘法的海洋中迷失。\n我想要用取自大卫∙魁克哈特（David Krackhardt）和凯思琳∙卡莉(Kathleen Carley) 的一个研究中的关于一个组织的数据模型作为一个例子。\n让我们想象ACME公司，一个制作装饰品的一个小公司。一些人通过某种彼此传达命令的形式正在为这个公司工作。这些人在公司内部和外部都存在友谊关系，在某个专业领域里受过正式的教育，并拥有一些资源。公司所生产的装饰品包括一些部件或分拆的任务，其中每一个单独的任务都需要一些人运用一种技能和资源才能完成（例如，制作一个链轮齿，一个人需要了解如何操作车床，具有钢原料，并花费足够多的时间）。\n你是否注意到所有的黑色斜体的词？从多模网络而言，这些词都可以被看作是节点，在此基础上，我们可以构建一个代表了ACME的社会网络，有些像图 5-8。图 5-8中的实体-关系示意图仅仅展现了组合中的四种实体，这种关系图可以变得非常复杂。在这个例子中，我们不会穷尽所有可能的关系——但我么将说明如何得出新的推论的方法（这种方法适用于其它的场景）。\nP 105\n图 5-8 一个简单组织的实体-关系示意图\n以一种矩阵的形式，这个组织模型看上去像表格 5-2。\n表格 5-2 作为一个邻接矩阵的实体和关系\n人(P) 技能(S) 资源(R) 任务(T)   人(P) PP：谁了解谁？ PS：谁了解什么？ PR：谁拥有什么？ PT：谁做什么工作？\n 技能(S) SS：什么样的技能同时被需要？ SR：某一种资源需要什么技能？ ST：一个任务需要什么样的技能？\n 资源\u0026reg; RR：什么资源同时被需要？ RT：一个任务需要什么资源？\n 任务(T) TT：任务之间的优先次序\n  每个矩阵都只不过是记录着乔（Joe）在多大程度上了解如何操作车床或者乔是否有铁原料制作链轮齿的一个表格。\n我们现在可以把以前几节中的每一个网络看作一个二元网络（bipartite network）。不幸的是，NetworkX尚未为分析多元网络（multipartite network）提供一个扩展的函数，所以我们必须回到矩阵的水平上进行计算：\nimport numpy as num pc=net.adj_matrix(g) #从网络中提取邻接矩阵 cp = pc.transpose() #得到转置矩阵 cc= pc*cp # 计算一个政治行动网络之间的网络 cc_graph = net.Graph(cc) #从一个邻接矩阵中重新创作一个NetworkX对象  现在让我们好好玩一下。因为我们可以进行无限长度的矩阵乘法以满足我们的需求，所以我们可以对数据进行很多的推论。比如：\n• PP * PP = PP: 这个心的网络的意义是“谁是朋友的朋友？”\n• PT * PTt = PT * TP = PP: 它的意义是“谁和谁在一起工作，完成多少任务？”\n• PT * TT = PT: 对每个人来说，对于他们来说至关重要的是那些任务？\n• TT * TT = TT: 相互依赖的任务\n• PT * TT * TP = PP:对一个人来说至关重要的是哪些人？\n• PT * TT * TT’ * TP = PP: 对于同时进行的任务，那些人在一起协同工作？\n####练习\n在这个模型当中，你如何判断那些任务是不可能完成的？让我们假设一项任务可以被完成如果被委派完成此任务的人拥有完成这个任务的资源。\n【警告标志】这个方程RTt* PRt = TR * RP = TP代表能够被一个人完成的任务。这个方程TP * PT = TT将生成一个矩阵。这个矩阵的对角线完成一个任务可能存在的方法的数量。如果这个数字是0表明这个任务是不可能完成的。\n可计算的组织理论的整个领域环绕着这种类型的模型成长起来。正如许多其它的模型，不管是静态的还是动态的，本书开始部分关于恐怖主义者网络的模拟是根据类似的原则（但在更高的水平上）建立的。资源分配和可行性评估现在已成为微软项目的一部分。\n这里有一个警告如果有人想要在咨询实践中使用这种方法。不管现在运行多么完好，没有一个商业拥有它的商业模型、社会网络、嵌入雇员的心智中的知识的完全信息。一些人想要通过积极地改造企业的结构的方式来巩固其组织模式——但是，正如我们在前面讲到非正式网络时提到过的，这将被非正式的组织结构直接规避。\n","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341100800,"objectID":"229dd66db5bb0dfcbf69109aa4f73d57","permalink":"https://chengjunwang.com/zh/archive/2012-07-01-snabook-chapter5.zh/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/zh/archive/2012-07-01-snabook-chapter5.zh/","section":"zh","summary":"","tags":null,"title":"第5章 二模网络","type":"zh"},{"authors":null,"categories":null,"content":"这一章或许是你挑选这本书的首要原因。很多人好奇事物（视频、网站、新闻等）如何像病毒一样在网络上传播开来——迅速扩散并成为文化中的一部分（同时在这个过程中，使得创造它们的作者富有）。我们应该预先告诉你我们并没有现成的答案。实际上没有任何人知道答案，并且这个过程中有一些运气的成分在——但在本章中，我们将要尝试使你更加理解驱动扩散的原因以及你的决策如何驱动购买行为。\n##6.1病毒视频剖析 假设给你的猫拍摄了一段非常可爱的视频，上传到YouTube网站上并通过推特进行宣传。你是否正走在通往财富的道路上？答案是，不一定。\n这主要取决于谁看到了这个视频，以及他们在看完之后做了什么。首先，唯一看到视频的是位于你的自我中心网（ego network）中的成员——比如你的朋友。这样的观看总数的增长是非常缓慢的；观看总次数随着时间是线性增长的，这意味着每个时间段的观看次数接近一个固定常数。在这种情况下， 我们可以将观看次数描述为一个泊松过程，其中的每个观看你的视频的浏览行为彼此之间是独立的。最后，你的视频所获得的总浏览数量与你的粉丝的数量（你的程度中心性）存在数学上的关联。\n但如果发生了一些其它的事情并且你的朋友们转发了这个视频给他们的朋友（等等，使得越来越多的人知晓这个视频），你的猫的视频将马上成为YouTube上面最流行的视频，并且好莱坞的制片人前来你家拜访。或者这一些都没有发生。\n有一个奇怪的事情在这个过程中间的某处发生了。你的一个朋友说“你看过这个视频吗？”，另一个朋友回答“是的，我已经看过了”，这强化了这个视频是一个“觅母”（meme） ——一个新的、独立的文化人造产品的观念。突然之间，让别人接触这个觅母就成一个人的第二天性或者甚至是一种必须的行为。\n从一个无足轻重的事物（但是可爱或有趣）变成一个必须分享的事物的质变过程是增长曲线的一个剧烈的转折，也被称为“临界质量”（critical mass）。如果在一定量的时间里，觅母未能在一定的时间范围里到达临界质量，它的采纳率开始下降并最终消亡。\n但是如果到达了临界质量，它将指数增长直到达到饱和点——也就是几乎每个可能采纳这个觅母的人都已经采纳。从这一点开始，觅母将会开始走下坡路。\n需要注意的是临界质量和饱和的概念适用于每个网络和社群——一个觅母在一个社群到达饱和点而在另一个社群里无人知晓是可能的。但是，因为社群是相互连接的，所以觅母通过跨界者从一个社群传入另一个社群并确立一个新的临界质量和更高的饱和点是可能的。\n###脸书做对了什么 在脸书（Facebook）出现之前，存在着其它社会网络。我们中的一切人或许还有聚友网（MySpace）的账号。一些人还记得Friendster。在Friendster之前，在所有其它SNS之前还有一个叫SixDegrees的网站。SixDegrees创立于1997年，它承诺将连接人们和他们的朋友、以及他们的朋友之间、最好的律师、医生、水暖工等。这样做，它将提供帮助人们通过社会网络完成任务的有用的功能。\nSixDegrees早于时代5年时间，并且尽管采用了全国范围内的广告宣传、良好的设计（对1997年而言）、在博客（令人尊重的Slashdot网站和波音波音（BoingBoing）网站都曾重点推介过它）和杂志（连线杂志）中良好的形象，它从未迎来增长的临界点。\n哪里出错了呢？答案非常简单——Sixdegrees未能到达它的临界质量。网站本身是全国性的，他们却实际上试图建立一个蔓延全国的地方化的市场，结果未能完成这个任务——实际上几乎不可能在这个网站上找到一个水暖工，部分原因是那时很少有水暖工使用互联网（或者觉得建立一个网络SNS账号很麻烦），部分原因是SNS的使用强度非常低。\n当脸书2003年建立的时候（仍使用最初的名字“Facemash”），它是一个哈佛本科生组成的小而紧密的网络社群。创立于一个较小的地区使得他们可以快速到达增长的临界质量。实际上，在它上线约四个小时内，就已经吸引了450个访问者，或者大约6%全部的本科生。记住6%这个数字，它非常重要。\n在哈佛内部，早期的脸书经历了一系列反复，直到找到一个易于扩展的设计并最终覆盖50%的哈佛本科生而达到饱和。从那开始，它的触角开始伸向其它常青藤高校，一个接一个，最终覆盖了美国所有大学。最后在2005年，它开始面向高中生——并奠定了它主宰世界的基础。\n脸书所遵循的规则——也是脸书不同于Sixdegrees和Friendster的地方——是在一个社群里到达饱和点之后才移入一个更大的社群。通过这种方式，临界质量从未被错过，并且新的成员完美地嵌入他们来自其他学校的伙伴建构的社会结构之中。\n###如何估计临界质量 在“三元组、网络密度和冲突”一节中，我们讨论了冲突如何在社会网络中蔓延及其对于网络链接的密度的影响。如果你回去重新仔细看图4-13，你会发现一个非常相似的增长方程——相同的S形曲线，如同我们在图 6-1中所观察到的一样。\n图 6-1 扩散曲线——临界质量、繁荣和萧条\n图字翻译：\n如果从线性的蔓延到指数（病毒式的）增长的确依赖于封闭的三元组（也就是说，朋友的朋友也是我的朋友） ，这样连接的临界质量的可以通过测量随机增加一个链接（比如，从A到B）与其它节点之间所形成的一个或多个开放三元组的概率的方法加以估计。这个概率与已经彼此相连的节点的数量（我们用2与节点数量相乘是因为每个边占用两个节点）：\nP(开放三元组) ~= 链接的数量/(2*节点的数量)\n这样，当四分之一的节点彼此相连的时候构成一个开放的三元组概率是50%——并且每一个新的链接使得闭合三元组能够创造甚至更多的链接，进一步增加形成级联（Cascade）的概率。\n我们在实验中发现当网络密度接近7%的时候将从线性增长（每一次增加一条链接）转化为病毒式扩散——也就是说，当有意采纳这个“觅母”、转发一个视频、加入一个网络社群等的人的比例达到7%的时候，其他人将会在关键阶段马上跟进。\n这是一个推动脸书走出哈佛的、神奇的数字。在我们的研究过程中，我们发现的一些其它的例子也表明当网络中的采纳比例小于10%时会发生病毒式扩散。\n从这一点可以得到的一个推论是在一个较小的社群里更容易达到临界质量——马克•扎克伯格（Mark Zuckerber）本能地知道或者（更可能）偶然发现。\ntips： 对于一个新兴公司（尤指新兴网络公司）的创立者而言，这是违背直觉的。每一个风险投资者都想知道整个市场到底有多大以及新兴公司完成市场渗透的计划。追逐小的自给自足的细分市场看上去与指数式的增长背道而驰。但是，一个细分市场的高饱和度是通往其它细分市场的一个好跳板——如果它们在地理上接近或者其利益非常吸引人。\n###维基经济的临界质量 关于临界质量的问题还有一种看法——参与成本理论。即使在一个提供免费服务品的世界，任何事物都有成本。这种成本包括金钱成本、时间成本、或者机会成本（也就是说，花费时间在脸书上，就无法花费时间在酒吧里——至少在移动手机变得普遍之前）。其它形式的参与文化，比如维基百科，需要其作者和编辑花费更多的时间，但得到的收益却非常短暂。\n一个过时但依然有说服力的例子是传真机的出现。当第一个传真机在上世纪七十年代中期，从施乐的装配线上生产出来之后，其成本高达几千美元并且完全得没有什么用处。另外不要忘记，如果一个传真从它那里发出，并没有位于另一端的一个传真机接受它。当第二台传真机在几分钟之后从生产线上滑落的时候，两台传真机的价值都无限增加了——现在一个银行可以（通过传真机）与其分支网点通讯了。但是，这台机器的用处随着越来越多的机器被生产出来而不断增加，直到传真机成为一种不可或缺的办公用品。\n在传真机的例子中，传真机最初被应用于大公司的总部连接其分支机构（代替了庞大的电传机）。所以每个公司独立地、按照自己的时间到达它们自己的临界质量——如果公司已经投资足够多资金到传真机设备上，在更大的范围销售传真机将会变得非常困难或者不可能。 一个经济学家会使用交易成本的概念讨论这件事情，并画出如图 6-2的曲线。\n图 6-2 成本曲线——社会化媒介的经济学\n图字翻译：\n假设参与成本是一个固定的值。在一些例子中（例如，传真机），当大规模生产时生产成本降低，但在参与式的文化（例如，维基百科）中，成本实际上随着生产规模膨胀而变大了——但我们可以在短期里认为它是常数。\n对于一个早期采纳者而言，成本是非常真实的，而利润还没有实现。当有更多人加入这个网络之后，收益以连接的数量的函数的形式增加，这使得新观念、觅母、社会网络网站的渗透漫漫长路中的每一步都变得更为容易。\n当使用一个产品带来的收益超过其成本的时候，扩散将接近临界质量。此时，每增加一个链接将会带来更多的链接，进一步增加收益——而成本却保持不变。\n如果没有到达成本/收益的平衡点，在网络中存在多少链接都是没有意义的——因为，最终在这个网络中的扩散都会失败。\n###内容（依旧）为王 当我开始1995年开始为网络项目而工作时 ，曾经有一个说法叫做“内容为王”。内容可以吸引使用者、留住使用者、挽回使用者。那时候流行很多理论——其中一个说应该确保用户点击鼠标不超过6次就能够找到他/她想要的内容，另一个说重要的信息不要被屏幕翻页所分割（载入的计算机屏幕的第一页之后部分信息）。不管是在过去还是在现在，这些都是好的设计准则。但是如果网站的内容非常吸引人，其它的这些都不再重要。如果翻页后的内容很有价值，人们就会点击和滚动鼠标去看。\n这种观点在今天同样存在：如果内容在某些方面是引人入胜的，这将提高收益并使得成本和收益的平衡更快到达，并因此将链接的临界质量从7%降低到3%或4%。如果内容的质量不是那么好，那么可能根本就无法到达临界质量。\n这是社会网络的定量分析止步的地方，也是关于信息重要性的理论过度盛行的领域。下面的这个理论是许多试图定性地解释信息扩散的一种方式。\n当我们想要知道一个信息是否可以在一个网络中扩散时，实际上我们的问题是“这个信息是否会和网络中的成员引起共鸣？”。或者，更准确地说，“个体如何获取信息？”。我们可以将信息的作用分解为几个维度的变量：\n• 相关性（Relevance） 我是否关心？（以及其变体，显著性（saliency）——我现在是否在乎？）\n• 共鸣（Resonance） 信息的内容和我所相信的内容是否一致？\n• 严重性(Severity) 信息的内容有多好或多坏？\n• 紧迫性（Immediacy） 这个信息是否需要（人们）马上行动？与严重性一起，表示（看到信息后）不做出任何行动的后果。\n• 确定性（certainty） 这个信息的效果是否会导致某种痛苦或者快乐？或者这种概率非常小？\n• 信源（source） 信息来自哪里？我是否信任发出信息的人？这是否曾被人们所验证？\n• 娱乐价值（Entertainment value） 信息是否好玩？是否耐读？\n###异质性偏好 我在以前的小节中的提到的评价方式适用于特定的信息（m）和人（p）。但是在实际生活当中，每个收到信息的人按照他们自己特殊的偏好来给信息打分。在经济学中，汇总异质化的个体偏好是一个困难的问题。为了简化这个问题，让我们假设以上所提到的所有变量都可以写成数值形式（我们规定其范围为0到1）。那么，每条信息都可以被评价为：\n公式6-1\n公式6-2\nBeta数值代表对于一个具体的个体，当他/她采用一条信息时每一个变量的重要性。有些人非常脆弱、害怕恐吓战术（具有很强紧迫性和严重性的信息，即使相关性不高并且也不相信信源），而有些人当信息来自于他们并不完全相信的信源时，毫不犹豫拒绝相信。\n让我们看一下是否我们可以将这个公式应用于一些可能的场景中去：\n####突尼斯和埃及革命 这些事件高度依赖于信息的扩散。在这个例子中，大多数信息可以被评价为高相关性、高紧迫性，一些信息会被评价为高严重性（比如，军事活动或者警察镇压活动中的信息）。但是，在任何一个像这样的快速改变的条件下，确定性很低并且对于信源的可信性超过信息本身的可信性。也就是说，一条来自你的阿姨的话比来自一个记者的信息更可信。谣言泛滥，并且有时候误导了许多人。\n这样，我们能够解释每一场革命都需要一个前后一致的领导——在一个混沌的时代，一条来自领导人的信息既负载着确定性（因为领导者肯定具有更多的信息或者令人信服的假信息），也负载着对于信源的超凡的信任。\n####保罗∙里维尔的乘骑 保罗•里维尔（Paul Revere）（1735年1月1日——1818年5月10日）是一名美国银器匠，也是美国革命战争中的爱国者。他最出名的事迹是在莱克辛顿和康科德之战前通知当地殖民军英军即将到来。（译者补注）这是关于高严重性、高紧迫性、高相关性、高确定性信息的一个最好的例子。即使信源并不太出名，信息很快就到达了临界质量。共鸣非常高，因为人们已经相信英国人的袭击迫在眉睫。有必要注意的是保罗∙里维尔并非是向世界发出一条微博，而是造访一系列的城镇——到达一大群分散的、小的地方的临界质量，这些地方稍后团结起来一起反抗英国军队。 ####电视广告 电视广告对大多数读者（一些正在选择新的、正在播出的电视的人例外）来说相关度不高，重要性不高，迫切性也不高。为克服这些缺点，广告主需要设计信息内容以提高信息的确定性（例如，“这将改善你的生活”）、信源的可信性（“六个医生有五个会推荐……”）、信息的娱乐价值。对于二手车销售者来说，其它的策略也很合适，例如放大严重性和迫切性（“现在行动，否则就没有机会了”）。\n对于广告的响应一般非常低，因为很多人对于品牌名字漠不关心。当然，在这种情况下，能够对抗这一规律的品牌将占据市场的主导地位。苹果公司花费数年时间和几百万美元培养了一群粉丝，正如多数体育队和一些其它公司所做的那样。迎合粉丝的品牌成功地获取回报，即使信息内容很普通——只要这些信息强化了粉丝已有的信念（我们将在本章“Python中的一个简单的动态模型”一节中讨论具体内容）。\n最后，多数广告无人理会——但是偶尔会有一个广告超出广告商的宣传活动，像病毒一样在互联网上传播。这经常意味着广告具有较高的娱乐价值并且值得人们在它上面花费时间（参照前面关于成本/收益分析部分），即使它不具备其它方面的因素。\n####连锁信 连锁信是这个类别中的一个奇特成员。来自于你认识并信任的人的信息非常重要。它通过一个好故事的娱乐价值吸引你，但如果你不转寄这封信会有严重和紧迫的后果。在这种情况下，造成伤害的确定性很低 ，但转寄电子邮件的成本同样很低(如果这个信件是真的呢？)。 ####搞笑猫图片 我不知道说什么好。从个人来讲，我不认为它们值得下载，但我猜我不是一个互联网媒介的典型消费者。对于一些人来说，搞笑猫图片的娱乐价值非常高，以至于你不仅仅满足于欣赏它们或者传播它们，还要去创造新的图片。我手上有额外的时间吗？\n许多其它的信息以相同的方式传播——思考一下宗教类的信息并且把天主教信息和热心的牧师的话对比。虽然信息的内容或许相同，信息所表达的意义却完全不同。有的信息强调商品的价值，有的信息剖析最新的流行时尚。\n##6.2信息如何影响网络 信息、观念和看法的改变相对得很快，并且在这个过程中，影响网络解构。同时，网络结构也制约着信息扩散的过程。结果构成了一个双重反馈回路：社会结构影响信息扩散，而信息则影响社会结构的变化。在这一节中，我们将要讨论内在机制——并尝试构建一个信息扩散的简单的动态模型。\n##具有相同羽毛的鸟 在第5章的“二模网络的理论”一节，我们简要得提及了同质性的概念——节点之间的链接的建立基于节点之间的相似度。但这个观念已经存在了几百年了（俗语说“羽毛相同的鸟总飞成一群”），在科学研究方面，拉扎斯菲尔德（Lazarsfeld）和墨顿（Merton）于1954年分析了这一下现象 ，他们区分了两种类型：身份同质性和价值同质性。\n身份同质性表示具有相同社会阶层、财富和地位的人（与随机的情况相比）更倾向于彼此相互联系。价值同质性表示倾向于与以相同方式思考或者喜欢相同的东西的人彼此相互联系，不管阶层和地位如何。\n美国文化当然更显著地受到价值同质性的影响，而在其它社会当中，个人的教育和阶层身份经常更清晰明确地影响他们所能接触到的信息或者文化人造品的类别。这在网络上更为明显，因为在互联网上“没有人知道你是一条狗”。一个人的网络身份虽然现在变得很普遍并接近于永久，但与线下的身份相比，仍然非常容易改变。\n地位同质性和价值同质性的一个区别正是在于“可塑性”（malleability） 。社会阶层和类别可被认为是永久的属性——社会流动通常是一个很缓慢的过程，因而无法通过社会网络分析把握。与之相反，价值同质性则以互联网的速度变化着。\n###同质性 VS. 好奇心 社会学家观察到另外一个有趣的现象——虽然同质性是一个很强的社会因素，但如果两个人不太像，但差异也没有达到使得两个人找不到谈话的话题时，另外一个因素将会发挥作用。这个因素是好奇心（获取信息的内在动机），结果使得形成链接的可能性呈现图 6-3中所示的双峰形状。对每个人来说，“好奇心山峰”的高度和位置是不同的，并且与我们的猎奇及规避猎奇的趋势有关（事实上，这可能是我们基因组成的一部分，尤其是我们大脑中的D1多巴胺受体的数量有关）——但它总以某种形状存在着。\n图 6-3 同质性与好奇心\n图字翻译：\n最主要的特征是“无聊的陷阱”。遇到一个和你在各个方面几乎一模一样无法提供新的信息或者刺激——于是建立链接的可能性迅速降低。人与人之间无聊的陷阱的位置和程度也不一样，并与我们的大脑对新奇性的需求和处理有关系。\n自我中心主义者的这个波动的极值是无法控制的，他们以没有能力处理新奇性和很难形成社会纽带并理解他人为特征。对威廉斯氏综合症患者来说，寻求新奇性和群集性走到了极端（缺乏抽象和空间逻辑能力）。\n你也可以把它看作一个随着时间的演变过程。想象一对刚刚遇到对方的男女。他们或许有一些相似的特质（都很年轻漂亮，如果没有其它地方相似），但总体上讲他们的同质化水平可能很低；相反，他们的好奇心都达到了顶峰。随着关系的进展，他们对彼此的了解不断加深，即使对于他们从来不会交流的事情。最终，男孩知道了他的女朋友背负着大笔的学生贷款，女孩了解到她的男朋友把脏袜子到处丢的坏习惯。这或许是位于好奇心和真的同质性之间的低谷。如果他们的关系走过了这个低谷，他们会变得能够接受了解对方所有的事情并且幸福得白头偕老。除了在之后的十几年里，他们没有对彼此说过一句话——如果他们相互之间没有什么新的消息为什么要说话呢？\n###跨界者\n我们每个人的基因组成和个性差异使得我们的社会网络也是不一样的，并且同质性到目前为止也不是普遍的。一些人喜欢做跨界者，他们和不同的群体存在联系，表现出来非常低的同质性。他们不仅是关键的信息通道，他们也可以利用作为中介和套利的机遇——这意味着在石器时代与不同部落建立贸易往来或者在现代在华尔街工作。我们已经在第4章的“禁止进入的三元组”和“结构洞”讨论过这个问题——但跨界行为也可以透过信息扩散的透镜来理解。\n###弱关系 在二十世纪七十年代，马克∙格兰诺维特（Mark Granovetter）开展了一项关于在南波斯顿某一个社群工作的蓝领工人的研究。他的大多数调查对象是爱尔兰移民，在建筑业或者其它技术工行业工作，并且花费大量的时间在酒吧里。工作，尤其是建筑业的工作，非常不稳定，在任何时间都有一部分人处于失业和找工作的状态中。这个研究项目的目标是研究工作信息如何在社会网络中流动。\n当地的酒吧是社交中心——每个人都定期地参加聚会并认识大多数其他去酒吧的人。所以最初的研究目的是分析酒吧里的谈话对于个人找工作能力的影响。\n但是结果非常令人吃惊——通过经常联系的酒吧里的朋友找到新工作仅占30%。大多数时候，工作信息来自于疏远的社会关系——远亲、朋友的姻亲等（也就是说，与他们存在弱的网络关系的人）。\n格兰诺维特推理强关系增加同质化程度——所以当一个人需要新的信息（比如，当找工作的时候），与处于中心的个体存在强关系的人缺乏任何新的信息。同时，通过弱关系联系的人们则完全不同（从信息连接的角度而言）。\n###邓巴数字和弱关系 在罗宾∙邓巴（Robin Dunbar）的论文中（现在已成为经典） ，人类社会网络的平均规模（也就是平均的程度中心性）是150——并且从认知学角度来看，这个数字为前额皮质的大小或者我们推理其他人和关系的天赋才能所局限。\n但这不是那么简单的事情。我想用一个金字塔来展示邓巴数字的各段（见图 6-4）。在顶端，最强的关系是我们直系亲属和最好的朋友，我们每天与他们打交道，并认为他们是最亲密可信的人。邓巴发现这个亲密的群体的大小平均是7——它包括我们的配偶、父母、兄弟姐妹和子女。注意，这个数字和人类工作记忆的容量大小相同（7+/-3） ，所以我们可以推断我们的直接的和最亲密的社会联系是那些我们能够或必须存储在工作记忆中的。\n图 6-4 邓巴金字塔\n图字翻译：\n这个列表进一步分层为“扩展家庭”（extended family，这个群体包括朋友、表兄妹、姻亲等）：他们不是你每天都打交道的人，也不是你认为最亲密的人。再往下一层是“伙伴”，包括同事、一个更大的朋友和陌生人圈子、远亲。最下面一层包括其他所有的人，主要是你的弱关系。\n但是你的脸书朋友和推特朋友在哪里呢？多数情况下，他们位于金字塔的最底部。正如你从上面关于四种关系的描述中所看到的，当我们从金字塔上走下来，不同的社会关系所附带的情绪性和信息分享类信息不断降低，而人数不断增加。所以你的837个推特朋友所包含的情绪性注意力有多少呢？其实很少。\n对于一个服务行业的商业公司而言，社会化媒体的个体接触主要也是因为这个原因。当一个公司的代表与一个推特粉丝在个体层面上互动（例如，回应一个抱怨）的时候，他或她就在这种关系中投入了一些情绪性的能量。因为这种互动是公开的，它不仅维系着与一个现在的消费者之间的关系，还支撑着与其它的推特粉丝之间建立关系的（想象中的）可能性。\n因为每个人对于亲密的个体联系具有不同的偏好，这个金字塔对于每个人可能完全不同。我认识的一些人的最主要的社会联系来自于脸书和博客，他们的线上关系和“扩展家庭”开始融合。因为维持一个线上关系需要很少的情感投入，他们线上朋友可能有几千个却很少跟他们的直系亲属联系。近几年，网络流浪者开始变得与现实中睡在沙发上、一年周游国家数次的流浪者一样。\n##6.3 Python中的一个简单的动态模型 既然我们已经了解了相关的理论和例子，让我们开始尝试为社会网络中的信息扩散建立模型。我们将建立一个非常简单的多主体模型，在这个模型当中，社会网络中的主体之间相互影响并达成共识（如果这是可能的）。\n这个模型最初是由诺亚∙弗里德金（Noah Friedkin）于1998年提出来的 。这个模型遵守一个非常简单的前提：每个参加讨论的人对于问题都有自己的看法（或者他们自己的态度），并且每个人都在一定程度上接受来自其社会网络的朋友的影响。我们同时做出一个假设，模型中的主体所要交流的信息是一个介于0和1之间的数值。它可以是股票市场上升的可能性，或者一个主体使用一种非法药物的概率（这个模型曾用于研究信息在这两种情况下的扩散）。\n让我们开始建立我们的简单模型。我们并不会使用一个多主体建模的软件包，或者模拟包——其实我们也并不需要用它们来建立模型。\n让我们从为一个人定义一个Python的类开始：\nclass Person(object): def __init__(self, id): #从一个单一的初始偏好开始 self.id=id self.i = r.random() self.a = self.i #我们将初始意见和随后的信息对等 self.alpha=0.8 def __str__(self): return(str(self.id))  一个人有一个编号ID和三个重要的额数字：self.i是一个初始态度，self.a是一个演化出来的态度（它累积了这个人所有朋友的影响），最后self.alpha是我称之为“轻信程度因子”（也就是说，alpha越高，我越相信我的朋友的意见，并且越不相信自己最初的知识）。首先，我们假设每个人的轻信程度是完全相同的。\n现在，让我们创造一个以人为节点的网络。NetworkX允许我们使用任何对象作为一个网络节点，而我们将要利用这一特点:\ndensity=0.9 g=net.Graph() ## 创造一个以人为对象的网络 for i in range(10): p=Person(i) g.add_node(p) ##这是一个简单的随机网络，每对节点之间存在链接的概率相同 for x in g.nodes(): for y in g.nodes(): if r.random()\u0026lt;=density: g.add_edge(x,y) ## 画出这个生成的网络并按照节点的数字给节点赋予颜色 col=[n.a for n in g.nodes()] pos=net.spring_layout(g) net.draw_networkx(g,pos=pos, node_color=col)  首先，我们初始化一个空的网络图，并在其中增加10个以人为类型的对象。然后，我们循环遍历每一个可能的两个节点之间的组合。使得概率等于密度的参数，我们将在两个节点之间添加一条链接。这种生成图的算法称之为厄多斯-任易（Erdos-Renyi）算法 ，是生成一个随机图的最简单的方法，并产生一个正态分布的度分布。\n厄多斯-任易（Erdos-Renyi）随机图已经成为许多图的算法和模型的一个基准，但我们现在知道，作为真实社会网络的代表它们非常不实际，因为多数社会网络具有一个长尾的度分布（也就是幂律）。但是，因为其它生成网络的方法更加复杂并超过了这个模型的范围，我们将在此使用这个简单的模型。这个网络看上去应与图 6-5相似。\n图 6-5 一个扩散模型的多主体的网络\n现在准备工作已经做完了，让我们开始创造模拟部分。在人这个类别中插入下面这个函数：\ndef step(self): # 循环遍历所有的邻居并累加他们的偏好 neighbors=g[self] # 所有的邻居节点的权重相同 w=1/float((len(neighbors)+1)) s=w*self.a for node in neighbors: s+=w*node.a # 更新我的意见为初始意见加上所有其它影响之和 self.a=(1-self.alpha)*self.i + self.alpha*s  这个函数基于他或她的朋友的态度加权总数和他或她的轻信程度因子（alpha）而更新一个个体的态度（a）。首先，我们将计算权重的大小。为了计算简便，每个人的意见所占的权重相等（第五行代码）。然后，我们计算一个个体自我意见，以及他或她的邻居中每个人的意见的加权之和（第6到第8行代码）。接着，我们更新现在的意见（第11行代码）:个体在时间t的意见等于客观知识乘以轻信因子，再加上他或她的所有朋友意见的加权之和。最后，让我们用一个循环的方式跑这段代码来看一下这个网络如何随着时间变化：\n##重复30个时间段 for i in range(30): ## 循环遍历所有的网络节点让它们走一步 for node in g.nodes(): node.step() ## 汇总演化而来的态度数值，输出到终端并画出结果。 col=[n.a for n in g.nodes()] print col plot.plot(col)  跑这个模型30个时间段所得的结果看上去如图 6-6所示。随着时间变化，主体之间的意见越来越彼此相近，虽然它们从未达到共识。\n图 6-6 扩散模型运转一步\n让我们现在开始调整一下模型参数。如果所有的主体都非常轻信并接受他们的朋友所说的一切，那么结果会是怎样？让我们设置alpha = 1并看一下结果如何变化。图 6-7表明每个人很快达到共识——即使基于事实来看这个共识是完全错误的。\n图 6-7 扩散模型中的共识\n###处于中间的影响者 现在我们假设一些宣传主体（影响者、福音传教士）被嵌入到网络当中。每一个这样的节点都具有重要影响。在这个模型中，这些主体的意见是1，而其他所有主体的意见分布于0到1之间。 我们在模型中定义一个影响者为一种特殊类型的人：\nclass Influencer(Person): def __init__(self,id): self.id=id self.i = r.random() self.a = 1 ## 它们的意见很强并且不可动摇 def step(self): pass  接着，我们添加一些影响者到这个网络中并将他们同其他主体相连：\ninfluencers=2 connections=4 ##将影响者加入到网络之中并将他们与其它3个节点相连 for i in range(influencers): inf=Influencer(\u0026quot;Inf\u0026quot;+str(i)) for x in range(connections): g.add_edge(r.choice(g.nodes()), inf)  之后，像以前一样跑这个模型：\n## 重复30个时间段 for i in range(30): ## 循环遍历网络中所有节点并让他们运转一步 for node in g.nodes(): node.step() ##汇总演化而来的态度数值，输出到终端并画出结果。 col=[n.a for n in g.nodes()] print col plot.plot(col)  图 6-8表明这两个影响者具有一个很强的效果——但是，初始位置并不允许主体完全地朝着极值迁移。影响者的数量越多，模型朝向一个极值的共识演化的可能性越高。\n图 6-8 添加两个影响者进入网络中以加速网络朝向极值的演化\n这个模型非常简单，没有考虑许多其它影响信息扩散的因素。其中没有同质化的影响，也没有临界质量的作用，并且模型的演化是线性的。但是，这是一个开始，我们要进一步优化这个模型。\n###练习 我在这里所展现的这个模型的实现方式过于简单。读者可以尝试下面这些主意：\n• 使得轻信程度因子异质化而不是所有的主体的轻信程度因子相同。\n• 试验使用多个参数调节的无标度网络而不是使用简单的随机网路。\n• 对于朋友的意见应用信任权重（也就是说，不是给所有的意见的相同权重）而不是基于主体之间的链接的强度。\n• 使用多个维度的态度进行计算——一个真实的人对于不同的事情有多种态度，模型中的主体也是这样。\n##6.4网络和信息的共同演化 现在我们将要优化这个模型中的影响因素，以便允许不同的网络类型、个体的态度和网络中的信息内容。首先，我们将把step函数从之前的模型中去掉，与之相反，引入一个和单一主体交换信息的互动函数，而不是和所有的邻居交换信息。轻信程度因子的作用在这里同样适用：\n## 随机的挑选一个节点交换信息， ## 而不是和所有的节点交换信息。 ## 这将创造一条边并根据他们之间的相似性赋予权重。 def interact(self): partner=r.choice(g.nodes()) s=0.5*(self.a + partner.a) # # 更新我的意见为初始意见加上所有其它影响之和 self.a=(1-self.alpha)*self.i + self.alpha*s g.add_edge(self,partner,weight=(1-self.a-partner.a))  到现在为止，这是一个随机的选择。在信息的交换和接收之后，我们将在两个节点之间创造一条链接。这条边将被按照相似度赋予权重——节点之间的相似程度越高，他们之间建立的链接的强度越高。\n但是，我们也知道在一段时间过去之后，链接会逐渐减少，一个最简单的方法是用一个为常数的衰变率（decay rate）来描述：\nv(t+1)=v(t)*(1-decay_rate)\n衰变率在现实网络中是非常低的，但是在线上社会网络中会明显得要高（因为在脸书上取消朋友关系或者只是忽视他们的信息与跟现实世界中的朋友吵架相比，要简单很多）。但是，这个模型非常抽象，所以我们将选择一个简单的数字。我们设置网络的衰变率在每个时间段为1%。\ntips: 一个模拟中的时间段是完全随意的。但是，人们也可以将它（以及衰变率）与作为交往频率的函数的链接的强度的概念相联系，见第2章“什么是图”一节的描述。\n所以，以之前的方式，让我们初始化这个网络，并运行这个模拟。图 6-9表明一个与其他节点联系紧密的节点，如何在他/她周围分布着一小群意见相似的粉丝，而那些与其他节点联系并不紧密的节点保持着与众不同的意见。这样，带有完全不同意见的节点可以和平共处并且共识会涌现（如图 6-10）。\n图 6-9 这个网络表明意见相似的节点之间联系紧密而意见不同的节点分布于边缘上\n图 6-10 网络和态度的改变允许冲突的态度和多种共识并存\n但是，这也依赖于传播参与者的随机选择这个概念——我们知道这是不正确的（见本章“信息如何影响网络（反之亦然）？”一节）。所以，现在让我们引入同质性的概念。这样做，每个人都维持着自己与他/她所知道的一系列的人的关系，以及自己在多大程度上与他们相似。在这个例子当中，我们已将同质化程度数值存储在图的链接属性中，通过下面这行代码:\ng.add_edge(self,partner,weight=(1-self.a-partner.a))  但是在我们开始利用这个信息选取互动对象之前，我们来讨论一点关于选择的事情。正如我们在 本章前面“信息如何影响网络（反之亦然）？”一节所讨论的一样，我们以更高的概率选择与我们相似的人——但是兴趣中的第二个峰值使我们与和我们非常不同的人交谈。一些传播行为也可能是随机的。为了允许我们按照正比于和其他人的相似度（或不相似度）水平的概率挑选互动对象，我们应用一个叫做“轮盘赌选择”的程序。\n图 6-11 选择网络伙伴的有权重的轮盘赌\n想象一个轮盘赌的轮子的各个扇区之间的权重是不同的（图 6-11）。这样，将赌注押在一些扇区上赢得概率更高，轮盘的旋转是公平的（也就是均匀分布的）。我们通过按照相似度水平构建一个传播伙伴的列表（如果需要，多次重复他们的名字）的方法应用轮盘赌方法。这样，一个从列表中进行的一致的随机选择，将返回一个权重分配合理的轮盘赌选择：\ndef _roulette_choice(self,names,values, inverse=False): \u0026quot;\u0026quot;\u0026quot; 轮盘赌方法基于一组数字得到不同权重的选择 名字和数值应该是等长的列表 数值的范围在0到1之间 如果 inverse=False, 数值较高的名字具有更高的选择概率 如果inverse=True，数值更低的名字具有更高的选择概率 \u0026quot;\u0026quot;\u0026quot; wheel=names for i in range(len(names)): if not inverse: wheel.extend([names[i] for x in range(1+int(values[i]*10))]) else: wheel.extend([names[i] for x in range(1+int((1-values[i])*10))]) return(r.choice(wheel))  最后，我们需要优化interact（）方法一允许我们使用轮盘赌方法。我们再一次掷骰子并决定是否传播伙伴是相似的（以一个0.6的概率）或不相似的（以一个0.3的概率）或完全随机的（以一个0.1的概率）。如果一个人不和任何人说话，他/她将随机地挑选并建立一些网络链接：\ndef interact(self): \u0026quot;\u0026quot;\u0026quot; 随机的挑选一个节点交换信息， 而不是和所有的节点交换信息。 这将创造一条边并根据他们之间的相似性赋予权重。 阶段 II –使用轮盘赌选择而非随机选择 \u0026quot;\u0026quot;\u0026quot; neighbors=g[self].keys() values=[v['weight'] for v in g[self].values()] ##掷骰子已决定互动的概率 ## 相似 (0.6), 不相似(0.3)或随机 (0.1) roll=r.random() if r \u0026lt;= 0.1 or len(neighbors)==0: partner=r.choice(g.nodes()) elif r\u0026lt;=0.4: partner=self._roulette_choice(neighbors,values,inverse=True) else: partner=self._roulette_choice(neighbors,values,inverse=False) w=0.5 s=self.a*w + partner.a*w # 更新我的意见为初始意见加上所有其它影响之和 self.a=(1-self.alpha)*self.i + self.alpha*s g.add_edge(self,partner,weight=(1-self.a-partner.a))  让我们也优化这个模型以便生成更多的一些图。第一个是“共识图”——展示的是网络中每个人的平均意见，以及最大和最小值：\ndef consensus(g): \u0026quot;\u0026quot;\u0026quot; 计算图中的作为共识的意见 \u0026quot;\u0026quot;\u0026quot; aa=[n.a for n in g.nodes()] return min(aa),max(aa),sum(aa)/len(aa)  我们将模型的每一次迭代生成的网络共识的数值添加到一个列表里，并在后面绘制出结果：\ncons=[] for i in range(runtime): for node in g.nodes(): node.interact() .... ....模拟代码在这里.... .... cons.append(consensus(g)) .... .... 模型的最后一次运转之后.... .... plot.figure(i+1) plot.plot(cons) 同时，让我们通过绘制直方图的方式来看一下边的数值。 plot.figure(i+2) plot.hist([e['weight'] for f,t,e in g.edges(data=True)]  tips: 完整的模型代码可以从Github下载（https://github.com/maksim2042/SNABook/chapter6）\n让我们现在重新载入并运转这个模型。结果如图 6-12和6-13所示。\n图 6-12 最终的网络中，节点的意见可以非常不一样\n图 6-13 网络收敛到一个在可接受范围内的意见，但允许内部存在一些多样性\n我们的第一个观察是网络迅速地到达了稳定状态——但这个稳定状态并非形成共识，而是排除了最高和最低极端意见的一种分布广泛的可接受的意见，这种状态适于形成一种让人感到舒适的平均意见。在缺少意见领袖的条件下，平均意见的选取是非常随机的——但是我们可以非常肯定的是，如果我们的随机数生成器是公平的，取得的结果是远离极值的。\n网络并未变成群集内部同质化——相反，如果节点的意见在可接受范围内，那么它们可以共存于一个稳定的动态均衡中。这是如何实现的呢？\n我们在本章中讨论了这个机制——它是弱关系。如果你以直方图的形式绘制出这个网络的链接的强度（图 6-14），你会发现强关系非常少见（特别弱的关系也很少见）。相反，链接的强度似乎分布于一个0.3的均值左右，这是一个很好的、稳定的弱关系。\n图 6-14 多数链接是弱关系或者中等弱关系，正如邓巴金字塔所展示的。\n这进一步加强了链接强度的邓巴金字塔——强关系很少见并且需要完全的共识（这也是很少见的），相反弱关系很容易建立并维持。\n##练习 • 加入影响者。他们如何改变演化动态？如果一些影响者互相冲突（具有截然相反地意见），网络会分化吗？\n• 在模型中加入大的冲击。例如，一个主体可以在一个随机的时刻将自己的意见改变为极值。他/她的朋友们是否回来劝阻他/她？\n• 加入不同传播能力的主体。例如，广播者可以一次同所有的人讲话。\n• 在这个模型的基础上构建一个选举模型。一些候选人为了获得全体的注意力而竞争。他们应采用什么样的竞选策略以影响结果？\n###为什么为网络建立模型 在本节里，我们已经表明使用寥寥数行代码，我们能够概述关于网络动态和变化的理论，并尝试去通过模拟的方法检验它们。经常地，在一个需要和很多实证数据打交道的环境里，形成一个关于驱动网络变化以及变化方向的简洁的理论变得非常困难。模拟模型帮助我们发展出更简洁的理论，并允许我们很快地检验多种不同的观点 。\n这个模型可以作为建立其它信息扩散模型的实验基地。例如，想象一个网络当中的一些节点出现然后又消失以传递一些独特的信息。或者一个在一段时间内可以不受干扰地演化的网络，之后注入一个重要的信息（例如，“传教士和野人”问题 ）。或者，想象着是一个模拟毒品贩运网络的模型，作为一个警察局的网络专家，你需要破坏网络中的信息流动。类似的可能性是无穷无尽的。\n可计算社会科学（Computational Social Science ，简称为CCS）的整个领域已经从社会网络分析、人工生命、人工智能以及其它的一些领域的交汇中开始升起。这或许将成为我们下一本书的主题。\n","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341100800,"objectID":"d5e2fa486e6dc1d627fe9043d3d195f8","permalink":"https://chengjunwang.com/zh/archive/2012-07-01-snabook-chapter6.zh/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/zh/archive/2012-07-01-snabook-chapter6.zh/","section":"zh","summary":"","tags":null,"title":"第6章 信息扩散：像病毒一样传播开来","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\nHow Nature Works: The Science of Self-Organized Criticality 作者: Per Bak\n黠之大者\n任何一个学科都需要从其它学科学习其精髓，对于在走向可计算化道路的社会科学，尤其是传播学而言，这种开放性更是时代的压力和必然的结果。因为网络时代的到来所带了的传播关系的变革、数字化的行为印记（digital traces or digital footprint）、大规模的网络数据的开放都推动着学科的变革。无疑对于传播学而言，这是一个必须抓住的机遇。\n爱因斯坦在老年时在一个自述中讨论了一个问题，即为什么他念了物理没有念数学。他说:“在数学领域里，我的直觉不够，不能辨别哪些是真正重要的研究，哪些只是不重要的。在物理领域里，我很快学到怎样找到基本的问题来下功夫。”我想这几句话的意思应该是每一个大学教授，每一个大学研究生应该仔细想法体会的。如果思考重要的问题，自然做出的东西不容易琐碎（trivial）。虽然最终问题的本质可以用一个美妙的数学形式表达（不应该是统计方程），但从那么多的相（万象）中找到基本的相，稳定的相（pattern)。依然是一个不容易的事情。 到幂律分布（power law）之类的发现依然是唯相的阶段。社会科学的冒进在于每次都妄想一个理论框架。每次都拿理论发现来宽慰自己。殊不知己之理论与彼之理论，相差如同天壤。大数据（big data）引发了很多欢呼和争论，虽然这是机遇，但也隐含着危险。大数据（big data）如果是无偏的，有代表性的，那么就蕴含着机遇。常见的一个错误是误以为google成功于海量数据，谬矣。信度和效度的问题，在我的理解里，这都是你选择的测量的可计算性的问题。好的测量（measure）往往一针见血，如货币，如基因，如能量，如比特。在互联网里目前最成功的测量是什么？我以为是pagerank。借助用户的评价，一下子就抓住了一个网页的重要性！googe最成功的是pagerank这个好的测量。这样好的测量才能赚钱，才有可计算性，基于兹的研究才有信度和效度。类似的测量当属度了，度分布的幂律分布（power law）被无数的研究所发现，可以算到了唯相了。\n作者愚见，觉得扩散是最为普遍而重要的现象，它广泛地存在于各个学科中，并几乎都成为最重要也是研究的最彻底的、最吸引人注意力的领域。我自己对于扩散有着超乎直觉的兴趣。借用古希腊哲学家的话：万物皆流，万物皆变。身在浩浩汤汤的洪流中的个体很容易对流产生兴趣。因而，我将研究流的扩散，更具体的说信息的扩散，作为了自己博士研究的主要工作。 而选择研究信息扩散的一个驱动力就是巴克（Per Bak）的这本书《大自然是如何工作的》，这本书通过沙堆模型讲自组织临界性，对我的启发很大。当我对信息扩散的数据浸淫日久之后，深感必须重返沙堆模型，才能真正理解信息的扩散，因此便有了本文。在本文当中，我将归纳关于扩散研究的三种路径。\n##一、描述式的社会科学套路 如经典的新闻扩散（news diffusion）的研究、两级传播理论（two-step flow）、创新的扩散（diffusion of innovations）。这些研究主要是为了描述现实，沿着这条道路走下去，可以更真实地理解5w，却很难理解1h（即how）。\n虽然社会科学因为无历史包袱，所以视角更为多元，比如两级传播理论所揭示的媒介的直接影响非常不同于自然系统的扩散的特点， 经典的新闻扩散研究发现的J曲线指出人际作用和媒介作用的对立，以及其对传播规模的非线性影响也很有想象力。但社会科学却在可计算化方面做得并不好（读者可参见本文作者在上一期杂志上关于计算传播学的文章）。比如经典的创新的扩散理论中所着重论述的s曲线实在是一个坏到家的定义。因为并未能给出s曲线的数学表达，而几乎不管什么曲线方程（如罗杰斯蒂方程，但注意s曲线不是罗杰斯蒂曲线），只要使用超过三个数学参数就可以拟合任何曲线，这使得大家即喜欢这个s曲线的比喻，又根本抓不住什么才是s曲线。成为了难以比较，不可琢磨的臆测。\n二、微分方程的数学视角。 比如Bass扩散模型(bass diffusion model), 这实在是一个了不起的工作。我写一个的短评，如下：\n从bass diffusion model开始讲，这个与生存（survival analysis）里的hazard rate息息相关。因为F\u0026rsquo;(t)/(1-F(t))被定义为hazard rate。其实是一个条件概率，就是没有采纳的人（没被传染的人）（1-F(t)）在时间点t采纳（被传染）的概率。\n关于hazard rate设置的方法导致Bass扩散模型(bass diffusion model)，前几天刚看了，h(t)=p+q*F(t)。解这个微分方程，可以求出F(t)和f(t)。这个东西可以预测增长曲线。p和q分别代表创新性和模仿性。感觉很好玩。p=0, 即没有创新性的时候，是罗杰斯蒂增长（logistic growth）；q=0, 即没有模仿性，只有创新性的时候，是指数增长（exponential growth）。\n讲到谣言传播的第一种模型的时候，hazard rate=d，这个时候就是指数增长；但这样设置有些随意（arbitrary），因为有些人拒绝传播。就有了一个叫拒绝率r的东西，这个我还是第一次看到，因此它是在试图修正hazard rate。那么r是什么呢？没有讲清楚。我试图从R(t)=r*F(t）/(1-F(t))这个我自己构造的公式来理解。r*F(t)衡量的是已经知道谣言的人拒绝传播的概率, 再除以1-F(t)就是不知道谣言的人受拒绝传播的人影响的概率。 那么就有h(t)=d-R(t)。 但这种工作有点arbitrary，因为你说p是创新性，q是模仿性，然后就开始推导了 （推导可见我的一篇博文， 另电子杂志可以加链接于我而言是意见快乐的事情） 下面沿着率方程的道路走下去的是一个伟大的传统，即传染模型（epidemic model）。最主要的是sis和sir。其主要思路是将传染的过程分为3个阶段：susceptible\u0026mdash;\u0026gt;infectious\u0026mdash;-\u0026gt;recovered (and immune)。sir说一次恢复，永远免疫，再也不怕了；sis则不然，好了还会被再次感染。传染病模型中一个主要的工作是确定一个传播率，它是感染率和治愈率的比值。这个传播率一般存在一个threshold，当高于这个threshold的时候，能够全局传播；否则只能感染少输人。\n网络科学开始考虑人际接触关系（contact relationship）是如何受网络度分布的影响的，加入度分布的因素之后开始考虑统合门槛(threshold)的大小问题，一个著名的工作是Romualdo etc在2001年发表的一篇题为epidemic spreading in scale-free networks的论文，被广泛引用，因为他们发现scale-free network里的感染门槛是0！！！没错，就是0，也就是说全局传播不是问题。\n不过，要小心，这个模型是根据sis做的，如果是sir情况是如何呢？（留作思考，其实我也不知道）这一点很重要，因为当你把它用在信息的渗流的时候，是有风险的。举例子说：Romero \u0026amp;Jon kleinberg （2011）等人研究hashtag(e.g. #ows)在twitter上的扩散，发现多次接触具有很高的边际作用，发现多次接触信息对于信息转发具有显著效果（Repeated exposures to a hashtag on Twitter has significant effects）。那么多次接触单个的信息（repeated exposure to a specific tweet）呢？其情况会大有不同。因为hashtag是一个类别（category），下面有很多子类别。正如感冒细菌下面包含各种各样的细菌一样。加到一块的影响，使得影响很大，但对于单个类别的感冒细菌来说，你得了一次，就不会再得第二次了。即对于单个信息来说，多次接触没有那么大的影响。\n##三、平均场理论视角下的门槛模型（threshold model） 门槛模型（threshold model）最好的诠释仍然是元胞自动机（cellular automaton）， Thomas Schelling的分隔模型（Models of segregation）说每个人都有一个关于周围邻居肤色比例的偏好（peference），超过一定比例后，就会迁移。最简单的就是Granovetter等提出的门槛模型了，计算每个个体（agent）行为改变时其朋友中行为改变比率，但按照平均场视角，这其实不重要，重要的是平均起来的总体效果，最简单的就是门槛的数学分布，按照格兰诺维特的想法，这个数学分布最终决定了扩散的规模。\n自组织临界性最早是BTW sandpile model所提出的，沙堆理论是一个非常强大的metaphor，其主要提出者bak写了另外一本非常强大的书籍介绍其核心思想：其所覆盖的范围真是超乎想象。\n自组织的魅力在于可以对扰动做出最丰富的反应!反应是很平常的，难在最丰富的反应。那是什么样的呢？其实是空间和时间两种分布的幂律特征。\n沙堆模型(Bak等人1988年的论文）所描述的自组织系统中流的规模分布（Size distribution，e.g., earthquake,financial markets,landscape formation;forest fires;landslides;epidemics; andbiological evolution）和流的持续时间分布（Duration distribution）都满足幂律的关系。 有趣的是我在新浪微博的扩散的研究中印证了扩散规模（diffusion range or cascade size）的幂律分布，这暗示着新浪微博中的信息扩散是连续的，同样的规律也存在于twitter中。\nBak曾说自己对自组织临界性的理解是压力和压力的释放。比如向沙堆上加沙子，这种动力推动系统重新演化到平衡状态。这种释放压力的系统被称为耗散系统（dissipative system。这是一个很好的概念和视角：其实森林火、地震、河流涌动，信息传播，树叶中的营养输送，等可以以之概括。\n自组织临界可以按照平均场方法进行解析式的理解。平均场方法首先要确定的是phase transition的问题。第一步，便是要有一个稳定的pattern作为起点。因为相变是由一个序转变为另外一个序。而用来标识这种转变的变量称之为“相变序参量” （sigma），一个相到另一个相的转变需要一个驱动，而这个驱动变量即称为“相变驱动参量。比如铁磁相变中： sigma=（t-tc)^r 这种标度律的稳定的关系吸引着科学家的注意力。 平均场方法认为跨越一切尺度的个体的相互作用结果的总体效果（即”平均场\u0026raquo;），而不简单的是每个个体的局部信息（local information），决定着相变。\n##结尾 It puzzles me that geophysicists show little interest in underlying principles of their science. Perhaps they take it for granted that the earth is so complicated and messy that no general principles apply. ——Bak， How nature works\n本文开始引用了Bak在其书中的一句戏谑地理学研究的一句话。其实地理科学家们当中也有一些有先见者。比如hack’s law揭示的流的直径和覆盖面积之间的标度关系。 用C来表示单位时间的平均流，A表示网络覆盖面积，之间也满足标度关系关系。\n相反，这句话是留给社会科学家（不是哲学家或价值批判研究者）的，对于网络科学所刻画的可计算性的传播行为的研究，在通往可计算性传播学研究的道路上，只有实在性是最好的没得。不能停留在表面，必须深入到简单的相下面的基本规律中去。\n","date":1337126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1337126400,"objectID":"3e6ade01d89a34f9bac4d75c8eabff47","permalink":"https://chengjunwang.com/zh/archive/2012-05-16-return-to-the-sandpile.zh/","publishdate":"2012-05-16T00:00:00Z","relpermalink":"/zh/archive/2012-05-16-return-to-the-sandpile.zh/","section":"zh","summary":"","tags":null,"title":"重返沙堆：通往理解信息扩散的实在之路","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n黠之大者\n引言：大道\n听李金铨(CC.Lee)老师讲治学，喟叹“大道不过三两句，说破能值几文钱？”这是一个开放性的问题，道出了社会科学家(social scientist)的无奈。诸多好玩的东西，归结到最后只有所为“理论”的贡献，而没有应用的价值。CC.Lee一语也是一种挑战：希望学术有助于现世之生活。\n但显然学术应辅助于生活，被认为是传播学创始人之一的卢因博士曾言： Many psychologists working today in an applied area are keenly aware of the need for close cooperation between theoretical and applied psychology. This can be accomplished in psychology, as it has been accomplished in physics, if the theorist does not look toward applied problems with highbrow aversion or with a fear of social problems, and if the applied psychologist realizes that there is nothing so practical as a good theory. ——Kurt Lewin (1943-44), Problems of research in social psychology\n实际上关注应用的理论研究才是真正的有价值的研究。然而学术研究如果止步于此，也多没有生命力，因为我们并没有探究真正的规律（the common pattern）。 一个人如果只是思考琐碎（trivial）的问题，自然不会有大的发现。拉普拉斯曾思考过太阳升起的概率，牛顿执着于重力，爱因斯坦对时间念念不放，这才可能做出真正的研究发现。然而显而易见的是一个可以稳定地（consistently）存在的一般规律（general law）不会是简单的定性描述可以刻画的。它们共享一个优秀品质，即可计算性（computational）。\n对于可计算性的追求在自然科学一直是主流。生物学也开始通过计算生物学的路径开始实现新的飞跃。试思考为什么经济学是自然科学中发展较好的？答案是货币。用货币度量经济行为使经济学具有了天然的可计算性；其次是心理学，不是量表，而是实验，使得心理学具有了“模糊的”比较能力（这种实验计算性的模糊性，局限了心理学的发展路径）。\n事实上，作为一个后起之声，计算社会科学（computational social science）已经在各个分支学科和新的交叉性学科中如火如荼！关于计算社会科学的介绍见Lazer, et al.2009年发表在《科学》杂志上的一文。其中包括：计算语言学（computational linguistics）、计算社会学，计算心理学，计算传播学等。\n也许看到这里，众多也许是全部社会科学家都会想到自然科学和社会科学的区别来。虽然牛顿(Issac Newton)说Truth is ever to be found in simplicity, and not in the multiplicity and confusion of things 。但社会科学家却“深信”社会如此复杂，无法定量甚至实证研究。对此，证明其观点的荒谬远不如开始努力做些东西来得实在。毕竟，你不能因为做一个东西困难就放弃努力。\n##计算传播学 本文的计算传播学不是虚拟之物，它有很多具体的分支。本文所主张的计算传播学是以网络科学为基础骨架，以计算新闻学为实践的知识框架。\n###网络科学（network science） 网络科学已经走出狭隘的传统的社会网研究（social network study）的藩篱，更主要是互联网浪潮的袭来（可参见吴军《浪潮之巅》一书），社会网络开始拥抱互联网网络科学（web science),一种以复杂网络（complex network）为代表的新型网络科学开始迅速成长（参见barabasi的《链接：网络新科学》一书）。\n听得春雷响，老树发新枝。各个分支的社会科学都开始出现网络社会学，网络传播学之类的新的研究版图。然而，此刻之网络科学却远远超越传统社会科学家（包括媒介研究者（media scholars））所理解的范畴。人类传播动态行为（human communication dynamics）开始成为人类动力学（human dynamics）关注的焦点。\n毫不夸张地说，人类的生活已经不可避免地大范围的网络化：网络购物，网络购票，网络交友，网络表达，网络新闻，网络游戏，网络电影，网络音乐，等，不一而足。其直接结果就是所谓的虚拟，变成了现实。其中包含了众多的传播学研究问题（其中之一就是我在关注的网络信息流动的问题）。\n数据新闻学或称数据驱动的新闻学（data driven journalism），被认为是计算传播学的一个具体应用。通过挖掘和展示数据背后的pattern，和丰富的、具有互动性的可视化，数据新闻学成为新闻学的新的疆域和应用范例。 挑战与机遇\n任何新的科学研究的兴起，总是伴随着新的挑战。不仅包括理论的，还包括方法的。普世法则（general law）的欠缺，海量数据（massive data）的逼迫，网络抽样，可视化。如何应对这种挑战？直面还是绕过，还是置之不理。\n###一、取法于自然科学\n网络科学开启了一个崭新的研究纪元，而网络公开数据和开源（open source）的精神都深刻地变革着既有的研究传统。复杂网络作为一个研究领域和研究视角一开始就吸引了众多目光。人类动力学（Human dynamics）与之相对的是人类传播行为(human communication behavior)所对应的传播网络(communication network)。如何借助既有的自然科学理论和模型，尤其是复杂网络中发展出来的模型来研究人类传播行为, 成为现在所面临的主要问题。\n就网络模型而言，图论，网络形态（规则网络、随机网络、无标度网络）、网络增长，网络内部结构特征（rich club、assortativity，etc）等研究，深入的丰富了我们对于传播网络的认识。\n就其研究背后的方法论而言，主要存在四种方法，大致可以分为两类，一类是动力学方法，有平均场方法和率方程方法，物理学家常用；另一类方法是概率论方法，有主方程方法和马氏链方法，数学家较喜欢。\n其研究发现也从各个方面深入地变革着既有的社会网络分析，使之进一步科学化，完备化，成为一个真正的网络科学（network science）。\n二、取法于计算机科学 深入变革网络科学的两大动力，除了物理学，主要是计算机科学。众多的计算机科学家，如Huberman，Lada Adamic，Jon Kleinberg， Hawoong Jeong， Jure Leskovec等人。 计算机科学革新了文本挖掘的技术，topic modeling, 情感分析等开始被广泛地应用到媒介内容的研究中来。试看现在的计算机科学的top conference，如WWW、SIGKDD等会议都开始研究社会化媒体（social media）。\n三、取法于数学 数学是变革网络科学的基础。看到这里，多少会有人开始畏惧。援引爱因斯坦的两句话共勉： Before God we are all equally wise and equally foolish. Do not worry about your difficulties in Mathematics. I can assure you mine are still greater.——Albert Einstein\n四、取法新的计算工具 目前常见的统计软件主要对付中等规模的数据，真正的大数据，其解决的究极之道依然是基于分布式计算的数据库技术。通常我们不会面临真正的大数据，因而现在的研究，即使是最为紧密的，也依然可以使用小数据来说明问题。但随着研究的深入，直接面对大数据依然是不可避免的。\n结语 人类不应停止对永恒的普适法则的追寻，不仅在学术，而且在生活中，曾如康德所言： A person acts morally when he or she acts as if his or her conduct was establishing a universal law governing others in similar circumstances. 大道在前，直面应对！千里之行，始于足下。\n","date":1328745600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1328745600,"objectID":"ba46881f0a584961e3daa7f4ee9d0a93","permalink":"https://chengjunwang.com/zh/archive/2012-02-19-computational-communication.zh/","publishdate":"2012-02-09T00:00:00Z","relpermalink":"/zh/archive/2012-02-19-computational-communication.zh/","section":"zh","summary":"","tags":null,"title":"计算传播学：宣言与版图 ","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n作者: Noam Chomsky; 出版社: Seven Stories Press; ISBN: 9781888363494\n黠之大者\n乔姆斯基（Noam Chomsky）在1991年开始出版第一版的《媒介控制》（Media Control: The Spectacular Achievements of Propaganda ）一书，讨论宣传的历史、旁观者民主（spectator democracy）、公关、被策划的观点（engineering opinion）、替代现实的再现（representation as reality）、异议文化、游行的敌人、选择性认知。之后讨论海湾战争，和想象中的传媒业——来自火星的记者。全书围绕媒介的作用展开，总共才101页，十分短小。\n乔氏的讨论问题比之经典的传播研究迟滞了至少70年，但讨论的视角更为广阔。例如乔氏讨论民主之理解，于细节处见思想的宏伟。乔氏将民主的理解非为两类：一类是参与的权力；一类是信息控制的权力。并认为信息控制是一个更为主导但被忽略的方面。这种思路是很有见地的。乔氏对于政治的叙述更多批判意识。例如他一针见血地指出特权阶级（specialized class）的存在，他欣赏李普曼对于大众的悲观思想（大众是惊恐的羊群；特权阶级必须安抚羊群以保护自己免于羊群的践踏）。这些羊群式的普罗大众，就是观察者。当这些羊群式的大众成为政治的参与者的时候，特权阶层必须考虑如何同化这些大众——通过被制造的合意（the manufacture of consent），使得社会被整合，大众被分心，最终使得羊群式的大众成为政治参与的观察者（spectators of action）。而制造合意的方法莫过于宣传。乔氏说宣传之于民主，恰若棒子之于专政。\n对于公关的讨论开始引入媒体作用，比如使个体原子化。这是最初的传播学研究的“巨大效果论”时期的滥觞。而实际却可能远非如此，虽然城市化开始使得人和人关系疏离。但人总是生活在社会的细胞之中，生活在参考群体（reference group）之中。乔氏认为世界进入一个商业化驱动的社会（business-run society）。将个体组织起来的力量是不存在的（unions are virtually nonexistent）。其中的一个问题是媒体所有权的控制问题。商业开始通过公关操纵政治，以至于政党也只是商业利益的代言人，进而大众不愿意选举因为它看起来无意义（Most of the population doesn’t even bother voting because it looks meaningless）。\n有能力策划合意的人（the people who are able to engineer consent）是占有资源和权力的。民众被认为从未被很好的安抚，屡有反抗，但媒介致力于改变之成为病态的居民，使之无力也无心反抗。例如，乔氏举例在海湾战争中华盛顿邮报鼓吹好战的精神（martial value）。之于关于作为显示的再现的讨论，大多是在回溯柏拉图问题——洞穴中被束缚的囚徒如何认识世界。但这些多很难有一致性的结论，因为媒体这样写了，读者未必这么认为。尤其是在媒体公信力下降的社会。\n乔氏之天才在于其视野之广阔。乔姆斯基反观历史，指出美国以非法占领和伤害人权作为参战理由。很多人也如是解读，这是宣传系统制造合意的力量。然而这种逻辑并没有被完全地应用于美国的行为。例如，1969年南非非法占领纳米比亚之时，美国政府并未作出任何反应，反而是二十年的冷外交。而在这二十年里，一百五十万非洲人被杀。再比如对于萨达姆-侯赛因的反对在美国的报纸上从来都有，在海湾战争之前就有，但是直到海湾战争时，美国人才认识到这是一个问题。似乎存在一个门槛（threshold），美国人对一些媒体上的问题视若无睹，直到美国的宣传工具开始告诉他们这是一个严重的问题。羊群式的美国人似乎真的没有认识能力（也许乔氏真得是唯一的例外）。以色列自从1978年就吞并了叙利亚戈兰高地和东耶路撒冷时，萨达姆宣称无法容忍以色列的吞并行为。伊拉克参战，继而美国参战，海湾战争爆发。乔氏认为萨达姆和布什总统的口号是一致的。然而美国人却毫不认同相同的口号。\n本书的局限很多，一个主要的方面是信手拈来，诸多不严谨之处。全书流于论辩、讲演式的思想铺陈，逻辑过于天马行空，缺乏现实的支撑。反观之现实，顿时觉得乔氏更像一个来自火星的记者，并没有去了解现实的受众。看似弱不禁风的羊群（herd），多大程度上被媒体的所指引？整体而言，这本书并未获得学术界的认可，因为乔氏的研究根本是与传统的研究是脱节的。书中主要的叙述手法仍然趋于评论性质，缺少严格的证据（evidence）。值得注意的是，1991年正是传播学发展由“有限效果论”、“一般效果论”再次进入“强大效果论”的时刻。回到一战和二战时的经典传播学研究，拉斯韦尔等人主要讨论宣传的作用（见《世界大战中的宣传技巧》一书），认为媒介的作用是“巨大效果”。但经历了严格的实证研究的洗礼，发现媒介的影响在很大程度上是受到局限的。因此经历了著名的传播学存在还是消亡的争论。但是伴随着议程设置理论的发展，媒体的作用开始被重新认识。但此时已非毫无限制的。经典的文献总结为“媒体也许并不能有效地控制人们如何想，但可以决定人们想什么”。在此之后的传播学理论也开始另辟蹊径，在媒介如何影响人们的认知框架（priming）和思维角度（framing）的角度展开，而非简单的媒介效果在行为层面的作用。但乔氏似乎也在另外的角度开始接近事实的真相。\n","date":1321488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1321488000,"objectID":"0ce42d58d83a3082919e218680c1e761","permalink":"https://chengjunwang.com/zh/archive/2011-11-17-media-control.zh/","publishdate":"2011-11-17T00:00:00Z","relpermalink":"/zh/archive/2011-11-17-media-control.zh/","section":"zh","summary":"","tags":null,"title":"媒介控制：呓语抑或现实？","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n王成军\n起初对科幻并无太多的兴趣，在深圳的时候李晓煦博士推荐的苏联科幻电影Solaris，用了三个小时，感受了“聚念成人”的快乐与痛苦：一个中年男人来到一个名为Solaris的陌生星球，调查发生在宇航员身上的各种离奇事件：他每天清晨发现自己少年时候爱过的女人坐在窗前，穿着那件记忆中的衣服。然而，一切都是虚幻的，她只不过是这个名为Solaris的星球根据你的想象生成的虚假的实体。假的依然是假的，甚至比不过记忆中模糊的形体。男人将她们通过小型发射器放逐到太空中。故事的结局令人唏嘘：把录音带投入到Solaris星球，搅乱了星球对于人类思维的识别，最终了结了这种种离奇事件。这个故事对我的吸引力在于，如果是你，你能强大到拒绝她们吗？我时时怀疑。因为记忆中的美好的身影早已将自己迷惑。或许，我会选择永远生活在那里。我喜欢这个能直面人性真实的星球，它抚慰时间箭头带给我们的损伤。四十年过去了，她还在，还是那样年轻，风姿绰约。这样的美丽你如何拒绝? 我觉得苏联电影的好处是特别的粗糙所指向的极度的真实，影片之初对于暴雨前的深林的拍摄令人无限忧郁。\n媒介技术学派是一个充满个性的群体，然而这也许并非一个准确的称谓 。或许更恰当的称谓仍是多伦多学派，以英尼斯，麦克卢汉等人为代表，其著作分析媒介与文明的关系，媒介技术对于文化和社会的影响。本文无意分析、辨明其思想脉络，只想在这个专刊里，从其源头走向、并走出其中一个集大成者：麦克卢汉。\n##呓语：技术与疆界\n麦克卢汉如同一个呓语者，他的文笔过于随意，远远非学派开创者英尼斯之历史视角和细致有力的分析。伴随着那个思想涌动的时代，这个伴随着邻邦实证主义发展起来的分析视角到了麦克卢汉这里，怵然开始转折：文笔之大胆生动，远远超出了想象。“地球村”早成现实，“媒介即信息”也被广泛印证，“媒介即按摩”也可以自圆其说，然而总是透着一种不够严谨的感觉。麦克卢汉对语言的随意应用，使他的思想因其看似荒诞而广泛流传。麦克卢汉像一个高高的奇形怪状的灯塔，立在传播学的海洋边上。若问一个其他学科中的人对于传播学大师们的认识，恐怕无人能出麦克卢汉之右。\n技术毫无疑问在不断深入地形塑着传播学，拓展着传播学的疆界，在mass media出现之初，人类传播行为只限于人际传播和群体传播。然而从印刷技术，造纸技术开始，书、报、杂志、广播，电视开始勾勒出传播学的疆界。在过去的二十多年里，这个疆界因互联网之产生，而变得无远弗至。\n然而，或许，这只是传播学疆界扩展的开始阶段。一个更为大胆的设想是：宇宙传播学。在我所接触到的不多的科幻小说里 ，这种想法已经开始变得不那么流于空想。\n##幻想：传播即死亡 在这里要聊的是刘慈欣的《三体》三部曲。我是先读第二部黑暗森林，然后读第三部 死神永生，最后读了第一部《地球往事》。三体三部曲汪洋恣肆，想象力异常丰富。一开始就被认为是开创了所谓“宇宙社会学”，因为大刘构造了“黑暗森林”的假说。这个假说所处理的是地球与外星球文明的关系，在《三体》三部曲中就是名为三体的这个星球。\n宇宙的文明发展并非均衡的，三体文明超越了地球文明，然而，三体人的人际传播方式完全不同于地球文明。三体人之间可以完全读出对方内心，不需要经过言语的交流和表达。这使得三体文明出现了一种更加简洁的社会构造。然而，单纯的三体文明内部发展的故事并不足为奇，故事的巧妙之处仍在于地球文明和三体文明的冲突。刘慈欣将宇宙间文明互动的规则总结为“黑暗森林”假说：宇宙如同一个黑暗而庞大的森林，文明分布稀疏（这符合一个称之为“费米悖论”的解释，费米说：如果存在外星文明，它们也该出现了。它们一直未出现。因此并不存在这个外星文明。） ，每一个文明都像一个在黑暗森林里跋涉的猎人，手执猎枪，当他发现一个外星文明的时候，因为无法判别对方的善意，因此最好的方法是消灭这个被发现的文明。这就是一个信息博弈的悖论。\n《三体①》的主旋律是失望和复仇，女主角的父亲在文革中被打死，她因缘巧合卷入一个军事计划，却通过太阳作为信息放大器向宇宙发射了关于地球的信息。三体人收到信息，制造出智子，人类陷入科学封锁的困境。《三体②》的主体是被分隔的爱情。为了对抗三体人的科学封锁和信息监控，地球联盟选择了五个面壁者。其中的逻辑是一个令人敬畏的思考者，作为一个面壁者，他有着自己对于情感的追求。 在一个幽静的欧洲密林深处，他守候着自己的爱人，过着最为普通的生活。读到这些美丽的文字，我都在想，何必要有责任，眼前的红袖添香、西窗剪烛不是人生最大的快乐吗？但是，逻辑依然是逻辑，为了肩负的面壁者的使命，以及妻子和孩子的安全，只好选择了和她们分开。《三体③》最为浪漫，一个男人在去世之前送给一个女人一个星球。之后这个男人的大脑被送往三体人。他的基因被复原，并在三体人的领地生活。潜伏其中的他跟女主角有了一次接触，传递了画中人以维度杀人的秘密。\n仔细辨明这些黑暗森林假说和其信息博弈的过程，我们会发现，悖论来源于宇宙文明之间的传播障碍。这种传播障碍在危机来临的时候，超越了文明内的传播障碍 。对此，在三体中所描述的危机纪元有充分的描述：一个恐怖组织的精神领袖，在地球面临外星球文明威胁的时候，变得土崩瓦解。曾经组织内部铁血的斗争意志，在全人类面临危机的时候被消解。而内部的传播机制决定了一切的游戏规则。比如，女主角叶文洁向宇宙发出了地球的信息，被三体人所截获，暴露了地球文明的位置，引来了三体文明的入侵。地球文明对于宇宙文明的广播行为，或者说对话行为招来杀身之祸。然而罗辑巧妙地利用向宇宙中广播三体星球的位置的做法，使得地球转危为安。全书中如果描绘了一种“宇宙传播学”的话，那么，在刘慈欣眼里，显然是“传播即死亡”。\n宇宙文明之间的传播行为是一个囚徒困境，走不出来。一旦经由广播等传播行为而暴露，就以为着文明的消亡。这是一种富有张力的图景。但透着文明间对话困境的思索。用禅语说，就是“不可说”。 ##宇宙传播学：宇宙传播技术的诞生 然而，当死亡的阴影笼罩整个宇宙之后，文明方可真正经由死亡走向永生：废弃理性主导的荒诞，由杀戮走向合作。三体三最后描述了维度之剑下宇宙文明损失殆尽，小的文明火种经由构造狭小的宇宙空间而得存留。然而这种存留的代价是抢夺宇宙的物质。痛定思痛的宇宙各文明最终放弃苟延残喘，将物质归还宇宙，期待宇宙文明的重新孕育和诞生。\n刘慈欣在书中略微调侃人类的传播媒介，在所有的传播媒介中，只有石刻最能经受岁月的摧残。而电子设备与之相比，其储存的期限远远不可比拟。\n很显然刘慈欣是一个传播学视角下的悲观主义者，然而，人类文明已经不止一次向其它宇宙文明“表达”自身的存在和存在的善意。很显然，如果费米悖论正确，那么人类是宇宙的孤家寡人，如果错误，人类在自取死亡。唯一可抱希望的是，是否有一种宇宙语言诞生，让宇宙文明可以对话 。对此，建造圣经中的巴别塔是有必要的。上帝为防止人类合作建造巴别塔，而使人类说不同语言，失去交流的可能，而终结了不同语言的种族间合作的可能。\n回到媒介技术学派的思路：是否可能有一种宇宙传播技术的诞生，使得宇宙文明之间可以在一个没有猜疑的语义空间里对话？\n","date":1311033600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1311033600,"objectID":"fad373b44597fa8d19cb04e84864e64a","permalink":"https://chengjunwang.com/zh/archive/2011-07-09-universal-communication.zh/","publishdate":"2011-07-19T00:00:00Z","relpermalink":"/zh/archive/2011-07-09-universal-communication.zh/","section":"zh","summary":"","tags":null,"title":"呓语与幻想：传播学疆界的扩张","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n——读《治史三书》\n黠之大者\n史学的视野对于媒介研究具有重要意义。互联网时代之历史观照更是非常重要。时代变革对于社会中智识分子的考验往往首先是观察视角的转变。\n二十世纪六十年代社会科学实证研究狂飙突进，拉杂斯菲尔德开创性的将panel study运用到媒介效果研究中来，时间的维度成为因果判定的重要依据。然而，即使如此，依然忽略了大的历史背景。拉氏的同事怀特-米尔斯反戈一击，历史社会学开始盛行。互联网时代同样提出了新的时代问题：如何运用和分析网络时代的海量数据。这当然是一个见仁见智的问题，远不是个人努力和方法洞见多能解决。在这种转折的时刻，思考史学对于媒介研究的启发不无助益。\n本文是作者上李金铨博士在香港城市大学所开的课程的所做之阅读笔记，李金铨老师极为推崇严耕望先生研究历史的视角和方法。严耕望（1916-1996）先生生逢乱世，而潜心治学，体现了一个史家的坚韧。《治史三书》上两篇谈治史经验，后一篇述人生际遇。两相匹对，可窥见其一生治学得失的深刻思考。抛书沉思，可悟社会科学知识的增长。\n史学是一门通观古今的学科，西学东渐，西方社会科学的套路逐渐与东方的治学传统相互交融。虽有方法之差异，然于追求历史知识的增长方面则有更多共同点。历史有着自身独特的优势与劣势，优势在于煌煌五千年，积累了大量的有价值的研究问题，且国人重历史记录，积累了大量的历史资料（朝代通史，县志乡约，个人札记），因而历史学有充足的研究数据。但是面对这些“历史现实”如何才能从纷繁复杂、真假难辨的史料中悟出其规律，洞见其真假，则是一个超越了平常人认识能力的问题。 互联网时代的对于网民行为的记录已经积累了超过20多年，瞬间所为，即可与过往相比对。虽然很短，但对于只重视截面数据的研究而言，已经是一个很大的机遇。\n史家之所为：读史，做札记，收集史料，然后以以线索连而贯之。其过程很类似康德所言之科学知识的增长：个人为自然立法。以先天综合观念统合历史资料，务求其融洽自如，殊非常人所为。因为社会科学面对的是一个复杂的过程，超越了简单的决定论的视野。康德之言颇有洞见，社会科学知识的增长首先是研究者自身修为的增长，自身修为不增长，妄图将人类之理智投射到社会规律上去，只能适得其反。媒介研究于理论构建方面往往广泛吸收，然而仍缺乏系统性。如何洞见传播现象之下隐藏的规律，莫非有充分的积累，实在是难以把握。\n严耕望先生讲专精通博的问题，很像中国武侠里之修习上乘内功的过程。需要付出长期而且艰苦的努力。初闻觉不适合于我辈之快节奏，三年博士教育，做的却是社会科学的训练，本是需要一个漫长艰辛的读书、做笔记、做调查的体悟过程，却被压缩成一个一个deadline之前的追赶。然而每个人都如此，何以见高下？短期之中，的确是难见高下的。一个人可以选择一个讨巧的题目和方法，精读几篇文章，少选几门课，也可以相对轻松，然而如果以十年之期衡量，比较一个读书做笔记、勤思考、每天写东西的人，和一个仓皇应对的人，再思严耕望先生之言方觉良药苦口，实在是看上去慢，其实很快的捷径。\n然而本书作为大家之言，其中有很多大胆的见解。例如耕望先生说集中精力做面的研究，不要做点的究。目标要大些，范围要大些，大问题里有许多小问题。这是很关键的，因为如果你的研究没有足够的研究意义（significance），纵然做的再精致，再深入，再举一反三，都很不值得。反面的例子是史学大家、旷世奇才的陈寅恪先生晚年所著述之《柳如是别传》。陈寅恪先生中年体弱，老年目盲，然而以毕生心血写就七十万言的《柳如是别传》，考究精密，令人赞叹。然而耕望先生评此书“虽极见才学”却“影响作用不会太大。”因而发出感悟“何不尚太史公转悲愤为力量，选取一个重大题目，一抒长才。”转思诸己，媒介研究本就显狭隘，若再略去政治和历史的场景，其研究的很难被评价为重大研究。圣经云上帝告诫人类说“你们要进窄门”。一个年轻学者用这句话反思自我做研究太追新潮，每次都不能将问题说透，反倒不如从一个小问题出发，然而却能跟许多有重大意义的问题对话。这不失为一种智慧的策略，媒介研究也要一小见大，把小的问题说透彻，跟大的理论对话。\n研究要无孔不入，有缝必弥。年轻人做论文，多容易宽容自己的缺点和错误。而无追求完美、严格要求的心性。于是一片文章做好投出去之后，就收到大量的意见，诸多地方需要修改。改完了仍无法发表，原来有一个小地方无法自圆其说，于是论文被拒。再去看大家的务求完美，严格要求，便多了很多理解。\n耕望先生说社会科学理论只是历史研究的辅助工具，不能以运用理论为主导方法。这个看起来也是极大胆的说法。社会科学本是追求建构理论的，单纯的运用理论的确不能成为主导方法，然而如果理论只是辅助工具，那么主要工具是什么呢？换言之，是相信既有理论，还是相信史实（数据）。原来耕望先生认为理论是演绎的路数，而历史研究更多要依赖归纳的方法去求得新结论。所以，有理论并不一定好，没有理论一定不好，且一定要发展新理论，找到新的概念。另外，耕望先生谈及这个问题的背景是针对单纯用决定论的唯物史观推论历史的问题。但不管怎么说这个对于年轻学者是很有启发的。理论是最重要的，但不是保守既有理论，而是说发展新的理论。当理论与数据不合时，理论是应当被质疑的，所以不应唯理论，而应重发展理论。尽信书不如无书，唯理论或许还不如接受纷乱的史实（数据）。同样的思路，耕望先生提醒我们研究历史不要从哲学入手，以免犯先入为主的错误。\n每一个研究者都是在从不同的视角下出发，进而丰富我们对于社会事实的认识。耕望先生总结了自己的两个兴趣政治制度和历史地理。这很像米尔斯所言之社会学的想象力，向社会学加入历史视角。同样做历史研究的也要增加新的视角。因而，可以想象这种对于新视角的掌控运用能力，是区分学科发展阶段的重要依据。Live and let live. 物理学和信息科学的视角同样有益于媒介分析和传播研究。引入统计物理的视角研究传播网络同样是有裨益的。在过去的五十年里，传播学广泛的引入了政治学、社会学、心理学、历史学、经济学多种理论视角，我们这些年轻人也将见证未来五十年传播学的发展。未来的传播学研究的主导视角是什么，这实在是一个猜不透的问题。\n其余各章述及诸多学者修养和个人经历的经验教训，一代学人的洞见饱含各种启发。我们这些年轻人看严耕望先生谈做研究的史识之培养（理论洞见），考据之修习（历史现实，数据），于我们这些数字时代的观察者而言，颇有助益。\n","date":1305417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1305417600,"objectID":"1730386bbadcc5a626b231f202d4ad17","permalink":"https://chengjunwang.com/zh/archive/2011-05-15-historical-insights.zh/","publishdate":"2011-05-15T00:00:00Z","relpermalink":"/zh/archive/2011-05-15-historical-insights.zh/","section":"zh","summary":"","tags":null,"title":"通识与考据：论社会科学知识的如何增长 ","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n黠之大者\nFBI在千禧年逮捕了一个加拿大少年黑客，他用不起眼的电脑当“弹弓”，打败了信息时代的巨人“歌利亚”，使一些网站因不断收到“好的，我听见了”而瘫痪；基督教的成功归功于一个保守而虔诚的犹太人：保罗。保罗最初反对基督教，后来却变为一个虔诚的基督徒。因为他对神学的熟悉和对社会网络的控制能力，基督教开始广为传播。保罗和黑客少年成功的关键隐藏在网络的结构和运行的拓扑结构中，也隐藏在他们操作网络的能力上。魔鬼就隐藏在“结构”之中，然而关于网络社会的研究长久以来被既有的科学框架的简化论所束缚。图或网络具有自身的属性，这种属性隐藏在它们自身的结构中，可以限制或增强我们使用网络的能力。尤其是在我们尚无法把握各种复杂网络的结构之前，理解网络结构就成了认识周围复杂世界的关键。\n《链接：网络新科学》一书作者艾伯特-拉斯洛•巴拉巴西（Barabási）是美国圣母院大学教授，致力于对于复杂网络的研究：找到下一场科学革命——网络新科学的奥秘。巴拉巴西和阿尔伯特、郑浩雄一起在1998年开始了对网络的研究，一年后在《科学》上发表了关于无标度网络的论文，掀起网络科学研究的新浪潮。诚如两千年前希腊哲学家引导我们“认识你自己”一样，《链接》一书引导我们认识世界的网络结构。\n##随机宇宙\n人类对于网络的认识最初源于规则网。例如哥斯堡七桥问题，一个四个点七个边的图，图上带有奇数边的点，不是行程的起点，就是终点。如果一个图中有两个以上这样的点，就不存在一次遍历七桥的路线。在哥斯堡图上，有4个这样的点，因而无法找到所需的路线。\n用规则网作为复杂网络的理想型显然存在不足。人类智识群体由规则网滑到另一个极端：随机网络。Eros和Renyi认为自然界所能提供的最简单解答：随机连接节点。他们得出结论，创造网络最简单的办法是掷骰子。规则网络图的特别之处就在于每个节点都有恰好同样书里那个的链接。而在随机网络图中，根本不存在这样的规则性。随机网络模型的柱状图遵循Poisson distribution，其分布有一个显著的峰值，表明大多数节点的平均链接数都是一样的。在峰值的两边，分布迅速下降，与平均值相差较大的值极为少见。这就是广为所知的ER模型（Eros-Renyi模型，下文简称为“ER模型”）。\n然而，如爱因斯坦却倾向于相反的观点：对于宇宙，上帝不喜欢掷骰子。社会网络极其复杂，没有任何成员能够游离在外，其中的每个节点都能被访问到，因此，世界上不存在完全和外部世界隔绝的孤岛。\n##六度分隔的小世界 郑浩雄创建了一个简单的网络爬虫，让它下载文件，查找文件中的所有链接，然后按照这些链接访问并下载指向的文档。就这样自动进行下去，直到得到所有关联的页面。用它获得网络的完整地图。首先，该机器人访问圣母院大学网站域名下的所有300000份文档，绘制出地图。我们只是关心网页上的链接，它们告诉我们如何从一个页面跳转到另一个页面。结果发现随着链接的增加，节点间的距离会骤然变小。巨大的网络变小了，造成了我们周围一个又一个网络的小小世界。 大量的社会链接能够将无比巨大的网络也缩小成小小世界。例如Renyi比Eros小7岁，但是在布达佩斯的时候，他们的父母早就有交往，因而两人得以结识。\n中心节点和连接者所造成的群集现象是ER模型的随机世界观的第一个裂隙。瓦茨和斯托加茨发现了一个惊人的特点：即使只是添加少数几个链接，就能把所有节点之间的平均间隔大大降低，这少数几个节点却不会改变网络的群集系数。\n规模不是演员网络最重要的因素，虽然三级片明星饰演过的影片数量惊人，但是他们没能靠近好莱坞的中心。网络真正的中心留给了在多个大型集群里都有自己的位置的节点。对于演员网络，这种节点就是饰演过多种类型影片的演员；根据美国电话电报公司的一项研究，一小部分电话号码打出或接听了极大量的电话，这主要包括电话销售公司和客户服务电话等；生态学家认为，食物链的中心节点就是其中的关键物种，该物种对于保持生态系统的稳定居功至伟。\n对于社会，这种节点就是那种和各个领域的人都有交往的人。万维网的拓扑结构具有高度的不均衡现象。对于万维网，这种节点不但提供独特的链接，而且提供各种不同类型链接的网站。 中心节点的确很特殊，在任何存在中心节点的网络中，它们都对网络结构起到关键作用，使该网络呈现小世界的特点。联结者现象（具有大量链接节点的存在）是对ER模型和watts和stogazt模型的致命打击，我们必须完全抛弃随机世界观。\n以上都是网络新科学的关于小世界网络的研究，但这种研究在社会科学中很早就有涉及。20世纪60年代，耶鲁大学的社会心理学家米尔格兰姆(Stanley Milgram)就设计了一个实验。他将一套信件随机发送给居住在内布拉斯加州奥马哈的160个人，信中放了一个波士顿股票经纪人的名字，信中要求每个收信人将这套信寄给自己认为是比较接近那个股票经纪人的朋友。朋友收信后照此办理。最终，大部分信在经过五、六个步骤后都抵达了该股票经纪人。于是米尔格兰姆提出六度分隔理论。然而，类似其它传统的社会网络研究，六度分隔理论仍然缺乏“可计算性”，网络新科学的研究深化了这些关于网络结构的认识，使得洞见具有了可证伪性。\n##幂律分布中的标度 通常各种社会现象都符合或者可以转化为正态分布，进而使用大数定律和中心极限定理为基础的统计方法，采用最小二乘法或者最大似然估计方法进行分析，正态分布的特点是其数学分布较为均匀，以人的身高为例，绝大多数正常的成年人都在一个稳定的范围内，即使存在高度如姚明的“小巨人”或者身高有限的侏儒，但并不存在真正的身高超过3米的巨人和身高小于5厘米的“米粒姑娘”。在分析符合正态分布的社会现象的时候，我们往往可以采用平均数（或众数）来测度群体的基本情况，在一个固定的分布中，总有一种处于理想状态的“平均人”或“常人”存在着，他代表着该群体的平均状况。\n如幂律分布（以经济学中的帕累托定律和语言学中的zipf律为代表）所揭示的，存在着诸多的社会现象不符合正态分布的状况，而幂律分布往往很难转化为正态分布来处理。在符合幂律分布的社会现象中存在真正的巨人，他们所占有的资源远远超过其他人所占有的资源的总和，恰如帕累托定律所揭示的，也许20%的人占有了整个社会的80%的财富，同样，可能仅仅是20%的人为整个社会贡献了80%的财富。做了20年铁路工程师的帕累托如此钟爱物理学中的数学之美，为了使经济学变成物理学一样严谨的科学，写成《普通社会学纲要》。他发现20%的豆荚结了80%的豆子，20%的人占有了80%土地，（后来发展成为墨菲管理定律，20%的员工创造了80%的利润），这就是帕累托分布的起源。1932年，哈佛大学的语言学专家Zipf在研究英文单词出现的频率时，发现如果把单词出现的频率按由大到小的顺序排列，则每个单词出现的频率与它的名次的常数次幂存在简单的反比关系，这种关系就称为Zipf定律。\nBarabási在其1999年发表在《科学》杂志上的一篇著名的论文《随机网络中尺度的涌现》一文中指出如基因网络和互联网这样具有复杂拓扑结构的网络中节点之间的联系符合一种普遍的无尺度的幂率分布。他认为这是由于两个原因造成的，一方面，新的节点持续不断地加入；另一方面，新的节点偏好选择那些已经具有良好连通性的网络。这篇论文引起巨大轰动，此后从这一角度出发，学界将之应用自然科学以外的到各个领域，其中不乏运用复杂网络的方法分析人类传播行为的研究出现。\n幂律分布的最突出特点，不仅是其中有许多小事件，而且是许多小事件伴随着少数极大的事件。这种超乎寻常的大事件是不可能存在于钟形曲线内的。在这分布图的末端，幂律分布和钟形分布也存在重要的性质差异，钟形曲线末端呈指数递减，递减速度比幂律分布曲线大。出现这种呈指数级递减的末端，原因在于钟形曲线上缺乏中心节点。相比之下，幂律分布曲线递减速度较慢，允许罕见事件如中心节点的存在。\n在随机网络中，分布的峰值意味着大多数节点的链接数量都相当，偏离此数值的节点极其少见。因此，随机网络的节点连通性具有自身的尺度特征，这种特征由普通节点体现出来，并受等级分布峰值的限制；而在幂律分布中，缺乏峰值，这说明在真实网络中，不存在带有随便性的典型节点，我们看到的是连续的有等级特征的节点，从罕见的中心节点到无数小节点一级一级分布开来。最大的中心节点后面紧跟着两三个较小的中心节点，然后是十几个更小的节点，以此类推，直到最后无数小节点。\n在互联网中发现幂律的存在，不仅使我们吃惊，还迫使我们承认中心节点确实存在。缓慢降低的幂律分布很自然地能和高度链接的异常节点结合起来，它预言每个无尺度网络都会有几个大的中心节点确定网络的拓扑结构。该拓扑结构决定了真实网络的结构稳定性、动态行为、稳健性（robustness）、容错性以及承受攻击的能力。\n##阿基里斯的脚踵 1965年美国东北部大停电，凸显了人造复杂网络的一个问题：由连通性所导致的脆弱性。大停电事故是一个典型的级联故障；经济领域经常出现级联故障，如1997年亚洲金融危机；互联网也存在路由器破坏造成的级联故障，重新发送的信息进一步加剧网络拥挤。与之不同，尤卡坦陨星撞击灭绝了成千上万物种，其中就包括恐龙，但整个生态系统显示出人造系统所不具备的容错性。1911年禁止猎捕海獭，海獭物种迅速恢复，海胆减少，海藻增多，为海洋鱼类提供了食物，避免了加州海滩的退化，保护好一个处于中心节点的物种，就极大地改变了海岸的生态。\n这种容错性是通过高度互联的复杂网络保证的。 Shlomo Havlin等发现对于无尺度网络来说，如果次数幂小于等于3，这一阈值就不存在。而绝大多数无尺度网络，无论是互联网还是细胞，都是无尺度的，而且其次数幂都小于3。因此，这些网络只有当所有节点被移除后才会崩溃。但实际上，删除多个节点后，造成的破坏就开始明显显现出来，进一步删除更多中心节点，就目睹了网络的大崩溃，把互联网分割成了细小的互相隔绝的碎片。破坏少数几个中心节点，一个无尺度网络就能立即瘫痪。\n我们发现网络的崩溃不是渐进的过程，随机网络存在一个错误临界阈值，只随机删除几个节点对网络的整体性影响不大，直到超过这一阈值才会崩溃；但互联网络却拒绝崩溃，证明了互联网络和人类的其它系统不同，它具有高度的稳健性。偶尔删除一个中心节点也不会带来致命的危害，其它的按等级分布的中心节点依然维持着网络的整体性。\n无尺度网络结构中隐藏着人们未曾料到的阿基里斯的脚踵。邓肯-瓦茨证明删除的节点的连通性越高，就越有可能使整个系统瘫痪。其面对故障的稳健性和面临针对中心节点的攻击的脆弱性是共存的。针对中心节点的攻击可以使网络迅速崩溃。如细胞的蛋白质网络，在发生随机突变的情况下不会崩溃，但某种药物或疾病关闭了编码生成连通性最强的蛋白质的基因，细胞就无法生存了；针对中心节点进行攻击的菲律宾爱虫电脑病毒（Love bug）可以在几小时之内传遍全世界，造成全球互联网崩溃。　判断性网络是无尺度的，还是随机的，我们无需完整的性网络地图，我们只需检测这个网络的等级分布。Liljeros证明了性网络的无尺度特征，艾滋病病毒的传播网络的无尺度拓扑特征使这一病毒会不断传播，难以消亡。被治疗的中心节点越多，该传染病的阈值越高，这一病毒消亡的可能性越高。即便是我们无法找到所有的中心节点，但只要朝偏向高连通度的节点的这个方向去做，就能降低疾病传播的速率。\n《圣经》中描述了大卫与巨人歌利亚之间的战斗，大卫，取出弹弓，借助上帝的帮助轻而易举地将巨人歌利亚杀死。歌利亚的死去使得敌军土崩瓦解，大卫一战成名。庞大的互联网中心节点也如同歌利亚一般，异常强大，它们带领着一个无标度的网路大军，所到之处，无往不胜。面对如洪水猛兽般的网络大军，黑客们只需要寻找中心节点，取其上将首级。当这些少数的巨人歌利亚倒下之后，网络大军就走到了崩溃的边缘。\n##网络地图 米尔格兰姆的实验对象根本就不知道联系到目标对象的最短路径。即使手头有指南针，而且知道出口大体上是在北方，想找出出口也会耗费大量的事件，而且我们的行动效率也会很低，相反，如果手头有迷宫地图，不出5分钟，我们就能走出来；大多数疾病，并不是由特定的某一个疾病基因引起的，多基因通过隐藏在细胞中的复杂网络相互作用。后基因组计划即绘制细胞内部的网络地图，有了生命之书，我们现在需要的是生命地图。\n社会网络、蛋白质网络等大多数网络是无向的，万维网和食物链是有方向的。有向性使万维网成为一个非均匀网络。\n万维网被分隔成3个主要的大陆:IN大陆、中央大陆、OUT大陆、从IN大陆到OUT大陆的管道、IN大陆和OUT大陆上的触须、孤岛。互联网呈现碎片状的特征，孤岛和IN大陆部分处于隔离状态，无论网络机器人多么努力也找不到那上面的文档。无论网络是随机的还是无尺度的，只要链接是有向的，就会存在3个大陆，3个大陆并不是仅有的分隔，仔细观察还会发现大陆会进一步分为很小的村庄和大城市。\n现在我们开始把细胞看作似乎一个整体，即作为一个网络，而不是一袋子独立的化学物质。例如，过去认为控制癌症的p53基因远没有想象的那么大力量，摆脱对p53细胞周期调控因子的迷信，而关注p53网络，这使我们看到另一条道路：首先需要破译网络地图的拓扑结构，找到修复p53细胞周期调控因子功能的药物。\n##互联网的觉醒：自组织和适应性 我们先遮盖细节，只观察节点和链接；完成这一步之后，我们必须跨越拓扑结构，关注链接上的动能，弄清楚节点和节点之间的动力学机制。\n幂律的存在，将复杂网络从ER模型的随机性的丛林里拯救出来，将其放在色彩斑斓的，充满了丰富理论营养的自组织的舞台的中心。1965年，Leo Kadanoff突然意识到：在临界点附近，我们就不能再把原子当成独立的粒子看待，而应该把它们看作是属于一个个社区，共同行动的群体。可以把原子看作是装在一个个盒子里，每个盒子里的原子都有同样的行为方式。Kenneth Wilson的重正化理论证明了每当无序变成有序的临界点，即由混沌到有序的临界点的时候都会发现幂律的存在，他给相变理论的金字塔添上了顶端的最后一块石头，并于1982年获得诺贝尔物理学奖。一旦系统被迫发生相变，一切随之改变，继而出现幂律。相变理论表明了从混沌到有序的过程受到自组织的影响。爱因斯坦对印度不知名的物理学者玻色论文，并在其基础上写成论文《单原子气体量子论》。爱因斯坦预测，如果全部的粒子足够冷却，粒子中的一大部分会安顿在最低的能量点上，他们会形成新的形态，称作“玻色-爱因斯坦凝聚”。直到1995年才被证明，“玻色-爱因斯坦凝聚”成了物理学家的标准工具箱。\n我们遇到一个问题，幂律的存在是否意味着网络是从无序到有序的相变的产物？答案是网络并不处于由随机到有序的道路上，它们也不处于随机性和混沌的边缘，无尺度拓扑结构表明网络的形成源于自组织原则的作用，不管网络多大、多复杂，只要存在优先原则和增长因素，它就会保持中心节点和无尺度拓扑结构。\n在某些网络中胜者通吃，会获得所有链接，因而带有明显的“玻色-爱因斯坦凝聚”特征。但胜者通吃网络并不是无尺度的，这种网络只有一个中心节点和多个微型节点。而无尺度网络中，节点带有明显的等级分布。胜者通吃行为会破坏无尺度拓扑结构中中心节点的等级分布，使其变成星状网络，如微软公司。节点永远为了为获得联系而竞争，因为在相互联系的世界中，连接数量就代表了生存能力。公司争夺客户、演员争夺角色、普通人找你过多的社会链接。 与胜者通吃的星状网络相比，无尺度网络是一个适应性网络。\n自组织网络具有的适应性和对内部故障的容忍度是其天然优势，基地组织是一个没有蜘蛛的网络，没有变成中央集权的网络，没有军队和企业所采用的属性结构，它发展成为一个自组织的网络，网络中的等级化的中心节点使组织联系在一起。因此，即使去除了拉登和他最亲近的亲信，也可能无法根除它带来的威胁。我们最大的敌人，可能是对这种新秩序不熟悉，而且缺乏有效的语言来表述我们的经历。针对基地组织的战斗，其手段可能是尽可能多的去除网络中的中心节点；然而是基地组织崩溃并不能终结这场战争，只有充分消除其自组织的法则——伊斯兰好战分子的愤怒——才能根除恐怖分子节点建立链接的需求和渴望。\n你知道字母a存储在大脑的哪个位置吗？自组织结构也不知道答案从哪里来的。 我们无法预言网络何时会具有自我意识，但显然它已经有了自己的生命，它在不断成长，不断演化。《黑客帝国》描绘了全球互联网具有智能后的图景，也许这并不仅仅是想象。或许有一天，互联网会觉醒。\n","date":1299715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1299715200,"objectID":"757f6db0b617d48bac664b0b21f011a4","permalink":"https://chengjunwang.com/zh/archive/2011-03-10-network-giant.zh/","publishdate":"2011-03-10T00:00:00Z","relpermalink":"/zh/archive/2011-03-10-network-giant.zh/","section":"zh","summary":"","tags":null,"title":"遭遇巨人歌利亚——读《链接：网络新科学》","type":"zh"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n本文是作者从技术和资本角度对于SNS浪潮的反思。其中部分内容取自作者硕士毕业论文，虽然名为《正在爆发的互联网革命》一书的读书笔记，但并不限于此。\n黠之大者\n“部落化——非部落化——重新部落化的三段论,是麦克卢汉的一个天才般的预言。人们曾经在部落化时代，面对面地进行口耳交流，而网络科技的发展虽然使在人们之间架起了信息的高速公路，却也把人类锁进了各自的“盒子”。地球变成了“地球村”，但村里的人却很少出门抛头露面，甚至不知道隔壁住的是男是女或者只是一条狗,亲近的信息距离与遥远的心理距离使网络社会进入令人尴尬的状态。社会性网络服务（SNS）的出现使人类在重新部落化的过程中，找回了村里的亲近感,回到了个人对个人真实交往的形态，这也显示出了人们对于回归真实人际交流的内在需求与渴望。（陈卉，2009）”\n这是一个对于互联网时代的网络社会交往的形象而生动的描述，表现了SNS在网络社会交往中的独特意义：相比于个人在社区生活“鸡犬相闻、老死不相往来”式的落寞，行动者个体在SNS上则表现出了超常的热情，加好友、写日志、发照片、更新状态、种菜偷菜，忙得不亦乐乎，很多人的SNS门户终日熙熙攘攘，一派繁忙景象，似乎真得通过网络实现了部落化，回归到奉行“差序格局”的传统村落。\nSNS 全称Social Networking Site，即社交网站，是基于六度空间理论下的典型媒介形态。随着互联网技术的进一步成熟，社交网站（SNS）迅速发展，继Facebook之后，其它SNS网站迅猛发展，2008年SNS的另一典型代表微博客twitter迅猛扩张。在中国以校内网和开心网为代表的SNS网站同样发展迅速，以校内网（www.xiaonei.com）为例，其实名制注册用户数1500多万，活跃用户高达880多万。\n技术与形式：SNS的流变 SNS的发展从1997年开始，SIX DEGREE网站创立，依靠站内信促成好友关系的形成，但由于其概念过于超前，未能获得广发扩散，于2000年被迫出售。随后出现一系列SNS网站，但未能掀起全球范围内的SNS“浪潮”，直到2003年3月Friendster.com诞生。Friendster.com获得极大成功，依然延续六度分割理论，使用率低，用户黏性弱，2004年因为访问量过大，服务器过载，导致用户流失。\nMyspace2003年7月在美国创立，是一个开放的交友网站，在2004年到2006年之间经历了高速增长期，允许用户以独特的页面和音乐展示自我，结交朋友和吸引异性，是一个基于兴趣为中心建立的SNS网站，但因陌生人的交友模式缺乏黏性，当用户的好奇心过去之后，就失去了吸引力。2008年6月，被Facebook所超越。\nFacebook创建于2004年2月，创建者为哈佛大学心理系的学生马克-扎克伯格（Mark Zuckberg），类似比尔-盖茨，他同样19岁辍学，开始创业，该网站的成功被认为是因为定位得当，致力于为主流用户群体为现实社会生活提供辅助的网络服务，而不是创建一个完全不存在的新社区，因而其网站经营策略更加务实，与Youtube等视频分享网站和Twitter等微博客的发展同步，SNS的发展进入到另外一个高潮。\nSNS发展过程可概括为：“早期概念化——SixDegrees代表的初探六度分隔理论阶段；结交陌生人——Friendster帮用户建立弱关系从而带来社会化实践价值的阶段；娱乐社交化——MySpace创造的丰富多媒体个性化空间吸引年轻人注意力的阶段；真实社交化——Facebook帮助用户将线下真实人际网络搬到线上，实现现实世界之外的社交阶段。”\n国外SNS的发展路径如下图所示：\n图 1 国外主要SNS网站的创建时间及社区网站转型为SNS网站的时间\n中国第一批SNS网站创业者模仿Friendster.com创立了UUme.com和亿友网等网站，但类似其模仿对象，最终未能幸存。在Myspace的发展迅猛的鼓舞之下，我国诞生了51.com、UU地带、魔时网、猫扑网等SNS网站，QQ也于200年推出QQ空间；此后，中国SNS网站再次复制Facebook的成功经验，校内网、5Q校园网、占座网、易聚网等众多SNS网站先后创立，其中，校内网的发展拔得头筹，但其创立者王兴最终因为资本瓶颈被迫将其出售给千橡互动集团，后者整合猫扑网、Kaixin.com、校内网，组建了现在的“人人网”。\n继校内网之后，另外一个以真实社会生活为SNS运作基础的网站Kaixin001.com成功攫取企业内部的社会网络关系这一细分市场，获得极大成功。模仿Youtube和Twitter，国内先后出现大批视频网站和微博客，类似国外SNS市场发展之势，中国SNS的发展风起云涌。\n我国校园SNS网站是指以我国校园大学生为主要目标用户群的交友网。国内最大的校园SNS网站是成立于2005年的校内网（www.xiaonei.com），2008年其实名制注册用户数1500 多万，几乎囊括中国所有的学校，成为一个极其活跃的大学生在线社会交往的网络社区。\nSNS的内部关系 但SNS的发展并不仅仅使得重新部落化的网络社会找回了真实交往的亲切感，它还将使用者之间的关系转化为资本——社会资本——这是SNS发展的一个真正更为宏大而深远的意义。\nSNS的整体发展路径，从形式上看，经历了从概念到现实的蜕变过程，这与中国互联网整体的发展趋势是相同的，从最初的通过Email和bbs互动，互联网的网络社交经历了不同 的网络服务形式，如下图所示：\n图 2 网络社交人脉演进简史\n在这种发展过程中，关系的强度对于SNS的发展存在着重要的作用，从最初SNS追逐概念开始，经历互联网市场严酷的大浪淘沙，生存下来的SNS网站所整个的关系强度大多较强，例如51.com是一个恋爱交友类网站，其关系相对较弱，校内网只所以能发展起来，其原因正是因为整合了现实的校园同学关系，其关系相对较强，Kaixin001.com致力于发展基于公司内部同事关系的社会网络，天际网则更有针对性地为白领等职业人士设计，以满足他们商业和职业方面的需要，帮助他们更有效地建立、管理、拓展人际关系网，后二者内部的社会关系更为密切。如下图所示：\n图 3 国内SNS用户群体分布\n在这里，值得注意的是豆瓣网，倘若从SNS的发展过程来看，豆瓣的幸存不啻是一个奇迹。豆瓣是一个以读书、电影、音乐兴趣为中心建立的SNS网站，在某种程度上与Myspace类似，但通过书评和音乐、电影评论，使其内部在陌生人之间建立起牢固的关系，豆瓣群组的关系更是促进使用者基于兴趣的交流，更为重要的是豆瓣将虚拟的网络关系引入现实，豆瓣上存在着大量以城市为中心的各种线下活动，这种以兴趣为基点，从线上关系到线下关系的过渡方式，使得豆瓣获得了长足的发展。\n社会性网络服务异军突起的原因在于社会性服务网络在人际传播方面的特殊优势。进一步摆脱虚拟束缚，沟通了线上与线下关系，通过线上线下的双重接触，更好的实现人际传播的最终目的。社会性网络服务不仅帮助用户权衡网络个人空间与公共领域，找到合适的传播的边界，还有助于他们拓展人际关系，分享个人信息，实现社会穿透。\n黑天鹅：重生抑或死亡？ SNS诞生之初，没人知道它会活下来，如同就在人类文明中的个体无法想象黑天鹅的存在。困于概念与技术黑洞中的个体将失去洞察社会趋势的能力。为潮流鼓噪呐喊者必为时代所遗忘，因为当你完全卷入时，也就失去了批判的能力。\nSNS并不是一个维系强关系最为经济和有效的手段，对于大学生群体的强关系而言，主要是跟自己关系紧密的身边的同学，多为同宿舍同学，舍弃直接的人际沟通而采用SNS并非最佳选择，校内网更为重要的作用在于维系弱关系。\nSNS本身是一个受到监视的私人空间和公共空间的融合，虽然可以通过写悄悄话、校内即时聊天、站内信的方式沟通，但是这种间接的沟通并不能满足维持强关系所需要的面对面的沟通，而维持紧密关系所使用的语言往往会因为预期到的他人的监视而有所增减，正如，校内个人主页上面可以设置特别好友，但是一旦你设置的特别好友之后，就意味着你明确告诉身边其他未能被你选为特别好友的同学你们之间的关系仅仅是弱关系，这有些类似《老友记》里Chandler与Joey争夺作为Ross的伴郎。校内网作为一个使得网络社会交往关系可视化的空间，赋予了其被监视的特点，这是有别于现实的交往空间的。\n图 4 校内网使用频率与满意度之间的对应关系\n校内网服务的使用频率来看，基本上都处于较低的水平上，如图校内网服务的使用频率所示，校内网服务的使用频率得分大多低于中等水平3分。浏览他人相册和评论他人相册功能的使用频率更高；此外是回复日志和留言功能、状态和分享功能。值得注意的这两项服务的功能都在于“监测环境”——即了解好友的动态、并对好友的动态做出简短的反应，这与使用校内网的最主要的目的在于了解朋友动态、与朋友联系是完全契合的。\n与此相比，校内网在表达自我、展现自我层面上则仍处于一个相对较弱的位置，虽然用户对于上传照片功能和写日志功能相对满意，但对于上传照片功能和写日志功能的使用则较少，对此的解释当然与中国特定的文化有关系，中庸的处世之道依然影响着中国大学生的交往行为，尤其是在SNS中的“印象管理”环节。印象管理不仅仅在中国是十分重要的影响因素，Anne Hewitt等发现三分之一的使用facebook的学生反对教师使用facebook，其主要的原因是个人隐私与印象管理。\n当然，对于用户对于上传照片功能和写日志功能使用较少的原因同样与用户的自我表达和自我展现的能力密切相关，毕竟有些人不善于叙述生活中的事情，不善于表达自我的情感。对此的一个佐证是几乎所有的用户对于“校内状态”功能的满意度和使用频率都相对较高。另外一个显著的调查发现时单身者更加倾向于使用校园类型SNS，这当然是校园类型SNS的生存之道，但也开启了其覆灭之门。\n商业逻辑同样会限制网络游戏类别的SNS的发展，上班族的偷菜行为虽然可以密切同事关系，增强组织效率，但同样面临因为投入时间过多，粘性过大，而损伤资本的商业利润。流畅的网络服务和角色扮演、深度介入的SNS游戏最终会被资本挤出工作的场所。\nSNS 因为使用者开辟一个新的自我展现和个体间互动的平台而崛起，但也最终为其膨胀设下一个最重要的障碍：当所有的人都只看不写的时候，传统的SNS就成了一片死地。\n技术乐观主义无法解救资本的陷阱中的黑天鹅。SNS躁动之时，没人知道它未来是否能活下来。流变，重生，抑或死亡。唯一可以确认的是未来的SNS绝非今日之SNS。\n参考文献 陈卉. 社会性网络服务（SNS）流行原因分析[J].新闻世界.2009.05:114-115.\n郑宇钧，林琳.当校园SNS 照进现实———校内网的人际传播模式探讨[J].广东技术师范学院学报，2008（3）.\n西门柳上，马国良，刘清华.正在爆发的互联网革命[M].北京：机械工业出版社.2009:96\nDanah, M. Boyd and Nicole, B. Ellison. 2007. Social Network Sites: Definition, History, and Scholarship Journal of Computer-Mediated Communication, 13(1), article 11, 2007\n李翔昊.SNS浪潮：拥抱社会化网络的新变革[M].北京：人民邮电出版社.2010:77\n","date":1299024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1299024000,"objectID":"fe9756029086f5e0843cb10bb37de55c","permalink":"https://chengjunwang.com/zh/archive/2011-03-02-sns-as-a-bridge.zh/","publishdate":"2011-03-02T00:00:00Z","relpermalink":"/zh/archive/2011-03-02-sns-as-a-bridge.zh/","section":"zh","summary":"","tags":null,"title":"从概念到真实：SNS的形式蜕变","type":"zh"},{"authors":null,"categories":null,"content":"民国时期的土匪（Bandits in Republican China，1988）英国学者贝思飞（Phil Billingsley）历时十年的作品，令人忍俊不禁、倍感亲切的是他边照顾孩子边写作的场景，这在大仲马是根本不可能的，想来贝思飞是一个模范好男人，他试图展现土匪群体的出现与壮大对现实的合理的反应，本书是根据其博士论文为雏形完成的，可见，学术大多是积累起来的。\n毛泽东将土匪归于游民阶层，指出其类似民族资产阶级的两面性和容易动摇的特点，贝思飞则将土匪分为偶尔为匪和惯匪，并将土匪群体分为三种基本类型：单纯的匪帮、综合的匪帮、匪军。\n全书就是以土匪为核心展开的，刻画了匪与农民、军阀、地方政府、兵、绅士、外国人、革命力量之间的立体的关系。从盗足石到童林响马，占山为王的匪在中国历史上并不少见，贝思飞区分了匪帮与秘密社团，指出前者的散漫无常与后者的长期维持的不同之处。\n从白朗到老洋人，樊钟秀，到临城劫车案的孙美瑶，匪在历史上留下了并不华丽却很抢眼的印迹。但究其为匪的原因，贫穷和饥饿是最主要的原因。平原多洪水多饥荒，遂多响马；边界地带三不管，遂多盘踞为匪者。有趣的是，匪的出现和农耕的周期密切相关，农民在春天吃完余粮，高粱高长时出现，到了5月收割小麦的时候消失。\n贝思飞讲到军阀统治时说，军阀统治有一种自身无法延续的悲剧，来自上层的暴力煽动下层的暴力，军阀征丁、牲畜，影响农业生产，入伍之后没有生计之道，遂为匪。形成一个恶性循环。张作霖在吉林大量流失枪支；冯玉祥在甘肃种鸦片引起叛乱；阎锡山在山西，红抢会涌现。河南、山东、江苏、安徽四省交界处形成了土匪中心。军阀割据下的土匪王国形成了一种地缘暴力政治。\n第三章讲了河南的土匪，主要讲了白朗及其后继者老洋人的故事。第一次听说白朗这个名字是在贾平凹的商州夜话一书中，没有想到白朗如此真切的存在过。在大刘庄，在车队，为匪，壮大，迁徙，叛变。一个最成功而传奇的土匪走不出匪之为匪的生命周期。\n衣食足而知荣辱，活不下去才会逼上梁山，去过颠沛流离的生活。匪帮的组成有着内部严密的规则，遵循着残酷的民主。土匪的生活是很凄惨的，他们注重内部的等级制度，为了突出这种等级，他们往往注重服饰，形成差别，这种差别往往到可笑的地步，除了服饰之外，土匪对于女性的态度也值得思索，很多土匪是为了娶老婆才加入土匪的。因为土匪的亡命生涯和土匪的道德劣势，他们对各种言语存在着禁忌，占卜、祈祷在土匪中是很常见的。视金钱如粪土的背后是土匪的生死无常和极度贫穷。\n土匪是一种艰苦而又危险的职业。地方统治是依靠乡绅的，也就是乡土绅士，传统 的乡土中国一直存在着权力不下县的说法：在这些土匪活动的基层地区，绅士、土匪、农民就构成了一个生态系统。地方官作为一个外来人，所关系的是金钱和仕途升迁，此外，他所掌握的少数武装力量使他缺乏对抗土匪的力量。地方官吏普遍的‘始而讳盗，继而纵盗，相习成风。\n兵与匪是相互依存的关系，没有了匪，兵的灰色收入就减少了；兵并不去全力剿匪，往往与匪还存在着默契甚至交易，比如出售枪支。匪与乡绅和农民也保持着辩证的关系，匪存在的主要经济来源来自于乡绅，通过打劫乡绅，匪获得自己的生命线，但当富人消失之后，匪往往退而求其次，压榨中等富裕甚至穷苦的人。\n对于绑票的介绍是十分有意思的，匪自身经常处于行走过程中，因此他们更倾向于绑票而不是抢劫其他不易携带之物，并且经常杀死因生病等不能跟上队伍者。已婚妇女一方面因裹脚，不便行走，并非理想的绑票对象，因为严格的道德对于已婚妇女有着严格的限制；未婚妇女则往往成为绑票对象。肉票还像期货一样在市场上流转，其他匪帮可以购买另一匪帮的肉票，以期勒索更高的价格。匪在绑票方面往往不择手段，儿童也会成为重要的绑票对象。后来，外国人也成为重点绑票的对象，例如孙美瑶在山东临城的劫车案中绑架外国人跟政府谈判，名利双收。除了绑架之外，敲诈也是匪的常用伎俩。\n事实证明匪对乡土有着强烈的依附。兔子不吃窝边草，离开的当地农民的帮助，匪往往会在中央剿匪的围攻下瓦解。例如，白朗杀富济贫使自己的匪在当地受到爱戴，农民往往积极参加其队伍，并为其免费侦查，但是当白朗开始扩大地盘，四处出击之后，往往面临着被当地农民所排斥的困境，尤其是其在甘肃遭遇了回民的排斥。土匪内部也存在着类似老乡的观念，例如白朗真正信任的人只是大刘乡的同乡。这种对乡土的依附和对迁移的不适应成为白朗起义失败的重要原因。此外，土匪的报复性行为往往使农民对匪产生强烈的恐惧和不信任，与传说中的大侠或者说罗宾汉相差甚远。\n随着袁世凯之后的军阀混战，土匪作为军事力量开始成为制度化的军事力量。但是值得注意的是这些土匪的战斗力往往很差，例如冯玉祥的第二、三师面对吴佩孚和张作霖的军队落荒而败，张宗昌的军队面对北伐军毫无抵抗之力。朱德和张作霖都注意到这个问题，后者清理了自己军队中的土匪成分。\n土匪只有利益，没有立场，镇嵩军从推翻清王朝的革命转变为出兵陕西围困冯玉祥，孙美瑶在临城劫车案被招安，去镇压其他匪帮，后被害。\n匪酋中的成功者莫过于张作霖、陆荣廷、杨虎城等人了，但大多数土匪头目都在社会的下层挣扎，往往在斗争中落败身亡，即使是聪敏如樊钟秀者在依靠本土的力量发展起来之后始终无法发展壮大，左右摇摆，最终还是失败了。\n兵匪不同于土匪，他们往往来自于解散的军队，具有更强的战斗力，对当地没有土匪那样的感性，往往会更为残酷的对待农民。如老洋人，快速行动，极度破坏，绑架洋人。\n日本为了占领东北，对土匪进行了有效的利用，如扶植张作霖、策划临城劫车案，利用日本浪人小日向白朗（当时成为满洲主要的土匪领袖）化解绑架外国人的事件，使土匪从南满迁到北京，清讨土匪。\n土匪生逢其时，遭遇了辛亥革命、二次革命、大革命、抗日战争、内战，在这个过程中作为地方势力的土匪往往革命的各个力量的游说的对象，很多土匪参与到革命的过程中来，虽然他们都有自己的考虑。白朗在二次革命中支持孙中山，成为袁世凯的眼中钉。游击战的方法和土匪的策略一脉相承，土匪经过军事化改造成为军队的重要来源。在49年之后，大陆仍有大量的土匪存在，经历了几年才完全镇压。\n像大门口的陌生人、中华帝国晚期的叛乱及其敌人、乡土中国一样，土匪一书也提供了我们看待近代史的一种视角，从这个视角里，我们能看到某种一直被我们所忽略的近代史生态链中不可或缺的一部分，他们当然不是这个社会和历史进步抑或退步的决定性力量，在某种程度上，他们一直在转变自己去适应历史的变化，但大多是失败的，然而，他们的确参与了历史过程。 ","date":1294444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1294444800,"objectID":"38bbc4497eb62a07a62bd8e5b86026e7","permalink":"https://chengjunwang.com/zh/archive/2011-01-08-bandit-in-the-chinese-of-republic.zh/","publishdate":"2011-01-08T00:00:00Z","relpermalink":"/zh/archive/2011-01-08-bandit-in-the-chinese-of-republic.zh/","section":"zh","summary":"","tags":null,"title":"民国时期的土匪","type":"zh"},{"authors":null,"categories":null,"content":" 使用注意力衡量价值 test\n引言：注意力的价值 人工智能的奠基人之一，诺贝尔经济学奖获得者赫伯特.西蒙在1971年就预言，人类社会正在步入一个新的阶段，信息的增长速度将远远超过人脑可以及时处理的速度 。七八十年代以降，一系列对信息社会进一步展望的著作，包括丹尼尔.贝尔的《后工业社会的来临》（1973），托夫勒的《第三次浪潮》（1980），尼葛洛庞帝的《数字化生存》（1996），曼纽尔·卡斯特的《网络社会的崛起》（1997）对信息技术的持续发展对人类固有社会结构带来的冲击进行了更详细的讨论。知识的快速增长和人类社会可支配的集体注意力及其有限之间的矛盾。在信息流的大量冲刷下，原有的工业社会形成的层级性的权力体系将会变得扁平化，去中心化，而个体的注意力也随之趋于碎片化。\n注意力经济作为一门单独的科学已经发展起来。经济学家古德哈伯（Goldhaber）在1997年的一篇长文《注意力经济学与网络》 中明确指出，古典经济学中用于调配资源在生产和消费各部门间流通的货币，在信息时代已经被新的稀缺资源，注意力，所取代。未来社会的经济体将会以注意力生产和交易为基石，甚至会出现“注意力货币”与“注意力银行”。因此，“注意力经济学”完全有必要成为一个单独的学科。达文波特和贝克（Davenport \u0026amp; Beck）在2001年的著作《注意力经济：理解新的贸易与货币》中对古德哈伯的观念进行了拓展，具体分析了媒体广告是如何使用受众的注意力来换取现金流的，来进一步描述了注意力经济的实现形式。\n最近十年，注意力研究浪潮席卷众多领域。这些浪潮中最值得一提有路易斯.冯.安(Luis von Ahn)等人开展的“人类计算”(human computation)研究，安德烈.布劳德(Andrei Broder)等人倡导的“计算广告学”（computational advertising），以及胡伯曼（huberman）等人倡导的“注意力动力学”（attention dynamics）。冯.安主张把人和机器结合起来。具体来说，就是把大量用户看做一个通过互联网连接的并行计算系统，在终端上通过人类技能接近计算机难以解决的复杂问题。冯.安2005年创造了一个游戏，让玩家查看并标记图片从而去改善图片的搜索。2007年，他创造了reCAPTCHA 项目，让人们在输入验证码的同时，将计算机难以识别的纸质图书数字化。2011 年，他创办了 Duolingo（中文名为多邻国），使用户在学习语言的同时，也在帮助翻译互联网上的内容。安德烈.布劳德(Andrei Broder)是雅虎的资深研究科学家，他在2008年提出了“计算广告”的概念。布劳德认为计算广告的目的就是采用算法，智能地为一定情境（context）下的用户寻找最有用的与消费行为有关的信息。物理学家胡伯曼已经开始考虑如何为注意力在互联网上的流动建立动力学模型。其主要结论有（1）网络社区的集体注意力在信息资源上分布极端不均，呈现幂律分布 ；（2）注意力随时间下降非常迅速。\n注意力流动网络 我们将沿着胡伯曼等人的思路，使用数据挖掘、网络科学与数学建模的方式，借助于互联网大数据中的人类注意力流动网络（Attention Flow Network, AFN）来衡量事物的价值。数字媒体为我们提供了一个观察大规模的人类集体行为中涌现的社会运行定律的“天文望远镜”。通过收集和分析这些数据，我们可以建立用户注意力在不同的事物（社会事件、人、商品、信息内容）之间的流动，进而采用网络科学的方法计算这些事物的价值和相似性。结合推荐系统的算法，我们可以更加有效地实现商品的推荐。\n采用网络科学有利于更好地衡量事物的价值。谷歌的成功在于其PageRank算法，在PageRank算法当中，将万维网看做一个由节点和链接组成的网络，而非单个的孤立的节点。节点是一个网页，链接是由一个网页指向另一个网页的超链接（可以看成投票）。在这个网络当中，节点是同一类型的事物（例如都是网页）。如果网络当中含有两类节点的时候，就构成了二模网络，比如用户和信息可以作为两类节点存在于同一个网络当中。此时，采用Hits算法就可以计算出这两类节点各自的权威性价值和导航性价值。但是在这两类网络当中，均没有考虑用户的注意力如何在事物当中流动。\n我们提出了注意力流动网络来捕捉注意力作为货币来衡量万物价值的功能。在这个注意力流动网络当中，节点是某一个类事物（社会事件、人、商品、信息内容）。链接则表达了用户的注意力流动。采用注意力流动网络的好处是我们可以确保在单个节点上流入的注意力和流出的注意力是守恒的，如果不守恒，则通过引入一个源节点（source）和一个汇节点（sink）的方式将其配平。采用这种链接有权重、流量守恒的注意力网络，我们可以更好地衡量节点间的价值和相似性。通过计算用户随机游走从源节点到达某一个节点的平均步数，我们可以定义流距离的概念，它衡量了一个节点的吸引力。流网络可以很好地采用矩阵的形式进行表达，通过构建马尔科夫转移矩阵计算流距离指标。另外，我们已经实现了采用类似PageRank算法的程序来计算流距离。\n注意力流动网络的算法可以应用到很多领域，例如新闻事件的价值、人物的重要性、商品的重要性等。收视率是衡量电视节目的重要指标，但是这个指标本身存在很多缺陷。例如，多数收视率数据的测量所追踪的样本数量非常有限，对现有的收视率测量方式的信度和效度造成影响。\n","date":1269907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1269907200,"objectID":"1352a2e54ca80b9a4aecce7079fccfb4","permalink":"https://chengjunwang.com/note/note_archive/2010-03-30-startup/","publishdate":"2010-03-30T00:00:00Z","relpermalink":"/note/note_archive/2010-03-30-startup/","section":"note","summary":"使用注意力衡量价值 test\n引言：注意力的价值 人工智能的奠基人之一，诺贝尔经济学奖获得者赫伯特.西蒙在1971年就预言，人类社会正在步入一个新的阶段，信息的增长速度将远远超过人脑可以及时处理的速度 。七八十年代以降，一系列对信息社会进一步展望的著作，包括丹尼尔.贝尔的《后工业社会的来临》（1973），托夫勒的《第三次浪潮》（1980），尼葛洛庞帝的《数字化生存》（1996），曼纽尔·卡斯特的《网络社会的崛起》（1997）对信息技术的持续发展对人类固有社会结构带来的冲击进行了更详细的讨论。知识的快速增长和人类社会可支配的集体注意力及其有限之间的矛盾。在信息流的大量冲刷下，原有的工业社会形成的层级性的权力体系将会变得扁平化，去中心化，而个体的注意力也随之趋于碎片化。\n注意力经济作为一门单独的科学已经发展起来。经济学家古德哈伯（Goldhaber）在1997年的一篇长文《注意力经济学与网络》 中明确指出，古典经济学中用于调配资源在生产和消费各部门间流通的货币，在信息时代已经被新的稀缺资源，注意力，所取代。未来社会的经济体将会以注意力生产和交易为基石，甚至会出现“注意力货币”与“注意力银行”。因此，“注意力经济学”完全有必要成为一个单独的学科。达文波特和贝克（Davenport \u0026amp; Beck）在2001年的著作《注意力经济：理解新的贸易与货币》中对古德哈伯的观念进行了拓展，具体分析了媒体广告是如何使用受众的注意力来换取现金流的，来进一步描述了注意力经济的实现形式。\n最近十年，注意力研究浪潮席卷众多领域。这些浪潮中最值得一提有路易斯.冯.安(Luis von Ahn)等人开展的“人类计算”(human computation)研究，安德烈.布劳德(Andrei Broder)等人倡导的“计算广告学”（computational advertising），以及胡伯曼（huberman）等人倡导的“注意力动力学”（attention dynamics）。冯.安主张把人和机器结合起来。具体来说，就是把大量用户看做一个通过互联网连接的并行计算系统，在终端上通过人类技能接近计算机难以解决的复杂问题。冯.安2005年创造了一个游戏，让玩家查看并标记图片从而去改善图片的搜索。2007年，他创造了reCAPTCHA 项目，让人们在输入验证码的同时，将计算机难以识别的纸质图书数字化。2011 年，他创办了 Duolingo（中文名为多邻国），使用户在学习语言的同时，也在帮助翻译互联网上的内容。安德烈.布劳德(Andrei Broder)是雅虎的资深研究科学家，他在2008年提出了“计算广告”的概念。布劳德认为计算广告的目的就是采用算法，智能地为一定情境（context）下的用户寻找最有用的与消费行为有关的信息。物理学家胡伯曼已经开始考虑如何为注意力在互联网上的流动建立动力学模型。其主要结论有（1）网络社区的集体注意力在信息资源上分布极端不均，呈现幂律分布 ；（2）注意力随时间下降非常迅速。\n注意力流动网络 我们将沿着胡伯曼等人的思路，使用数据挖掘、网络科学与数学建模的方式，借助于互联网大数据中的人类注意力流动网络（Attention Flow Network, AFN）来衡量事物的价值。数字媒体为我们提供了一个观察大规模的人类集体行为中涌现的社会运行定律的“天文望远镜”。通过收集和分析这些数据，我们可以建立用户注意力在不同的事物（社会事件、人、商品、信息内容）之间的流动，进而采用网络科学的方法计算这些事物的价值和相似性。结合推荐系统的算法，我们可以更加有效地实现商品的推荐。\n采用网络科学有利于更好地衡量事物的价值。谷歌的成功在于其PageRank算法，在PageRank算法当中，将万维网看做一个由节点和链接组成的网络，而非单个的孤立的节点。节点是一个网页，链接是由一个网页指向另一个网页的超链接（可以看成投票）。在这个网络当中，节点是同一类型的事物（例如都是网页）。如果网络当中含有两类节点的时候，就构成了二模网络，比如用户和信息可以作为两类节点存在于同一个网络当中。此时，采用Hits算法就可以计算出这两类节点各自的权威性价值和导航性价值。但是在这两类网络当中，均没有考虑用户的注意力如何在事物当中流动。\n我们提出了注意力流动网络来捕捉注意力作为货币来衡量万物价值的功能。在这个注意力流动网络当中，节点是某一个类事物（社会事件、人、商品、信息内容）。链接则表达了用户的注意力流动。采用注意力流动网络的好处是我们可以确保在单个节点上流入的注意力和流出的注意力是守恒的，如果不守恒，则通过引入一个源节点（source）和一个汇节点（sink）的方式将其配平。采用这种链接有权重、流量守恒的注意力网络，我们可以更好地衡量节点间的价值和相似性。通过计算用户随机游走从源节点到达某一个节点的平均步数，我们可以定义流距离的概念，它衡量了一个节点的吸引力。流网络可以很好地采用矩阵的形式进行表达，通过构建马尔科夫转移矩阵计算流距离指标。另外，我们已经实现了采用类似PageRank算法的程序来计算流距离。\n注意力流动网络的算法可以应用到很多领域，例如新闻事件的价值、人物的重要性、商品的重要性等。收视率是衡量电视节目的重要指标，但是这个指标本身存在很多缺陷。例如，多数收视率数据的测量所追踪的样本数量非常有限，对现有的收视率测量方式的信度和效度造成影响。","tags":null,"title":"创业","type":"note"},{"authors":null,"categories":null,"content":" 我今天又将博客改回原来的设置，结果上传的900多个模板都没有显示出来，我后来突然想起来，原来html的地址才是最重要的。\n一般而言，一个post的物理地址：chengjun.github.io / _posts / 2010-01-01.md， 经过试验，这并不会被显示。只有当010-01-01.md被修改为010-01-01-test.md之后，才显示！居然是这样。好吧，以后写东西更方便了。呵呵。\nmathjax 设定 \u0026lt;!--mathjax start--\u0026gt; \u0026lt;script type=\u0026quot;text/x-mathjax-config\u0026quot;\u0026gt; MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\u0026quot;\\\\(\u0026quot;,\u0026quot;\\\\)\u0026quot;] ], processEscapes: true }, TeX: { equationNumbers: { autoNumber: \u0026quot;AMS\u0026quot; } } }); \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot; src=\u0026quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0026quot;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;!--mathjax end--\u0026gt;  ","date":1263081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1263081600,"objectID":"12a2f5c587ddf4217e2e92d2c7afe474","permalink":"https://chengjunwang.com/note/note_archive/2010-01-10-markdown-name/","publishdate":"2010-01-10T00:00:00Z","relpermalink":"/note/note_archive/2010-01-10-markdown-name/","section":"note","summary":" 我今天又将博客改回原来的设置，结果上传的900多个模板都没有显示出来，我后来突然想起来，原来html的地址才是最重要的。\n一般而言，一个post的物理地址：chengjun.github.io / _posts / 2010-01-01.md， 经过试验，这并不会被显示。只有当010-01-01.md被修改为010-01-01-test.md之后，才显示！居然是这样。好吧，以后写东西更方便了。呵呵。\nmathjax 设定 \u0026lt;!--mathjax start--\u0026gt; \u0026lt;script type=\u0026quot;text/x-mathjax-config\u0026quot;\u0026gt; MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\u0026quot;\\\\(\u0026quot;,\u0026quot;\\\\)\u0026quot;] ], processEscapes: true }, TeX: { equationNumbers: { autoNumber: \u0026quot;AMS\u0026quot; } } }); \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot; src=\u0026quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0026quot;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;!--mathjax end--\u0026gt;  ","tags":null,"title":"Markdown名称中有字母才会显示","type":"note"},{"authors":null,"categories":null,"content":"我不再像先前那样崇拜他了，但我自觉在深层的心理和情感距离上，似乎是离他越来越近；我也不再将他视作一个偶像，他分明就在我们中间，和我们一样在深重的危机中苦苦挣扎。 ——王晓明 自己在网上碰到这本书，就下了下来，但自己对于鲁迅的记忆却局限于高中教科书《社戏》、《从百草园到三味书屋》里面，恰若我们对于马克思同样很无知一样，我们距离这些曾经吸引民族目光的人物似乎很近，但又的确很远。但人生的某个阶段总会有难解的问题，这个时候就只好去走进这些被我们所远离的灵魂。\n鲁迅本姓周，名樟寿，后改为树人：号豫山，后改为豫才。鲁迅是他的笔名，一八八一年九月二十五日出生在绍兴城内周姓望族，祖父周介孚，出身翰林，让鲁迅在启蒙的时候先读历史，而不是四书五经；父亲周伯宜，对鲁迅非常宽厚，允许他读闲书；母亲鲁瑞更是喜欢他。少年鲁迅便生活在这种颇为繁华而宽厚的环境中读书长大，调皮好斗，有着少年所特有的骄傲。但祖父却因为一次科场行贿案下狱，父亲也吐血并终于去世，亲戚便不再对鲁迅家客气，分房子的时候给鲁迅家最差的房子。这种世态炎凉、由繁华转为凄苦的经历很容易让人想到曹雪芹，另一个在中国的晚期封建社会反儒家的困顿的斗士。后来在广州，青年学生问他为什么憎恶旧社会，他回答：“我小的时候，因为家境好，人们看我像王子一样，但是，一旦我家庭发生变故后，人们就把我看成叫花子都不如了，我感到这不是一个人住的社会，从那时起，我就恨这个社会。”今天再思考这个，我们究竟走出去多远呢？市场经济之后，实用主义潮起，我们仿佛又能看到那些忧伤的娜拉了。\n若以事件史的眼光看个体的人，就要重视他在十八岁的选择，这一年鲁迅乡试成绩为中上等，却因为一个弟弟的夭亡而放弃复试，家境的中落、人情的冷落也使他不能去经商或者像很多绍兴人一样选择去做师爷、幕僚。*如今日高考无望的情况相识，鲁迅只能选择去读江南水师学堂，差不多是免费。*王晓明写到：“可也惟其如此，学生多不愿以本名注册，而要改换姓名，鲁迅那个‘周树人’的名字，就是这样起的。”但不满意学堂教员的无知只好转到路矿学院，1902年，因为没有钱只好争取公费去那个极度自卑并极度自大的在7年前打败中国的地方留学去了，在日本呆了七年，因为日本人的傲慢、侮辱和留日学生的不成器的丑态而痛苦，终于无法忍受，放弃学医转而从文，要医治这个民族的精神状况。但如王晓明所言，“一九0六年初夏，鲁迅返回东京，这时候他已经二十六岁了。用去了八年的青春，从中国到日本，又从仙台回东京，四处寻求生路，却总是走不通，兜了一个大圈子，还是回到老地方：没有钱，也没有文凭，两手空空，一无所有。”在这一点上，马克思比鲁迅幸运多了，至少他在大学阶段找到了自己受用终生的道路——哲学。\n我们已经知道了鲁迅从少年时代就开始大量阅读各种杂书，他应该感谢自己的这种习惯，王晓明描绘了鲁迅的读书状况：林纾翻译的小说一本不落；梁启超主笔的《时务报》几乎是每期必读；他更用心读理论书，严复翻译的《天演论》和《法意》，他是读了又读，还郑重其事地向别人推荐，还曾给周作人推荐约翰•穆勒的《逻辑体系》。以今日状况来看，有多少人真正读过《进化论》和《论法的精神》呢？更不用说小穆勒的书了。尤其是达尔文的理论使鲁迅走出了历史悲观主义关于“今不胜昔”和“一乱一治”的历史循环主义，对于鲁迅来说这不啻是精神革命，正如马克思读了在大学里成为了一个激进的青年黑格尔主义者一样，鲁迅也成了一个“我以我血荐轩辕”的社会进化论者，从仙台来到东京，他毅然剪掉了辫子，严肃地和同学们一起思考民族的问题。\n话说回来，也许正如张饶庭所说，人本身就是loglinear，是非线性的，总是充满了矛盾。记得我自己更夸张的说过“人即回归”的话，都是一样的，只不过是加入了点宿命的色彩。传统与革命便如此自然地熔铸在鲁迅的遭遇中。热血青年鲁迅在日本思想开始倾向于革命，并且 *真真正正的加入了光复会*，然而当被要求回国像徐锡麟一样刺杀满清高官的时候，鲁迅却问了句：“如果我被抓住，被砍头，剩下我的母亲，谁负责赡养她呢？”领导收回成命，刺杀遂无疾而终。对此王晓明写道：他不能无条件地相信别人。即便一时冲动，时间稍长，他对卑劣人心的体验，对一切冠冕堂皇的东西的习惯性怀疑。正是在1906年，鲁迅被母亲以生病为由骗回家，娶了朱安，后者曾经拒绝按照鲁迅的意见进入新式学堂读书。鲁迅在婚后第四天就回了日本。\n一九○八年夏天，继续在东京读书学德语。从夏天开始，每星期日往章太炎在东京的寓所，听他讲学，历时大约半年。称章太炎为鲁迅的老师，跟这个有关系吧。1909年，与周作人合译的《域外小说集》第一册出版，不久《域外小说集》第二册出版。为了负担家庭经济，离开日本回国，结束了七年的留学生活。 回国后，就任杭州的浙江两级师范学堂的生理和化学教员，兼任日籍教师的翻译。1910年担任绍兴府中学堂的监学，兼教生物课。1911年，武昌起义爆发，绍兴城内一片混乱，遂应府中学堂学生的请求，回校暂管校务。 带领学生演说队上街宣传革命，安定民心。不久，受新任绍兴军政府都督王金发委任，担任山会初级师范学堂监督。但是，革命并没有给民族带来更多的东西，革命党的官员一样压抑自由和新思想，鲁迅最终选择离开。\n靠着朋友的推荐、应教育总长蔡元培邀请，去南京中华民国临时政府的教育部任职。从此，逃离绍兴。因教育部北迁，单身前往北京，住进宣武门外的绍兴会馆。 任北洋政府教育部佥事，兼第一科科长。这便是鲁迅中年一次重要选择：为官的仕途之路，所幸收入颇高。但鲁迅虽有怀疑的毛病，却无法接受现实的倾轧，他去研究石刻拓本、抄古碑，他每天上午九、十点钟起床，梳洗后直接去部里办公，到黄昏时返回会馆。吃过晚饭，八点钟开始抄碑，看佛经，读墓志，常常要到半夜一两点钟。对此，王晓明说：对自己的个人幸福，他也不能再抱什么希望了。他刻了一方石章，曰“堂”；又给自己选了一个号，叫做“俟堂”。笔划虽不同，意思是一个，就是“待死堂”。这个时候，鲁迅已经不得不去思考死亡、品味孤独、遭遇自我。生活、婚姻、国家的不顺遂和鲁迅的悲观主义都把他引入到了遭遇虚无的境地。从这个角度上讲，鲁迅和陀思妥耶夫斯基和托尔斯泰是有相近之处的。鲁迅的待死堂和陀思妥耶夫斯基的《死屋手记》中的死屋何其相似。\n对于在五四阶段鲁迅带着面具的呐喊，王晓明直言：对启蒙的信心，他其实比其他人小，对中国的前途，也看得比其他人糟。五四的成功使鲁迅获得了极高的文学声望，“他不再是绍兴会馆里那个默默无闻的“待死”者了，他现在成了大学讲台上的名教授，读者钦慕的名作家。”\n1925年，“鲁迅和女师大的学生许广平等人开始来往，通信日渐频繁，好感逐渐加深，他在感情上，也会不自觉地向这批学生倾斜，于是在五月十二日的《京报副刊》上，他公开表态支持学生，随后又联络其他一些教员，联名宣告反对杨荫榆。”这场纠纷使鲁迅失去了他的官位——章士钊撤了她的职。后来，鲁迅起诉了章士钊重新获得了这个职位。对此王晓明说：从少年时代起，他就吃够了贫困的苦头，他很早就懂得了没有钱，什么事都干不成，在那篇《娜拉走后怎样》的演讲中，他那样强调“经济权”，就正是出于自己的痛苦经验。\n人存在的意义是什么？王晓明说：“人的生存意义，就体现在他人对你的需要之中，即使鲁迅对社会的变革完全失去信心，对自己在这变革中的作用也不存指望，他的精神世界大概仍不会垮掉，还有一根坚固的支柱在支撑着他，那就是他对和睦的家庭生活的期待，对自己作为这个家庭的主要维持者的自豪。” 1923年，鲁迅和羽太信子发生严重的冲突 ，随之和周作人兄弟反目，他就迁往西城的砖塔胡同六十一号。鲁迅对自己的母亲并没有太大的好感，家庭的分裂，更让他陷入了痛苦的深渊之中。\n鲁迅从人道主义转向了个人主义，由启蒙的悲观主义，转向了存在的虚无主义。俄国作家阿尔志跋绥夫在小说《工人绥惠略夫》中，以主人公绥惠略夫表现的一种思想，用鲁迅的话说，就是“要救群众，而反被群众所迫害，终至成了单人，忿激之余，一转而仇视一切，无论对谁都开枪，自己也归于毁灭。” 王晓明写到：从启蒙者的悲观和绝望，从对尼采和绥惠略夫的共鸣和认同，鲁迅一步步走进了虚无感。\n鲁迅在虚无主义的鬼气中滑落的太远，但1925年，他还是找打了一个缺口：对女人的爱情，逃了出来。这一年他和许广平相爱了，许并不漂亮，但对于新思想、自由、革命的坚毅鼓舞了鲁迅。26年，鲁迅到厦门大学任教，后来又去了广州中山大学，此刻许广平已经陪伴在他身边了。因为老对手顾颉刚要到中大，鲁迅和许广平便到了上海。王晓明写道：“从某种意义上讲，鲁迅和许广平相爱而终于同居，在上海建立新的家庭，是他一生中最有光彩的举动。正是在这件事情上，他充分表现了生命意志的执拗的力量，表现了背叛传统礼教的坚决的勇气，表现了一个现代人追求个人自由的个性风采。但是，也恰恰在这件事情上，他内心深处的软弱和自卑，他对传统道德的下意识的认同，他对社会和人性的根深蒂固的不信任，都表现得格外触目。一个人一旦相信爱情，就不再是虚无主义者。”\n鲁迅的人生是在上海画上终点的，在这个时期，鲁迅不断遭遇到华盖运。早期，鲁迅是要医治民族性，对大众，他是轻蔑的，他依靠知识分子的，尤其是学生，但人生的种种遭遇却使他不断看到知识分子的局限性，读了一些马克思主义的东西之后，鲁迅转而提出大众才是推动历史变革者。但是这与他素有的思想是矛盾的。终于，他提出了新知识分子的说法。“一九三二年底，他第二次回北京探望母亲，去北京女子文理学院和北京师范大学演讲，都特别挑起知识阶级会不会灭亡的话题，反复强调说，有一种新的知识者，他们与群众结合，反对个人主义，能够把握住实际人生，因此在将来仍能生存。”\n一九三０年五月，他发起成立了左联的筹备会。他刚刚和共产党人结盟，共产党的一位领导人李立三，就秘密约见他，要他以周树人的名字写一篇骂蒋介石的文章，被鲁迅婉言拒绝。虽然他倾向于共产党，但他同样厌恶成仿吾和周扬那一类共产党人。\n在生命中的最后一年，1936年，鲁迅写了《死》，显示出一种非常特别的态度：既不回避，也不设法改造，就站在那里谈论自己的死。十月十九日，上午五时二十五分逝世。\n这便是鲁迅的一生，一个对我们来说应该熟悉、但其实显然十分陌生的人生，我们在他的身上看到了太多的矛盾，看到了存在主义哲学对人生的思考的深刻的印记。处于一个悲剧似的、似乎看不到希望地转折的时代，鲁迅经历了人生中的种种波折，大到祖国，中到家庭，小到个人，没有一个顺遂人心，这个小个子、坏脾气、多疑的人，在那个时代里耗尽了自己的所有生命力。鲁迅在他的人生的当中不可避免的遭遇虚无，国家风雨飘摇、鸡鸣不已，大众是冷漠的、愚蠢的群体，少年家道中落，慈母是误进的毒药，朱安是无法交流的对象，和弟弟周作人虽志趣相近却终于反目，最后自己所倾向的知识分子也多靠不住。鲁迅的幸运是青少年时的广泛读书、留学日本的经历、加入光复会的经验、许广平的爱情和共产主义的发展。\n鲁迅故去93年了，我们已经从鲁迅的铁屋走出了很远，但我们绝大多数人对鲁迅的认识依然很浅薄。娜拉出走之后怎样？我们挣脱了一个旧的世界，我们又能走多远？鲁迅今日若在，他又能写写什么呢？鲁迅说：“跨过那站着的前人。”我们真的超越了吗？\n","date":1234569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1234569600,"objectID":"5c303b708c57c9dea7e1344ea2a3c988","permalink":"https://chengjunwang.com/zh/archive/2009-02-14-read-luxun-in-text.zh/","publishdate":"2009-02-14T00:00:00Z","relpermalink":"/zh/archive/2009-02-14-read-luxun-in-text.zh/","section":"zh","summary":"","tags":null,"title":"我们能走多远——读王晓明的《鲁迅传》","type":"zh"},{"authors":null,"categories":null,"content":" The Academic framework enables you to easily create a beautifully simple personal or academic website using the Hugo static site generator.\nKey features:\n Easily manage your homepage, blog posts, publications, talks, and projects Configurable widgets available for Biography, Publications, Projects, News/Blog, Talks, and Contact Need a different section? Just use the Custom widget! Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Easy to customize  Installation  Install Hugo and create a new website by typing the following commands in your Terminal or Command Prompt app:\nhugo new site my_website cd my_website  Install Academic with git:\ngit clone https://github.com/gcushen/hugo-academic.git themes/academic  Or alternatively, download Academic and extract it into a themes/academic folder within your Hugo website.\n If you are creating a new website, copy the contents of the exampleSite folder to your website root folder, overwriting existing files if necessary. The exampleSite folder contains an example config file and content to help you get started.\ncp -av themes/academic/exampleSite/* .  Start the Hugo server from your website root folder:\nhugo server --watch  Now you can go to localhost:1313 and your new Academic powered website should appear.\n Customize your website - refer to the Getting Started section below\n Build your site by running the hugo command. Then host it for free using Github Pages. Or alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as your university\u0026rsquo;s hosting service).\n  Getting Started Assuming you created a new website with the example content following the installation steps above, this section explores just a few more steps in order to customize it.\nCore parameters The core parameters for the website can be edited in the config.toml configuration file:\n Set baseurl to your website URL (we recommend GitHub Pages for free hosting) Set title to your desired website title such as your name The example Disqus commenting variable should be cleared (e.g. disqusShortname = \u0026quot;\u0026quot;) or set to your own Disqus shortname to enable commenting Edit your details under [params]; these will be displayed mainly in the homepage about and contact widgets (if used). To disable a contact field, simply clear the value to \u0026quot;\u0026quot;. Place a square cropped portrait photo named portrait.jpg into the static/img/ folder, overwriting any defaults. Alternatively, you can edit the avatar filepath to point to a different image name or clear the value to disable the avatar feature. To enable LaTeX math for your site, set math = true Social/academic networking links are defined as multiples of [[params.social]]. They can be created or deleted as necessary.  Introduce yourself Edit your biography in the about widget content/home/about.md that you copied across from the themes/academic/exampleSite/ folder. The research interests and qualifications are stored as interests and education variables. The academic qualifications are defined as multiples of [[education.courses]] and can be created or deleted as necessary. It\u0026rsquo;s possible to completely hide the interests and education lists by deleting their respective variables.\nCustomize the homepage Refer to our guide on using widgets to customize your homepage.\nAdd your content Refer to our guide on managing content to create your own publications, blog posts, talks, and projects.\nRemove unused widgets and pages How to remove unused widgets and content pages.\nCustomization \u0026amp; Upgrading Continue reading below for advanced customization tips and instructions for keeping the framework up-to-date with any improvements that become available.\nAdvanced customization It is possible to carry out many customizations without touching any files in themes/academic, making it easier to upgrade the framework in the future.\nNavigation menu The [[menu.main]] entries towards the bottom of config.toml define the navigation links at the top of the website. They can be added or removed as desired.\nTo create a dropdown sub-menu, add identifier = \u0026quot;something\u0026quot; to the parent item and parent = \u0026quot;something\u0026quot; to the child item.\nWebsite icon Save your main icon and mobile icon as square PNG images named icon.png and apple-touch-icon.png, respectively. Place them in your root static/img/ folder.\nTheme color (CSS) You can link custom CSS assets (relative to your root static/css) from your config.toml using custom_css = [\u0026quot;custom.css\u0026quot;].\nFor example, lets make a green theme. First, define custom_css = [\u0026quot;green.css\u0026quot;] in config.toml. Then we can download the example green theme and save it as static/css/green.css, relative to your website root (i.e. not in the themes directory).\nAnalytics To enable Google Analytics, add your tracking code in config.toml similarly to googleAnalytics = \u0026quot;UA-12345678-9\u0026quot;.\nThird party and local scripts (JS) To add a third party script, create a file named head_custom.html in a layouts/partials/ folder at the root of your website (not in the themes folder). Any HTML code added to this file will be included within your website\u0026rsquo;s \u0026lt;head\u0026gt;. Therefore, it\u0026rsquo;s suitable for adding custom metadata or third party scripts specified with the async attribute.\nWhereas for your own local scripts, you can link your local JS assets (relative to your root static/js) from your config.toml using custom_js = [\u0026quot;custom.js\u0026quot;].\nLanguage and translation The interface text (e.g. buttons) is stored in language files which are collected from Academic\u0026rsquo;s themes/academic/i18n/ folder, as well as an i18n/ folder at the root of your project.\nTo edit the interface text, copy themes/academic/i18n/en.yaml to i18n/en.yaml (relative to the root of your website). Open the new file and make any desired changes to the text appearing after translation:. Note that the language files are formatted in YAML syntax.\nTo translate the interface text to another language, follow the above instructions, but name the new file in the form i18n/X.yaml where X is the appropriate ISO/RFC5646 language identifier for the translation. Then follow the brief instructions in the Language section at the bottom of your config.toml. To change the default language used by Academic, set defaultContentLanguage to the desired language identifier in your configuration file.\nTo translate the navigation bar, you can edit the default [[menu.main]] instances in config.toml. However, for a multilingual site, you will need to duplicate all of the [[menu.main]] instances and rename the new instances from [[menu.main]] to [[languages.X.menu.main]], where X is the language identifier (e.g. [[languages.zh.menu.main]] for Simplified Chinese). Thus, the navigation bar can be displayed in multiple languages.\nTo translate a content file in your content/ folder into another language, copy the file to filename.X.md where filename is your existing filename and X is the appropriate ISO/RFC5646 language identifier for the translation. Then translate the content in the new file to the specified language.\nFor further details on Hugo\u0026rsquo;s internationalization and multilingual features, refer to the associated Hugo documentation.\nPermalinks Permalinks, or permanent links, are URLs to individual pages and posts on your website. They are permanent web addresses which can be used to link to your content. Using Hugo\u0026rsquo;s permalinks option these can be easily customized. For example, the blog post URL can be changed to the form yourURL/2016/05/01/my-post-slug by adding the following near the top of your config.toml (before [params] settings):\n[permalinks] post = \u0026quot;/:year/:month/:day/:slug\u0026quot;  Where :slug defaults to the filename of the post, excluding the file extension. However, slug may be overridden on a per post basis if desired, simply by setting slug = \u0026quot;my-short-post-title\u0026quot; in your post preamble.\nUpgrading Feel free to star the project on Github and monitor the commits for updates.\nBefore upgrading the framework, it is recommended to make a backup of your entire website directory, or at least your themes/academic directory. You can also read about the most recent milestones (but this doesn\u0026rsquo;t necessarily reflect the latest master release).\nBefore upgrading for the first time, the remote origin repository should be renamed to upstream:\n$ cd themes/academic $ git remote rename origin upstream  To list available updates:\n$ cd themes/academic $ git fetch upstream $ git log --pretty=oneline --abbrev-commit --decorate HEAD..upstream/master  Then, upgrade by running:\n$ git pull upstream  If you have modified files in themes/academic, git will attempt to auto-merge changes. If conflicts are reported, you will need to manually edit the files with conflicts and add them back (git add \u0026lt;filename\u0026gt;).\nIf there are any issues after upgrading, you may wish to compare your site with the latest example site to check if any settings changed.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor general questions about Hugo, there is a Hugo discussion forum.\nLicense Copyright 2016 George Cushen.\nReleased under the MIT license.\n","date":956160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":956160000,"objectID":"9e03aea66ae4ed94e66eb931fc6752b8","permalink":"https://chengjunwang.com/note/note_archive/2000-04-20-getting-started/","publishdate":"2000-04-20T00:00:00+08:00","relpermalink":"/note/note_archive/2000-04-20-getting-started/","section":"note","summary":" ","tags":["academic","hugo","news"],"title":"Getting started with the Academic framework for Hugo","type":"note"},{"authors":null,"categories":null,"content":" 教学  复旦大学《计算新闻传播学》课程  python代码、PPT见GitHub 。课程内容包括：计算传播学导论、大数据简介、数据科学的编程工具、数据抓取、数据清洗、统计分析、机器学习、文本挖掘、推荐系统、网络科学多个部分。  \n 南京大学研究生课程 《大数据挖掘与分析》\n 2018 春季 周\u0008二 第5-6节  南京大学本科生课程 《计算传播》\n 2018 春季 2017 春季  南京大学本科生课程 《数据新闻》\n 2017 秋季 周一 第3-4节 逸B-210 1-18周 2016 秋季 2015 秋季  南京大学人文艺术传播类《媒介案例研究》\n 《计算传播》案例部分 每周二7、8节（4-18周）逸B-104   学生  研究生(在读)：秦强、陈志聪 已毕业研究生：周纬(2017) 本科生（指导毕业论文）：  2017：沈越、曾维靓   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5d0cba2601063c4a27b7e2d644fc362d","permalink":"https://chengjunwang.com/zh/cn/teaching/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/cn/teaching/","section":"zh","summary":" 教学  复旦大学《计算新闻传播学》课程  python代码、PPT见GitHub 。课程内容包括：计算传播学导论、大数据简介、数据科学的编程工具、数据抓取、数据清洗、统计分析、机器学习、文本挖掘、推荐系统、网络科学多个部分。  \n 南京大学研究生课程 《大数据挖掘与分析》\n 2018 春季 周\u0008二 第5-6节  南京大学本科生课程 《计算传播》\n 2018 春季 2017 春季  南京大学本科生课程 《数据新闻》\n 2017 秋季 周一 第3-4节 逸B-210 1-18周 2016 秋季 2015 秋季  南京大学人文艺术传播类《媒介案例研究》\n 《计算传播》案例部分 每周二7、8节（4-18周）逸B-104   学生  研究生(在读)：秦强、陈志聪 已毕业研究生：周纬(2017) 本科生（指导毕业论文）：  2017：沈越、曾维靓   ","tags":null,"title":"","type":"zh"},{"authors":null,"categories":null,"content":" Set up Octopress I refer to this blog and this blog to setup octopress. It\u0026rsquo;s very helpful for windows users.\nFor encoding errors Most chinese windows users encounter the problem of encoding error, such as this one: invalid byte sequence in GBK. I handle it following three suggestions:\n1.Modify the file located at C:\\Ruby193\\lib\\ruby\\gems\\1.9.1\\gems\\jekyll-0.11.2\\lib\\jekyll\\convertible.rb, to change:\nself.content = File.read(File.join(base, name))  into:\nself.content = File.read(File.join(base, name), :encoding =\u0026gt; \u0026quot;utf-8\u0026quot;)  2.Make sure the markdown file is encoded with utf-8 without BOM\n3.Set the language in the git bash:\nset LANG=zh_CN.UTF-8 set LC_ALL=zh_CN.UTF-8  Writing markdown post with MarkdownPad Using MarkdownPad, you can instantly see what your Markdown documents look like in HTML. While you type, LivePreview will automatically scroll to the current location you’re editing.\nUnderstanding the git flow of Octopress blogs First, we operate at the local, and then we push the changes to the server of github.\nFor the local files, there are two parts: sources \u0026amp; public. We first write post to the directory of \u0026laquo;_posts\u0026raquo;; Second, we copy the file to the public file (rake generate), and at the moment, you can preview the local files (rake preview); Third, you can publish/push the local files to the server (rake deploy).\nOn the server, there are two parts: master \u0026amp; source. In the source part of the server, we can archive the local files.\nIf you undertand the logic above well, you know clearly how to modify one post.\nModifying a post After you have publish a post, you may need to modify the content: First, to find the post in the directory of \u0026laquo;octopress/source/_posts\u0026raquo;; Second, to modify it with MarkdownPad; Third, to publish the modified post:\nrake generate rake preview rake deploy  Click here to preview http://localhost:4000\nCopy the changes to the source for memory.\ngit add . git commit -m 'your message' git push origin source  Clone Your Octopress to Blog From Two Places Refer to this post: http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/\nAdd mathjax to write eqations Refer to this post: http://www.yanjiuyanjiu.com/blog/20130402/\n$$ logit(Y{ij} = 1) = ln(\\frac{p{ij}}{1-p{ij}}) = {\\theta }^{T} \\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]{ij} $$\n以上公式当中，定义$$Y{ij}$$为节点i和j之间形成链接的一个随机变量。当$$y{ij}$$取值由0变为1的时候，所带来的$$g(\\mathbf{y},\\mathbf{X})$$的变化表示为$$\\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]_{ij}$$。\nUsing kramdown, you can also present the tables on octopress.[^1]. Other text.[^footnote]. One example:\n|-----------------+------------+-----------------+----------------| | Default aligned |Left aligned| Center aligned | Right aligned | |-----------------|:-----------|:---------------:|---------------:| | First body part |Second cell | Third cell | fourth cell | | Second line |foo | **strong** | baz | | Third line |quux | baz | bar | |-----------------+------------+-----------------+----------------|  Check the result here:\n|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| | Default aligned |Left aligned| Center aligned | Right aligned | |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;:|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;:| | First body part |Second cell | Third cell | fourth cell | | Second line |foo | strong | baz | | Third line |quux | baz | bar | |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-|\nGist Embedding Refer to this post: http://octopress.org/docs/blogging/code/\nInsert photos and modify the size Refer to this link: http://octopress.org/docs/plugins/image-tag/\n I am Optimus Prime, and I send this message to any surviving Autobots taking refuge among the stars: we are here, we are waiting.\n Use the Twilight Color Scheme def hello puts \u0026quot;Hello!\u0026quot; end  {:lang=\u0026laquo;ruby\u0026raquo;}\nJust add {:lang =\u0026laquo;ruby\u0026raquo;} below your code block, and bear in mind that there is no indent for this line:\n def hello puts \u0026quot;Hello!\u0026quot; end {:lang=\u0026quot;ruby\u0026quot;}  {:lang=\u0026laquo;ruby\u0026raquo;}\nfor thie inline script def hello{:lang=\u0026laquo;ruby\u0026raquo;}, you can write in this way:\nfor the inline script 'def hello'{:lang=\u0026quot;ruby\u0026quot;}, you can write in this way:  {:lang=\u0026laquo;ruby\u0026raquo;}\nRefer to this link to use the twilight color scheme:http://blog.alestanis.com/2013/02/04/octopress-and-the-twilight-color-scheme/\nHowever, this link is simpler: http://cabeca.github.io/blog/2013/06/09/putting-some-twilight-on-octopress/\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b5ea2360a3526602812904ade96af888","permalink":"https://chengjunwang.com/post/en/2013-08-03-bloging-with-markdown-on-octopress/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-08-03-bloging-with-markdown-on-octopress/","section":"post","summary":"Set up Octopress I refer to this blog and this blog to setup octopress. It\u0026rsquo;s very helpful for windows users.\nFor encoding errors Most chinese windows users encounter the problem of encoding error, such as this one: invalid byte sequence in GBK. I handle it following three suggestions:\n1.Modify the file located at C:\\Ruby193\\lib\\ruby\\gems\\1.9.1\\gems\\jekyll-0.11.2\\lib\\jekyll\\convertible.rb, to change:\nself.content = File.read(File.join(base, name))  into:\nself.content = File.read(File.join(base, name), :encoding =\u0026gt; \u0026quot;utf-8\u0026quot;)  2.","tags":null,"title":"Blogging with markdown on Octopress","type":"post"},{"authors":null,"categories":null,"content":" The long-tail distribution can be quantified in primarily three ways, see Newman \u0026rsquo;s paper here:\n Power law distribution Zipf distribution Pareto distribution  Here, I talk about the Zipf distribution which assesses the relationship between rank order and Frequency (probability).\n Zipf\u0026rsquo;s law now refers more generally to frequency distributions of \u0026laquo;rank data,\u0026raquo; in which the relative frequency of the nth-ranked item is given by the Zeta distribution. from Wikipedia\n DGBD In Gustavo Martínez-Mekler et al\u0026rsquo;s article, they proposed a discrete generalized beta distribution: $$f\u0026reg; = A(N+1-r)^b/r^a$$, where r is the rank, N is maximum value, A the normalization constant and (a, b) two fitting exponents.\nIt\u0026rsquo;s interesting to find that Wu and Zhang (2011) adopt the DGBD distribution to quantify the online social systems. Basically, they are interested in accelerating growth in human online behaviors.\nDeﬁning P as the number of active users in a day and T as the total activity generated by these users, they find a power law relationship between them $$T = P^\\gamma$$. Given $$\\gamma$$ larger than 1, there exists an accelerating growth phenomena in online systems (e.g., tagging, microblogging)\nThey denote the activity of a user in one day with t\u0026reg;, in which r is the decreasing rank of the activity among all individual activities in the day. Thus the maximum value of r, $$r_{max}$$, equals population P. The DGBD model of individual activities is then\n$$t\u0026reg; = A(P+1−r)^b r^a (a \u0026gt; 0,b \u0026gt; 0)$$\nThey introduced that a determines the activities of highly active users(corresponds to the exponent $$\\alpha$$ in Zipf’s law), b determines the activities of the less active users. Using the DGBD, They can ﬁt the empirical curves with $$R^2$$ \u0026gt; 0.9.\nHere I start with an empirical dataset. The Tweet of Milan city in December 2013. Basically, we know the language of each tweet. Thus we have the frequency of each language.\nfreq = c(1116, 2067, 137 , 124, 643, 2042, 55 ,47186, 7504, 1488, 211, 1608, 3517 , 7 , 896 , 378, 17 ,3098, 164977 , 601 , 196, 637, 149 , 44,2 , 1801, 882 , 636,5184, 1851, 776 , 343 , 851, 33 ,4011, 209, 715 , 937 , 20, 6922, 2028 , 23, 3045 , 16 , 334, 31 , 2) lan = c(\u0026quot;af\u0026quot;,\u0026quot;ar\u0026quot;,\u0026quot;bg\u0026quot;,\u0026quot;cs\u0026quot;,\u0026quot;da\u0026quot;,\u0026quot;de\u0026quot;,\u0026quot;el\u0026quot;,\u0026quot;en\u0026quot;,\u0026quot;es\u0026quot;,\u0026quot;et\u0026quot;,\u0026quot;fa\u0026quot;,\u0026quot;fi\u0026quot;,\u0026quot;fr\u0026quot;,\u0026quot;he\u0026quot;,\u0026quot;hr\u0026quot;,\u0026quot;hu\u0026quot;,\u0026quot;id\u0026quot;,\u0026quot;it\u0026quot;,\u0026quot;ja\u0026quot;,\u0026quot;ko\u0026quot;,\u0026quot;lt\u0026quot;,\u0026quot;lv\u0026quot;,\u0026quot;mk\u0026quot;,\u0026quot;ne\u0026quot;,\u0026quot;nl\u0026quot;,\u0026quot;no\u0026quot;,\u0026quot;pl\u0026quot;,\u0026quot;pt\u0026quot;,\u0026quot;ro\u0026quot;,\u0026quot;ru\u0026quot;,\u0026quot;sk\u0026quot;,\u0026quot;sl\u0026quot;,\u0026quot;so\u0026quot;,\u0026quot;sq\u0026quot;,\u0026quot;sv\u0026quot;,\u0026quot;sw\u0026quot;,\u0026quot;th\u0026quot;,\u0026quot;tl\u0026quot;,\u0026quot;tr\u0026quot;,\u0026quot;uk\u0026quot;,\u0026quot;und\u0026quot;,\u0026quot;ur\u0026quot;,\u0026quot;vi\u0026quot;,\u0026quot;zh-cn\u0026quot;,\u0026quot;zh-tw\u0026quot;)  Thus, we can calculate the decreasing rank for each language.\nRank = rank(-freq, ties.method = c(\u0026quot;first\u0026quot;) ) data = data.frame(lan, freq, Rank) data$Probability = data$Freq/sum(data$Freq)  We can write a simple function to fit the rank ordered data and capture the distribution.\nget_dgbd = function(freq){ Rank = rank(-freq, ties.method = c(\u0026quot;first\u0026quot;) ) p = freq/sum(as.numeric(freq)) # get the log form log.f = log(freq) log.p = log(p) log.rank = log(Rank) log.inverse.rank = log(length(Rank)+1-Rank) # linear regression of zifp: for probability cozp=coef(lm(log.p~log.rank)) zipf.p = function(x) exp(cozp[[1]] + cozp[2]*log(x)) # linear regression of zifp: for frequency cozf=coef(lm(log.f~log.rank)) zipf.f = function(x) exp(cozf[[1]] + cozf[2]*log(x)) # linear regression of dgbd: for probability codp=coef(lm(log.p~log.inverse.rank + log.rank)) dgbd.p = function(x) exp(codp[[1]]+ codp[[2]]*log(length(x)+1-x) + codp[[3]]*log(x)) # linear regression of dgbd: for frequency codf=coef(lm(log.f~log.inverse.rank + log.rank)) dgbd.f = function(x) exp(codf[[1]]+ codf[[2]]*log(length(x)+1-x) + codf[[3]]*log(x)) return(c(zipf.p, zipf.f, dgbd.p, dgbd.f)) } zipf.p = get_dgbd(data$Freq)[[1]] zipf.f = get_dgbd(data$Freq)[[2]] dgbd.p = get_dgbd(data$Freq)[[3]] dgbd.f = get_dgbd(data$Freq)[[4]] plot(freq~Rank,log=\u0026quot;xy\u0026quot;, xlab = \u0026quot;Rank (log)\u0026quot;, ylab = \u0026quot;Frequency (log)\u0026quot;, data = data) curve(zipf.f, col=\u0026quot;red\u0026quot;, add = T, n = length(data$Rank)) curve(dgbd.f, col=\u0026quot;blue\u0026quot;, add = T, n = length(data$Rank))  Remember to specify the length of values in \u0026lsquo;curve\u0026rsquo;. About its importance, check this post on stackoverflow.\nFinally, we can plot it with ggplot2.\nrequire(ggplot2) P = ggplot(data=data, aes(x=Rank, y=Freq, label = Var1)) + geom_point() + coord_trans(xtrans = \u0026quot;log10\u0026quot;, ytrans = \u0026quot;log10\u0026quot;)+ stat_function(fun = dgbd.f, n = length(Rank), colour = 'red', size = 1)+ geom_text(aes(label=Var1),hjust=1.5, vjust=0, angle = 45, size = 3) png(file = \u0026quot;./language_rank_order_distribution2.png\u0026quot;, width=8, height=5, units=\u0026quot;in\u0026quot;, res=700) P dev.off()  How to construct your model? Using the DGBD model, we can fit the frequency-rank data almost perfectly. However, there are many other other forms of alternative equations. For example, there are Zipf-Manderbrot Model and its modifications, How to guarantee that which specific model is the right one? We need to:\n learn more about the underlying mechanisms. observe the patterns of the data  In the paper titled Modeling bursts and heavy tails in human dynamics, Alexei Vázquez et al tried to propose two queuing models to explain the value of scaling parameter in the temporal patterns of human behaviors. They capture the temporal patterns with two measurements: interevent time $$\\tau$$ and waiting times $$\\tau_{w}$$.\nThe time between two consecutive events is called the interevent time, $$\\tau$$; the waiting (or response) time, $$\\tau_w$$, representing the amount of time a task waits on an individual’s priority list before being executed.\nAssuming that the tasks are executed independently from each other at a constant rate $$\\lambda$$, the time can be approximated by a Poisson process:\n$$p(\\tau) = \\lambda e^{-\\lambda \\tau}$$ .\nHowever, we know that in many human behaviors, the Poisson process fails to capture the burst phenomenon. The temporal patterns can be generally categorized into two classes:\n A. The $$\\alpha$$= 1 universality class: Web browsing, email, and library datasets\n B. The $$\\alpha$$=3\u0026frasl;2 universality class: The correspondence of Einstein, Darwin, and Freud, which is characterized by a power law decay combined with an exponential cutoff.\n  $$p(\\tau)\\simeq \\tau^{-3\u0026frasl;2} e^{-\\tau / \\tau_{0}}$$.\nin which $$\\tau_0 = \\frac{1}{\\mu (1-\\sqrt{\\rho})}$$, and $$\\rho = \\lambda / \\mu$$. Recall that $$\\lambda$$ is the arrival rate of new task, and $$\\mu$$ is the response rate , thus $$\\rho$$ is the task/job/traffic intensity.\n Subcritical regime: When $$\\rho$$ \u0026lt; 1, there are fewer job, and more queuing space. Critical regime: When $$\\rho$$ = 1, arrival rate equals response rate Supercritical regime: When $$\\rho$$ \u0026gt; 1, there are more job, and less queuing space.  However, they also find that the interevent time distribution between two consecutive transactions made by a stock broker. The distribution follows a power law with the exponential cutoff $$p(\\tau)\\simeq \\tau^{-1.3} e^{-\\tau / \\tau_{0}}$$.\n####References\nMartínez-Mekler G, Martínez RA, del Río MB, Mansilla R, Miramontes P, et al. (2009) Universality of Rank-Ordering Distributions in the Arts and Sciences. PLoS ONE 4(3): e4791. doi:10.1371/journal.pone.0004791\nWu L, Zhang J. (2011) Accelerating growth and size-dependent distribution of human online activities. PHYSICAL REVIEW E 84, 026113 (2011)\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0643a8ae6f1817e2deff2fc05bd633fe","permalink":"https://chengjunwang.com/post/en/2014-03-17-fit-power-law/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-03-17-fit-power-law/","section":"post","summary":"The long-tail distribution can be quantified in primarily three ways, see Newman \u0026rsquo;s paper here:\n Power law distribution Zipf distribution Pareto distribution  Here, I talk about the Zipf distribution which assesses the relationship between rank order and Frequency (probability).\n Zipf\u0026rsquo;s law now refers more generally to frequency distributions of \u0026laquo;rank data,\u0026raquo; in which the relative frequency of the nth-ranked item is given by the Zeta distribution. from Wikipedia","tags":null,"title":"Fitting rank order distribution with R","type":"post"},{"authors":null,"categories":null,"content":" We know that the most simple network is the regular network, such as the ring network. If all the edges in a network are generated randomly, we can get a random graph or Erdos-Renyi network (ER network).\nErdős–Rényi Random Graph model  The Erdős–Rényi model, named for Paul Erdős and Alfréd Rényi, is used for generating random graphs in which edges are set between nodes with equal probabilities.\n There is a continuous shift between randomness and regularity. What are the networks between random network and regular networks?\nWatts-Strogatz Small World model  The Watts and Strogatz model is a random graph generation model that produces graphs with small-world properties. An initial lattice structure is used to generate a Watts-Strogatz model. Each node in the network is initially linked to its k closest neighbors. Another parameter is specified as the rewiring probability. Each edge has a probability p that it will be rewired to the graph as a random edge.\n Barabási–Albert (BA) Preferential Attachment model  The Barabási–Albert model is a random network model used to demonstrate a preferential attachment or a \u0026laquo;rich-get-richer\u0026raquo; effect. In this model, an edge is most likely to attach to nodes with higher degrees. The network begins with an initial network of m nodes. m ≥ 2 and the degree of each node in the initial network should be at least 1, otherwise it will always remain disconnected from the rest of the network.\nIn the BA model, new nodes are added to the network one at a time. Each new node is connected to m existing nodes with a probability that is proportional to the number of links that the existing nodes already have.\n We can use igraph to play the network games, and explore the properties of generated networks.\n igraph is an open source C library for the analysis of large-scale complex networks, with interfaces to R, Python and Ruby.\n Here is the R script for generating and visualizing networks.\nlibrary(igraph) g1 \u0026lt;- graph.ring(500) g2 \u0026lt;- erdos.renyi.game(500, 0.0035) g3 \u0026lt;- rewire.edges( g1, prob = 0.5 ) g4 \u0026lt;- barabasi.game(500) # 保存图片格式 png(\u0026quot;d:/network_game.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) # 绘制图片 par(mfrow=c(2,2)) plot(g1, vertex.label= NA, edge.arrow.size=0.02,vertex.size = 0.5, xlab = \u0026quot;Ring Network\u0026quot;) plot(g2, vertex.label= NA, edge.arrow.size=0.02,vertex.size = 0.5, xlab = \u0026quot;Random Network\u0026quot;) plot(g3, vertex.label= NA, edge.arrow.size=0.02,vertex.size = 0.5, xlab = \u0026quot;Small World Network\u0026quot;) plot(g4, vertex.label= NA, edge.arrow.size=0.02,vertex.size = 0.5, xlab = \u0026quot;Scale-free Network\u0026quot;) # 结束保存图片 dev.off()  Of courese, there are other network games in the library of igraph, such as the game of forest fire.\ng5 \u0026lt;- forest.fire.game(200, fw.prob=0.37, bw.factor=0.32/0.37) plot(g5, vertex.label= NA, edge.arrow.size=0.02,vertex.size = 0.5)  References\nhttp://en.wikipedia.org/wiki/Network_science#Network_models\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9fc25494a632e3020cafaaa72ddc4051","permalink":"https://chengjunwang.com/post/en/2013-08-12-generating-networks-with-igraph/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-08-12-generating-networks-with-igraph/","section":"post","summary":"We know that the most simple network is the regular network, such as the ring network. If all the edges in a network are generated randomly, we can get a random graph or Erdos-Renyi network (ER network).\nErdős–Rényi Random Graph model  The Erdős–Rényi model, named for Paul Erdős and Alfréd Rényi, is used for generating random graphs in which edges are set between nodes with equal probabilities.\n There is a continuous shift between randomness and regularity.","tags":null,"title":"Generating networks with igraph","type":"post"},{"authors":null,"categories":null,"content":"##\nI have made a dzslides from a markdown file using pandoc, and then I want to archive and present it on octopress. Check the result to learn about how to make simple slides using pandoc here.\nThe mechanism of octopress is a little bit inflexible.\nBasicially, we generate markdown files in the directory of _posts:\nrake new_post[\u0026quot;the title of your post\u0026quot;]  and then we transform the markdown files to html placed in the dirctory of public.\nrake generate  After that, we deploy the html files to the server.\nrake deploy  Thus, accordingly, the solution is given as following:\nFirst, we make a slides folder in the source directory, e.g., \u0026laquo;octopress/source/slides/\u0026raquo;, and put the html of slide into this folder.\nSecond, we generate the file to the public folder and deploy the html file to the server.\nrake generate rake deploy  You can open the slides directly with the url: http://chengjun.github.io/slides/pandoc-slides\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b71e7863e16818851b2de2e8ddb2d3fc","permalink":"https://chengjunwang.com/post/en/2013-08-06-present-pandoc-slides-on-octopress/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-08-06-present-pandoc-slides-on-octopress/","section":"post","summary":"##\nI have made a dzslides from a markdown file using pandoc, and then I want to archive and present it on octopress. Check the result to learn about how to make simple slides using pandoc here.\nThe mechanism of octopress is a little bit inflexible.\nBasicially, we generate markdown files in the directory of _posts:\nrake new_post[\u0026quot;the title of your post\u0026quot;]  and then we transform the markdown files to html placed in the dirctory of public.","tags":null,"title":"Hosting pandoc slides on Octopress","type":"post"},{"authors":null,"categories":null,"content":" The epidemic model is another intellectual source for information diffusion research. The first known mathematical model of epidemiology is formulated by Daniel Bernoulli (1760) when he studied the mortality rates in order to eradicate the smallpox. However, it was not until the early twentieth century that deterministic modeling of epidemiology started. Ross (1911) developed differential equation models of epidemics in 1911. Later, Kermack and McKendrick (1927) found the epidemic threshold and they argued that the density of susceptible must exceed a critical value to make the outbreak of an epidemic happen.\nThe mathematical models developed by epidemic research help clarify assumptions, variables, and parameters for diffusion research, lead to useful concepts (e.g., threshold, reproduction number), supply an experimental tool for testing theoretical conjectures, and forecast epidemic spreading in the future (Hethcote, 2009). Although epidemic models are simplifications of reality, they help us refine our understandings about the logic of diffusion beneath social realities (disease transmission, information diffusion through networks, and adoption of new technologies or behaviors). To understand the epidemic models in a better way, I will briefly review the basic epidemic models: SI, SIR, SIS, and the applications in networks.\nSI model The SI model is the simplest possible model of infection. In the SI model, there are only two phases in the SI epidemic spreading process: Susceptible and Infectious. Let S be the proportion of the population that are susceptible. Let I be the proportion of the population that are infectious. At the initial time, the proportion of people who are infected is x0, the proportion of people who are susceptible is S0. β is the transmission rate, and it incorporates the encounter rate between susceptible and infectious individuals together with the probability of transmission. Consider a “closed population” with no births, deaths, or migrations, and assume the mixing is homogeneous (e.g., the susceptible individuals are uniformly spread in a geographic area, and the probability of contracting the infection is uniformly the same for all actors (T. G. Lewis, 2011)), yielding βSI as the transmission term. Thus, the equation for SI model is:\n dS/dt= -βSI dI/( dt)= βSI  Given every individual in the system must be either susceptible or infected, I + S = 1. Thus, the equations above can be transformed to:\n dI/dt=βI(1-I)  To solve this differential equation, we can get the cumulative growth curve as a function of time:\n$$I[t]= \\frac{x{0} e^{\\beta t }}{1-x{0}+ x_{0} e^{\\beta t }}$$\nInterestingly, this is a logistic growth featured by its S-shaped curve. $$$x_{0}$$ is the initial value of I[t]. The curve grows exponentially shortly after the system is infected, and then saturates as the number of susceptible shrinks which makes it harder to find the next victims. Thus, it could be used to model the classic diffusion of innovations. In the naive model of SI, once one is infected, it is always infectious. However, this is not realistic for many situations of disease spreading. For many diseases, people recover after a certain time because their immune systems act to fight with the diseases. There is usually a status of recovery denoted by R. Let γ denote the removal or recovery rate. Usually, researchers are more interested in its reciprocal (1/γ) which determines the average infectious period.\nSIR model There are two stages of the dynamics of the SIR model. In the first stage, susceptible individuals become infected by the infectious ones with who they contact. Similar to the SI model, β is the transmission rate between individuals; In the second stage, infected individuals recover at the average rate γ. Given the premise that underlying epidemiological rates are constant, the differential equations of simple SIR model (with no births, deaths, or migrations) are:\n dS/dt= -βSI dI/( dt)= βSI- γI dR/dt= βI  However, the differential equations above could not be analytically solved. In practice, researchers can evaluate SIR model numerically, as it is showed in the figure below.\n# -*- coding: utf-8 -*- ################################### ### Written by Ilias Soumpasis # ### ilias.soumpasis@ucd.ie (work) # ### ilias.soumpasis@gmail.com # ################################### import scipy.integrate as spi import numpy as np import pylab as pl beta=1.4247 gamma=0.14286 TS=1.0 ND=70.0 S0=1-1e-6 I0=1e-6 INPUT = (S0, I0, 0.0) def diff_eqs(INP,t): '''The main set of equations''' Y=np.zeros((3)) V = INP Y[0] = - beta * V[0] * V[1] Y[1] = beta * V[0] * V[1] - gamma * V[1] Y[2] = gamma * V[1] return Y # For odeint t_start = 0.0; t_end = ND; t_inc = TS t_range = np.arange(t_start, t_end+t_inc, t_inc) RES = spi.odeint(diff_eqs,INPUT,t_range) print RES #Ploting pl.plot(RES[:,0], '-bs', label='Susceptibles') # I change -g to g-- # RES[:,0], '-g', pl.plot(RES[:,2], '-g^', label='Recovereds') # RES[:,2], '-k', pl.plot(RES[:,1], '-ro', label='Infectious') pl.legend(loc=0) pl.title('SIR epidemic without births or deaths') pl.xlabel('Time') pl.ylabel('Susceptibles, Recovereds, and Infectious') pl.savefig('2.1-SIR-high.png', dpi=900) # This does, too pl.show()  SIS model Another extension of the SI model is the one that allows for reinfection. If infected individuals are not immune to the diseases after their recovery, they can be infected more than once. The most simple model that captures this features is the SIS model. There are only two states: susceptible and infected, and infected individuals become susceptible after recovery. The differential equations for the simple SIS epidemic model are: dS/dt= γI-βSI dI/( dt)= βSI- γI\nGiven S + I = 1, the differential equations have the solution:\n$$I[t]=(1-\\frac{\\gamma}{\\beta}) \\frac{C e^{(\\beta - \\gamma)t}}{1 + C e^{(\\beta - \\gamma)t}}$$\nC is the integration constant in the form of $$C=\\frac{ \\beta x{0}}{\\beta-\\gamma-\\beta x{0}} $$.\n# -*- coding: utf-8 -*- import scipy.integrate as spi import numpy as np import pylab as pl beta=1.4247 gamma=0.14286 I0=1e-6 ND=70 TS=1.0 INPUT = (1.0-I0, I0) def diff_eqs(INP,t): '''The main set of equations''' Y=np.zeros((2)) V = INP Y[0] = - beta * V[0] * V[1] + gamma * V[1] Y[1] = beta * V[0] * V[1] - gamma * V[1] return Y # For odeint t_start = 0.0; t_end = ND; t_inc = TS t_range = np.arange(t_start, t_end+t_inc, t_inc) RES = spi.odeint(diff_eqs,INPUT,t_range) print RES #Ploting pl.plot(RES[:,0], '-bs', label='Susceptibles') pl.plot(RES[:,1], '-ro', label='Infectious') pl.legend(loc=0) pl.title('SIS epidemic without births or deaths') pl.xlabel('Time') pl.ylabel('Susceptibles and Infectious') pl.savefig('2.5-SIS-high.png', dpi=900) # This does increase the resolution. pl.show()  One important contribution of epidemic models is the threshold phenomenon of epidemic diffusion existing in SIR model. The threshold of SIR model asks what factors determine whether an epidemic occur or fail. As the first step of analyzing the threshold of SIR model, the differential equation of SIR (dI/dt= βSI- βI) can be rewritten in the form:\ndI/( dt)=(βS - β)I\nIf dI/dt is smaller than 0, the contagion will soon wither and die out. Thus, as a boundary condition, $$(\\beta S- \\gamma)$$ should be larger than 0, and S should be larger than γ/β. This is the threshold phenomenon (Kermack \u0026amp; McKendarick, 1927). Based on the rationales above, if the initial fraction of susceptible (S(0)) is less than γ/β, the infection would not be able to start the invasion in the population. Here γ/β is defined as basic reproductive ratio $$R_{0}$$.\nTo summarize, “for an infectious disease with an average infectious period give by 1/γ and a transmission rate β, its basic reproductive ratio R0 is determined by γ/β. In a closed population, an infection with a specified R0 can invade only if there is a threshold fraction of susceptible greater than 1/γ ” (Keeling \u0026amp; Rohani, 2011, p. 21).\n###The Other Extentions? In the section above, I mainly focus on the deterministic models of epidemics. However, despite the many advantages of deterministic models, it can be difficult to include realistic population networks, to incorporate realistic probability distributions for the time spent in the infectious period, and to assess the probability of an outbreak. Thus, the stochastic epidemic simulations, such as stochastic differential equations, Markov Chain Monte Carlo (MCMC), and agent based modeling, have been used to remedy the defect.\nNetwork epidemic models have also been developed to investigate the widespread and rapid propagations (e.g., the contagion of computer virus) through a network. Typically, the network epidemic is brought about by adjacent nodes through propagations along one or more links. Network epidemic models consider the topology of the network as well as infection rate, death rate, and state transitions. This line of research is interested in the following questions: under what conditions will an initial outbreak spread to a nontrivial portion of the population? What percentage of the population will eventually become infected? What is the effect of immunization policies? For example, Pastor-Satorras et al. (2001a, 2001b) study the spreading of epidemics in complex networks using the mean-field method for network SIS model. Their findings indicate that in exponential networks (e.g., random graph network, small-world network), there is the usual epidemic threshold below which there is no prevalence of epidemic. Yet, on a wide range of scale-free networks, there is an absence of an epidemic threshold, which implies that scale-free networks are prone to the spreading of epidemics, as well as other spreading phenomena, e.g., information diffusion. Based on this rationale of the absence of epidemic threshold, network scientists expect online information diffuse to a great proportion of the population.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7a22b30874cbd1094a1b608fbb93ec91","permalink":"https://chengjunwang.com/post/en/2013-03-14-learn-basic-epidemic-models-with-python/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-03-14-learn-basic-epidemic-models-with-python/","section":"post","summary":"The epidemic model is another intellectual source for information diffusion research. The first known mathematical model of epidemiology is formulated by Daniel Bernoulli (1760) when he studied the mortality rates in order to eradicate the smallpox. However, it was not until the early twentieth century that deterministic modeling of epidemiology started. Ross (1911) developed differential equation models of epidemics in 1911. Later, Kermack and McKendrick (1927) found the epidemic threshold and they argued that the density of susceptible must exceed a critical value to make the outbreak of an epidemic happen.","tags":null,"title":"Learning basic epidemic models with Python","type":"post"},{"authors":null,"categories":null,"content":" My ideal career path is to work in a research university where I can continue my on-going study of opinion dynamics, and to share my understanding of computational communication (e.g. human online behavior, network science, and data journalism).\nComputational Communication (CC) Computational communication is part of computational social science (pdf). Computational communication emphasizes the importance of computational thinking in both theory-building and method-development. Network science, natural language processing, as well as the agent-based modeling methods opened a new door to the development of human communication research. The increasingly widely used machine learning techniques enriched our understanding about how we can understand the outside world in an efficient way. Further, there are mainly two applications of computational communication in the industry, including both computational advertising and data journalism. Put them together, we get a brand new framework for communication research.\nComputability and Research\nI have drafted one article to outline the emerging framework of computational communication (In Chinese,click here to read).\nTo embrace the trend of “Computational Communication”, we have organized one google group to discuss issues relate with data crawling, analyzing, and visualization using various programming tools (Click here to see the google group).\nResearch “Truth is ever to be found in simplicity, and not in the multiplicity and confusion of things.” (Issac Newton)\n“Any intelligent fool can make things bigger, more complex, and more violent. It takes a touch of genius and a lot of courage to move in the opposite direction.” (Einstein)\nSocial events are thought to be too complex to capture the nature since there are too many competing mechanisms. However, it should not be used as the excuse of giving up finding the universal law. We live on our digital traces, and further human dynamics \u0026amp; Internet make it possible to quantify the human behaviors in general, and communication behavior in specific.\nSandglass metaphor My understanding of study could be described as a sandglass metaphor. Metaphor serves as the structure of comparison. Just like the sandglass, academic study start with a broad topic which is always a specific and significant puzzlement. Gradually, scholars should narrow down the research topic to draw your study on a general but significant theoretical issue, and to investigate it with a new perspective. Eventually, you can handle the research question which has important theoretical implications. While, this part of logic is corresponding to the introduction part and literature part.\nWhen you have finished your finding part, you should head towards the discussion part. Despite of justifying the expected and unexpected result of your findings, the most important part of discussion is to generalize your findings by talking with prior relevant findings, propositions and established theories. Following this line of logic, the conclusion is only a natural part of this conversation.\nIt’s helpful to understand the pyramid with the pyramid of scientific research on gravitation. Human beings had be curious about the earth’s position in the university. The overall framework of gravitation supplies a good example about the levels of research in science.\nThe ladder of gravitation theories\nAlthough there are significant difference between social science and natural science (here humanity is not discussed, the readers can refer to computational humanity for more information), there are more similarities in the fundamental understandings about the basic logic of knowledge.\nHere, I strongly recommend readers to watch the lecture given by Richard Feynman, which is titled The Character of Physical Law – Part 1 The Law of Gravitation\nAccordingly, we argues that, there are five levels of science: data, pattern, law, mechanism, and principle. Then you may ask, where is theory?\nTheory is a contemplative and rational type of abstract or generalizing thinking, or the results of such thinking. Depending on the context, the results might for example include generalized explanations of how nature works, or even how divine or metaphysical matters are thought to work. The word has its roots in ancient Greek, but in modern use it has taken on several different related meanings. (Cited from Wikipedia)\n“Scientific theories are the most reliable, rigorous, and comprehensive form of scientific knowledge.” It’s how observers look at the outside world. According to Kant’s idea, human beings give orders to the whole universe (aka 人类为自然立法). In the pyramid of science, theory is about the pattern, law, mechanism, and principle which is based on the data (either empirical or simulated).\nThe pyramid of science\nTeaching As a junior faculty member, I plan to teach some introductory courses on basic statistics, network analysis. To be specific, I want to teach three courses, both theoretical and practical.\nFirst, writing for ssci journals. The idea comes from CC Lee’s class, in which he enlighten me to write in a logical way. The practice works for everybody. Even you have been a senior professor, or you are just a phd students who learnt little about the tradition of research. I was inspired to share my understanding of how to construct the structure of the paper, and how to polish it to get published.\nSecond, I want to teach social network analysis for both the theory and the application. There isn’t a steep threshold, so it could be attended for everyone. However, for the undergraduate, I will focus on the applications. While for the graduate students, I will put emphasis on theory.\nThird, I want to give a class of market research in the perspective of media analysis, which will focus on the method of data collection, data analysis, and strategy consultation.\nTeaching Philosophy Teaching is one process of self-presentation, through which you represent the long-living knowledge of human kind. It really matters what you are thinking about your teaching philosophy. For me, according to my understandings of teaching, I would like to highlight the equality of teaching and learning, the nature of human beings, and being open-minded.\n####Skinner Box - Everyone is equal\nRespect Your Audience. A good lesson I learnt from this class come with a question: what should you do when your students did a good job? If not, what will you do? Reflect about the answer. Do you want to reward or punish them? Remember your answer in heart.\nI would like to introduce Skinner’s box invented by Frederic Skinner, which contains levers that an animal can press, stimulus lights, electric grid, and food pellet. Following the logic of behaviorism, when the subject correctly performs the behavior, the chamber mechanism delivers food or another reward. Or else, the box delivers a punishment for incorrect or missing responses.\nThus, you may realize that you are treating your students as passive experimental subjects. The beginning point is never to treat your students as experimental rats, and even animals deserve your respects. Students are human beings who have their own feelings, emotions, and values. The first step of teaching should be to learn to respect your audiences, even though they behave passively, or make no progress.\n Understanding human nature  Effective teaching is to impose a set of values \u0026amp; beliefs on the student. The most important part should be teaching the students how to learn. The best way of learning should be acting according to the nature of human beings. Everyone had been a curious kid who wanted to explore every part of the world. Just like the cat is curious about the fish (sometime, for eating, while sometimes just for fun), human beings, in the nature, are curious about the part of knowledge they are interested in. The second step of effective teaching should be inspiring your students to fulfill their interests in the learning process.\nI was always not surprised about the story of Thomas Suarez, the 12 years old kid who made two iphone Apps by learning python, java, and c. Little Thomas has been fascinated by computers and technology before kindergarten. What the teacher should think is how could we contribute to the audiences’ real interests, rather than beat around the bush complaining why the students have no passion in the boring class.\n Being Open-minded  The world is always changed by new comers. The teacher will finally find his or her understandings about the cutting-edge scientific study are not perfect. The best way is not to constrain the students from challenging the tradition. Being open-minded, sit down, and enjoy the new outline drawn by the young people.\nMy motto is “follow your logic”, which is a rational approach working in most parts of my life, especially in my academic career. The most important part of research is the logic which determines your research method and your theoretical work.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e04385767ae8cb78cb7afa5cf233564","permalink":"https://chengjunwang.com/post/en/2014-04-06-vison-statement/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-04-06-vison-statement/","section":"post","summary":"My ideal career path is to work in a research university where I can continue my on-going study of opinion dynamics, and to share my understanding of computational communication (e.g. human online behavior, network science, and data journalism).\nComputational Communication (CC) Computational communication is part of computational social science (pdf). Computational communication emphasizes the importance of computational thinking in both theory-building and method-development. Network science, natural language processing, as well as the agent-based modeling methods opened a new door to the development of human communication research.","tags":null,"title":"My vision statement","type":"post"},{"authors":null,"categories":null,"content":"Githubarchive整理了github的历史数据，每一个小时一个数据文件，我下载了2011-2014年四年的数据，结果发现2012年的多数数据存在错误换行的问题，需要清洗。一般而言，正确的情况是一个字典格式的数据占一行，错误的情况就会是所有的字典格式的数据合并为了一行。似乎是缺乏换行符造成的。\nhttp://stackoverflow.com/questions/10432432/yajl-parse-error-with-githubarchive-org-json-stream-in-python# 这里详细记录了这个问题。\n按照这个帖子，我尝试了很多方法，yajl和ijson，但是都不能很优雅的解决我的问题。不妨采用暴力的方法。\nrirwin利用了{和}出现的偶数关系来分割字符串，但是这种方法容易遗漏数据且速度较慢。\n仔细思考这个问题就是：Parse multiple json objects that are in one line。 搜索之，发现了http://stackoverflow.com/questions/36967236/parse-multiple-json-objects-that-are-in-one-line\n其中，Francesco的解决方法比较高效：\nf = '/Users/chengjun/百度云同步盘/githubarchive/2012-03-10-22.json.gz' f = gzip.open(f, 'rb') f = f.readline() r = re.split('(\\{.*?\\})(?= *\\{)', f) accumulator = '' res = [] for subs in r: accumulator += subs try: res.append(json.loads(accumulator)) accumulator = '' except: pass len(res)   Out [29]: 1270\n 基于这种方法，可以写一个函数来实现对于数据的正确读取。\n#f = '/Users/chengjun/百度云同步盘/test.json' #f = open(f) f = '/Users/chengjun/百度云同步盘/githubarchive/2012-06-01-15.json.gz' f = gzip.open(f, 'rb') files = f.readlines() length = len(files) if length \u0026gt; 1: print 'Correct: ' + str(length) else: f2 = files[0] r = re.split('(\\{.*?\\})(?= *\\{)', f2) r = [i for i in r if i] # delete the '' accumulator = '' acts = [] for subs in r: accumulator += subs try: acts.append(json.loads(accumulator)) accumulator = '' except Exception, e: print e pass print 'Wrong: ' + str(len(acts))   Out [30]: Wrong: 4491\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7fe81abfc59eda6e7e593737d26e7562","permalink":"https://chengjunwang.com/zh/archive/2016-06-18-parsing-githubarchive-json.zh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/archive/2016-06-18-parsing-githubarchive-json.zh/","section":"zh","summary":"","tags":null,"title":"Parsing Githubarchive Data using Python","type":"zh"},{"authors":null,"categories":null,"content":"To visualize the regression coefficient is very useful. There are at least to packages (arm, coefplot) devoted to this purpose. However, both them are not beautiful enough, compared with the effect of boxplot.\nI refer to the R script written by Carlisle Rainey. What I do is to add rectangles and vertical line into the plot made by Carlisle Rainey.Please refer to this post for more information: http://www.carlislerainey.com/2012/06/30/coefficient-plots-in-r/\nFigure 1 Plot with rectangles and vertical lines\nHere is the R script:\nlibrary(arm) library(alr3) # load the alr3 package (contains data set for illustration) data(highway) # load the highway data set from alr3 d \u0026lt;- highway # call the data set d for convenience m \u0026lt;- lm(Rate ~ Lwid + Shld + Lane + Len + ADT + Trks, data = d) # estimate the normal linear model ## create a vector to store the variable names var.names \u0026lt;- c(\u0026quot;lane width, in feet\u0026quot;, \u0026quot;width in feet of outer\\nshoulder on the roadway\u0026quot;, \u0026quot;total number of lanes\\nof traffic\u0026quot;, \u0026quot;length of the highway\\nsegment in miles\u0026quot;, \u0026quot;average daily traffic\\ncount in thousands\u0026quot;, \u0026quot;truck volume as a percent\\nof the total volume\u0026quot;) ## set up the plot region: plot(c(100, 250), c(300, 450), type = \u0026quot;n\u0026quot;) rect(120,300, 180, 305, col=rainbow(11, start=.7,end=.1)) ## Plot Labels outside graph # set the graphical parameters par( family = \u0026quot;serif\u0026quot;, # I don't plot in anything but serif oma = c(0,0,0,0), # Since it is a single plot, I set the outer margins to zero. mar = c(5,10,4,2) # Inner margins are set through a little trial and error. ) # create an empty plot for total customization plot(NULL, # create empty plot xlim = c(-2, 2), # set xlim by guessing ylim = c(.7, length(var.names) + .3), # set ylim by the number of variables axes = F, xlab = NA, ylab = NA) # turn off axes and labels # add the data est \u0026lt;- coef(m)[-1] # conveniently store the estimates (minus the constant) se \u0026lt;- sqrt(diag(vcov(m)))[-1] # conveniently store the std. errors (minus the constant) for (i in 1:length(est)) { # loop over a counter the length of the estimate vector points(est[i], i, pch = 3, cex = .5) # add the points to the plot points(est[i]+ 1.64*se[i], i, pch = \u0026quot;|\u0026quot;, cex = 1.5) ## add the verticle lines points(est[i]- 1.64*se[i], i, pch = \u0026quot;|\u0026quot;, cex = 1.5) ## add the verticle lines lines(c(est[i] + 1.64*se[i], est[i] - 1.64*se[i]), c(i, i), ) # add the 90% confidence intervals rect(est[i] + .67*se[i],i-0.1, est[i]- .67*se[i], i+0.1, col=\u0026quot;#0000ff22\u0026quot;) ## add rectancles to present 50% confidence intervals text(-2.9, i, var.names[i], xpd = T, cex = .8) # add the variable names } # add axes and labels axis(side = 1) # add bottom axis abline(v = 0, lty = 3, col = \u0026quot;grey\u0026quot;) # add verticle line mtext(side = 1, \u0026quot;Linear Regression Coefficient\u0026quot;, line = 3) # label bottom axis mtext(side = 3, \u0026quot;Linear Regression Model of\\n the Accident Rate per Million Vehicle Miles\u0026quot;, line = 1) # add title box()  {:lang=\u0026laquo;ruby\u0026raquo;}\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"125c3a36d6fea611075662b5ce83a8ce","permalink":"https://chengjunwang.com/post/en/2013-08-16-plot-regression-coefficient-with-r/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-08-16-plot-regression-coefficient-with-r/","section":"post","summary":"To visualize the regression coefficient is very useful. There are at least to packages (arm, coefplot) devoted to this purpose. However, both them are not beautiful enough, compared with the effect of boxplot.\nI refer to the R script written by Carlisle Rainey. What I do is to add rectangles and vertical line into the plot made by Carlisle Rainey.Please refer to this post for more information: http://www.carlislerainey.com/2012/06/30/coefficient-plots-in-r/\nFigure 1 Plot with rectangles and vertical lines","tags":null,"title":"Plot regression coefficient with R","type":"post"},{"authors":null,"categories":null,"content":"Recoding variables is fairly easy in R. Here I summarize three appoaches and recommend the first one to you.\n##1.List slicing\nThe method of list slicing is the most convenient way to recode a variable.\n x = 1:10 x[x == 1] = 0 x[x \u0026gt; 1 \u0026amp; x \u0026lt; 6] = 1 x[x \u0026gt;= 6] = 3 \u0026gt; x \u0026gt; [1] 0 1 1 1 1 3 3 3 3 3 x[x == 1 | x == 0] = 4 \u0026gt; x \u0026gt; [1] 4 4 4 4 4 3 3 3 3 3  Here is another example to create 3 age categories\nattach(mydata) mydata$agecat[age \u0026gt; 75] \u0026lt;- \u0026quot;Elder\u0026quot; mydata$agecat[age \u0026gt; 45 \u0026amp; age \u0026lt;= 75] \u0026lt;- \u0026quot;Middle Aged\u0026quot; mydata$agecat[age \u0026lt;= 45] \u0026lt;- \u0026quot;Young\u0026quot; detach(mydata)  ##2.ifelse For dummy coding, ifelse function could be easily employed.\ntop$sportsEtc\u0026lt;-ifelse(top$category==\u0026quot;Animals\u0026quot; |top$category==\u0026quot;Autos\u0026quot; |top$category==\u0026quot;Games\u0026quot; |top$category==\u0026quot;People\u0026quot; |top$category==\u0026quot;Sports\u0026quot; |top$category==\u0026quot;Travel\u0026quot;, 1, 0)  ##3. Using the recode function in the car library\nTaking the example from recode in the car package\nlibrary(car) x \u0026lt;- rep(1:3, 3) \u0026gt; x [1] 1 2 3 1 2 3 1 2 3 newx \u0026lt;- recode(x, \u0026quot;c(1,2)='A'; else='B'\u0026quot;) \u0026gt; newx [1] \u0026quot;A\u0026quot; \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;A\u0026quot; \u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;A\u0026quot; \u0026quot;A\u0026quot; \u0026quot;B\u0026quot;  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4f330cb1e2d52fe7520d3d9f14bef98e","permalink":"https://chengjunwang.com/post/en/2013-08-14-recoding-in-r/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-08-14-recoding-in-r/","section":"post","summary":"Recoding variables is fairly easy in R. Here I summarize three appoaches and recommend the first one to you.\n##1.List slicing\nThe method of list slicing is the most convenient way to recode a variable.\n x = 1:10 x[x == 1] = 0 x[x \u0026gt; 1 \u0026amp; x \u0026lt; 6] = 1 x[x \u0026gt;= 6] = 3 \u0026gt; x \u0026gt; [1] 0 1 1 1 1 3 3 3 3 3 x[x == 1 | x == 0] = 4 \u0026gt; x \u0026gt; [1] 4 4 4 4 4 3 3 3 3 3  Here is another example to create 3 age categories","tags":null,"title":"Recoding variables in R","type":"post"},{"authors":null,"categories":null,"content":" Weibo Oauth2.0 I would like to introduce you how to use python to scrape tweets from Sina Weibo in this post.\nAutomatically get authorization by oauth2.0 First, following this webpage to set your app, especially to get the app key, app secret, and set the callback url. See an introduction.\nSecond, following this link, you can automatically get the code from the callback url.\nThe following python script demonstrates how to automatically get authorization.\n#!/usr/bin/env python # -*- coding: utf8 -*- from weibo import APIClient import urllib2 import urllib import sys import time from time import clock import csv import random reload(sys) sys.setdefaultencoding('utf-8') '''Step 0 Login with OAuth2.0''' if __name__ == \u0026quot;__main__\u0026quot;: APP_KEY = '663...' # app key APP_SECRET = '2fc....' # app secret CALLBACK_URL = 'https://api.weibo.com/oauth2/default.html' # set callback url exactly like this! AUTH_URL = 'https://api.weibo.com/oauth2/authorize' USERID = 'w...4' # your weibo user id PASSWD = 'w....' #your pw client = APIClient(app_key=APP_KEY, app_secret=APP_SECRET, redirect_uri=CALLBACK_URL) referer_url = client.get_authorize_url() print \u0026quot;referer url is : %s\u0026quot; % referer_url cookies = urllib2.HTTPCookieProcessor() opener = urllib2.build_opener(cookies) urllib2.install_opener(opener) postdata = {\u0026quot;client_id\u0026quot;: APP_KEY, \u0026quot;redirect_uri\u0026quot;: CALLBACK_URL, \u0026quot;userId\u0026quot;: USERID, \u0026quot;passwd\u0026quot;: PASSWD, \u0026quot;isLoginSina\u0026quot;: \u0026quot;0\u0026quot;, \u0026quot;action\u0026quot;: \u0026quot;submit\u0026quot;, \u0026quot;response_type\u0026quot;: \u0026quot;code\u0026quot;, } headers = {\u0026quot;User-Agent\u0026quot;: \u0026quot;Mozilla/5.0 (Windows NT 6.1; rv:11.0) Gecko/20100101 Firefox/11.0\u0026quot;, \u0026quot;Host\u0026quot;: \u0026quot;api.weibo.com\u0026quot;, \u0026quot;Referer\u0026quot;: referer_url } req = urllib2.Request( url = AUTH_URL, data = urllib.urlencode(postdata), headers = headers ) try: resp = urllib2.urlopen(req) print \u0026quot;callback url is : %s\u0026quot; % resp.geturl() code = resp.geturl()[-32:] print \u0026quot;code is : %s\u0026quot; % code except Exception, e: print e r = client.request_access_token(code) access_token1 = r.access_token # The token return by sina expires_in = r.expires_in print \u0026quot;access_token=\u0026quot; ,access_token1 print \u0026quot;expires_in=\u0026quot; ,expires_in # access_token lifetime by second. http://open.weibo.com/wiki/OAuth2/access_token \u0026quot;\u0026quot;\u0026quot;save the access token\u0026quot;\u0026quot;\u0026quot; client.set_access_token(access_token1, expires_in)  Get the number of retweets Step 1. Assume that you have had a list of tweet ids, you want to get the number of repsots. Thus, you can have the distribution of the size of diffusion.\n''' Step 1 Get the number of reposts''' \u0026quot;\u0026quot;\u0026quot;get the user ids\u0026quot;\u0026quot;\u0026quot; dataReader = csv.reader(open('C:/Python27/weibo/sampledRtIds2.csv', 'r'), delimiter=',', quotechar='|') ids = [] for row in dataReader: ids.append(int(row[0])) # modify the number to get the diffusers' ids file = open(\u0026quot;C:/Python27/weibo/repostsRT300000m2.csv\u0026quot;,'wb') # save to csv file start = clock() print start for seqNum in range(1500, 2999): id = ids[(0 + 100*seqNum) : (100+100*seqNum)] id = str(id).strip('[]').replace('L', '') rate = client.get.account__rate_limit_status() sleep_time = rate.reset_time_in_seconds + 300 remaining_ip_hits = rate.remaining_ip_hits remaining_user_hits = rate.remaining_user_hits if remaining_ip_hits \u0026gt;= 10 and remaining_user_hits \u0026gt;= 5: rtc = client.get.statuses__count(ids = id) # mid, 100 for n in range(0, len(rtc)): # 0-99 mid = rtc[n]['id'] reposts = rtc[n]['reposts'] comments = rtc[n]['comments'] attitudes = rtc[n]['attitudes'] timePass = clock()-start if round(timePass) % 10 == 0: print mid, reposts, len(rtc), \u0026quot;I have been working for %s seconds\u0026quot; % round(timePass) print \u0026gt;\u0026gt;file, \u0026quot;%s,%s,%s,%s\u0026quot; % (mid, reposts, comments, attitudes) elif remaining_ip_hits \u0026lt; 10 or remaining_user_hits \u0026lt; 5: print \u0026quot;Python will sleep %s seconds\u0026quot; % sleep_time time.sleep(sleep_time+60) file.close()  Get the list of diffusers Step 2. If you want to step further and get the list of diffusers for a list of weibos. Thus, you will know how many reposts or retweets have been deleted by the website.\n# '''Step 2 Get the diffusers''' \u0026quot;\u0026quot;\u0026quot;read ids\u0026quot;\u0026quot;\u0026quot; dataReader = csv.reader(open('C:/Python27/weibo/repostsSample3.csv', 'r'), delimiter=',', quotechar='|') ids = [] for row in dataReader: ids.append(int(row[1])) # get the number to get the mid addressForSavingData= \u0026quot;C:/Python27/weibo/diffsersSave.csv\u0026quot; file = open(addressForSavingData,'wb') # save to csv file start = clock() print start lenid = len(ids) # lenid = 8 # test with the first two cases for n in range(0, lenid+1): # the 78 should be 77 here rate = client.get.account__rate_limit_status() sleep_time = rate.reset_time_in_seconds + 300 remaining_ip_hits = rate.remaining_ip_hits remaining_user_hits = rate.remaining_user_hits if remaining_ip_hits \u0026gt;= 10 and remaining_user_hits \u0026gt;= 3: if reposts[n]%200 == 0: pages = reposts[n]/200 else: pages = reposts[n]/200 + 1 try: for pageNum in range(1, pages + 1): r = client.get.statuses__repost_timeline(id = ids[n], page = pageNum, count = 200) if len(r) == 0: pass else: m = int(len(r['reposts'])) for i in range(0, m): \u0026quot;\u0026quot;\u0026quot;1.1 reposts\u0026quot;\u0026quot;\u0026quot; mid = r['reposts'][i].id text = r['reposts'][i].text.replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;) created = r['reposts'][i].created_at \u0026quot;\u0026quot;\u0026quot;1.2 reposts.user\u0026quot;\u0026quot;\u0026quot; user = r['reposts'][i].user user_id = user.id user_name = user.name user_province = user.province user_city = user.city user_gender = user.gender user_url = user.url user_followers = user.followers_count user_bifollowers = user.bi_followers_count user_friends = user.friends_count user_statuses = user.statuses_count user_created = user.created_at user_verified = user.verified \u0026quot;\u0026quot;\u0026quot;2.1 retweeted_status\u0026quot;\u0026quot;\u0026quot; rts = r['reposts'][i].retweeted_status rts_mid = rts.id rts_text = rts.text.replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;) rts_created = rts.created_at \u0026quot;\u0026quot;\u0026quot;2.2 retweeted_status.user\u0026quot;\u0026quot;\u0026quot; rtsuser_id = rts.user.id rtsuser_name = rts.user.name rtsuser_province = rts.user.province rtsuser_city = rts.user.city rtsuser_gender = rts.user.gender rtsuser_url = rts.user.url rtsuser_followers = rts.user.followers_count rtsuser_bifollowers = rts.user.bi_followers_count rtsuser_friends = rts.user.friends_count rtsuser_statuses = rts.user.statuses_count rtsuser_created = rts.user.created_at rtsuser_verified = rts.user.verified timePass = clock()-start if round(timePass) % 10 == 0: print mid, rts_mid, \u0026quot;I have been working for %s seconds\u0026quot; % round(timePass) time.sleep( random.randrange(3, 9, 1) ) # To avoid http error 504 gateway time-out print \u0026gt;\u0026gt;file, \u0026quot;%s,'%s','%s',%s,'%s',%s,%s,%s,'%s',%s,%s,%s,'%s',%s,%s,'%s',%s,'%s',%s,%s,%s,'%s',%s,%s,%s,%s,%s\u0026quot; % (mid, created, text, # 3 # \u0026quot;%s,%s,|%s|,%s,|%s|,%s,%s,%s,|%s|,%s,%s,%s,%s,%s,%s,%s,%s,|%s|,%s,%s,%s,|%s|,%s,%s,%s,%s,%s\u0026quot; % (mid, created, text, # 3 user_id, user_name, user_province, user_city, user_gender, # 5 --\u0026gt; 5 user_url, user_followers, user_friends, user_statuses, user_created, user_verified, # rts_text, # 6 --\u0026gt; 9 rts_mid, rts_created, # 2 rtsuser_id, rtsuser_name, rtsuser_province, rtsuser_city, rtsuser_gender, # 5 --\u0026gt; 18 rtsuser_url, rtsuser_followers, rtsuser_friends, rtsuser_statuses, rtsuser_created, rtsuser_verified) # 6 --\u0026gt; 22 except Exception, e: print \u0026gt;\u0026gt; sys.stderr, 'Encountered Exception:', e, ids[n] time.sleep(120) pass elif remaining_ip_hits \u0026lt; 10 or remaining_user_hits \u0026lt; 3: print \u0026quot;Python will sleep %s seconds\u0026quot; % sleep_time time.sleep(sleep_time+60) file.close()  Get the following relationships Step 3. Now, you may want to get the social graph for all the diffusers.\n'''Step 3 Get the social graph''' \u0026quot;\u0026quot;\u0026quot;read ids\u0026quot;\u0026quot;\u0026quot; dataReader = csv.reader(open('C:/Python27/weibo/SocialGraphIdsForStepThree.csv', 'r'), delimiter=',', quotechar='|') ids = [] for row in dataReader: ids.append(int(row[0])) # get the number to get the mid ids = ids[188648:697060] addressForSavingData= \u0026quot;C:/Python27/weibo/socialgraphSave142_2.csv\u0026quot; file = open(addressForSavingData,'wb') # save to csv file addressForSavingError = \u0026quot;C:/Python27/weibo/socialgraphSaveError142_2.csv\u0026quot; errorlog = open(addressForSavingError,'w') errorlog.close() start = clock() print start for id in ids: try: rate = client.get.account__rate_limit_status() sleep_time = rate.reset_time_in_seconds + 300 remaining_ip_hits = rate.remaining_ip_hits remaining_user_hits = rate.remaining_user_hits if remaining_ip_hits \u0026gt;= 10 and remaining_user_hits \u0026gt;= 3: cursor = -1 fids=[] while cursor != 0: response = client.get.friendships__friends__ids(uid=id, count= 5000, cursor=cursor) # the biggest count is 5000 fids += response.ids cursor = response.next_cursor # previousCursor = response.previous_cursor timePass = clock()-start if round(timePass) % 10 == 0: print id, \u0026quot;I have been working for %s seconds\u0026quot; % round(timePass) # time.sleep( 0.01 * random.randrange(0, 5, 1) ) # To avoid http error 504 gateway time-out if cursor == 0: totalNum = response.total_number for fid in fids: print \u0026gt;\u0026gt;file, \u0026quot;%s,%s,%s\u0026quot; % (id, fid, totalNum) break elif remaining_ip_hits \u0026lt; 10 or remaining_user_hits \u0026lt; 3: print \u0026quot;Python will sleep %s seconds\u0026quot; % sleep_time time.sleep(sleep_time+60) except Exception, e: print \u0026gt;\u0026gt;sys.stderr, 'Encountered Exception:', e, id errorlog = open(addressForSavingError, 'a') print \u0026gt;\u0026gt;errorlog, \u0026quot;%s,%s\u0026quot; % (id, e) errorlog.close() print 'When the error happens, the id is:', id time.sleep(60) pass file.close()  Get the diffusion network Step 4. Given the collected data of retweets, we can get the diffusion path by parsing the text of weibo.\nimport re import sys from time import clock reload(sys) sys.setdefaultencoding('utf-8') ''' Convert \u0026quot;Thu Aug 04 11:39:32 +0800 2011\u0026quot; to the ISO format: YYYY-MM-DD H:M:S Refer to: http://stackoverflow.com/questions/15727510/using-python-regex-to-identify-retweeters-from-tweets-with-chinese-characters ''' file = open(\u0026quot;D:/chengjun/New/repostsReSampleClean.csv\u0026quot;, 'r') lines = file.readlines() addressForSavingData= \u0026quot;D:/chengjun/New/diffusion_path6.csv\u0026quot; file = open(addressForSavingData,'wb') # save to csv file addressForSavingError = \u0026quot;D:/chengjun/New/Error.csv\u0026quot; errorlog = open(addressForSavingError,'w') errorlog.close start = clock() print start for line in lines: list = line.split(',') rtsmid = list[15].strip() #rmid userName = list[5].strip().replace(\u0026quot;'\u0026quot;, \u0026quot;\u0026quot;) # username submitterName = list[18].strip().replace(\u0026quot;'\u0026quot;, \u0026quot;\u0026quot;) tweet = list[3].replace(',','') RTpattern = r'''//?@(\\w+)''' rt = re.findall(RTpattern, tweet.decode(\u0026quot;utf-8\u0026quot;), re.UNICODE) if rt == None or len(rt)==0: target = userName source = submitterName print \u0026gt;\u0026gt;file, \u0026quot;%s,%s,%s\u0026quot; % (rtsmid, source, target) elif rt != None and len(rt) != 0: rt.insert(0, userName) # for i in xrange(len(rt) - 1): target = rt[i].encode('utf-8') source = rt[i + 1].encode('utf-8') print \u0026gt;\u0026gt;file, \u0026quot;%s,%s,%s\u0026quot; % (rtsmid, source, target)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"963502689f5b5052c059c94cdbb86f07","permalink":"https://chengjunwang.com/post/en/2014-03-16-scraping-weibo-using-python/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-03-16-scraping-weibo-using-python/","section":"post","summary":"Weibo Oauth2.0 I would like to introduce you how to use python to scrape tweets from Sina Weibo in this post.\nAutomatically get authorization by oauth2.0 First, following this webpage to set your app, especially to get the app key, app secret, and set the callback url. See an introduction.\nSecond, following this link, you can automatically get the code from the callback url.\nThe following python script demonstrates how to automatically get authorization.","tags":null,"title":"Scraping data from Sina Weibo using Python","type":"post"},{"authors":null,"categories":null,"content":"I have read the blog post about Scraping New York Times Articles with R. It’s great. I want to reproduce the work with python. First, we should learn about nytimes article search api.\nhttp://developer.nytimes.com/docs/article_search_api/\nSecond, we need to register and get the key which will be used in python script.\nhttp://developer.nytimes.com/apps/register\n# !/usr/bin/env python # -*- coding: UTF-8 -*- # Scraping New York Times using python # 20120421@ Canberra # chengjun wang import json import urllib2 ''' About the api and the key, see the links above. ''' '''step 1: input query information''' apiUrl='http://api.nytimes.com/svc/search/v1/article?format=json' query='query=occupy+wall+street' # set the query word here apiDate='begin_date=20110901\u0026amp;end_date=20120214' # set the date here fields='fields=body%2Curl%2Ctitle%2Cdate%2Cdes_facet%2Cdesk_facet%2Cbyline' offset='offset=0' key='api-key=c2c5b91680.......2811165' # input your key here '''step 2: get the number of offset/pages''' link=[apiUrl, query, apiDate, fields, offset, key] ReqUrl='\u0026amp;'.join(link) jstr = urllib2.urlopen(ReqUrl).read() # t = jstr.strip('()') ts = json.loads( jstr ) number=ts['total'] # the number of queries # query=ts['tokens'] # result=ts['results'] print number seq=range(number/9) # this is not a good way print seq '''step 3: crawl the data and dump into csv''' import csv addressForSavingData= \u0026quot;D:/Research/Dropbox/tweets/wapor_assessing online opinion/News coverage of ows/nyt.csv\u0026quot; file = open(addressForSavingData,'wb') # save to csv file for i in seq: nums=str(i) offsets=''.join(['offset=', nums]) # I made error here, and print is a good way to test links=[apiUrl, query, apiDate, fields, offsets, key] ReqUrls='\u0026amp;'.join(links) print \u0026quot;*_____________*\u0026quot;, ReqUrls jstrs = urllib2.urlopen(ReqUrls).read() t = jstrs.strip('()') tss= json.loads( t ) # error no joson object result = tss['results'] for ob in result: title=ob['title'] # body=ob['body'] # body,url,title,date,des_facet,desk_facet,byline print title url=ob['url'] date=ob['date'] # desk_facet=ob['desk_facet'] # byline=ob['byline'] # some author names don't exist w = csv.writer(file,delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL) w.writerow((date, title, url)) # write it out file.close() pass  see the result:\nSimilarly, you can crawl the article data from The Guardian. See the link below.\nhttp://explorer.content.guardianapis.com/#/?format=json\u0026amp;order-by=newest\nAfter you have registered you app and got the key, we can work on the python script.\n# !/usr/bin/env python # -*- coding: UTF-8 -*- # Scraping The Guardian using Python # 20120421@ Canberra # chengjun wang import json import urllib2 ''' http://content.guardianapis.com/search?q=occupy+wall+street\u0026amp;from-date=2011-09-01\u0026amp;to-date=2012-02-14\u0026amp;page=2 \u0026amp;page-size=3\u0026amp;format=json\u0026amp;show-fields=all\u0026amp;use-date=newspaper-edition\u0026amp;api-key=m....g33gzq ''' '''step 1: input query information''' apiUrl='http://content.guardianapis.com/search?q=occupy+wall+street' # set the query word here apiDate='from-date=2011-09-01\u0026amp;to-date=2011-10-14' # set the date here apiPage='page=2' # set the page apiNum=10 # set the number of articles in one page apiPageSize=''.join(['page-size=',str(apiNum)]) fields='format=json\u0026amp;show-fields=all\u0026amp;use-date=newspaper-edition' key='api-key=mudfuj...g33gzq' # input your key here '''step 2: get the number of offset/pages''' link=[apiUrl, apiDate, apiPage, apiPageSize, fields, key] ReqUrl='\u0026amp;'.join(link) jstr = urllib2.urlopen(ReqUrl).read() # t = jstr.strip('()') ts = json.loads( jstr ) number=ts['response']['total'] # the number of queries # query=ts['tokens'] # result=ts['results'] print number seq=range(number/(apiNum-1)) # this is not a good way print seq '''step 3: crawl the data and dump into csv''' import csv addressForSavingData= \u0026quot;D:/Research/Dropbox/tweets/wapor_assessing online opinion/News coverage of ows/guardian.csv\u0026quot; file = open(addressForSavingData,'wb') # save to csv file for i in seq: nums=str(i+1) apiPages=''.join(['page=', nums]) # I made error here, and print is a good way to test links= [apiUrl, apiDate, apiPages, apiPageSize, fields, key] ReqUrls='\u0026amp;'.join(links) print \u0026quot;*_____________*\u0026quot;, ReqUrls jstrs = urllib2.urlopen(ReqUrls).read() t = jstrs.strip('()') tss= json.loads( t ) result = tss['response']['results'] for ob in result: title=ob['webTitle'].encode('utf-8') # body=ob['body'] # body,url,title,date,des_facet,desk_facet,byline print title section=ob[\u0026quot;sectionName\u0026quot;].encode('utf-8') url=ob['webUrl'] date=ob['fields']['newspaperEditionDate'] # date=ob['webPublicationDate'] # byline=ob['fields']['byline'] w = csv.writer(file,delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL) w.writerow((date, title, section, url)) # write it out file.close() pass  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1eb5582de1fd8d81c3e44b2002ee98d","permalink":"https://chengjunwang.com/post/en/2012-04-23-scraping-newyork-times-with-python/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2012-04-23-scraping-newyork-times-with-python/","section":"post","summary":"I have read the blog post about Scraping New York Times Articles with R. It’s great. I want to reproduce the work with python. First, we should learn about nytimes article search api.\nhttp://developer.nytimes.com/docs/article_search_api/\nSecond, we need to register and get the key which will be used in python script.\nhttp://developer.nytimes.com/apps/register\n# !/usr/bin/env python # -*- coding: UTF-8 -*- # Scraping New York Times using python # 20120421@ Canberra # chengjun wang import json import urllib2 ''' About the api and the key, see the links above.","tags":null,"title":"Scraping New York Times \u0026 The Guardian using Python","type":"post"},{"authors":null,"categories":null,"content":"I want to randomly sample twitter streams. Thus, i turn to the stream api of twitter.\n The set of streaming APIs offered by Twitter give developers low latency access to Twitter\u0026rsquo;s global stream of Tweet data. A proper implementation of a streaming client will be pushed messages indicating Tweets and other events have occurred, without any of the overhead associated with polling a REST endpoint.[from Twitter]\n Of course, as the first step, you should register the stream api on Twitter to get the consumer key, consumer secret, access key, and access secret.\nWith the help of tweepy package of Python, I tried the following scripts. So far it works pretty well.\n# Twitter API Crawler # -*- coding: utf-8 -*- ''' Author: chengjun wang Email: wangchj04@gmail.com Hong Kong, 2013/01/20 ''' import sys import tweepy import codecs from time import clock '''OAuth Authentication''' consumer_key=\u0026quot;xcEI4sb...fi6AzBQ\u0026quot; consumer_secret=\u0026quot;5nfeG8...jUX8nU2pafr4hU\u0026quot; access_token=\u0026quot;37595783-Fazh...8fPaH5IaTlz7y\u0026quot; access_token_secret=\u0026quot;fyqUf5...YijKwvQe3I\u0026quot; auth1 = tweepy.OAuthHandler(consumer_key, consumer_secret) auth1.set_access_token(access_token, access_token_secret) api = tweepy.API(auth1) ''' # Note: Had you wanted to perform the full OAuth dance instead of using # an access key and access secret, you could have uses the following # four lines of code instead of the previous line that manually set the # access token via auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET). # auth_url = auth.get_authorization_url(signin_with_twitter=True) # webbrowser.open(auth_url) # verifier = raw_input('PIN: ').strip() # auth.get_access_token(verifier) ''' file = open(\u0026quot;C:/Python27/twitter/mydata6.csv\u0026quot;,'wb') # save to csv file print api.me().name # api.update_status('Updating using OAuth authentication via Tweepy!') start = clock() print start '''Specify the stream''' class StreamListenerChengjun(tweepy.StreamListener): def on_status(self, status): try: tweet = status.text.encode('utf-8') tweet = tweet.replace('\\n', '\\\\n') user = status.author.screen_name.encode('utf-8') userid = status.author.id time = status.created_at source = status.source tweetid = status.id timePass = clock()-start if timePass%60==0: print \u0026quot;I have been working for\u0026quot;, timePass, \u0026quot;seconds.\u0026quot; if not ('RT @' in tweet) : # Exclude re-tweets print \u0026gt;\u0026gt;file, \u0026quot;%s,%s,%s,%s,|%s|,%s\u0026quot; % (userid, user, time, tweetid, tweet, source) except Exception, e: print \u0026gt;\u0026gt; sys.stderr, 'Encountered Exception:', e pass def on_error(self, status_code): print 'Error: ' + repr(status_code) return True # False to stop def on_delete(self, status_id, user_id): \u0026quot;\u0026quot;\u0026quot;Called when a delete notice arrives for a status\u0026quot;\u0026quot;\u0026quot; print \u0026quot;Delete notice for %s. %s\u0026quot; % (status_id, user_id) return def on_limit(self, track): \u0026quot;\u0026quot;\u0026quot;Called when a limitation notice arrvies\u0026quot;\u0026quot;\u0026quot; print \u0026quot;!!! Limitation notice received: %s\u0026quot; % str(track) return def on_timeout(self): print \u0026gt;\u0026gt; sys.stderr, 'Timeout...' time.sleep(10) return True '''Link the tube with tweet stream''' streamTube = tweepy.Stream(auth=auth1, listener=StreamListenerChengjun(), timeout= 300) # https://github.com/tweepy/tweepy/issues/83 # setTerms = ['good', 'goodbye', 'goodnight', 'good morning'] # streamer.filter(track = setTerms) streamTube.sample() file.close() pass timePass = time.clock()-start print timePass  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9cd347ef503d2918b3d7cccd12e90eea","permalink":"https://chengjunwang.com/post/en/2013-01-20-scraping-tweets-from-twitter/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-01-20-scraping-tweets-from-twitter/","section":"post","summary":"I want to randomly sample twitter streams. Thus, i turn to the stream api of twitter.\n The set of streaming APIs offered by Twitter give developers low latency access to Twitter\u0026rsquo;s global stream of Tweet data. A proper implementation of a streaming client will be pushed messages indicating Tweets and other events have occurred, without any of the overhead associated with polling a REST endpoint.[from Twitter]\n Of course, as the first step, you should register the stream api on Twitter to get the consumer key, consumer secret, access key, and access secret.","tags":null,"title":"Scraping tweets using Twitter stream API","type":"post"},{"authors":null,"categories":null,"content":" In an earlier post, I tried to reproduce the sentiment analysis using machine learning in Python. Here, I will introduce how to do it in the framework of R.\nIn the landscape of R, both sentiment analysis package and the general text mining package of machine learning have been well developed by Timothy P. Jurka. You can check out thesentiment package and the fantastic RTextTools package. Actually, Timothy also writes an maxent package for low-memory multinomial logistic regression (also known as maximum entropy).\nTimothy P. Jurka However, the naive bayes method is not included into RTextTools. Maybe the reason is it\u0026rsquo;s too easy to make it in R, since the e1071 package did a good job. e1071 seems to be a course of the Department of Statistics (e1071), TU Wien. Its primary developer is David Meyer.\nText analysis in R has been well recognized (see the R views on natural language processing). Part of the success belongs to the tm package: A framework for text mining applications within R. It did a good job for text cleaning (stemming, delete the stopwords, etc) and transforming texts to document-term matrix (dtm). There is one paper about it. As you know the most important part of text analysis is to get the feature vectors for each document. The word feature is the most important one. Of course, you can also extend the unigram word features to bigram and trigram, and so on to n-grams. However, here for our simple case, we stick to the unigram word features.\nNote, it\u0026rsquo;s easy to use ngrams in R. In the past, the package of Rweka supplies functions to do it (check this example). Now, you can set the ngramLength in the function of create_matrix using RTextTools.\nThe first step is to read data:\n########################################### \u0026quot;Sentiment analysis with machine learning\u0026quot; ########################################## library(RTextTools) library(e1071) pos_tweets = rbind( c('I love this car', 'positive'), c('This view is amazing', 'positive'), c('I feel great this morning', 'positive'), c('I am so excited about the concert', 'positive'), c('He is my best friend', 'positive') ) neg_tweets = rbind( c('I do not like this car', 'negative'), c('This view is horrible', 'negative'), c('I feel tired this morning', 'negative'), c('I am not looking forward to the concert', 'negative'), c('He is my enemy', 'negative') ) test_tweets = rbind( c('feel happy this morning', 'positive'), c('larry friend', 'positive'), c('not like that man', 'negative'), c('house not great', 'negative'), c('your song annoying', 'negative') ) tweets = rbind(pos_tweets, neg_tweets, test_tweets)  Then we can build the document-term matrix:\n# build dtm matrix= create_matrix(tweets[,1], language=\u0026quot;english\u0026quot;, removeStopwords=FALSE, removeNumbers=TRUE, # we can also removeSparseTerms stemWords=FALSE)  Now, we can train the naive Bayes model with the training set. Note that, e1071 asks the response variable to be numeric or factor. Thus, we convert characters to factors here. This is a little trick.\n# train the model mat = as.matrix(matrix) classifier = naiveBayes(mat[1:10,], as.factor(tweets[1:10,2]) )  Now we can step further to test the accuracy.\n# test the validity predicted = predict(classifier, mat[11:15,]); predicted table(tweets[11:15, 2], predicted) recall_accuracy(tweets[11:15, 2], predicted) \u0026gt; 0.8  Apparently, the result is the same with Python (compare it with the results in an earlier post).\nHow about the other machine learning methods? As I mentioned, we can do it using RTextTools. Let\u0026rsquo;s rock!\nFirst, to specify our data:\n# build the data to specify response variable, training set, testing set. container = create_container(matrix, as.numeric(as.factor(tweets[,2])), trainSize=1:10, testSize=11:15,virgin=FALSE)  Second, to train the model with multiple machine learning algorithms:\nmodels = train_models(container, algorithms=c(\u0026quot;MAXENT\u0026quot; , \u0026quot;SVM\u0026quot;, \u0026quot;RF\u0026quot;, \u0026quot;BAGGING\u0026quot;, \u0026quot;TREE\u0026quot;))  Now, we can classify the testing set using the trained models.\nresults = classify_models(container, models)  How about the accuracy?\n# accuracy table table(as.numeric(as.factor(tweets[11:15, 2])), results[,\u0026quot;FORESTS_LABEL\u0026quot;]) table(as.numeric(as.factor(tweets[11:15, 2])), results[,\u0026quot;MAXENTROPY_LABEL\u0026quot;]) # recall accuracy recall_accuracy(as.numeric(as.factor(tweets[11:15, 2])), results[,\u0026quot;FORESTS_LABEL\u0026quot;]) recall_accuracy(as.numeric(as.factor(tweets[11:15, 2])), results[,\u0026quot;MAXENTROPY_LABEL\u0026quot;]) recall_accuracy(as.numeric(as.factor(tweets[11:15, 2])), results[,\u0026quot;TREE_LABEL\u0026quot;]) recall_accuracy(as.numeric(as.factor(tweets[11:15, 2])), results[,\u0026quot;BAGGING_LABEL\u0026quot;]) recall_accuracy(as.numeric(as.factor(tweets[11:15, 2])), results[,\u0026quot;SVM_LABEL\u0026quot;])  To summarize the results (especially the validity) in a formal way:\n# model summary analytics = create_analytics(container, results) summary(analytics) head(analytics@document_summary) analytics@ensemble_summary  To cross validate the results:\nN=4 set.seed(2014) cross_validate(container,N,\u0026quot;MAXENT\u0026quot;) cross_validate(container,N,\u0026quot;TREE\u0026quot;) cross_validate(container,N,\u0026quot;SVM\u0026quot;) cross_validate(container,N,\u0026quot;RF\u0026quot;)  The results can be found on my Rpub page. It seems that maxent reached the same recall accuracy as naive Bayes. The other methods even did a worse job. This is understandable, since we have only a very small data set. To enlarge the training set, we can get a much better results for sentiment analysis of tweets using more sophisticated methods. I will show the results with anther example.\nSentiment analysis for tweets The data comes from https://github.com/victorneo/Twitter-Sentimental-Analysis. victorneo shows how to do sentiment analysis for tweets using Python. Here, I will demonstrate how to do it in R.\nRead data:\n################### \u0026quot;load data\u0026quot; ################### setwd(\u0026quot;D:/Twitter-Sentimental-Analysis-master/\u0026quot;) happy = readLines(\u0026quot;./happy.txt\u0026quot;) sad = readLines(\u0026quot;./sad.txt\u0026quot;) happy_test = readLines(\u0026quot;./happy_test.txt\u0026quot;) sad_test = readLines(\u0026quot;./sad_test.txt\u0026quot;) tweet = c(happy, sad) tweet_test= c(happy_test, sad_test) tweet_all = c(tweet, tweet_test) sentiment = c(rep(\u0026quot;happy\u0026quot;, length(happy) ), rep(\u0026quot;sad\u0026quot;, length(sad))) sentiment_test = c(rep(\u0026quot;happy\u0026quot;, length(happy_test) ), rep(\u0026quot;sad\u0026quot;, length(sad_test))) sentiment_all = as.factor(c(sentiment, sentiment_test)) library(RTextTools)  First, try naive Bayes.\n# naive bayes mat= create_matrix(tweet_all, language=\u0026quot;english\u0026quot;, removeStopwords=FALSE, removeNumbers=TRUE, stemWords=FALSE, tm::weightTfIdf) mat = as.matrix(mat) classifier = naiveBayes(mat[1:160,], as.factor(sentiment_all[1:160])) predicted = predict(classifier, mat[161:180,]); predicted table(sentiment_test, predicted) recall_accuracy(sentiment_test, predicted) \u0026gt; 0.65  Then, try the other methods:\n# the other methods mat= create_matrix(tweet_all, language=\u0026quot;english\u0026quot;, removeStopwords=FALSE, removeNumbers=TRUE, stemWords=FALSE, tm::weightTfIdf) container = create_container(mat, as.numeric(sentiment_all), trainSize=1:160, testSize=161:180,virgin=FALSE) #可以设置removeSparseTerms models = train_models(container, algorithms=c(\u0026quot;MAXENT\u0026quot;, \u0026quot;SVM\u0026quot;, #\u0026quot;GLMNET\u0026quot;, \u0026quot;BOOSTING\u0026quot;, \u0026quot;SLDA\u0026quot;,\u0026quot;BAGGING\u0026quot;, \u0026quot;RF\u0026quot;, # \u0026quot;NNET\u0026quot;, \u0026quot;TREE\u0026quot; )) # test the model results = classify_models(container, models) table(as.numeric(as.numeric(sentiment_all[161:180])), results[,\u0026quot;FORESTS_LABEL\u0026quot;]) \u0026gt; 1 2 1 10 0 2 1 9 recall_accuracy(as.numeric(as.numeric(sentiment_all[161:180])), results[,\u0026quot;FORESTS_LABEL\u0026quot;]) \u0026gt; 0.95  Here we also want to get the formal test results, including:\n analytics@algorithm_summary: SUMMARY OF PRECISION, RECALL, F-SCORES, AND ACCURACY SORTED BY TOPIC CODE FOR EACH ALGORITHM\n analytics@label_summary: SUMMARY OF LABEL (e.g. TOPIC) ACCURACY\n analytics@document_summary: RAW SUMMARY OF ALL DATA AND SCORING\n analytics@ensemble_summary: SUMMARY OF ENSEMBLE PRECISION/COVERAGE. USES THE n VARIABLE PASSED INTO create_analytics()\n  Now let\u0026rsquo;s see the results:\n# formal tests analytics = create_analytics(container, results) summary(analytics) head(analytics@algorithm_summary) head(analytics@label_summary) head(analytics@document_summary) analytics@ensemble_summary # Ensemble Agreement # Cross Validation N=3 cross_SVM = cross_validate(container,N,\u0026quot;SVM\u0026quot;) cross_GLMNET = cross_validate(container,N,\u0026quot;GLMNET\u0026quot;) cross_MAXENT = cross_validate(container,N,\u0026quot;MAXENT\u0026quot;)  You can find that compared with naive Bayes, the other algorithms did a much better job to achieve a recall accuracy higher than 0.95. Check the results on Rpub.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cd545878e883be4298c212bd6e125626","permalink":"https://chengjunwang.com/post/en/2014-04-07-sentiment-analysis-with-machine-learning-in-r/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-04-07-sentiment-analysis-with-machine-learning-in-r/","section":"post","summary":"In an earlier post, I tried to reproduce the sentiment analysis using machine learning in Python. Here, I will introduce how to do it in the framework of R.\nIn the landscape of R, both sentiment analysis package and the general text mining package of machine learning have been well developed by Timothy P. Jurka. You can check out thesentiment package and the fantastic RTextTools package. Actually, Timothy also writes an maxent package for low-memory multinomial logistic regression (also known as maximum entropy).","tags":null,"title":"Sentiment analysis with machine learning in R","type":"post"},{"authors":null,"categories":null,"content":"Learning To Do Sentiment Analysis Using Python \u0026amp; NLTK\nThis is my first try to learn sentiment analysis using python. You can find the original post by Laurent Luce following this link.\nI am glad to know that, with the aid of naive Bayes, NLTK could distinguish ‘like’ and ‘does not like’ into \u0026lsquo;positive\u0026rsquo; and \u0026lsquo;negative\u0026rsquo; respectively. I am wondering how R behaves compared with it. The method below employed the procedures depicted in the following figure.\nFigure created by Laurent Luce\nLoad in the data first.\n# Python script import nltk pos_tweets = [('I love this car', 'positive'), ('This view is amazing', 'positive'), ('I feel great this morning', 'positive'), ('I am so excited about the concert', 'positive'), ('He is my best friend', 'positive')] neg_tweets = [('I do not like this car', 'negative'), ('This view is horrible', 'negative'), ('I feel tired this morning', 'negative'), ('I am not looking forward to the concert', 'negative'), ('He is my enemy', 'negative')] tweets = [] for (words, sentiment) in pos_tweets + neg_tweets: words_filtered = [e.lower() for e in words.split() if len(e) \u0026gt;= 3] tweets.append((words_filtered, sentiment)) test_tweets = [ (['feel', 'happy', 'this', 'morning'], 'positive'), (['larry', 'friend'], 'positive'), (['not', 'like', 'that', 'man'], 'negative'), (['house', 'not', 'great'], 'negative'), (['your', 'song', 'annoying'], 'negative')]  Then we need to get the unique word list as the features for classification.\n# get the word lists of tweets def get_words_in_tweets(tweets): all_words = [] for (words, sentiment) in tweets: all_words.extend(words) return all_words # get the unique word from the word list def get_word_features(wordlist): wordlist = nltk.FreqDist(wordlist) word_features = wordlist.keys() return word_features word_features = get_word_features(get_words_in_tweets(tweets))  To create a classifier, we need to decide what features are relevant. To do that, we first need a feature extractor.\ndef extract_features(document): document_words = set(document) features = {} for word in word_features: features['contains(%s)' % word] = (word in document_words) return features  Then, we can build up the training set and create the classifier:\ntraining_set = nltk.classify.util.apply_features(extract_features, tweets) classifier = nltk.NaiveBayesClassifier.train(training_set)  You may want to know how to define the \u0026lsquo;train\u0026rsquo; method in NLTK here:\ndef train(labeled_featuresets, estimator=nltk.probability.ELEProbDist): # Create the P(label) distribution label_probdist = estimator(label_freqdist) # Create the P(fval|label, fname) distribution feature_probdist = {} return NaiveBayesClassifier(label_probdist, feature_probdist)  Now, we can use the naive bayes method to train the data. Have a look:\ntweet_positive = 'Larry is my friend' tweet_negative = 'Larry is not my friend' print classifier.classify(extract_features(tweet_positive.split())) # \u0026gt; positive print classifier.classify(extract_features(tweet_negative.split())) # \u0026gt; negative  Don\u0026rsquo;t be too positive, let\u0026rsquo;s try another example:\ntweet_negative2 = 'Your song is annoying' print classifier.classify(extract_features(tweet_negative2.split()))  Now, we will classify the test_tweets and calculate the recall accuracy.\ndef classify_tweet(tweet): return \\ classifier.classify(extract_features(tweet)) # nltk.word_tokenize(tweet) total = accuracy = float(len(test_tweets)) for tweet in test_tweets: if classify_tweet(tweet[0]) != tweet[1]: accuracy -= 1 print('Total accuracy: %f%% (%d/20).' % (accuracy / total * 100, accuracy)) # 0.8  Of course, this is only the starting point. In the future, I will use the same data set, to so how to do it in R using naive Bayes and beyond.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a397e5aca8428b1de5bfb8e3f8a6c2c2","permalink":"https://chengjunwang.com/post/en/2012-03-19-sentiment-analysi-with-python/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2012-03-19-sentiment-analysi-with-python/","section":"post","summary":"Learning To Do Sentiment Analysis Using Python \u0026amp; NLTK\nThis is my first try to learn sentiment analysis using python. You can find the original post by Laurent Luce following this link.\nI am glad to know that, with the aid of naive Bayes, NLTK could distinguish ‘like’ and ‘does not like’ into \u0026lsquo;positive\u0026rsquo; and \u0026lsquo;negative\u0026rsquo; respectively. I am wondering how R behaves compared with it. The method below employed the procedures depicted in the following figure.","tags":null,"title":"Sentiment analysis with Python","type":"post"},{"authors":null,"categories":null,"content":" Introduction Different from the traditional diffusion research, network diffusion research focuses on how network structure exerts its impact on the diffusion process. In this post, I present how to simulate the most simple network diffusion with R.\nAs the first step, the algorithm is quite simple:\n Generate a network g: g(V, E). Randomly select one or n nodes as seeds. Each infected node influences its neighbors with probability p (transmission rate, $$\\beta$$).  SI model Actually, this is the most basic epidemic model (SI model) which has only two states: Susceptible (S) and Infected (I). However, we will extend it to networks.\nSI model describes the status of individuals switching from susceptible to infected. In this model, every individual will be infected eventually. Considering a close population without birth, death, and mobility, and assuming that each agent is homogeneous mixing, SI model implies that each individual has the same probability to transfer the something (e.g., disease, innovation or information) to its neighbors (T. G. Lewis, 2011).\nGiven the transmission rate $$\\beta$$, SI model can be described as:\n$$\\frac{dS}{dt}=-\\beta SI$$\n$$\\frac{dI}{dt}=\\beta SI$$\nNote that I + S = 1, the equation $$\\frac{dI}{dt}=\\beta SI$$ can be simplified as:\n$$\\frac{dI}{dt}=\\beta I(1-I)$$\nSolve this equation, we can get a logistic growth function featured by its s-shaped curve. The logistic curve increases fast after it crosses the critical point, and grows much slower in the late stage. It can be used to fit the curve of diffusion of innovations.\nNote that the SI model is quite naive. In the real case of epidemic spreading, we have to consider how the status of the infected change: the infected can recover and become susceptible again (SIS model), or the infected can recover and get immune (SIR, $$\\gamma$$ denotes the removal or recovery rate).\nIn this post, I intend to bring the network back into the simulation of SI model using R and the package igraph.\nGenerate the network require(igraph) # generate a social graph size = 50 # regular network g = graph.tree(size, children = 2); plot(g) g = graph.star(size); plot(g) g = graph.full(size); plot(g) g = graph.ring(size); plot(g) g = connect.neighborhood(graph.ring(size), 2); plot(g) # 最近邻耦合网络 # random network g = erdos.renyi.game(size, 0.1) # small-world network g = rewire.edges(erdos.renyi.game(size, 0.1), prob = 0.8 ) # scale-free network g = barabasi.game(size) ; plot(g)  Initiate the diffusers seeds_num = 1 set.seed(2014); diffusers = sample(V(g),seeds_num) ; diffusers infected =list() infected[[1]]= diffusers # for example, set percolation probability p = 0.128 coins = c(rep(1, p*1000), rep(0,(1-p)*1000)) n = length(coins) sample(coins, 1, replace=TRUE, prob=rep(1/n, n))  Update the diffusers # function for updating the diffusers update_diffusers = function(diffusers){ nearest_neighbors = neighborhood(g, 1, diffusers) nearest_neighbors = data.frame(table(unlist(nearest_neighbors))) nearest_neighbors = subset(nearest_neighbors, !(nearest_neighbors[,1]%in%diffusers)) # toss the coins toss = function(freq) { tossing = NULL for (i in 1:freq ) tossing[i] = sample(coins, 1, replace=TRUE, prob=rep(1/n, times=n)) tossing = sum(tossing) return (tossing) } keep = unlist(lapply(nearest_neighbors[,2], toss)) new_infected = as.numeric(as.character(nearest_neighbors[,1][keep \u0026gt;= 1])) diffusers = unique(c(diffusers, new_infected)) return(diffusers) }  Start the contagion! R you Ready? Now we can start the contagion!\ni = 1 while(length(infected[[i]]) \u0026lt; size){ infected[[i+1]] = sort(update_diffusers(infected[[i]])) cat(length(infected[[i+1]]), \u0026quot;\\n\u0026quot;) i = i + 1 }  Let\u0026rsquo;s look at the diffusion curve first:\n# \u0026quot;growth_curve\u0026quot; num_cum = unlist(lapply(1:i, function(x) length(infected［x］) )) p_cum = num_cum/max(num_cum) time = 1:i png(file = \u0026quot;./temporal_growth_curve.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=300) plot(p_cum~time, type = \u0026quot;b\u0026quot;) dev.off()  To visualize the diffusion process, we label the infected nodes with the red color.\nE(g)$color = \u0026quot;blueviolet\u0026quot; V(g)$color = \u0026quot;white\u0026quot; set.seed(2014); layout.old = layout.fruchterman.reingold(g) V(g)$color[V(g)%in%diffusers] = \u0026quot;red\u0026quot; plot(g, layout =layout.old)  I make the animated gif using the package animation developed by Yihui Xie.\nlibrary(animation) saveGIF({ ani.options(interval = 0.5, convert = shQuote(\u0026quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe\u0026quot;)) # start the plot m = 1 while(m \u0026lt;= length(infected)){ V(g)$color = \u0026quot;white\u0026quot; V(g)$color[V(g)%in%infected[[m]]] = \u0026quot;red\u0026quot; plot(g, layout =layout.old) m = m + 1} })  Similar to Netlogo (a software used for agent-based modeling), we can monitor the dynamic diffusion process with multiple plots.\nsaveGIF({ ani.options(interval = 0.5, convert = shQuote(\u0026quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe\u0026quot;)) # start the plot m = 1 while(m \u0026lt;= length(infected)){ # start the plot layout(matrix(c(1, 2, 1, 3), 2,2, byrow = TRUE), widths=c(3,1), heights=c(1, 1)) V(g)$color \u0026lt;- \u0026quot;white\u0026quot; V(g)$color[V(g)%in%infected[[m]]] = \u0026quot;red\u0026quot; num_cum = unlist(lapply(1:m, function(x) length(infected[[x]]) )) p_cum = num_cum/size p = diff(c(0, p_cum)) time = 1:m plot(g, layout =layout.old, edge.arrow.size=0.2) title(paste(\u0026quot;Scale-free Network \\n Day\u0026quot;, m)) plot(p_cum~time, type = \u0026quot;b\u0026quot;, ylab = \u0026quot;CDF\u0026quot;, xlab = \u0026quot;Time\u0026quot;, xlim = c(0,i), ylim =c(0,1)) plot(p~time, type = \u0026quot;h\u0026quot;, ylab = \u0026quot;PDF\u0026quot;, xlab = \u0026quot;Time\u0026quot;, xlim = c(0,i), ylim =c(0,1), frame.plot = FALSE) m = m + 1} }, ani.width = 800, ani.height = 500)  Based on this post, I made slides using Rpres in Rstudio, you can view it following this link.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2f9e752f79409ccfa351af2b742e6409","permalink":"https://chengjunwang.com/post/en/2014-03-09-simulate-network-diffusion-with-r/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-03-09-simulate-network-diffusion-with-r/","section":"post","summary":"Introduction Different from the traditional diffusion research, network diffusion research focuses on how network structure exerts its impact on the diffusion process. In this post, I present how to simulate the most simple network diffusion with R.\nAs the first step, the algorithm is quite simple:\n Generate a network g: g(V, E). Randomly select one or n nodes as seeds. Each infected node influences its neighbors with probability p (transmission rate, $$\\beta$$).","tags":null,"title":"Simulating network diffusion with R","type":"post"},{"authors":null,"categories":null,"content":"View it here http://chengjun.github.io/globe/ashoka.html\n####Social Entrepreneurs Worldwide Ashoka is the largest network of social entrepreneurs worldwide. Ashoka Fellows are leading social entrepreneurs who we recognize to have innovative solutions to social problems and the potential to change patterns across society. They demonstrate unrivaled commitment to bold new ideas and prove that compassion, creativity, and collaboration are tremendous forces for change. Ashoka Fellows work in over 70 countries around the globe in every area of human need.\nIn this post, I would try to visualize its global distributions using WebGL Globe. The WebGL Globe is an open platform for geographic data visualization.\n####Data Cleaning First, I get the country frequency using the following R script:\n dat2 = read.csv(\u0026quot;D:/Dropbox/Crystal_RA_Job/Ashoka Project/data/ashoka/ashoka_data_cleaningSep.csv\u0026quot;, header = F, sep = \u0026quot;|\u0026quot;, quote = \u0026quot;\u0026quot;, stringsAsFactors=F); dim(dat2) names(dat2) = c('name', 'category', 'subsectors', 'targets', 'organization', 'location1', 'location2', 'profileIntro', 'year_fellowship', 'introduction', 'idea', 'problem', 'strategy', 'person', 'rnames', 'rorgs') # country country = NULL for (i in 1:length(dat2$name)){ country[[i]] = gsub( \u0026quot;, \u0026quot;, \u0026quot;\u0026quot;, dat2$location1[i], fixed = T) } ids = which(nchar(country) \u0026gt; 30) for (i in ids){ cat(dat2$name[i], country[i], '\\n') } country[ids] = c('United States', 'Belgium', 'Czech Republic', 'Paraguay') data = data.frame(table(country)) write.table(data, 'D:/Dropbox/Crystal_RA_Job/Ashoka Project/data/ashoka/ashoka_country.csv', sep = '\\t', row.names = FALSE, col.names = FALSE, quote = FALSE)  Second, we can get the geolocation coordinates using Google\u0026rsquo;s Geo API. In this post, I use the pygeocoder module of Python to fetch the geo information for countries.\n from pygeocoder import Geocoder import time import os # change work directory os.chdir('D:/Dropbox/Crystal_RA_Job/Ashoka Project/data/ashoka/') # read country data with open('./ashoka_country.csv') as f: location = {} for line in f: country, freq = line.strip().split('\\t') location[country] = int(freq) maxFreq = max(location.values()) #get geo coordinates results = [] for i in location.keys(): time.sleep(1) latitude, longtitude = Geocoder.geocode(i)[0].coordinates results.extend([latitude, longtitude, location[i]/maxFreq]) # make json data = [[\u0026quot;data\u0026quot;,results]] # save json import json with open('./ashoka_locations.json', 'w') as outfile: json.dump(data, outfile)  ####visualization In this visualization, each pillar stands for one country. By the year of 2013, there are 2334 fellows from 76 countries. The top 3 countries are India (N = 303), Brazil (N = 286), and United States(N = 160).\nUsing python, we can sort the country frequency like this:\n sorted(location.items(), key=lambda x: x[1])  And here is the result:\n #[('Italy', 1), ('Netherlands', 1), ('Iceland', 1), ('Togo', 1), ('Saudi Arabia', 1), # ('Latvia', 1), ('Guinea-Bissau', 1), ('Mozambique', 1), ('Niger', 1), ('Botswana', 1), #('Hong Kong S.A.R.China', 1), ('Norway', 2), ('Singapore', 2), ('Denmark', 2), #('Morocco', 2), ('Japan', 2), ('Timor-Leste', 2), ('Austria', 2), ('Zambia', 2), # ('Afghanistan', 3), ('Sweden', 3), ('Nicaragua', 3), ('Cameroon', 4), #('Ivory Coast', 4), ('Lebanon', 5), ('Ghana', 5), ('Israel', 5), ('Guatemala', 5), # ('Belgium', 5), ('Switzerland', 5), ('El Salvador', 6), ('Gambia', 6), #('Tanzania', 6), ('Lithuania', 7), ('Palestinian Territory', 7), ('Jordan', 8), # ('Costa Rica', 10), ('Ireland', 10), ('Mali', 13), ('United Kingdom', 13), #('Zimbabwe', 13), ('Venezuela', 15), ('Paraguay', 16), ('Slovakia', 18), #('Sri Lanka', 18), ('Senegal', 20), ('Uganda', 20), ('Uruguay', 20), # ('Bolivia', 23), ('Kenya', 24), ('Turkey', 24), ('Spain', 25), ('Czech Republic', 26), # ('Hungary', 27), ('Burkina Faso', 28), ('Ecuador', 31), ('France', 33), ('Peru', 36), # ('Canada', 40), ('Germany', 40), ('Egypt', 40), ('Chile', 41), ('Nepal', 41), #('Pakistan', 45), ('Colombia', 50), ('Argentina', 53), ('Bangladesh', 61), #('Poland', 69), ('Nigeria', 70), ('Thailand', 88), ('South Africa', 94), #('Indonesia', 123), ('Mexico', 153), ('United States', 160), ('Brazil', 286), ('India', 303)]  \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8d3e111748f382d51e6ecaa21bfe5e8b","permalink":"https://chengjunwang.com/post/en/2014-08-20-ashoka-fellows-worldwide/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-08-20-ashoka-fellows-worldwide/","section":"post","summary":"View it here http://chengjun.github.io/globe/ashoka.html\n####Social Entrepreneurs Worldwide Ashoka is the largest network of social entrepreneurs worldwide. Ashoka Fellows are leading social entrepreneurs who we recognize to have innovative solutions to social problems and the potential to change patterns across society. They demonstrate unrivaled commitment to bold new ideas and prove that compassion, creativity, and collaboration are tremendous forces for change. Ashoka Fellows work in over 70 countries around the globe in every area of human need.","tags":null,"title":"Social Entrepreneurs Worldwide: Visualization using WebGL Globe","type":"post"},{"authors":null,"categories":null,"content":" I learnt that many people like to subscribe a blog by email. The website usually supplies its feed, but not such subscription service. Actually, it\u0026rsquo;s quite straightford to do so using the feedburner of Google. After the webmaster sucessfully makes up the feedburner, he or she can look into the Publicize webpage, and click the button of Subscription Management. After it is activated, you can got the url for email subscription. That\u0026rsquo;s it.\nThen you can find the html code for email subscription as below:\nSubscription Form \u0026lt;form style=\u0026quot;border:1px solid #ccc;padding:3px;text-align:center;\u0026quot; action=\u0026quot;http://feedburner.google.com/fb/a/mailverify\u0026quot; method=\u0026quot;post\u0026quot; target=\u0026quot;popupwindow\u0026quot; onsubmit=\u0026quot;window.open('http://feedburner.google.com/fb/a/mailverify?uri=github/zoiS', 'popupwindow', 'scrollbars=yes,width=550,height=520');return true\u0026quot;\u0026gt;\u0026lt;p\u0026gt;Enter your email address:\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; style=\u0026quot;width:140px\u0026quot; name=\u0026quot;email\u0026quot;/\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;input type=\u0026quot;hidden\u0026quot; value=\u0026quot;github/zoiS\u0026quot; name=\u0026quot;uri\u0026quot;/\u0026gt;\u0026lt;input type=\u0026quot;hidden\u0026quot; name=\u0026quot;loc\u0026quot; value=\u0026quot;en_US\u0026quot;/\u0026gt;\u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;Subscribe\u0026quot; /\u0026gt;\u0026lt;p\u0026gt;Delivered by \u0026lt;a href=\u0026quot;http://feedburner.google.com\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;FeedBurner\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/form\u0026gt;  Enter your email address:\nDelivered by FeedBurner\n Subscription Url  \u0026lt;a href=\u0026quot;http://feedburner.google.com/fb/a/mailverify?uri=github/zoiS\u0026amp;amp;loc=en_US\u0026quot;\u0026gt;Subscribe to Cheng-Jun Wang by Email\u0026lt;/a\u0026gt;  Subscribe to Cheng-Jun Wang by Email\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f32021fb0c1d19e29987e3277f37eedb","permalink":"https://chengjunwang.com/post/en/2014-09-03-subscribe-by-email/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-09-03-subscribe-by-email/","section":"post","summary":"I learnt that many people like to subscribe a blog by email. The website usually supplies its feed, but not such subscription service. Actually, it\u0026rsquo;s quite straightford to do so using the feedburner of Google. After the webmaster sucessfully makes up the feedburner, he or she can look into the Publicize webpage, and click the button of Subscription Management. After it is activated, you can got the url for email subscription.","tags":null,"title":"Subscribe to This Blog by Email","type":"post"},{"authors":null,"categories":null,"content":" As an American sociologist, Howard S. Becker writes the book titled Writing for Social Scientists in which he generously shares his experience and insightful understandings by analyzing the writing issues in the perspective of sociology. Howard works in the way of anthropology and treats his classroom of writing as a field of observation.\nFirst, He asks his students whose fears of writing overshadow their torture of taking class of composition again,to share their experience of writing, which convinces readers that all of us share common problems of writing: instead of treating writing as a work which should be done at once, we turn to all the rituals we know and as a result waste a lot time. How to solve this problem? The answer is quite simple but very useful:\nto start the writing right now!!!! Further, He discusses what to do in the beginning of writing. Write an outline first, and write your introduction last. Writing a sentence doesn’t hurt you, and it even helps you to find out what you have and what you would like to say. It helps to sort your thoughts. Don’t intend to be critical at this phase. This suggestion reminds me about YAN Gengwang’s reflection about the failure of his friend who is believed to be very promising in history research but seldom begins to write until he feels he had got ready for it. It turns out that he only writes one piece of paper in his life.\nSecond, Howard S. Becker proposes to write clear, understandable, and plain prose. He explains why he did so in chapter 2 of this book, which claims that we write flowery sentences to merely distinguish ourselves from others to pursue these personas rather than answering the research questions.\nThird and an important part is how to prepare for the writing, on which I have great passions. C. Wright Mills share his \u0026laquo;secrets\u0026raquo; of doing research: making notes on a specific topic, and shuffles the notes to combine the different concepts in order to get the imagination of sociology. Howard S. Becker holds similar but more concrete ideas.\n Begin by taking notes on what you have written, put each idea on a file card. Then sort your stack of cards into files, and sequence the files.\n Howard reminds us to be critical at this time. We can put out the generalization cards on a table, a door, or a wall.\nIf we can’t find the right way, Howard suggests us to talk about why we can’t, and why you choose a less-than-perfect solution, and what it all means: we can’t solve the question in one paper.\nScholars must learn to write professionally. He gives us his own experience of submitting a paper to American Journal of Sociology. Everett Hughes reviews this paper and comments that his sentences sounded like they have been translated from German. The solution is to proofread it first.\nTo carefully polish your paper before submission is necessary for non-native speakers. CHEN Guanrong, a professor of city university of Hong Kong, shares his comments on it. Chen said that if you write you paper within three days and submit it out without editing, it’s unlikely to be accepted by the journal. Even the reviewers have to spend two weeks to read through your paper and give their comments which are usually very long and carefully written.\nBecker further discussed a lot of things on writing as a professional, risks of sitting down to write (which means to trust your peers and yourself), submitting, literature review, and writing with computers. Most of them are very interesting.\nLast, do not be defensive. I want to quote Howard’s words:\n“they don’t argue with me, they just don’t do it”. 　","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"90bb3216380b9af08cf71fd8f8659436","permalink":"https://chengjunwang.com/post/en/2011-03-18-craft-of-writing/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2011-03-18-craft-of-writing/","section":"post","summary":"As an American sociologist, Howard S. Becker writes the book titled Writing for Social Scientists in which he generously shares his experience and insightful understandings by analyzing the writing issues in the perspective of sociology. Howard works in the way of anthropology and treats his classroom of writing as a field of observation.\nFirst, He asks his students whose fears of writing overshadow their torture of taking class of composition again,to share their experience of writing, which convinces readers that all of us share common problems of writing: instead of treating writing as a work which should be done at once, we turn to all the rituals we know and as a result waste a lot time.","tags":null,"title":"The Craft of Writing","type":"post"},{"authors":null,"categories":null,"content":" This post is about the opinions tweeted \u0026amp; retweeted by the most influential users of Sina Weibo.\nAbout Sina Weibo, you can refer to the webpage of wikipedia:\n Sina Weibo (Chinese: 新浪微博; pinyin: Xīnlàng Wēibó; literally “Sina Microblog”) is a Chinese microblogging (weibo) website. Akin to a hybrid of Twitter and Facebook, it is one of the most popular sites in China, in use by well over 30% of Internet users, with a similar market penetration that Twitter has established in the USA. It was launched by SINA Corporation on 14 August 2009, and has more than 300 million registered users as of February 2012.\n To study the news diffusion of Weibo Users, My collaborator Linwu and I had set up a research project of Weibo Landscape aiming at archiving the historical tweets of 800 verified weibo accounts (Rich club of Sina Weibo) before March 2012. Both the tweets created by them and the tweets retweeted by them are collected and indexed. So this archive can supply you the historical opinions reflected by these most influential users: including 400 media accounts+100 website accounts+ 100 government accounts +100 celebrities accounts+100 grass root accounts\nHow does the media landscape look like?\nThe Opinions of the Rich Club Understanding the rich club, see my slides here:\n the weighted rich-club effect tests whether a select group of nodes share their strongest ties with each other in a weighted network (Opsahl et al., 2008) 80-20 rule (Pareto, 1897) high degree nodes form many ties with each other (Borgatti and Everett, 1999; Colizza et al., 2006; Newman, 2002)  Although Sina Weibo is very densely connected, Individuals are separated from each other but closer to the celebrities. Thus the most influential users become the core of Sina Weibo, and they are followed by the common users. As the core of Sina Weibo, they have great influence on the information diffusion on the social media website.\n 800 Influential Users (400 media accounts+100 website accounts+ 100-government accounts +100 celebrities accounts+100 grass root accounts) are identified by Sina Weibo.\n The data were collected though user timeline api using Python. The following relationship of the rich club reveals that they are closed connected (see the figure below).\n  What is the relationship between rich club, random sample, and the unsampled majority in our data?\nHow is the weighted rich-club effect in Sina Weibo?\nHave a try! Unfortunately, this section does not work now. :\u0026lt;\nFirst, open the url: http://weblab.com.cityu.edu.hk/demo/weibo.html\nSecond, input and query key words (e.g. 占领华尔街，艾未未，汶川地震，动车出轨， 日本地震) and click the search button to see the results. For example, you can query for Occupying Wall Street (占领华尔街), and you can find the items such as:\nrelated 1-th-weibo: mid:3365546399651413 score:-5.76427445942 uid:1893278624 link:source time:Thu Oct 06 17:10:59 +0800 2011 content:【“占领华尔街”继续发酵 全美75所高校学生响应】“占领华尔街”抗议活动进入第19日，活动影响继续发酵，占领运动延伸至高校校园，最新发起的“占领高校”运动，号召全美高校学生5日下午加入上街游行的队伍。图为大批示威者在“占领华尔街”大本营——华尔街附近的祖科提公园Zuccotti Park集会。  If you have login Sina weibo, click the link of source, you can find the original tweet.\nVisualization of diffusion path Click the source of the top 1000 list of archive items, you can get the url of a given tweet, and then you can further visualize the diffusion path using the apps of Sina Weibo.\n doodod\n newgraph\n  For example, using the doodod, you can visualize the diffusion path following this link. The figure looks like this:\n######The Landscape of Information Diffusion on Sina Weibo： Investigating the Rich-Club Effect\nThis blog post is derived from my project of information diffusion on Sina Weibo. Based on the data of weibo landscape, we find that:\nRich-club as a closely connected community in networks has important influences on the information flow within the online social system. We study the competing mechanisms underlying the information flows within and among different social groups inside the rich club of Sina Weibo. The results demonstrate that: first, there is relatively strong rich-club effect in both influential users and random sampled users; second, social selection, geographic proximity, and social influence have significant influence on the information flow within the rich-club for different social groups, and the impact of social influence is overwhelmingly strong. The implications help shed new light on our knowledge about the underlying mechanisms of information diffusion on the microblog.\nIn the following post, I will introduce how to scrape data from Sina Weibo using Python.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"16ae635bca66ec290ffaff7a493a34bd","permalink":"https://chengjunwang.com/post/en/2014-03-14-weibo-landscape/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2014-03-14-weibo-landscape/","section":"post","summary":"This post is about the opinions tweeted \u0026amp; retweeted by the most influential users of Sina Weibo.\nAbout Sina Weibo, you can refer to the webpage of wikipedia:\n Sina Weibo (Chinese: 新浪微博; pinyin: Xīnlàng Wēibó; literally “Sina Microblog”) is a Chinese microblogging (weibo) website. Akin to a hybrid of Twitter and Facebook, it is one of the most popular sites in China, in use by well over 30% of Internet users, with a similar market penetration that Twitter has established in the USA.","tags":null,"title":"The Rich-club on Sina Weibo","type":"post"},{"authors":null,"categories":null,"content":" Introduction I had made slides to understand the bass diffusion model which is proposed by Frank M. Bass in 1969. The model proposes that diffusion is motivated both by inovativeness and imitation: first, the innovative early adopters adopted the products, after which the followers will imitate them and adopt the products.\n The Bass model coefficient (parameter) of innovation is p.\n The Bass model coefficient (parameter) of imitation is q.\n  The slides will show you how to deprive the equation of Bass diffusion model by both discrete-time model and continuous model (using Hazard rate).\n “The probability of adopting by those who have not yet adopted is a linear function of those who had previously adopted.”\n We can solve the differential equation of bass diffusion model using Mathematica.\nHere, we can also simulate the Bass diffusion model using R code (Click here to view it on Rpub).\n# basss diffusion model chengjun, 20120424@canberra # refer to http://en.wikipedia.org/wiki/Bass_diffusion_model and # http://book.douban.com/subject/4175572/discussion/45634092/ # BASS Diffusion Model three parameters: the total number of people who # eventually buy the product, m; the coefficient of innovation, p; and the # coefficient of imitation, q # example T79 \u0026lt;- 1:10 Tdelt \u0026lt;- (1:100)/10 Sales \u0026lt;- c(840, 1470, 2110, 4000, 7590, 10950, 10530, 9470, 7790, 5890) Cusales \u0026lt;- cumsum(Sales) Bass.nls \u0026lt;- nls(Sales ~ M * (((P + Q)^2/P) * exp(-(P + Q) * T79))/(1 + (Q/P) * exp(-(P + Q) * T79))^2, start = list(M = 60630, P = 0.03, Q = 0.38)) summary(Bass.nls)  This is the result:\n## ## Formula: Sales ~ M * (((P + Q)^2/P) * exp(-(P + Q) * T79))/(1 + (Q/P) * ## exp(-(P + Q) * T79))^2 ## ## Parameters: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## M 6.80e+04 3.13e+03 21.74 1.1e-07 *** ## P 6.59e-03 1.43e-03 4.61 0.0025 ** ## Q 6.38e-01 4.14e-02 15.41 1.2e-06 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 727 on 7 degrees of freedom ## ## Number of iterations to convergence: 8 ## Achieved convergence tolerance: 7.32e-06  Then we can get the regression coefficient and plot the growth:\n# get coefficient Bcoef \u0026lt;- coef(Bass.nls) m \u0026lt;- Bcoef[1] p \u0026lt;- Bcoef[2] q \u0026lt;- Bcoef[3] # setting the starting value for M to the recorded total sales. ngete \u0026lt;- exp(-(p + q) * Tdelt) # plot pdf Bpdf \u0026lt;- m * ((p + q)^2/p) * ngete/(1 + (q/p) * ngete)^2 plot(Tdelt, Bpdf, xlab = \u0026quot;Year from 1979\u0026quot;, ylab = \u0026quot;Sales per year\u0026quot;, type = \u0026quot;l\u0026quot;) points(T79, Sales)  We can also plot the cdf:\n# plot cdf Bcdf \u0026lt;- m * (1 - ngete)/(1 + (q/p) * ngete) plot(Tdelt, Bcdf, xlab = \u0026quot;Year from 1979\u0026quot;, ylab = \u0026quot;Cumulative sales\u0026quot;, type = \u0026quot;l\u0026quot;) points(T79, Cusales)  When q=0, only Innovator without immitators.\n# when q=0, only Innovator without immitators. Ipdf \u0026lt;- m * ((p + 0)^2/p) * exp(-(p + 0) * Tdelt)/(1 + (0/p) * exp(-(p + 0) * Tdelt))^2 Impdf \u0026lt;- Bpdf - Ipdf plot(Tdelt, Bpdf, xlab = \u0026quot;Year from 1979\u0026quot;, ylab = \u0026quot;Sales per year\u0026quot;, type = \u0026quot;l\u0026quot;, col = \u0026quot;red\u0026quot;) lines(Tdelt, Impdf, col = \u0026quot;green\u0026quot;) lines(Tdelt, Ipdf, col = \u0026quot;blue\u0026quot;)  The cdf in this case can also be plotted:\n# when q=0, only Innovator without immitators. Icdf \u0026lt;- m * (1 - exp(-(p + 0) * Tdelt))/(1 + (0/p) * exp(-(p + 0) * Tdelt)) # plot(Tdelt, Icdf, xlab = 'Year from 1979',ylab = 'ICumulative sales', # type='l') Imcdf \u0026lt;- m * (1 - ngete)/(1 + (q/p) * ngete) - Icdf plot(Tdelt, Imcdf, xlab = \u0026quot;Year from 1979\u0026quot;, ylab = \u0026quot;Cumulative sales\u0026quot;, type = \u0026quot;l\u0026quot;, col = \u0026quot;red\u0026quot;) lines(Tdelt, Bcdf, col = \u0026quot;green\u0026quot;) lines(Tdelt, Icdf, col = \u0026quot;blue\u0026quot;)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"767462167b8d993fbbff37d31ca5fcc6","permalink":"https://chengjunwang.com/post/en/2012-04-26-understanding-bass-diffusion-model-with-r/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2012-04-26-understanding-bass-diffusion-model-with-r/","section":"post","summary":"Introduction I had made slides to understand the bass diffusion model which is proposed by Frank M. Bass in 1969. The model proposes that diffusion is motivated both by inovativeness and imitation: first, the innovative early adopters adopted the products, after which the followers will imitate them and adopt the products.\n The Bass model coefficient (parameter) of innovation is p.\n The Bass model coefficient (parameter) of imitation is q.","tags":null,"title":"Understanding Bass diffusion model with R","type":"post"},{"authors":null,"categories":null,"content":" I am inspired to use markdown to make HTML5 slides, However the specification is too hard. Actually, I don\u0026rsquo;t know how to make it less ugly, especilly for the first page of the slides.\nBy chance, I find Torres\u0026rsquo;s slides (Click here), it is made through R using the slidify package. Of course, you also need to write R markdown using Rstudio and Knitr.\nInstall slidify package in Rstudio install_github('slidify', 'ramnathv') install_github('slidifyLibraries', 'ramnathv')  {:lang=\u0026laquo;ruby\u0026raquo;}\nHowever, to install R packages host on Github is very painful. I failed in installing the slidifyLibrairies package.\nFollowing thie post installing-slidify-on-a-windows-machine. Althought I have tried R CMD INSTALL, but failed. I don\u0026rsquo;t know why :\u0026lt;, however, I use the alternative method to install R packages on local computers.\nFirst, download slidifyLibraries from github to your local directory, e.g., \u0026laquo;D:/github/\u0026laquo;.\nSecond, extract it and rename it as \u0026laquo;slidifyLibraries\u0026raquo;.\nThird, build it with this R script:\nbuild(\u0026quot;D:/github/slidifyLibraries/\u0026quot;, binary=FALSE)  {:lang=\u0026laquo;ruby\u0026raquo;}\nFourth, install the tar.gz file following this R script:\ninstall.packages(\u0026quot;D:/github/slidifyLibraries_0.1.tar.gz\u0026quot;, repos = NULL, type = \u0026quot;source\u0026quot;)  {:lang=\u0026laquo;ruby\u0026raquo;}\nUsing slidify to write R markdown initialize a presentation following this introduction about slidify.\nlibrary(slidify) author('mydeck')  {:lang=\u0026laquo;ruby\u0026raquo;}\nWrite markdown files  \u0026lt;iframe width=\u0026quot;420\u0026quot; height=\u0026quot;315\u0026quot; src=\u0026quot;//www.youtube.com/embed/I95GOmLc7TA\u0026quot; frameborder=\u0026quot;0\u0026quot; allowfullscreen\u0026gt;\u0026lt;/iframe\u0026gt;  {:lang=\u0026laquo;ruby\u0026raquo;}\nCheck my first slidify HTML5 slides here: chengjun.github.io/slides/computational-communication.html\nClick here to see it.\nThe markdown file is given below (I choose \u0026laquo;standalone\u0026raquo; as the mode):\n--- title : The Way to Computational Communication subtitle : author : Cheng-Jun Wang job : Web Mining Web, City University of Hong Kong framework : io2012 # {io2012, html5slides, shower, dzslides, ...} highlighter : highlight.js # {highlight.js, prettify, highlight} hitheme : tomorrow # widgets : [] # {mathjax, quiz, bootstrap} mode : standalone # {standalone, draft, selfcontained} --- ## Three metaphors of theory \u0026gt;Immanuel Kant: All our knowledge begins with the senses, proceeds then to the understanding, and ends with reason. There is nothing higher than reason. ![](http://farm8.staticflickr.com/7379/9532736494_99b95287a2_z.jpg) --- .class #id ## Sandglass of generalization ![](http://farm8.staticflickr.com/7366/9529954881_53a00fe15b_z.jpg) --- ## Five levels of Research ![](http://farm3.staticflickr.com/2819/9529954801_e6d59c8eba_z.jpg) --- ## Computational Thinking ![](http://farm4.staticflickr.com/3669/9529954763_06a6c95970_z.jpg) --- ## The Way to Computational Communication ![](http://farm6.staticflickr.com/5540/9529954731_4cbf032b06_z.jpg) --- ## Network Science ![](http://farm8.staticflickr.com/7353/9529954585_94686e3aa4_z.jpg) --- .class1 #id1 bg:yellow ## What should we do? - Network science - Statistical linguistics - Human dynamics - Big data\u0026amp; digital traces - Digital media - Data journalism - Computational advertising ![](http://gifs.gifbin.com/1236681924_snail_transformers.gif) --- ## Thank you for your attention! ## wangchj04@gmail.com ![](http://farm3.staticflickr.com/2840/9508319890_2cbaa2c4d4_n.jpg)  {:lang=\u0026laquo;ruby\u0026raquo;}\nHow to host your slidify HTML5 presentations on github I failed in publish it directly to github following the the way introduced by slidify website. I am not sure why it does not work. However, I figured out my solutions.\nYou can still do it very easily. But, first, you should know the structure of github repository. Assume you have a github repo named \u0026laquo;slidify\u0026raquo;. We can work at different branches: \u0026laquo;master\u0026raquo; or \u0026laquo;gh-pages\u0026raquo;. You can generate your gh-pages branch following the figure on the right. gh-pages is a very special branch of github repository. The branch of gh-pages are acturally a website host by Github.The files in slidify/test/index.html on the branch of gh-pages could be displayed by your default github website. e.g., chengjun.github.io/slidify/test. So the first move is to make a gh-pages, and upload your slidify stuff to this branch.\nYou can generate new sub-branch too. e.g., slidify/computational-communication. See two examples:\nhttp://chengjun.github.io/slides/slidify/\nIf your markdown file is \u0026lsquo;selfcontained\u0026rsquo;{:lang=\u0026laquo;ruby\u0026raquo;} , it will not turn to https://code.google.com/p/slidifylibraries/ for the font and theme information (but it still needs to refer to the other websites where your insert your pictures into your slides). So theoretically, self-contained file is a little little little bit faster than \u0026lsquo;standalone\u0026rsquo;{:lang=\u0026laquo;ruby\u0026raquo;} files. However, you can almost not detect it if the internet access is good. Check this standalone HTML in the following link and compare it with the two selfcontained ones on the above:\n [](http://chengjun.github.io/slides/)\nIn you sub-directory, you have to have everything the selfcontained html needs, it is not clever enough to scan the upper-directory. Anyway, enjoy your HTML5 slides host on github!\nAfterwords I have also tried to use pandoc and reveal.js to make slides.\nUsing reveal.js, I have reproduced the slides of computational communication on slid.es.\n However, using pandoc and markdown, it seems to be quite limited to set the slides, here is the result:chengjun.github.io/slides/reveal.js/cc\nThe method is briefly introduced here: [](chengjun.github.io/slides/reveal.js/pandoc-revealjs-slides)\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"020f60dc6bcf3ea4a7fb47df7eebc864","permalink":"https://chengjunwang.com/post/en/2013-08-18-using-slidify-to-publish-html5-presentations/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-08-18-using-slidify-to-publish-html5-presentations/","section":"post","summary":"I am inspired to use markdown to make HTML5 slides, However the specification is too hard. Actually, I don\u0026rsquo;t know how to make it less ugly, especilly for the first page of the slides.\nBy chance, I find Torres\u0026rsquo;s slides (Click here), it is made through R using the slidify package. Of course, you also need to write R markdown using Rstudio and Knitr.\nInstall slidify package in Rstudio install_github('slidify', 'ramnathv') install_github('slidifyLibraries', 'ramnathv')  {:lang=\u0026laquo;ruby\u0026raquo;}","tags":null,"title":"Using slidify to publish HTML5 presentations","type":"post"},{"authors":null,"categories":null,"content":" Using a Landing Page rather than the Blog Page It\u0026rsquo;s annoying to find that users are directed to your blog page directly. In my point of view, octopress is not just a personal blog. It is your website, your home online, where you can present yourself easily, rather than limiting yourself to the blog posts.\nI have made a \u0026laquo;Home\u0026raquo; page before. However, the home page is not directed as the landing page.\nTo have a look at the navigation method used in my navigation.html:\n\u0026lt;ul class=\u0026quot;main-navigation\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/home\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/cv\u0026quot;\u0026gt;CV\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/\u0026quot;\u0026gt;Blog\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/blog/archives\u0026quot;\u0026gt;Archives\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;  You will find that the root_url is directed to the blog page！ How to change it? Bear in mind that octopress orgainze the pages by index page. There is a index page for any pages, e.g, an index page for the blog page, an index page for the archives page, an index page for the home page. Thus, we can think in another way, why not make a index page for the root_url? This can solve the problem.\nFirst, Of course, we should move the index page to the blog directory first.By default Octopress generates your blog’s post index at your site’s root directory. If you’d rather publish your blog index somewhere else like blog/index.html do this in your terminal.\nmv source/index.html source/blog/index.html  Second,we can make an index page for the root_url of the source.\nrake new_page[index.html]  Third, you’ll want to update your Rakefile to be sure your new blog index is preserved when you update Octopress. This tells the octopress that your index page for the blog is moved to the directory of \u0026laquo;source/blog\u0026raquo;.\nblog_index_dir = 'source/blog'  Fourth, remember to update the main navigation for your site(octopress/source/_includes/custom/navigation.html), since currently the blog link points to /. Skip down to the section on changing navigation, add a ‘home’ link and update the ‘blog’ link to point to /blog/.\n\u0026lt;ul class=\u0026quot;main-navigation\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/home\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/cv\u0026quot;\u0026gt;CV\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/blog\u0026quot;\u0026gt;Blog\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ root_url }}/blog/archives\u0026quot;\u0026gt;Archives\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;  Finally, source/index.html can become the landing page of your \u0026laquo;wildest dreams\u0026raquo;. My dream is fairly small: to let the index page of the source be directed to the index page of the Home page (I have make a home page before). The bad news is I have no prior knowledge of html language, if you know how to do it, tell me please. The good news is I can copy and paste the index page of the Home directly (\u0026laquo;octopress/public/home/index.html\u0026raquo;).\nReferences Landing Page vs. Blog Index. http://octopress.org/docs/theme/template/\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2d00cfb8a0704a0bc45d8214f24e71bf","permalink":"https://chengjunwang.com/post/en/2013-08-06-using-the-front-page-of-octopress-instead-of-the-blog-page/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2013-08-06-using-the-front-page-of-octopress-instead-of-the-blog-page/","section":"post","summary":"Using a Landing Page rather than the Blog Page It\u0026rsquo;s annoying to find that users are directed to your blog page directly. In my point of view, octopress is not just a personal blog. It is your website, your home online, where you can present yourself easily, rather than limiting yourself to the blog posts.\nI have made a \u0026laquo;Home\u0026raquo; page before. However, the home page is not directed as the landing page.","tags":null,"title":"Using the front-page of Octopress instead of the blog page","type":"post"},{"authors":null,"categories":null,"content":" GoogleVis could be used to visualize the dynamic change of social pattern. Here I will test some examples.\nFirst, let us see the examples in googleVis:\nlibrary(googleVis) data(package=\u0026quot;googleVis\u0026quot;) # Data sets in package ‘googleVis’: # Andrew Hurricane Andrew: googleVis example data set # CityPopularity CityPopularity: googleVis example data set # Exports Exports: googleVis example data set # Fruits Fruits: googleVis example data set # OpenClose OpenClose: googleVis example data set # Population Population: googleVis example data set # Regions Regions: googleVis example data set # Stock Stock: googleVis example data set  Second, we try the example of hurricane of andrew:\n# Visualizing the hurricane of Andrew data(Andrew) plot(Andrew) AndrewGeoMap \u0026lt;- gvisGeoMap(Andrew, locationvar='LatLong', numvar='Speed_kt', hovervar='Category', options=list(width=600,height=300, region='US', dataMode='Markers')) plot(AndrewGeoMap) AndrewGeoMap$html$chart setwd(\u0026quot;d:/r\u0026quot;) cat(AndrewGeoMap$html$chart, file=\u0026quot;AndrewGeoMap.html\u0026quot;) # then you can find it in the work directory.  Check the results below:\n // jsData function gvisDataGeoMapID14fd70aa () { var data = new google.visualization.DataTable(); var datajson = [ [ 10.8, -35.5, 25, \"Tropical Depression\" ], [ 11.2, -37.4, 30, \"Tropical Depression\" ], [ 11.7, -39.6, 30, \"Tropical Depression\" ], [ 12.3, -42, 35, \"Tropical Storm\" ], [ 13.1, -44.2, 35, \"Tropical Storm\" ], [ 13.6, -46.2, 40, \"Tropical Storm\" ], [ 14.1, -48, 45, \"Tropical Storm\" ], [ 14.6, -49.9, 45, \"Tropical Storm\" ], [ 15.4, -51.8, 45, \"Tropical Storm\" ], [ 16.3, -53.5, 45, \"Tropical Storm\" ], [ 17.2, -55.3, 45, \"Tropical Storm\" ], [ 18, -56.9, 45, \"Tropical Storm\" ], [ 18.8, -58.3, 45, \"Tropical Storm\" ], [ 19.8, -59.3, 40, \"Tropical Storm\" ], [ 20.7, -60, 40, \"Tropical Storm\" ], [ 21.7, -60.7, 40, \"Tropical Storm\" ], [ 22.5, -61.5, 40, \"Tropical Storm\" ], [ 23.2, -62.4, 45, \"Tropical Storm\" ], [ 23.9, -63.3, 45, \"Tropical Storm\" ], [ 24.4, -64.2, 50, \"Tropical Storm\" ], [ 24.8, -64.9, 50, \"Tropical Storm\" ], [ 25.3, -65.9, 55, \"Tropical Storm\" ], [ 25.6, -67, 60, \"Tropical Storm\" ], [ 25.8, -68.3, 70, \"Hurricane\" ], [ 25.7, -69.7, 80, \"Hurricane\" ], [ 25.6, -71.1, 90, \"Hurricane\" ], [ 25.5, -72.5, 105, \"Hurricane\" ], [ 25.4, -74.2, 120, \"Hurricane\" ], [ 25.4, -75.8, 135, \"Hurricane\" ], [ 25.4, -77.5, 125, \"Hurricane\" ], [ 25.4, -79.3, 120, \"Hurricane\" ], [ 25.6, -81.2, 110, \"Hurricane\" ], [ 25.8, -83.1, 115, \"Hurricane\" ], [ 26.2, -85, 115, \"Hurricane\" ], [ 26.6, -86.7, 115, \"Hurricane\" ], [ 27.2, -88.2, 115, \"Hurricane\" ], [ 27.8, -89.6, 120, \"Hurricane\" ], [ 28.5, -90.5, 120, \"Hurricane\" ], [ 29.2, -91.3, 115, \"Hurricane\" ], [ 30.1, -91.7, 80, \"Tropical Storm\" ], [ 30.9, -91.6, 50, \"Tropical Storm\" ], [ 31.5, -91.1, 35, \"Tropical Depression\" ], [ 32.1, -90.5, 30, \"Tropical Depression\" ], [ 32.8, -89.6, 30, \"Tropical Depression\" ], [ 33.6, -88.4, 25, \"Tropical Depression\" ], [ 34.4, -86.7, 20, \"Tropical Depression\" ], [ 35.4, -84, 20, \"Tropical Depression\" ] ]; data.addColumn('number','Latitude'); data.addColumn('number','Longitude'); data.addColumn('number','Speed_kt'); data.addColumn('string','Category'); data.addRows(datajson); return(data); } // jsDrawChart function drawChartGeoMapID14fd70aa() { var data = gvisDataGeoMapID14fd70aa() var chart = new google.visualization.GeoMap( document.getElementById('GeoMapID14fd70aa') ); var options ={}; options[\"dataMode\"] = \"Markers\"; options[\"width\"] = 600; options[\"height\"] = 300; options[\"region\"] = \"US\"; chart.draw(data,options); } // jsDisplayChart function displayChartGeoMapID14fd70aa() { google.load(\"visualization\", \"1\", { packages:[\"geomap\"] }); google.setOnLoadCallback(drawChartGeoMapID14fd70aa); } // jsChart displayChartGeoMapID14fd70aa() //--   Further, I visualize the dynamic change of cell phone ratio in the world.\nThe motion chart of Fixed telephone use # load data ftel=read.csv(\u0026quot;d:/r/Fixed Telephone.csv\u0026quot;, header = T, sep = \u0026quot;,\u0026quot;, quote = \u0026quot;\\\u0026quot;'\u0026quot;,\u0026amp;nbsp;\u0026amp;nbsp;dec = \u0026quot;.\u0026quot;)[1:7263,] ftelr=read.csv(\u0026quot;d:/r/Fixed Telephone ratio.csv\u0026quot;, header = T, sep = \u0026quot;,\u0026quot;, quote = \u0026quot;\\\u0026quot;'\u0026quot;,\u0026amp;nbsp; \u0026amp;nbsp;dec = \u0026quot;.\u0026quot;) ftelm=merge(ftelr, ftel, by=c(\u0026quot;Country.or.Area\u0026quot;,\u0026quot;Year\u0026quot;)) ftelm=cbind(ftelm[,1:3], ftelm[,5]) names(ftelm)=c(\u0026quot;Country or Area\u0026quot;,\u0026quot;Year\u0026quot;,\u0026quot;Percentage\u0026quot;,\u0026quot;Users\u0026quot;) # load googleVis library(\u0026quot;googleVis\u0026quot;) fixed_telephone_motion= gvisMotionChart(ftelm, idvar=\u0026quot;Country or Area\u0026quot;, timevar=\u0026quot;Year\u0026quot;, options=list(width=1024, height=768)) # plot plot(fixed_telephone_motion) setwd(\u0026quot;d:/r\u0026quot;) cat(fixed_telephone_motion$html$chart, file=\u0026quot;fixed_telephone_motion.html\u0026quot;)  Here is the result:\n // jsData function gvisDataMotionChartID483d6724 () { var data = new google.visualization.DataTable(); var datajson = [ [ \"Afghanistan\", 1960, 0.07726128, 7700 ], [ \"Afghanistan\", 1965, 0.08334506, 9300 ], [ \"Afghanistan\", 1970, 0.1270264, 16000 ], [ \"Afghanistan\", 1975, 0.150147, 21500 ], [ \"Afghanistan\", 1976, 0.1634933, 22200 ], [ \"Afghanistan\", 1977, 0.1608285, 22200 ], [ \"Afghanistan\", 1978, 0.1811345, 25300 ], [ \"Afghanistan\", 1979, 0.1804037, 25300 ], [ \"Afghanistan\", 1980, 0.185002, 25800 ], [ \"Afghanistan\", 1981, 0.2309618, 31700 ], [ \"Afghanistan\", 1982, 0.2091107, 28000 ], [ \"Afghanistan\", 1983, 0.2231954, 29000 ], [ \"Afghanistan\", 1984, 0.2379568, 30000 ], [ \"Afghanistan\", 1985, 0.2521749, 31000 ], [ \"Afghanistan\", 1986, 0.2655955, 32000 ], [ \"Afghanistan\", 1987, 0.2778125, 33000 ], [ \"Afghanistan\", 1988, 0.2867569, 34000 ], [ \"Afghanistan\", 1989, 0.2899051, 35000 ], [ \"Afghanistan\", 1990, 0.2877489, 36200 ], [ \"Afghanistan\", 1991, 0.2755445, 37000 ], [ \"Afghanistan\", 1992, 0.1990072, 29000 ], [ \"Afghanistan\", 1993, 0.1828378, 29000 ], [ \"Afghanistan\", 1994, 0.1697727, 29000 ], [ \"Afghanistan\", 1995, 0.160365, 29000 ], [ \"Afghanistan\", 1996, 0.1541938, 29000 ], [ \"Afghanistan\", 1997, 0.1502337, 29000 ], [ \"Afghanistan\", 1998, 0.1474651, 29000 ], [ \"Afghanistan\", 1999, 0.1447032, 29000 ], [ \"Afghanistan\", 2000, 0.1412168, 29000 ], [ \"Afghanistan\", 2001, 0.1369545, 29000 ], [ \"Afghanistan\", 2002, 0.1507541, 33050 ], [ \"Afghanistan\", 2003, 0.1612805, 36700 ], [ \"Afghanistan\", 2004, 0.2116181, 50000 ], [ \"Afghanistan\", 2005, 0.4080494, 100000 ], [ \"Afghanistan\", 2006, 0.3544694, 90000 ], [ \"Afghanistan\", 2007, 0.3090498, 81249 ], [ \"Afghanistan\", 2008, 0.3716657, 101124 ], [ \"Afghanistan\", 2009, 0.4594259, 129328 ], [ \"Albania\", 1960, 0.4250064, 6845 ], [ \"Albania\", 1965, 0.748205, 13991 ], [ \"Albania\", 1970, 8.100772, 173000 ], [ \"Albania\", 1975, 0.9021993, 21660 ], [ \"Albania\", 1976, 0.9167752, 22500 ], [ \"Albania\", 1977, 0.9489535, 23800 ], [ \"Albania\", 1978, 0.964045, 24700 ], [ \"Albania\", 1979, 0.9936824, 26000 ], [ \"Albania\", 1980, 1.021974, 27300 ], [ \"Albania\", 1981, 1.064216, 29000 ], [ \"Albania\", 1982, 1.080097, 30000 ], [ \"Albania\", 1983, 1.094794, 31000 ], [ \"Albania\", 1984, 1.106915, 32000 ], [ \"Albania\", 1985, 1.125147, 33275 ], [ \"Albania\", 1986, 1.153741, 35000 ], [ \"Albania\", 1987, 1.155128, 36000 ], [ \"Albania\", 1988, 1.157841, 37000 ], [ \"Albania\", 1989, 1.183792, 38550 ], [ \"Albania\", 1990, 1.215997, 40000 ], [ \"Albania\", 1991, 1.261251, 41500 ], [ \"Albania\", 1992, 1.374116, 44848 ], [ \"Albania\", 1993, 1.335543, 43000 ], [ \"Albania\", 1994, 1.308038, 41500 ], [ \"Albania\", 1995, 1.34503, 42150 ], [ \"Albania\", 1996, 2.055768, 63850 ], [ \"Albania\", 1997, 2.811968, 86800 ], [ \"Albania\", 1998, 3.76102, 115675 ], [ \"Albania\", 1999, 4.573244, 140392 ], [ \"Albania\", 2000, 4.97748, 152687 ], [ \"Albania\", 2001, 6.434388, 197496 ], [ \"Albania\", 2002, 7.15149, 220000 ], [ \"Albania\", 2003, 8.261153, 255000 ], [ \"Albania\", 2004, 8.860458, 274557 ], [ \"Albania\", 2005, 8.968523, 278973 ], [ \"Albania\", 2006, 8.200526, 256000 ], [ \"Albania\", 2007, 9.577144, 300000 ], [ \"Albania\", 2008, 10.93093, 343591 ], [ \"Albania\", 2009, 11.50456, 363000 ], [ \"Algeria\", 1965, 0.6097458, 72700 ], [ \"Algeria\", 1970, 0.6969207, 95800 ], [ \"Algeria\", 1975, 0.80471, 128900 ], [ \"Algeria\", 1976, 0.8511485, 140723 ], [ \"Algeria\", 1977, 1.010069, 172400 ], [ \"Algeria\", 1978, 1.174492, 207000 ], [ \"Algeria\", 1979, 1.430348, 260400 ], [ \"Algeria\", 1980, 1.655397, 311400 ], [ \"Algeria\", 1981, 1.866511, 362900 ], [ \"Algeria\", 1982, 2.031276, 408211 ], [ \"Algeria\", 1983, 2.14693, 445779 ], [ \"Algeria\", 1984, 2.170951, 465309 ], [ \"Algeria\", 1985, 2.43041, 537056 ], [ \"Algeria\", 1986, 2.543138, 578571 ], [ \"Algeria\", 1987, 2.713984, 634859 ], [ \"Algeria\", 1988, 2.901974, 697209 ], [ \"Algeria\", 1989, 3.041421, 749851 ], [ \"Algeria\", 1990, 3.211706, 812000 ], [ \"Algeria\", 1991, 3.408262, 883120 ], [ \"Algeria\", 1992, 3.626165, 962247 ], [ \"Algeria\", 1993, 3.934595, 1068094 ], [ \"Algeria\", 1994, 4.048233, 1122409 ], [ \"Algeria\", 1995, 4.161698, 1176316 ], [ \"Algeria\", 1996, 4.444185, 1278142 ], [ \"Algeria\", 1997, 4.793124, 1400343 ], [ \"Algeria\", 1998, 4.982058, 1477000 ], [ \"Algeria\", 1999, 5.320636, 1600000 ], [ \"Algeria\", 2000, 5.773696, 1761327 ], [ \"Algeria\", 2001, 6.073472, 1880000 ], [ \"Algeria\", 2002, 6.207401, 1950000 ], [ \"Algeria\", 2003, 6.521674, 2079464 ], [ \"Algeria\", 2004, 7.683095, 2486720 ], [ \"Algeria\", 2005, 7.828447, 2572000 ], [ \"Algeria\", 2006, 8.519254, 2841297 ], [ \"Algeria\", 2007, 9.062537, 3068409 ], [ \"Algeria\", 2008, 8.928816, 3069140 ], [ \"Algeria\", 2009, 7.38252, 2576165 ], [ \"American Samoa\", 1982, 13.19488, 4600 ], [ \"American Samoa\", 1983, 12.6638, 4600 ], [ \"American Samoa\", 1984, 12.27658, 4650 ], [ \"American Samoa\", 1985, 11.91291, 4700 ], [ \"American Samoa\", 1986, 11.57436, 4750 ], [ \"American Samoa\", 1987, 11.25783, 4800 ], [ \"American Samoa\", 1988, 10.97062, 4850 ], [ \"American Samoa\", 1989, 10.71999, 4900 ], [ \"American Samoa\", 1990, 11.6753, 5500 ], [ \"American Samoa\", 1991, 11.36786, 5500 ], [ \"American Samoa\", 1992, 12.11167, 6000 ], [ \"American Samoa\", 1993, 15.8084, 8000 ], [ \"American Samoa\", 1994, 18.39944, 9500 ], [ \"American Samoa\", 1995, 18.61349, 9800 ], [ \"American Samoa\", 1996, 18.63204, 10000 ], [ \"American Samoa\", 1997, 18.46874, 10100 ], [ \"American Samoa\", 1998, 18.31173, 10200 ], [ \"American Samoa\", 1999, 17.9872, 10200 ], [ \"American Samoa\", 2000, 17.76622, 10252 ], [ \"American Samoa\", 2001, 21.44439, 12587 ], [ \"American Samoa\", 2002, 23.54449, 14053 ], [ \"American Samoa\", 2003, 17.65229, 10713 ], [ \"American Samoa\", 2004, 16.77658, 10354 ], [ \"American Samoa\", 2005, 16.56605, 10400 ], [ \"American Samoa\", 2006, 16.27976, 10400 ], [ \"American Samoa\", 2007, 15.99434, 10400 ], [ \"American Samoa\", 2008, 15.71306, 10400 ], [ \"American Samoa\", 2009, 15.44126, 10400 ], [ \"Andorra\", 1965, 2.700367, 500 ], [ \"Andorra\", 1970, 7.786108, 1890 ], [ \"Andorra\", 1975, 12.54472, 3857 ], [ \"Andorra\", 1976, 12.97886, 4174 ], [ \"Andorra\", 1977, 14.16081, 4713 ], [ \"Andorra\", 1978, 16.09699, 5543 ], [ \"Andorra\", 1979, 17.70053, 6329 ], [ \"Andorra\", 1980, 18.82031, 7026 ], [ \"Andorra\", 1981, 22.79888, 8944 ], [ \"Andorra\", 1982, 25.08757, 10385 ], [ \"Andorra\", 1983, 27.49708, 12000 ], [ \"Andorra\", 1984, 28.44203, 13000 ], [ \"Andorra\", 1985, 29.52341, 14000 ], [ \"Andorra\", 1986, 32.03255, 15588 ], [ \"Andorra\", 1987, 34.09389, 16885 ], [ \"Andorra\", 1988, 35.63173, 17911 ], [ \"Andorra\", 1989, 37.89303, 19427 ], [ \"Andorra\", 1990, 40.74046, 21502 ], [ \"Andorra\", 1991, 42.61406, 23416 ], [ \"Andorra\", 1992, 43.88975, 25302 ], [ \"Andorra\", 1993, 44.23067, 26760 ], [ \"Andorra\", 1994, 45.0405, 28362 ], [ \"Andorra\", 1995, 46.05172, 29795 ], [ \"Andorra\", 1996, 47.26967, 30964 ], [ \"Andorra\", 1997, 48.7723, 31980 ], [ \"Andorra\", 1998, 50.41623, 32946 ], [ \"Andorra\", 1999, 51.3225, 33607 ], [ \"Andorra\", 2000, 51.51232, 34215 ], [ \"Andorra\", 2001, 50.49094, 34505 ], [ \"Andorra\", 2002, 49.15476, 34922 ], [ \"Andorra\", 2003, 47.41177, 35171 ], [ \"Andorra\", 2004, 45.37743, 35040 ], [ \"Andorra\", 2005, 44.42996, 35444 ], [ \"Andorra\", 2006, 44.66344, 36507 ], [ \"Andorra\", 2007, 44.63627, 37153 ], [ \"Andorra\", 2008, 44.27688, 37375 ], [ \"Andorra\", 2009, 44.30384, 37882 ], [ \"Angola\", 1960, 0.1330143, 6666 ], [ \"Angola\", 1965, 0.1816476, 10000 ], [ \"Angola\", 1970, 0.213723, 13000 ], [ \"Angola\", 1975, 0.2642112, 18000 ], [ \"Angola\", 1976, 0.2717431, 19000 ], [ \"Angola\", 1977, 0.2785551, 20000 ], [ \"Angola\", 1978, 0.3386078, 25000 ], [ \"Angola\", 1979, 0.3943784, 30000 ], [ \"Angola\", 1980, 0.4583649, 36000 ], [ \"Angola\", 1981, 0.451515, 36700 ], [ \"Angola\", 1982, 0.5848284, 49280 ], [ \"Angola\", 1983, 0.5252665, 45890 ], [ \"Angola\", 1984, 0.5087442, 46000 ], [ \"Angola\", 1985, 0.5074347, 47350 ], [ \"Angola\", 1986, 0.5010377, 48090 ], [ \"Angola\", 1987, 0.6295937, 62000 ], [ \"Angola\", 1988, 0.6438951, 65000 ], [ \"Angola\", 1989, 0.6466455, 67000 ], [ \"Angola\", 1990, 0.6565705, 70000 ], [ \"Angola\", 1991, 0.6543786, 72000 ], [ \"Angola\", 1992, 0.4297528, 48900 ], [ \"Angola\", 1993, 0.4527062, 53300 ], [ \"Angola\", 1994, 0.4358206, 53020 ], [ \"Angola\", 1995, 0.4206033, 52740 ], [ \"Angola\", 1996, 0.4083324, 52625 ], [ \"Angola\", 1997, 0.4711403, 62279 ], [ \"Angola\", 1998, 0.480535, 65100 ], [ \"Angola\", 1999, 0.4835987, 67200 ], [ \"Angola\", 2000, 0.4544971, 64900 ], [ \"Angola\", 2001, 0.5222933, 76800 ], [ \"Angola\", 2002, 0.5288833, 80200 ], [ \"Angola\", 2003, 0.5435158, 85043 ], [ \"Angola\", 2004, 0.584303, 94280 ], [ \"Angola\", 2005, 0.5822746, 96760 ], [ \"Angola\", 2006, 0.5744301, 98165 ], [ \"Angola\", 2007, 0.5371474, 94294 ], [ \"Angola\", 2008, 0.6342495, 114296 ], [ \"Angola\", 2009, 1.639015, 303179 ], [ \"Antigua and Barbuda\", 1970, 2.584411, 1700 ], [ \"Antigua and Barbuda\", 1975, 3.061208, 1900 ], [ \"Antigua and Barbuda\", 1976, 2.490334, 1900 ], [ \"Antigua and Barbuda\", 1981, 4.906084, 3500 ], [ \"Antigua and Barbuda\", 1982, 5.671265, 4000 ], [ \"Antigua and Barbuda\", 1983, 7.167739, 5000 ], [ \"Antigua and Barbuda\", 1984, 8.417567, 5796 ], [ \"Antigua and Barbuda\", 1985, 10.33409, 7000 ], [ \"Antigua and Barbuda\", 1986, 12.05655, 8000 ], [ \"Antigua and Barbuda\", 1987, 14.65733, 9500 ], [ \"Antigua and Barbuda\", 1988, 17.36084, 11000 ], [ \"Antigua and Barbuda\", 1989, 20.86008, 13000 ], [ \"Antigua and Barbuda\", 1990, 25.80666, 15980 ], [ \"Antigua and Barbuda\", 1991, 21.96019, 13670 ], [ \"Antigua and Barbuda\", 1992, 26.60719, 16820 ], [ \"Antigua and Barbuda\", 1993, 29.7042, 19210 ], [ \"Antigua and Barbuda\", 1994, 36.58386, 24284 ], [ \"Antigua and Barbuda\", 1995, 37.98527, 25890 ], [ \"Antigua and Barbuda\", 1996, 40.0183, 28000 ], [ \"Antigua and Barbuda\", 1997, 43.15866, 31000 ], [ \"Antigua and Barbuda\", 1998, 46.14612, 34000 ], [ \"Antigua and Barbuda\", 1999, 48.36872, 36500 ], [ \"Antigua and Barbuda\", 2000, 49.65385, 38300 ], [ \"Antigua and Barbuda\", 2001, 47.37471, 37264 ], [ \"Antigua and Barbuda\", 2002, 47.54324, 38046 ], [ \"Antigua and Barbuda\", 2003, 46.76347, 38000 ], [ \"Antigua and Barbuda\", 2004, 46.10643, 38000 ], [ \"Antigua and Barbuda\", 2005, 43.67084, 36480 ], [ \"Antigua and Barbuda\", 2006, 44.31995, 37500 ], [ \"Antigua and Barbuda\", 2007, 44.25451, 37900 ], [ \"Antigua and Barbuda\", 2008, 43.86269, 38000 ], [ \"Antigua and Barbuda\", 2009, 42.63699, 37350 ], [ \"Argentina\", 1960, 4.43663, 914656 ], [ \"Argentina\", 1965, 4.936476, 1100000 ], [ \"Argentina\", 1970, 5.370934, 1287000 ], [ \"Argentina\", 1975, 6.337968, 1651000 ], [ \"Argentina\", 1976, 6.346896, 1678000 ], [ \"Argentina\", 1977, 6.29728, 1692000 ], [ \"Argentina\", 1978, 6.329482, 1728000 ], [ \"Argentina\", 1979, 6.480327, 1797000 ], [ \"Argentina\", 1980, 6.674054, 1879000 ], [ \"Argentina\", 1981, 7.696981, 2199000 ], [ \"Argentina\", 1982, 8.148524, 2361350 ], [ \"Argentina\", 1983, 7.729741, 2271525 ], [ \"Argentina\", 1984, 8.723177, 2599607 ], [ \"Argentina\", 1985, 8.96839, 2710894 ], [ \"Argentina\", 1986, 9.323541, 2859209 ], [ \"Argentina\", 1987, 9.531686, 2965970 ], [ \"Argentina\", 1988, 10.05774, 3175756 ], [ \"Argentina\", 1989, 9.626465, 3084000 ], [ \"Argentina\", 1990, 9.313736, 3026732 ], [ \"Argentina\", 1991, 9.501224, 3131235 ], [ \"Argentina\", 1992, 10.75799, 3594533 ], [ \"Argentina\", 1993, 11.75896, 3982435 ], [ \"Argentina\", 1994, 14.53044, 4986887 ], [ \"Argentina\", 1995, 16.43336, 5714158 ], [ \"Argentina\", 1996, 17.78022, 6262637 ], [ \"Argentina\", 1997, 19.13824, 6826799 ], [ \"Argentina\", 1998, 19.64892, 7095464 ], [ \"Argentina\", 1999, 19.7703, 7223168 ], [ \"Argentina\", 2000, 21.37108, 7894205 ], [ \"Argentina\", 2001, 21.78959, 8131435 ], [ \"Argentina\", 2002, 20.4599, 7708568 ], [ \"Argentina\", 2003, 22.62779, 8603869 ], [ \"Argentina\", 2004, 22.8306, 8760566 ], [ \"Argentina\", 2005, 24.37718, 9441673 ], [ \"Argentina\", 2006, 24.19054, 9459794 ], [ \"Argentina\", 2007, 24.05644, 9500000 ], [ \"Argentina\", 2008, 24.42855, 9742833 ], [ \"Argentina\", 2009, 24.25277, 9768135 ], [ \"Armenia\", 1975, 6.724117, 190000 ], [ \"Armenia\", 1976, 7.284506, 210000 ], [ \"Armenia\", 1977, 8.508666, 250000 ], [ \"Armenia\", 1978, 9.024203, 270000 ], [ \"Armenia\", 1979, 9.525173, 290000 ], [ \"Armenia\", 1980, 9.68899, 300000 ], [ \"Armenia\", 1981, 10.80777, 340000 ], [ \"Armenia\", 1982, 11.2751, 360000 ], [ \"Armenia\", 1983, 11.73125, 380000 ], [ \"Armenia\", 1984, 12.16698, 400000 ], [ \"Armenia\", 1985, 12.57806, 420000 ], [ \"Armenia\", 1986, 12.95447, 440000 ], [ \"Armenia\", 1987, 13.5954, 470000 ], [ \"Armenia\", 1988, 14.27173, 501000 ], [ \"Armenia\", 1989, 14.96027, 530000 ], [ \"Armenia\", 1990, 15.79826, 560000 ], [ \"Armenia\", 1991, 16.2896, 572100 ], [ \"Armenia\", 1992, 16.76545, 578400 ], [ \"Armenia\", 1993, 17.31137, 583460 ], [ \"Armenia\", 1994, 17.84239, 587113 ], [ \"Armenia\", 1995, 18.08158, 582800 ], [ \"Armenia\", 1996, 18.26833, 579500 ], [ \"Armenia\", 1997, 18.11297, 567800 ], [ \"Armenia\", 1998, 17.90297, 556600 ], [ \"Armenia\", 1999, 17.60909, 544197 ], [ \"Armenia\", 2000, 17.34134, 533387 ], [ \"Armenia\", 2001, 17.3371, 531456 ], [ \"Armenia\", 2002, 17.73663, 542846 ], [ \"Armenia\", 2003, 18.4211, 563679 ], [ \"Armenia\", 2004, 18.90929, 578973 ], [ \"Armenia\", 2005, 19.39375, 594404 ], [ \"Armenia\", 2006, 19.68079, 603900 ], [ \"Armenia\", 2007, 20.33231, 624700 ], [ \"Armenia\", 2008, 20.34392, 626000 ], [ \"Armenia\", 2009, 20.43497, 630000 ], [ \"Aruba\", 1982, 14.41846, 9000 ], [ \"Aruba\", 1983, 15.77337, 10000 ], [ \"Aruba\", 1984, 17.16203, 11000 ], [ \"Aruba\", 1985, 18.6515, 12000 ], [ \"Aruba\", 1986, 20.40481, 13055 ], [ \"Aruba\", 1987, 21.98388, 13887 ], [ \"Aruba\", 1988, 25.1988, 15718 ], [ \"Aruba\", 1989, 28.06265, 17469 ], [ \"Aruba\", 1990, 29.59214, 18712 ], [ \"Aruba\", 1991, 28.99701, 19000 ], [ \"Aruba\", 1992, 29.60125, 20400 ], [ \"Aruba\", 1993, 28.79118, 21000 ], [ \"Aruba\", 1994, 27.95293, 21500 ], [ \"Aruba\", 1995, 33.97593, 27300 ], [ \"Aruba\", 1996, 40.41357, 33576 ], [ \"Aruba\", 1997, 38.96911, 33220 ], [ \"Aruba\", 1998, 40.28585, 35064 ], [ \"Aruba\", 1999, 41.1831, 36557 ], [ \"Aruba\", 2000, 42.02654, 38100 ], [ \"Aruba\", 2001, 40.03925, 37132 ], [ \"Aruba\", 2002, 39.12297, 37132 ], [ \"Aruba\", 2003, 38.50987, 37390 ], [ \"Aruba\", 2004, 38.32338, 38003 ], [ \"Aruba\", 2005, 37.8667, 38259 ], [ \"Aruba\", 2006, 37.63559, 38651 ], [ \"Aruba\", 2007, 37.06132, 38609 ], [ \"Aruba\", 2008, 36.47148, 38461 ], [ \"Aruba\", 2009, 35.95468, 38300 ], [ \"Australia\", 1960, 15.19945, 1561968 ], [ \"Australia\", 1965, 17.44015, 2010000 ], [ \"Australia\", 1970, 21.2439, 2704000 ], [ \"Australia\", 1975, 25.97525, 3539000 ], [ \"Australia\", 1976, 26.76755, 3700000 ], [ \"Australia\", 1977, 27.83999, 3907000 ], [ \"Australia\", 1978, 29.22725, 4165945 ], [ \"Australia\", 1979, 30.73751, 4449468 ], [ \"Australia\", 1980, 32.2732, 4742662 ], [ \"Australia\", 1981, 33.99831, 5069342 ], [ \"Australia\", 1982, 35.41875, 5356572 ], [ \"Australia\", 1983, 36.45422, 5591667 ], [ \"Australia\", 1984, 37.59266, 5850594 ], [ \"Australia\", 1985, 39.1562, 6186835 ], [ \"Australia\", 1986, 40.49989, 6501468 ], [ \"Australia\", 1987, 41.77214, 6816301 ], [ \"Australia\", 1988, 42.75549, 7091549 ], [ \"Australia\", 1989, 44.0438, 7419982 ], [ \"Australia\", 1990, 45.56068, 7786889 ], [ \"Australia\", 1991, 46.46386, 8046029 ], [ \"Australia\", 1992, 47.11191, 8257000 ], [ \"Australia\", 1993, 48.18051, 8540000 ], [ \"Australia\", 1994, 49.38524, 8850000 ], [ \"Australia\", 1995, 49.12185, 8900000 ], [ \"Australia\", 1996, 50.05674, 9170000 ], [ \"Australia\", 1997, 50.47939, 9350000 ], [ \"Australia\", 1998, 50.93324, 9540000 ], [ \"Australia\", 1999, 51.5148, 9760000 ], [ \"Australia\", 2000, 52.42311, 10050000 ], [ \"Australia\", 2001, 51.83716, 10060000 ], [ \"Australia\", 2002, 52.91856, 10400000 ], [ \"Australia\", 2003, 52.55291, 10460000 ], [ \"Australia\", 2004, 51.45705, 10370000 ], [ \"Australia\", 2005, 49.62061, 10120000 ], [ \"Australia\", 2006, 48.18689, 9940000 ], [ \"Australia\", 2007, 46.80184, 9760000 ], [ \"Australia\", 2008, 44.46157, 9370000 ], [ \"Australia\", 2009, 42.36155, 9020000 ], [ \"Austria\", 1960, 6.084094, 428807 ], [ \"Austria\", 1965, 9.008531, 655000 ], [ \"Austria\", 1970, 12.97695, 969000 ], [ \"Austria\", 1975, 19.85776, 1505000 ], [ \"Austria\", 1976, 21.41002, 1623000 ], [ \"Austria\", 1977, 23.06067, 1747000 ], [ \"Austria\", 1978, 24.91261, 1885000 ], [ \"Austria\", 1979, 26.90381, 2033000 ], [ \"Austria\", 1980, 29.02449, 2191000 ], [ \"Austria\", 1981, 30.79122, 2323000 ], [ \"Austria\", 1982, 32.32943, 2438672 ], [ \"Austria\", 1983, 33.76738, 2547908 ], [ \"Austria\", 1984, 34.97361, 2640843 ], [ \"Austria\", 1985, 36.10484, 2729389 ], [ \"Austria\", 1986, 37.22721, 2818437 ], [ \"Austria\", 1987, 38.32042, 2906736 ], [ \"Austria\", 1988, 39.46458, 3001319 ], [ \"Austria\", 1989, 40.65008, 3102814 ], [ \"Austria\", 1990, 42.02015, 3223161 ], [ \"Austria\", 1991, 43.32076, 3344179 ], [ \"Austria\", 1992, 44.56646, 3466493 ], [ \"Austria\", 1993, 45.66417, 3579900 ], [ \"Austria\", 1994, 46.76581, 3691800 ], [ \"Austria\", 1995, 47.84627, 3796900 ], [ \"Austria\", 1996, 49.01234, 3901600 ], [ \"Austria\", 1997, 49.79494, 3969400 ], [ \"Austria\", 1998, 50.25061, 4008000 ], [ \"Austria\", 1999, 49.33237, 3939000 ], [ \"Austria\", 2000, 49.93309, 3997000 ], [ \"Austria\", 2001, 49.72198, 3997000 ], [ \"Austria\", 2002, 48.0355, 3883000 ], [ \"Austria\", 2003, 47.65812, 3877000 ], [ \"Austria\", 2004, 46.67587, 3821000 ], [ \"Austria\", 2005, 45.41878, 3739000 ], [ \"Austria\", 2006, 43.58033, 3605000 ], [ \"Austria\", 2007, 41.01361, 3407000 ], [ \"Austria\", 2008, 39.40125, 3285000 ], [ \"Austria\", 2009, 38.89342, 3253000 ], [ \"Azerbaijan\", 1975, 3.691335, 210000 ], [ \"Azerbaijan\", 1976, 3.976083, 230000 ], [ \"Azerbaijan\", 1977, 4.593197, 270000 ], [ \"Azerbaijan\", 1978, 4.856647, 290000 ], [ \"Azerbaijan\", 1979, 5.276258, 320000 ], [ \"Azerbaijan\", 1980, 5.519031, 340000 ], [ \"Azerbaijan\", 1981, 6.231484, 390000 ], [ \"Azerbaijan\", 1982, 6.447609, 410000 ], [ \"Azerbaijan\", 1983, 6.654905, 430000 ], [ \"Azerbaijan\", 1984, 6.854234, 450000 ], [ \"Azerbaijan\", 1985, 7.046317, 470000 ], [ \"Azerbaijan\", 1986, 7.37975, 500000 ], [ \"Azerbaijan\", 1987, 7.702605, 530000 ], [ \"Azerbaijan\", 1988, 7.999697, 559000 ], [ \"Azerbaijan\", 1989, 8.312406, 590000 ], [ \"Azerbaijan\", 1990, 8.59715, 620000 ], [ \"Azerbaijan\", 1991, 8.459982, 620150 ], [ \"Azerbaijan\", 1992, 8.323512, 620300 ], [ \"Azerbaijan\", 1993, 8.192448, 620390 ], [ \"Azerbaijan\", 1994, 8.266254, 635237 ], [ \"Azerbaijan\", 1995, 8.21621, 639532 ], [ \"Azerbaijan\", 1996, 8.198278, 645068 ], [ \"Azerbaijan\", 1997, 8.290558, 658296 ], [ \"Azerbaijan\", 1998, 8.499124, 680200 ], [ \"Azerbaijan\", 1999, 9.054641, 730000 ], [ \"Azerbaijan\", 2000, 9.865281, 801200 ], [ \"Azerbaijan\", 2001, 10.57009, 864800 ], [ \"Azerbaijan\", 2002, 11.23449, 926000 ], [ \"Azerbaijan\", 2003, 11.333, 941366 ], [ \"Azerbaijan\", 2004, 12.09887, 1013400 ], [ \"Azerbaijan\", 2005, 12.94466, 1094200 ], [ \"Azerbaijan\", 2006, 13.78472, 1176976 ], [ \"Azerbaijan\", 2007, 14.52005, 1253300 ], [ \"Azerbaijan\", 2008, 15.01054, 1310500 ], [ \"Azerbaijan\", 2009, 15.8636, 1401100 ], [ \"Bahamas\", 1970, 12.0181, 20400 ], [ \"Bahamas\", 1975, 12.07301, 22800 ], [ \"Bahamas\", 1976, 13.69479, 26400 ], [ \"Bahamas\", 1977, 13.45936, 26500 ], [ \"Bahamas\", 1978, 14.51429, 29200 ], [ \"Bahamas\", 1979, 14.15363, 29100 ], [ \"Bahamas\", 1980, 14.79232, 31080 ], [ \"Bahamas\", 1981, 15.01406, 32240 ], [ \"Bahamas\", 1982, 18.09716, 39720 ], [ \"Bahamas\", 1983, 16.17398, 36275 ], [ \"Bahamas\", 1984, 16.94314, 38803 ], [ \"Bahamas\", 1985, 17.97146, 41986 ], [ \"Bahamas\", 1986, 20.34538, 48433 ], [ \"Bahamas\", 1987, 22.23795, 53891 ], [ \"Bahamas\", 1988, 23.68275, 58400 ], [ \"Bahamas\", 1989, 24.64489, 61853 ], [ \"Bahamas\", 1990, 27.33614, 69872 ], [ \"Bahamas\", 1991, 30.00342, 78161 ], [ \"Bahamas\", 1992, 28.91433, 76806 ], [ \"Bahamas\", 1993, 28.12263, 76180 ], [ \"Bahamas\", 1994, 28.55104, 78836 ], [ \"Bahamas\", 1995, 29.76344, 83707 ], [ \"Bahamas\", 1996, 31.25749, 89463 ], [ \"Bahamas\", 1997, 33.7131, 98125 ], [ \"Bahamas\", 1998, 35.79425, 105869 ], [ \"Bahamas\", 1999, 37.01765, 111184 ], [ \"Bahamas\", 2000, 37.51394, 114347 ], [ \"Bahamas\", 2001, 39.88639, 123302 ], [ \"Bahamas\", 2002, 40.39206, 126556 ], [ \"Bahamas\", 2003, 41.54162, 131856 ], [ \"Bahamas\", 2004, 43.53234, 139936 ], [ \"Bahamas\", 2005, 40.88345, 133074 ], [ \"Bahamas\", 2006, 39.9222, 131564 ], [ \"Bahamas\", 2007, 39.82327, 132854 ], [ \"Bahamas\", 2008, 39.31554, 132756 ], [ \"Bahamas\", 2009, 37.74044, 128964 ], [ \"Bahrain\", 1965, 1.675173, 3200 ], [ \"Bahrain\", 1970, 2.869284, 6300 ], [ \"Bahrain\", 1975, 5.148232, 14000 ], [ \"Bahrain\", 1976, 5.490951, 15700 ], [ \"Bahrain\", 1977, 6.444412, 19400 ], [ \"Bahrain\", 1978, 7.029121, 22262 ], [ \"Bahrain\", 1979, 10.02691, 33310 ], [ \"Bahrain\", 1980, 11.87907, 41220 ], [ \"Bahrain\", 1981, 12.64494, 45627 ], [ \"Bahrain\", 1982, 13.50748, 50503 ], [ \"Bahrain\", 1983, 14.73693, 56974 ], [ \"Bahrain\", 1984, 16.09658, 64330 ], [ \"Bahrain\", 1985, 16.75877, 69297 ], [ \"Bahrain\", 1986, 17.02524, 72907 ], [ \"Bahrain\", 1987, 16.9226, 75080 ], [ \"Bahrain\", 1988, 18.05379, 82996 ], [ \"Bahrain\", 1989, 18.42452, 87737 ], [ \"Bahrain\", 1990, 19.06778, 93995 ], [ \"Bahrain\", 1991, 19.72091, 100581 ], [ \"Bahrain\", 1992, 21.33776, 112530 ], [ \"Bahrain\", 1993, 22.83001, 124353 ], [ \"Bahrain\", 1994, 24.1922, 135853 ], [ \"Bahrain\", 1995, 24.38155, 140850 ], [ \"Bahrain\", 1996, 24.35166, 144391 ], [ \"Bahrain\", 1997, 25.07363, 152303 ], [ \"Bahrain\", 1998, 25.36249, 157619 ], [ \"Bahrain\", 1999, 26.02003, 165369 ], [ \"Bahrain\", 2000, 26.30351, 170976 ], [ \"Bahrain\", 2001, 26.14542, 173855 ], [ \"Bahrain\", 2002, 25.79057, 175446 ], [ \"Bahrain\", 2003, 26.69307, 185756 ], [ \"Bahrain\", 2004, 26.91493, 191553 ], [ \"Bahrain\", 2005, 26.59805, 193520 ], [ \"Bahrain\", 2006, 26.11839, 194196 ], [ \"Bahrain\", 2007, 26.79722, 203541 ], [ \"Bahrain\", 2008, 28.41545, 220386 ], [ \"Bahrain\", 2009, 30.07051, 238000 ], [ \"Bangladesh\", 1970, 0.06932968, 45000 ], [ \"Bangladesh\", 1975, 0.08199167, 60000 ], [ \"Bangladesh\", 1976, 0.08373993, 68000 ], [ \"Bangladesh\", 1977, 0.09111191, 76000 ], [ \"Bangladesh\", 1978, 0.1003723, 86000 ], [ \"Bangladesh\", 1979, 0.1011264, 89000 ], [ \"Bangladesh\", 1980, 0.1050918, 95000 ], [ \"Bangladesh\", 1981, 0.1087818, 101000 ], [ \"Bangladesh\", 1982, 0.1132687, 108000 ], [ \"Bangladesh\", 1983, 0.1170532, 114580 ], [ \"Bangladesh\", 1984, 0.1205685, 121100 ], [ \"Bangladesh\", 1985, 0.147, 151400 ], [ \"Bangladesh\", 1986, 0.1552995, 163900 ], [ \"Bangladesh\", 1987, 0.1613689, 174400 ], [ \"Bangladesh\", 1988, 0.1691632, 187100 ], [ \"Bangladesh\", 1989, 0.1697283, 192000 ], [ \"Bangladesh\", 1990, 0.1885289, 218000 ], [ \"Bangladesh\", 1991, 0.1875171, 221513 ], [ \"Bangladesh\", 1992, 0.1929305, 232700 ], [ \"Bangladesh\", 1993, 0.1998059, 245947 ], [ \"Bangladesh\", 1994, 0.2088483, 262274 ], [ \"Bangladesh\", 1995, 0.223759, 286605 ], [ \"Bangladesh\", 1996, 0.242003, 316081 ], [ \"Bangladesh\", 1997, 0.2763976, 368017 ], [ \"Bangladesh\", 1998, 0.3040759, 412607 ], [ \"Bangladesh\", 1999, 0.3132126, 432968 ], [ \"Bangladesh\", 2000, 0.3490188, 491303 ], [ \"Bangladesh\", 2001, 0.3942254, 564880 ], [ \"Bangladesh\", 2002, 0.4155982, 605931 ], [ \"Bangladesh\", 2003, 0.5004325, 742048 ], [ \"Bangladesh\", 2004, 0.5512975, 830950 ], [ \"Bangladesh\", 2005, 0.698789, 1070000 ], [ \"Bangladesh\", 2006, 0.7294336, 1134000 ], [ \"Bangladesh\", 2007, 0.7523931, 1186919 ], [ \"Bangladesh\", 2008, 0.8402843, 1344456 ], [ \"Bangladesh\", 2009, 0.9387824, 1522900 ], [ \"Barbados\", 1960, 3.00571, 6933 ], [ \"Barbados\", 1965, 4.592262, 10801 ], [ \"Barbados\", 1970, 7.82479, 18682 ], [ \"Barbados\", 1975, 11.01293, 27046 ], [ \"Barbados\", 1976, 11.7501, 28962 ], [ \"Barbados\", 1977, 12.66989, 31313 ], [ \"Barbados\", 1978, 13.13746, 32539 ], [ \"Barbados\", 1979, 13.60099, 33765 ], [ \"Barbados\", 1980, 13.87214, 34539 ], [ \"Barbados\", 1981, 13.99157, 34962 ], [ \"Barbados\", 1982, 15.22102, 38190 ], [ \"Barbados\", 1983, 16.63168, 41917 ], [ \"Barbados\", 1984, 18.18541, 46050 ], [ \"Barbados\", 1985, 19.05645, 48488 ], [ \"Barbados\", 1986, 20.21627, 51692 ], [ \"Barbados\", 1987, 21.42026, 55040 ], [ \"Barbados\", 1988, 23.04644, 59487 ], [ \"Barbados\", 1989, 25.52084, 66113 ], [ \"Barbados\", 1990, 27.78201, 72141 ], [ \"Barbados\", 1991, 29.9975, 77977 ], [ \"Barbados\", 1992, 30.81632, 80095 ], [ \"Barbados\", 1993, 31.78664, 82507 ], [ \"Barbados\", 1994, 32.97453, 85376 ], [ \"Barbados\", 1995, 34.93624, 90132 ], [ \"Barbados\", 1996, 37.6016, 96547 ], [ \"Barbados\", 1997, 42.48418, 108457 ], [ \"Barbados\", 1998, 44.53985, 113031 ], [ \"Barbados\", 1999, 45.54473, 115000 ], [ \"Barbados\", 2000, 49.20685, 123832 ], [ \"Barbados\", 2001, 51.30923, 128956 ], [ \"Barbados\", 2002, 52.88901, 133000 ], [ \"Barbados\", 2003, 53.1841, 134000 ], [ \"Barbados\", 2004, 53.73482, 135732 ], [ \"Barbados\", 2005, 53.25863, 134878 ], [ \"Barbados\", 2006, 52.88156, 134261 ], [ \"Barbados\", 2007, 52.7459, 134261 ], [ \"Barbados\", 2008, 58.77674, 150000 ], [ \"Barbados\", 2009, 53.03433, 135700 ], [ \"Belarus\", 1960, 0.9157509, 75000 ], [ \"Belarus\", 1965, 1.33496, 114900 ], [ \"Belarus\", 1970, 2.849715, 257600 ], [ \"Belarus\", 1975, 5.233264, 490200 ], [ \"Belarus\", 1976, 5.739999, 541000 ], [ \"Belarus\", 1977, 6.162488, 584300 ], [ \"Belarus\", 1978, 6.619804, 631400 ], [ \"Belarus\", 1979, 7.043128, 675900 ], [ \"Belarus\", 1980, 7.484599, 722900 ], [ \"Belarus\", 1981, 7.781702, 756700 ], [ \"Belarus\", 1982, 8.202183, 803200 ], [ \"Belarus\", 1983, 8.723058, 860300 ], [ \"Belarus\", 1984, 9.787919, 972100 ], [ \"Belarus\", 1985, 10.0305, 1002900 ], [ \"Belarus\", 1986, 11.07941, 1114874 ], [ \"Belarus\", 1987, 12.12577, 1227516 ], [ \"Belarus\", 1988, 13.2393, 1347501 ], [ \"Belarus\", 1989, 14.32016, 1464128 ], [ \"Belarus\", 1990, 15.34312, 1574158 ], [ \"Belarus\", 1991, 16.27283, 1673460 ], [ \"Belarus\", 1992, 16.94236, 1744496 ], [ \"Belarus\", 1993, 17.618, 1814359 ], [ \"Belarus\", 1994, 18.36894, 1890000 ], [ \"Belarus\", 1995, 19.16766, 1968435 ], [ \"Belarus\", 1996, 20.78198, 2127972 ], [ \"Belarus\", 1997, 22.67313, 2312599 ], [ \"Belarus\", 1998, 24.52301, 2489851 ], [ \"Belarus\", 1999, 26.11457, 2638468 ], [ \"Belarus\", 2000, 27.37248, 2751905 ], [ \"Belarus\", 2001, 28.61036, 2862376 ], [ \"Belarus\", 2002, 29.80048, 2967163 ], [ \"Belarus\", 2003, 30.99316, 3071342 ], [ \"Belarus\", 2004, 32.19977, 3175886 ], [ \"Belarus\", 2005, 33.45715, 3284272 ], [ \"Belarus\", 2006, 34.47267, 3367950 ], [ \"Belarus\", 2007, 37.76006, 3671850 ], [ \"Belarus\", 2008, 38.41464, 3718094 ], [ \"Belarus\", 2009, 41.2028, 3969290 ], [ \"Belgium\", 1960, 8.513278, 779262 ], [ \"Belgium\", 1965, 11.09475, 1049970 ], [ \"Belgium\", 1970, 13.91471, 1343541 ], [ \"Belgium\", 1975, 18.8758, 1849960 ], [ \"Belgium\", 1976, 19.81222, 1941000 ], [ \"Belgium\", 1977, 20.89523, 2050000 ], [ \"Belgium\", 1978, 22.17799, 2178000 ], [ \"Belgium\", 1979, 23.58013, 2317000 ], [ \"Belgium\", 1980, 24.84797, 2441993 ], [ \"Belgium\", 1981, 26.33136, 2587107 ], [ \"Belgium\", 1982, 27.72189, 2722107 ], [ \"Belgium\", 1983, 28.71692, 2818084 ], [ \"Belgium\", 1984, 29.81234, 2924966 ], [ \"Belgium\", 1985, 30.89235, 3032418 ], [ \"Belgium\", 1986, 32.83323, 3227160 ], [ \"Belgium\", 1987, 34.18813, 3367192 ], [ \"Belgium\", 1988, 35.69881, 3525140 ], [ \"Belgium\", 1989, 37.4786, 3711641 ], [ \"Belgium\", 1990, 39.38999, 3912629 ], [ \"Belgium\", 1991, 41.10949, 4096071 ], [ \"Belgium\", 1992, 42.66092, 4264342 ], [ \"Belgium\", 1993, 43.8352, 4395695 ], [ \"Belgium\", 1994, 45.17471, 4543468 ], [ \"Belgium\", 1995, 46.43052, 4682086 ], [ \"Belgium\", 1996, 45.75, 4623685 ], [ \"Belgium\", 1997, 47.09186, 4768235 ], [ \"Belgium\", 1998, 47.87675, 4856502 ], [ \"Belgium\", 1999, 49.27147, 5008640 ], [ \"Belgium\", 2000, 49.41014, 5036422 ], [ \"Belgium\", 2001, 50.17577, 5131694 ], [ \"Belgium\", 2002, 48.03102, 4931600 ], [ \"Belgium\", 2003, 47.27103, 4875000 ], [ \"Belgium\", 2004, 46.33077, 4801000 ], [ \"Belgium\", 2005, 46.03436, 4794583 ], [ \"Belgium\", 2006, 45.14924, 4727800 ], [ \"Belgium\", 2007, 46.02949, 4847263 ], [ \"Belgium\", 2008, 44.70583, 4734517 ], [ \"Belgium\", 2009, 43.54348, 4635989 ], [ \"Belize\", 1960, 1.096758, 1018 ], [ \"Belize\", 1965, 2.620496, 2800 ], [ \"Belize\", 1970, 2.445685, 3000 ], [ \"Belize\", 1975, 2.467566, 3300 ], [ \"Belize\", 1976, 2.469017, 3345 ], [ \"Belize\", 1977, 2.565374, 3518 ], [ \"Belize\", 1978, 2.583023, 3588 ], [ \"Belize\", 1979, 2.729967, 3851 ], [ \"Belize\", 1980, 2.691313, 3870 ], [ \"Belize\", 1981, 2.648098, 3898 ], [ \"Belize\", 1982, 3.457899, 5229 ], [ \"Belize\", 1983, 3.878787, 6039 ], [ \"Belize\", 1984, 3.790444, 6079 ], [ \"Belize\", 1985, 4.239932, 7000 ], [ \"Belize\", 1986, 4.711619, 8000 ], [ \"Belize\", 1987, 5.729937, 10000 ], [ \"Belize\", 1988, 6.829763, 12250 ], [ \"Belize\", 1989, 8.270664, 15254 ], [ \"Belize\", 1990, 9.124337, 17320 ], [ \"Belize\", 1991, 10.88075, 21276 ], [ \"Belize\", 1992, 12.32589, 24840 ], [ \"Belize\", 1993, 13.78062, 28624 ], [ \"Belize\", 1994, 13.17445, 28192 ], [ \"Belize\", 1995, 13.14112, 28947 ], [ \"Belize\", 1996, 13.06555, 29600 ], [ \"Belize\", 1997, 13.17232, 30667 ], [ \"Belize\", 1998, 13.58942, 32487 ], [ \"Belize\", 1999, 14.72356, 36116 ], [ \"Belize\", 2000, 14.2154, 35754 ], [ \"Belize\", 2001, 13.67275, 35237 ], [ \"Belize\", 2002, 11.86114, 31300 ], [ \"Belize\", 2003, 12.32372, 33278 ], [ \"Belize\", 2004, 12.2086, 33716 ], [ \"Belize\", 2005, 11.96275, 33770 ], [ \"Belize\", 2006, 11.90125, 34325 ], [ \"Belize\", 2007, 11.51156, 33905 ], [ \"Belize\", 2008, 10.35234, 31124 ], [ \"Belize\", 2009, 10.15982, 31168 ], [ \"Benin\", 1960, 0.09395193, 2176 ], [ \"Benin\", 1965, 0.09080335, 2300 ], [ \"Benin\", 1970, 0.123762, 3500 ], [ \"Benin\", 1975, 0.1653987, 5313 ], [ \"Benin\", 1976, 0.183692, 5861 ], [ \"Benin\", 1977, 0.194444, 6371 ], [ \"Benin\", 1978, 0.2088744, 7032 ], [ \"Benin\", 1979, 0.2222442, 7692 ], [ \"Benin\", 1980, 0.2391898, 8515 ], [ \"Benin\", 1981, 0.256815, 9409 ], [ \"Benin\", 1982, 0.2565893, 9680 ], [ \"Benin\", 1983, 0.256061, 9950 ], [ \"Benin\", 1984, 0.2643627, 10581 ], [ \"Benin\", 1985, 0.2639911, 10882 ], [ \"Benin\", 1986, 0.2835394, 12033 ], [ \"Benin\", 1987, 0.3017977, 13184 ], [ \"Benin\", 1988, 0.3021839, 13596 ], [ \"Benin\", 1989, 0.3067772, 14236 ], [ \"Benin\", 1990, 0.3081904, 14778 ], [ \"Benin\", 1991, 0.3023348, 15011 ], [ \"Benin\", 1992, 0.3060976, 15760 ], [ \"Benin\", 1993, 0.382132, 20409 ], [ \"Benin\", 1994, 0.4326852, 23945 ], [ \"Benin\", 1995, 0.4928276, 28206 ], [ \"Benin\", 1996, 0.5532882, 32679 ], [ \"Benin\", 1997, 0.5990151, 36453 ], [ \"Benin\", 1998, 0.6120954, 38354 ], [ \"Benin\", 1999, 0.6762609, 43656 ], [ \"Benin\", 2000, 0.7755134, 51644 ], [ \"Benin\", 2001, 0.8619981, 59298 ], [ \"Benin\", 2002, 0.881058, 62669 ], [ \"Benin\", 2003, 0.9039103, 66511 ], [ \"Benin\", 2004, 0.9563997, 72789 ], [ \"Benin\", 2005, 0.9693776, 76267 ], [ \"Benin\", 2006, 0.9515259, 77342 ], [ \"Benin\", 2007, 1.31971, 110765 ], [ \"Benin\", 2008, 1.330961, 115289 ], [ \"Benin\", 2009, 1.423047, 127149 ], [ \"Bermuda\", 1960, 20.79885, 9300 ], [ \"Bermuda\", 1965, 25.67924, 12542 ], [ \"Bermuda\", 1970, 30.97639, 16034 ], [ \"Bermuda\", 1975, 32.24736, 17500 ], [ \"Bermuda\", 1976, 32.74131, 17900 ], [ \"Bermuda\", 1977, 35.21621, 19383 ], [ \"Bermuda\", 1978, 37.0143, 20500 ], [ \"Bermuda\", 1979, 38.58786, 21500 ], [ \"Bermuda\", 1980, 39.91116, 22371 ], [ \"Bermuda\", 1981, 41.67302, 23499 ], [ \"Bermuda\", 1982, 46.63211, 26453 ], [ \"Bermuda\", 1983, 48.14802, 27480 ], [ \"Bermuda\", 1984, 50.00784, 28720 ], [ \"Bermuda\", 1985, 51.59421, 29823 ], [ \"Bermuda\", 1986, 53.88184, 31356 ], [ \"Bermuda\", 1987, 56.00341, 32818 ], [ \"Bermuda\", 1988, 58.61181, 34588 ], [ \"Bermuda\", 1989, 61.09232, 36298 ], [ \"Bermuda\", 1990, 62.41053, 37319 ], [ \"Bermuda\", 1991, 64.81638, 38989 ], [ \"Bermuda\", 1992, 65.77394, 39786 ], [ \"Bermuda\", 1993, 69.18169, 42068 ], [ \"Bermuda\", 1994, 72.34603, 44215 ], [ \"Bermuda\", 1995, 75.54868, 46402 ], [ \"Bermuda\", 1996, 78.62085, 48524 ], [ \"Bermuda\", 1997, 83.61903, 51853 ], [ \"Bermuda\", 1998, 86.24675, 53730 ], [ \"Bermuda\", 1999, 87.77763, 54933 ], [ \"Bermuda\", 2000, 89.19731, 56073 ], [ \"Bermuda\", 2001, 88.9239, 56151 ], [ \"Bermuda\", 2002, 88.29604, 56000 ], [ \"Bermuda\", 2003, 84.78302, 54000 ], [ \"Bermuda\", 2004, 84.21431, 53850 ], [ \"Bermuda\", 2005, 81.76364, 52471 ], [ \"Bermuda\", 2006, 89.55544, 57654 ], [ \"Bermuda\", 2007, 89.22071, 57600 ], [ \"Bermuda\", 2008, 89.00014, 57600 ], [ \"Bermuda\", 2009, 88.95673, 57700 ], [ \"Bhutan\", 1960, 0, 0 ], [ \"Bhutan\", 1965, 0.02632787, 250 ], [ \"Bhutan\", 1970, 0.03673878, 385 ], [ \"Bhutan\", 1975, 0.04907811, 570 ], [ \"Bhutan\", 1976, 0.1806782, 670 ], [ \"Bhutan\", 1977, 0.174461, 670 ], [ \"Bhutan\", 1978, 0.1686714, 670 ], [ \"Bhutan\", 1979, 0.2682109, 1100 ], [ \"Bhutan\", 1980, 0.2815942, 1190 ], [ \"Bhutan\", 1981, 0.2763672, 1200 ], [ \"Bhutan\", 1982, 0.2921526, 1300 ], [ \"Bhutan\", 1983, 0.3072345, 1400 ], [ \"Bhutan\", 1984, 0.3102115, 1450 ], [ \"Bhutan\", 1985, 0.3119684, 1500 ], [ \"Bhutan\", 1986, 0.3221325, 1600 ], [ \"Bhutan\", 1987, 0.320787, 1650 ], [ \"Bhutan\", 1988, 0.3200566, 1700 ], [ \"Bhutan\", 1989, 0.3382283, 1838 ], [ \"Bhutan\", 1990, 0.3409418, 1871 ], [ \"Bhutan\", 1991, 0.4578646, 2500 ], [ \"Bhutan\", 1992, 0.551436, 2959 ], [ \"Bhutan\", 1993, 0.7267655, 3809 ], [ \"Bhutan\", 1994, 0.8902251, 4572 ], [ \"Bhutan\", 1995, 1.030676, 5243 ], [ \"Bhutan\", 1996, 1.189681, 6074 ], [ \"Bhutan\", 1997, 1.240999, 6430 ], [ \"Bhutan\", 1998, 1.968083, 10437 ], [ \"Bhutan\", 1999, 2.19931, 11990 ], [ \"Bhutan\", 2000, 2.520604, 14145 ], [ \"Bhutan\", 2001, 3.035365, 17553 ], [ \"Bhutan\", 2002, 3.287087, 19615 ], [ \"Bhutan\", 2003, 3.843336, 23657 ], [ \"Bhutan\", 2004, 4.780463, 30285 ], [ \"Bhutan\", 2005, 5.078181, 33000 ], [ \"Bhutan\", 2006, 4.748149, 31526 ], [ \"Bhutan\", 2007, 4.416455, 29857 ], [ \"Bhutan\", 2008, 4.000501, 27475 ], [ \"Bhutan\", 2009, 3.778385, 26348 ], [ \"Bolivia\", 1980, 2.522396, 135100 ], [ \"Bolivia\", 1981, 2.593398, 142000 ], [ \"Bolivia\", 1982, 2.647168, 148100 ], [ \"Bolivia\", 1983, 2.624693, 150000 ], [ \"Bolivia\", 1984, 2.701539, 157719 ], [ \"Bolivia\", 1985, 2.661064, 158746 ], [ \"Bolivia\", 1986, 2.620377, 159774 ], [ \"Bolivia\", 1987, 2.634928, 164248 ], [ \"Bolivia\", 1988, 2.59319, 165296 ], [ \"Bolivia\", 1989, 2.606361, 169932 ], [ \"Bolivia\", 1990, 2.738692, 182686 ], [ \"Bolivia\", 1991, 2.989209, 204059 ], [ \"Bolivia\", 1992, 2.977256, 208034 ], [ \"Bolivia\", 1993, 3.240247, 231739 ], [ \"Bolivia\", 1994, 3.318184, 242823 ], [ \"Bolivia\", 1995, 3.298704, 246881 ], [ \"Bolivia\", 1996, 4.556861, 348595 ], [ \"Bolivia\", 1997, 4.920216, 384530 ], [ \"Bolivia\", 1998, 5.66819, 452381 ], [ \"Bolivia\", 1999, 6.167861, 502568 ], [ \"Bolivia\", 2000, 6.140822, 510755 ], [ \"Bolivia\", 2001, 6.177508, 524391 ], [ \"Bolivia\", 2002, 6.81901, 590638 ], [ \"Bolivia\", 2003, 6.906966, 610261 ], [ \"Bolivia\", 2004, 6.942133, 625428 ], [ \"Bolivia\", 2005, 7.038626, 646291 ], [ \"Bolivia\", 2006, 7.125993, 666553 ], [ \"Bolivia\", 2007, 7.120566, 678198 ], [ \"Bolivia\", 2008, 7.117722, 690000 ], [ \"Bolivia\", 2009, 8.214463, 810181 ], [ \"Bosnia and Herzegovina\", 1992, 15.26175, 600000 ], [ \"Bosnia and Herzegovina\", 1993, 16.31581, 600000 ], [ \"Bosnia and Herzegovina\", 1994, 7.221113, 250000 ], [ \"Bosnia and Herzegovina\", 1995, 7.137882, 237843 ], [ \"Bosnia and Herzegovina\", 1996, 8.235869, 272250 ], [ \"Bosnia and Herzegovina\", 1997, 8.999675, 302889 ], [ \"Bosnia and Herzegovina\", 1998, 9.573722, 333182 ], [ \"Bosnia and Herzegovina\", 1999, 10.21634, 367921 ], [ \"Bosnia and Herzegovina\", 2000, 21.11773, 780000 ], [ \"Bosnia and Herzegovina\", 2001, 22.59728, 847026 ], [ \"Bosnia and Herzegovina\", 2002, 23.90952, 902836 ], [ \"Bosnia and Herzegovina\", 2003, 24.7952, 938019 ], [ \"Bosnia and Herzegovina\", 2004, 25.1609, 951526 ], [ \"Bosnia and Herzegovina\", 2005, 25.6225, 968857 ], [ \"Bosnia and Herzegovina\", 2006, 26.15373, 989000 ], [ \"Bosnia and Herzegovina\", 2007, 28.17196, 1064452 ], [ \"Bosnia and Herzegovina\", 2008, 27.33442, 1031355 ], [ \"Bosnia and Herzegovina\", 2009, 26.51329, 998644 ], [ \"Botswana\", 1960, 0.06992347, 400 ], [ \"Botswana\", 1965, 0.1844885, 1200 ], [ \"Botswana\", 1970, 0.3066912, 2300 ], [ \"Botswana\", 1975, 0.5313124, 4700 ], [ \"Botswana\", 1976, 0.5895121, 5000 ], [ \"Botswana\", 1977, 0.6243161, 5500 ], [ \"Botswana\", 1978, 0.644641, 5900 ], [ \"Botswana\", 1979, 0.6735849, 6400 ], [ \"Botswana\", 1980, 0.7236174, 7128 ], [ \"Botswana\", 1981, 0.7660874, 7812 ], [ \"Botswana\", 1982, 0.8048881, 8486 ], [ \"Botswana\", 1983, 0.8685607, 9459 ], [ \"Botswana\", 1984, 0.8964298, 10079 ], [ \"Botswana\", 1985, 0.9113179, 10576 ], [ \"Botswana\", 1986, 0.981296, 11751 ], [ \"Botswana\", 1987, 1.181349, 14591 ], [ \"Botswana\", 1988, 1.430472, 18215 ], [ \"Botswana\", 1989, 1.691424, 22195 ], [ \"Botswana\", 1990, 1.950801, 26367 ], [ \"Botswana\", 1991, 2.343381, 32607 ], [ \"Botswana\", 1992, 2.54804, 36477 ], [ \"Botswana\", 1993, 2.955037, 43487 ], [ \"Botswana\", 1994, 3.338243, 50447 ], [ \"Botswana\", 1995, 3.850164, 59673 ], [ \"Botswana\", 1996, 4.546586, 72189 ], [ \"Botswana\", 1997, 5.268134, 85592 ], [ \"Botswana\", 1998, 6.145453, 102016 ], [ \"Botswana\", 1999, 7.314389, 123819 ], [ \"Botswana\", 2000, 7.889448, 135900 ], [ \"Botswana\", 2001, 8.471717, 148155 ], [ \"Botswana\", 2002, 8.360689, 148155 ], [ \"Botswana\", 2003, 7.325911, 131399 ], [ \"Botswana\", 2004, 7.258308, 131774 ], [ \"Botswana\", 2005, 7.420299, 136463 ], [ \"Botswana\", 2006, 7.080213, 132034 ], [ \"Botswana\", 2007, 7.236531, 136946 ], [ \"Botswana\", 2008, 7.406193, 142282 ], [ \"Botswana\", 2009, 7.048077, 137422 ], [ \"Brazil\", 1960, 0.8935645, 650000 ], [ \"Brazil\", 1965, 1.007963, 850000 ], [ \"Brazil\", 1970, 1.302234, 1250000 ], [ \"Brazil\", 1975, 2.035841, 2201242 ], [ \"Brazil\", 1976, 2.267222, 2510000 ], [ \"Brazil\", 1977, 2.69969, 3060000 ], [ \"Brazil\", 1978, 3.205683, 3720000 ], [ \"Brazil\", 1979, 3.611107, 4290073 ], [ \"Brazil\", 1980, 4.070109, 4950000 ], [ \"Brazil\", 1981, 4.28133, 5330000 ], [ \"Brazil\", 1982, 4.569513, 5822397 ], [ \"Brazil\", 1983, 4.832745, 6300000 ], [ \"Brazil\", 1984, 5.026966, 6700000 ], [ \"Brazil\", 1985, 5.289422, 7201516 ], [ \"Brazil\", 1986, 5.362113, 7451000 ], [ \"Brazil\", 1987, 5.511465, 7810000 ], [ \"Brazil\", 1988, 5.727552, 8270000 ], [ \"Brazil\", 1989, 5.97914, 8790000 ], [ \"Brazil\", 1990, 6.290679, 9409000 ], [ \"Brazil\", 1991, 6.626272, 10075920 ], [ \"Brazil\", 1992, 7.017521, 10841000 ], [ \"Brazil\", 1993, 7.205169, 11303000 ], [ \"Brazil\", 1994, 7.703441, 12269000 ], [ \"Brazil\", 1995, 8.202633, 13263000 ], [ \"Brazil\", 1996, 9.202122, 15105890 ], [ \"Brazil\", 1997, 10.22432, 17038820 ], [ \"Brazil\", 1998, 11.81505, 19986560 ], [ \"Brazil\", 1999, 14.55364, 24985000 ], [ \"Brazil\", 2000, 17.75592, 30926270 ], [ \"Brazil\", 2001, 21.18814, 37430780 ], [ \"Brazil\", 2002, 21.66702, 38810680 ], [ \"Brazil\", 2003, 21.59611, 39205000 ], [ \"Brazil\", 2004, 21.52624, 39578900 ], [ \"Brazil\", 2005, 21.41754, 39852600 ], [ \"Brazil\", 2006, 20.62103, 38800200 ], [ \"Brazil\", 2007, 20.72355, 39399620 ], [ \"Brazil\", 2008, 21.47988, 41235250 ], [ \"Brazil\", 2009, 21.4196, 41497000 ], [ \"Brunei Darussalam\", 1977, 4.142264, 7200 ], [ \"Brunei Darussalam\", 1978, 4.546891, 8200 ], [ \"Brunei Darussalam\", 1979, 5.086606, 9500 ], [ \"Brunei Darussalam\", 1980, 5.750461, 11100 ], [ \"Brunei Darussalam\", 1981, 7.034727, 14006 ], [ \"Brunei Darussalam\", 1982, 7.316538, 15000 ], [ \"Brunei Darussalam\", 1983, 8.061457, 17000 ], [ \"Brunei Darussalam\", 1984, 8.762261, 19000 ], [ \"Brunei Darussalam\", 1985, 9.330816, 20808 ], [ \"Brunei Darussalam\", 1986, 9.721054, 22300 ], [ \"Brunei Darussalam\", 1987, 10.42855, 24612 ], [ \"Brunei Darussalam\", 1988, 11.35414, 27570 ], [ \"Brunei Darussalam\", 1989, 12.09536, 30217 ], [ \"Brunei Darussalam\", 1990, 13.61878, 35000 ], [ \"Brunei Darussalam\", 1991, 14.78819, 39092 ], [ \"Brunei Darussalam\", 1992, 17.69544, 48107 ], [ \"Brunei Darussalam\", 1993, 19.75936, 55228 ], [ \"Brunei Darussalam\", 1994, 21.45409, 61620 ], [ \"Brunei Darussalam\", 1995, 23.09687, 68127 ], [ \"Brunei Darussalam\", 1996, 26.02842, 78794 ], [ \"Brunei Darussalam\", 1997, 24.73147, 76789 ], [ \"Brunei Darussalam\", 1998, 24.42942, 77742 ], [ \"Brunei Darussalam\", 1999, 24.26688, 79086 ], [ \"Brunei Darussalam\", 2000, 24.14003, 80500 ], [ \"Brunei Darussalam\", 2001, 25.94172, 88440 ], [ \"Brunei Darussalam\", 2002, 23.33969, 81280 ], [ \"Brunei Darussalam\", 2003, 23.04442, 81925 ], [ \"Brunei Darussalam\", 2004, 22.90714, 83100 ], [ \"Brunei Darussalam\", 2005, 22.66838, 83890 ], [ \"Brunei Darussalam\", 2006, 21.24194, 80176 ], [ \"Brunei Darussalam\", 2007, 20.67132, 79554 ], [ \"Brunei Darussalam\", 2008, 20.59396, 80786 ], [ \"Brunei Darussalam\", 2009, 20.15302, 80549 ], [ \"Bulgaria\", 1979, 9.110855, 805000 ], [ \"Bulgaria\", 1980, 10.24653, 908000 ], [ \"Bulgaria\", 1981, 12.87401, 1144300 ], [ \"Bulgaria\", 1982, 12.6788, 1130300 ], [ \"Bulgaria\", 1983, 15.13414, 1352700 ], [ \"Bulgaria\", 1984, 15.63506, 1400000 ], [ \"Bulgaria\", 1985, 16.74029, 1500000 ], [ \"Bulgaria\", 1986, 17.86375, 1600000 ], [ \"Bulgaria\", 1987, 19.51194, 1745000 ], [ \"Bulgaria\", 1988, 21.14928, 1886000 ], [ \"Bulgaria\", 1989, 22.46349, 1994000 ], [ \"Bulgaria\", 1990, 24.66769, 2175423 ], [ \"Bulgaria\", 1991, 25.22559, 2205483 ], [ \"Bulgaria\", 1992, 27.04414, 2339668 ], [ \"Bulgaria\", 1993, 28.19045, 2410427 ], [ \"Bulgaria\", 1994, 29.44288, 2487918 ], [ \"Bulgaria\", 1995, 30.66926, 2562915 ], [ \"Bulgaria\", 1996, 32.00121, 2647459 ], [ \"Bulgaria\", 1997, 32.70409, 2681074 ], [ \"Bulgaria\", 1998, 33.92263, 2757990 ], [ \"Bulgaria\", 1999, 35.1234, 2833395 ], [ \"Bulgaria\", 2000, 35.99501, 2881786 ], [ \"Bulgaria\", 2001, 36.32513, 2887000 ], [ \"Bulgaria\", 2002, 36.38606, 2871801 ], [ \"Bulgaria\", 2003, 35.93726, 2817512 ], [ \"Bulgaria\", 2004, 35.0072, 2726800 ], [ \"Bulgaria\", 2005, 32.17349, 2490022 ], [ \"Bulgaria\", 2006, 31.20192, 2399424 ], [ \"Bulgaria\", 2007, 30.10526, 2300355 ], [ \"Bulgaria\", 2008, 28.84118, 2189773 ], [ \"Bulgaria\", 2009, 29.2315, 2205394 ], [ \"Burkina Faso\", 1970, 0.0281474, 1500 ], [ \"Burkina Faso\", 1975, 0.04035412, 2400 ], [ \"Burkina Faso\", 1976, 0.04127199, 2600 ], [ \"Burkina Faso\", 1977, 0.06218467, 4000 ], [ \"Burkina Faso\", 1978, 0.06087588, 4000 ], [ \"Burkina Faso\", 1981, 0.09507658, 6670 ], [ \"Burkina Faso\", 1982, 0.1000838, 7180 ], [ \"Burkina Faso\", 1983, 0.1020152, 7488 ], [ \"Burkina Faso\", 1984, 0.1037358, 7797 ], [ \"Burkina Faso\", 1985, 0.1031908, 7950 ], [ \"Burkina Faso\", 1986, 0.1212159, 9582 ], [ \"Burkina Faso\", 1987, 0.1423518, 11556 ], [ \"Burkina Faso\", 1988, 0.1534925, 12804 ], [ \"Burkina Faso\", 1989, 0.169034, 14493.5 ], [ \"Burkina Faso\", 1990, 0.1836064, 16183 ], [ \"Burkina Faso\", 1991, 0.1969292, 17844 ], [ \"Burkina Faso\", 1992, 0.2123525, 19784 ], [ \"Burkina Faso\", 1993, 0.228325, 21873 ], [ \"Burkina Faso\", 1994, 0.2672899, 26328 ], [ \"Burkina Faso\", 1995, 0.296656, 30043 ], [ \"Burkina Faso\", 1996, 0.3271046, 34055 ], [ \"Burkina Faso\", 1997, 0.3387649, 36258 ], [ \"Burkina Faso\", 1998, 0.374453, 41218 ], [ \"Burkina Faso\", 1999, 0.4177936, 47338 ], [ \"Burkina Faso\", 2000, 0.4557751, 53217 ], [ \"Burkina Faso\", 2001, 0.481798, 58036 ], [ \"Burkina Faso\", 2002, 0.497722, 61908 ], [ \"Burkina Faso\", 2003, 0.5184519, 66639 ], [ \"Burkina Faso\", 2004, 0.6412625, 85225 ], [ \"Burkina Faso\", 2005, 0.6633433, 91191 ], [ \"Burkina Faso\", 2006, 0.6661567, 94758 ], [ \"Burkina Faso\", 2007, 0.7930341, 116746 ], [ \"Burkina Faso\", 2008, 0.9725491, 148157 ], [ \"Burkina Faso\", 2009, 0.9675808, 152461 ], [ \"Burundi\", 1965, 0.0435748, 1400 ], [ \"Burundi\", 1970, 0.0569233, 2000 ], [ \"Burundi\", 1975, 0.07336157, 2700 ], [ \"Burundi\", 1976, 0.06948875, 2600 ], [ \"Burundi\", 1981, 0.04693366, 2000 ], [ \"Burundi\", 1982, 0.04994064, 2200 ], [ \"Burundi\", 1983, 0.05329878, 2430 ], [ \"Burundi\", 1984, 0.08072051, 3810 ], [ \"Burundi\", 1985, 0.1087111, 5310 ], [ \"Burundi\", 1986, 0.1312542, 6631 ], [ \"Burundi\", 1987, 0.1361262, 7107 ], [ \"Burundi\", 1988, 0.1363921, 7346 ], [ \"Burundi\", 1989, 0.1383528, 7666 ], [ \"Burundi\", 1990, 0.1399338, 7950 ], [ \"Burundi\", 1991, 0.1762848, 10236 ], [ \"Burundi\", 1992, 0.2177829, 12888 ], [ \"Burundi\", 1993, 0.2585315, 15550 ], [ \"Burundi\", 1994, 0.2589328, 15788 ], [ \"Burundi\", 1995, 0.2797965, 17255 ], [ \"Burundi\", 1996, 0.2439866, 15181 ], [ \"Burundi\", 1997, 0.2532195, 15867 ], [ \"Burundi\", 1998, 0.2827777, 17849 ], [ \"Burundi\", 1999, 0.2978442, 18993 ], [ \"Burundi\", 2000, 0.3089938, 20000 ], [ \"Burundi\", 2001, 0.3110834, 20543 ], [ \"Burundi\", 2002, 0.3263695, 22084 ], [ \"Burundi\", 2003, 0.3435302, 23895 ], [ \"Burundi\", 2004, 0.3873733, 27744 ], [ \"Burundi\", 2005, 0.4215161, 31100 ], [ \"Burundi\", 2006, 0.3667525, 27886 ], [ \"Burundi\", 2007, 0.3636141, 28500 ], [ \"Burundi\", 2008, 0.3766416, 30411 ], [ \"Burundi\", 2009, 0.3793659, 31500 ], [ \"Cambodia\", 1960, 0.03265046, 1774 ], [ \"Cambodia\", 1987, 0.02875116, 2510 ], [ \"Cambodia\", 1988, 0.02953031, 2670 ], [ \"Cambodia\", 1989, 0.0309408, 2896 ], [ \"Cambodia\", 1990, 0.03214619, 3115 ], [ \"Cambodia\", 1991, 0.03872826, 3885 ], [ \"Cambodia\", 1992, 0.03920013, 4068 ], [ \"Cambodia\", 1993, 0.03931013, 4215 ], [ \"Cambodia\", 1994, 0.06278373, 6943 ], [ \"Cambodia\", 1995, 0.07493594, 8528 ], [ \"Cambodia\", 1996, 0.1324231, 15475 ], [ \"Cambodia\", 1997, 0.1673648, 20044 ], [ \"Cambodia\", 1998, 0.1980302, 24261 ], [ \"Cambodia\", 1999, 0.2214213, 27704 ], [ \"Cambodia\", 2000, 0.2420098, 30880 ], [ \"Cambodia\", 2001, 0.2577566, 33494 ], [ \"Cambodia\", 2002, 0.267984, 35419 ], [ \"Cambodia\", 2003, 0.2336123, 31379 ], [ \"Cambodia\", 2004, 0.2358061, 32180 ], [ \"Cambodia\", 2005, 0.2377822, 32971 ], [ \"Cambodia\", 2006, 0.1820063, 25648 ], [ \"Cambodia\", 2007, 0.2620037, 37529 ], [ \"Cambodia\", 2008, 0.2959757, 43100 ], [ \"Cambodia\", 2009, 0.3660837, 54200 ], [ \"Cameroon\", 1975, 0.1717406, 12989 ], [ \"Cameroon\", 1976, 0.1679162, 13529 ], [ \"Cameroon\", 1977, 0.1700192, 14112 ], [ \"Cameroon\", 1978, 0.1771416, 15152 ], [ \"Cameroon\", 1979, 0.1880616, 16576 ], [ \"Cameroon\", 1980, 0.1894755, 17204 ], [ \"Cameroon\", 1981, 0.1957781, 18304 ], [ \"Cameroon\", 1982, 0.221493, 21316 ], [ \"Cameroon\", 1983, 0.2532414, 25086 ], [ \"Cameroon\", 1984, 0.2756359, 28115 ], [ \"Cameroon\", 1985, 0.2841532, 29861 ], [ \"Cameroon\", 1986, 0.2990903, 32400 ], [ \"Cameroon\", 1987, 0.3133242, 35000 ], [ \"Cameroon\", 1988, 0.312527, 36000 ], [ \"Cameroon\", 1989, 0.3239624, 38468 ], [ \"Cameroon\", 1990, 0.3287672, 40218 ], [ \"Cameroon\", 1991, 0.3329417, 41933 ], [ \"Cameroon\", 1992, 0.4218699, 54672 ], [ \"Cameroon\", 1993, 0.4290131, 57168 ], [ \"Cameroon\", 1994, 0.4251015, 58200 ], [ \"Cameroon\", 1995, 0.4667363, 65597 ], [ \"Cameroon\", 1996, 0.4894705, 70558 ], [ \"Cameroon\", 1997, 0.5090096, 75200 ], [ \"Cameroon\", 1998, 0.6206393, 93920 ], [ \"Cameroon\", 1999, 0.6104832, 94599 ], [ \"Cameroon\", 2000, 0.5987852, 95000 ], [ \"Cameroon\", 2001, 0.6543767, 106287 ], [ \"Cameroon\", 2002, 0.6668967, 110881 ], [ \"Cameroon\", 2003, 0.5723033, 97393 ], [ \"Cameroon\", 2004, 0.570941, 99439 ], [ \"Cameroon\", 2005, 0.5629188, 100331 ], [ \"Cameroon\", 2006, 0.7166075, 130694 ], [ \"Cameroon\", 2007, 1.01219, 188874 ], [ \"Cameroon\", 2008, 1.337494, 255306 ], [ \"Cameroon\", 2009, 2.230412, 435413 ], [ \"Canada\", 1960, 27.84912, 4987502 ], [ \"Canada\", 1965, 26.77609, 5269000 ], [ \"Canada\", 1970, 29.99514, 6514000 ], [ \"Canada\", 1975, 35.77004, 8278000 ], [ \"Canada\", 1976, 36.78667, 8614000 ], [ \"Canada\", 1977, 37.64476, 8920000 ], [ \"Canada\", 1978, 38.66842, 9271000 ], [ \"Canada\", 1979, 39.56596, 9595000 ], [ \"Canada\", 1980, 40.70357, 9979000 ], [ \"Canada\", 1981, 41.56061, 10294500 ], [ \"Canada\", 1982, 41.31525, 10335440 ], [ \"Canada\", 1983, 41.43098, 10468340 ], [ \"Canada\", 1984, 46.31088, 11827270 ], [ \"Canada\", 1985, 48.29495, 12480670 ], [ \"Canada\", 1986, 49.45179, 12948040 ], [ \"Canada\", 1987, 50.62875, 13444320 ], [ \"Canada\", 1988, 51.87055, 13975830 ], [ \"Canada\", 1989, 53.59498, 14647790 ], [ \"Canada\", 1990, 55.21786, 15295820 ], [ \"Canada\", 1991, 56.37883, 15814930 ], [ \"Canada\", 1992, 57.2368, 16246590 ], [ \"Canada\", 1993, 58.24121, 16716800 ], [ \"Canada\", 1994, 59.46875, 17250410 ], [ \"Canada\", 1995, 59.95135, 17567000 ], [ \"Canada\", 1996, 60.75427, 17974000 ], [ \"Canada\", 1997, 62.50004, 18660000 ], [ \"Canada\", 1998, 64.04939, 19294000 ], [ \"Canada\", 1999, 67.0436, 20380000 ], [ \"Canada\", 2000, 67.91188, 20840000 ], [ \"Canada\", 2001, 68.16338, 21126000 ], [ \"Canada\", 2002, 65.85361, 20622000 ], [ \"Canada\", 2003, 65.13216, 20612000 ], [ \"Canada\", 2004, 64.30113, 20563000 ], [ \"Canada\", 2005, 56.17344, 18148000 ], [ \"Canada\", 2006, 55.88989, 18236000 ], [ \"Canada\", 2007, 55.49205, 18282030 ], [ \"Canada\", 2008, 54.87179, 18250000 ], [ \"Canada\", 2009, 52.49671, 17624960 ], [ \"Cape Verde\", 1960, 0.0957469, 188 ], [ \"Cape Verde\", 1975, 0.536276, 1490 ], [ \"Cape Verde\", 1980, 0.4975245, 1439 ], [ \"Cape Verde\", 1981, 0.5328835, 1565.1 ], [ \"Cape Verde\", 1982, 0.5683414, 1700 ], [ \"Cape Verde\", 1983, 0.6191667, 1890 ], [ \"Cape Verde\", 1984, 0.7024522, 2190 ], [ \"Cape Verde\", 1985, 0.7166703, 2282 ], [ \"Cape Verde\", 1986, 1.144833, 3722 ], [ \"Cape Verde\", 1987, 1.691377, 5614 ], [ \"Cape Verde\", 1988, 1.890016, 6406 ], [ \"Cape Verde\", 1989, 1.963394, 6800 ], [ \"Cape Verde\", 1990, 2.327925, 8246 ], [ \"Cape Verde\", 1991, 2.508211, 9095 ], [ \"Cape Verde\", 1992, 3.131142, 11629 ], [ \"Cape Verde\", 1993, 4.009348, 15252 ], [ \"Cape Verde\", 1994, 4.738022, 18450 ], [ \"Cape Verde\", 1995, 5.402589, 21513 ], [ \"Cape Verde\", 1996, 6.203807, 25232 ], [ \"Cape Verde\", 1997, 8.010015, 33241 ], [ \"Cape Verde\", 1998, 9.451155, 39985 ], [ \"Cape Verde\", 1999, 10.87252, 46865 ], [ \"Cape Verde\", 2000, 12.4482, 54644 ], [ \"Cape Verde\", 2001, 14.35131, 64132 ], [ \"Cape Verde\", 2002, 15.43569, 70187 ], [ \"Cape Verde\", 2003, 15.50817, 71716 ], [ \"Cape Verde\", 2004, 15.25441, 71700 ], [ \"Cape Verde\", 2005, 14.99671, 71600 ], [ \"Cape Verde\", 2006, 14.76873, 71578 ], [ \"Cape Verde\", 2007, 14.59457, 71764 ], [ \"Cape Verde\", 2008, 14.41027, 71860 ], [ \"Cape Verde\", 2009, 14.21542, 71874 ], [ \"Cayman Islands\", 1970, 13.90821, 1400 ], [ \"Cayman Islands\", 1975, 18.58736, 2450 ], [ \"Cayman Islands\", 1976, 19.63585, 2750 ], [ \"Cayman Islands\", 1977, 20.82913, 3100 ], [ \"Cayman Islands\", 1978, 21.55582, 3400 ], [ \"Cayman Islands\", 1979, 22.85989, 3800 ], [ \"Cayman Islands\", 1980, 23.85195, 4150 ], [ \"Cayman Islands\", 1984, 33.69478, 6712 ], [ \"Cayman Islands\", 1985, 35.50087, 7343 ], [ \"Cayman Islands\", 1986, 36.04522, 7780 ], [ \"Cayman Islands\", 1987, 38.98058, 8810 ], [ \"Cayman Islands\", 1988, 40.25969, 9550 ], [ \"Cayman Islands\", 1989, 43.19724, 10760 ], [ \"Cayman Islands\", 1990, 47.16729, 12330 ], [ \"Cayman Islands\", 1991, 43.00664, 11795 ], [ \"Cayman Islands\", 1992, 44.32434, 12753 ], [ \"Cayman Islands\", 1993, 46.46481, 14011 ], [ \"Cayman Islands\", 1994, 55.83032, 17610 ], [ \"Cayman Islands\", 1995, 58.96112, 19410 ], [ \"Cayman Islands\", 1997, 53.55665, 19026 ], [ \"Cayman Islands\", 1998, 75.02711, 27673 ], [ \"Cayman Islands\", 1999, 81.88717, 31511 ], [ \"Cayman Islands\", 2000, 86.61223, 35000 ], [ \"Cayman Islands\", 2001, 88.91801, 38000 ], [ \"Cayman Islands\", 2002, 83.74656, 38000 ], [ \"Cayman Islands\", 2003, 79.01358, 38000 ], [ \"Cayman Islands\", 2004, 75.1404, 38000 ], [ \"Cayman Islands\", 2005, 72.26533, 38000 ], [ \"Cayman Islands\", 2006, 70.31568, 38000 ], [ \"Cayman Islands\", 2007, 63.70179, 35050 ], [ \"Cayman Islands\", 2008, 64.26723, 35766 ], [ \"Cayman Islands\", 2009, 64.39896, 36151 ], [ \"Central African Rep.\", 1978, 0.118636, 2557 ], [ \"Central African Rep.\", 1979, 0.1079478, 2385 ], [ \"Central African Rep.\", 1980, 0.115349, 2617 ], [ \"Central African Rep.\", 1981, 0.1059854, 2474 ], [ \"Central African Rep.\", 1982, 0.1189072, 2860 ], [ \"Central African Rep.\", 1983, 0.1129565, 2800 ], [ \"Central African Rep.\", 1984, 0.1084588, 2767 ], [ \"Central African Rep.\", 1985, 0.09924763, 2600 ], [ \"Central African Rep.\", 1986, 0.1454328, 3902 ], [ \"Central African Rep.\", 1987, 0.1495102, 4100 ], [ \"Central African Rep.\", 1988, 0.1549799, 4340 ], [ \"Central African Rep.\", 1989, 0.1579624, 4520 ], [ \"Central African Rep.\", 1990, 0.1710111, 5008 ], [ \"Central African Rep.\", 1991, 0.1784683, 5358 ], [ \"Central African Rep.\", 1992, 0.197698, 6092 ], [ \"Central African Rep.\", 1993, 0.2135096, 6757 ], [ \"Central African Rep.\", 1994, 0.2268837, 7373 ], [ \"Central African Rep.\", 1995, 0.2514611, 8385 ], [ \"Central African Rep.\", 1996, 0.2838179, 9704 ], [ \"Central African Rep.\", 1997, 0.2801088, 9814 ], [ \"Central African Rep.\", 1998, 0.2665992, 9563 ], [ \"Central African Rep.\", 1999, 0.2688118, 9860 ], [ \"Central African Rep.\", 2000, 0.252768, 9468 ], [ \"Central African Rep.\", 2001, 0.2334573, 8917 ], [ \"Central African Rep.\", 2002, 0.2313668, 9000 ], [ \"Central African Rep.\", 2003, 0.2399753, 9500 ], [ \"Central African Rep.\", 2004, 0.2482238, 10000 ], [ \"Central African Rep.\", 2005, 0.2438142, 10000 ], [ \"Central African Rep.\", 2006, 0.2872238, 12000 ], [ \"Central African Rep.\", 2007, 0.281862, 12000 ], [ \"Central African Rep.\", 2008, 0.2765447, 12000 ], [ \"Central African Rep.\", 2009, 0.2713461, 12000 ], [ \"Chad\", 1965, 0.04439345, 1500 ], [ \"Chad\", 1970, 0.05057257, 1900 ], [ \"Chad\", 1975, 0.05734908, 2400 ], [ \"Chad\", 1976, 0.0565429, 2400 ], [ \"Chad\", 1977, 0.05540353, 2400 ], [ \"Chad\", 1981, 0.01166952, 550 ], [ \"Chad\", 1982, 0.0138852, 670 ], [ \"Chad\", 1983, 0.02345174, 1160 ], [ \"Chad\", 1984, 0.03131055, 1590 ], [ \"Chad\", 1985, 0.04023368, 2101 ], [ \"Chad\", 1986, 0.04255332, 2289 ], [ \"Chad\", 1987, 0.04366446, 2423 ], [ \"Chad\", 1988, 0.05793064, 3319 ], [ \"Chad\", 1989, 0.06151549, 3639 ], [ \"Chad\", 1990, 0.06594207, 4026 ], [ \"Chad\", 1991, 0.06543447, 4121 ], [ \"Chad\", 1992, 0.06467027, 4200 ], [ \"Chad\", 1993, 0.06825704, 4571 ], [ \"Chad\", 1994, 0.06852298, 4733 ], [ \"Chad\", 1995, 0.07483412, 5334 ], [ \"Chad\", 1996, 0.0816012, 6004 ], [ \"Chad\", 1997, 0.09834351, 7471 ], [ \"Chad\", 1998, 0.1099745, 8631 ], [ \"Chad\", 1999, 0.1195208, 9700 ], [ \"Chad\", 2000, 0.1221301, 10261 ], [ \"Chad\", 2001, 0.1227475, 10689 ], [ \"Chad\", 2002, 0.131029, 11835 ], [ \"Chad\", 2003, 0.132928, 12450 ], [ \"Chad\", 2004, 0.134056, 13000 ], [ \"Chad\", 2005, 0.1297587, 13000 ], [ \"Chad\", 2006, 0.1936819, 20000 ], [ \"Chad\", 2007, 0.3012354, 32000 ], [ \"Chad\", 2008, 0.4123271, 45000 ], [ \"Chad\", 2009, 0.5199555, 58267 ], [ \"Chile\", 1960, 1.724431, 131803 ], [ \"Chile\", 1965, 1.88513, 163000 ], [ \"Chile\", 1970, 2.476586, 237000 ], [ \"Chile\", 1975, 2.852145, 297000 ], [ \"Chile\", 1976, 2.913255, 308000 ], [ \"Chile\", 1977, 3.03142, 325000 ], [ \"Chile\", 1978, 3.174188, 345000 ], [ \"Chile\", 1979, 3.184802, 351000 ], [ \"Chile\", 1980, 3.246475, 363000 ], [ \"Chile\", 1981, 3.406714, 386706 ], [ \"Chile\", 1982, 3.505492, 404196 ], [ \"Chile\", 1983, 3.728204, 436860 ], [ \"Chile\", 1984, 4.038109, 481002 ], [ \"Chile\", 1985, 4.434849, 537089 ], [ \"Chile\", 1986, 4.531296, 557987 ], [ \"Chile\", 1987, 4.638101, 580795 ], [ \"Chile\", 1988, 4.910779, 625466 ], [ \"Chile\", 1989, 4.983871, 645863 ], [ \"Chile\", 1990, 6.551336, 864155 ], [ \"Chile\", 1991, 7.862227, 1056027 ], [ \"Chile\", 1992, 9.378808, 1283048 ], [ \"Chile\", 1993, 10.91313, 1520291 ], [ \"Chile\", 1994, 11.19506, 1587000 ], [ \"Chile\", 1995, 12.61622, 1818000 ], [ \"Chile\", 1996, 14.70156, 2151000 ], [ \"Chile\", 1997, 18.14854, 2693286 ], [ \"Chile\", 1998, 20.25837, 3046698 ], [ \"Chile\", 1999, 20.41073, 3108799 ], [ \"Chile\", 2000, 21.41883, 3302506 ], [ \"Chile\", 2001, 22.22179, 3467013 ], [ \"Chile\", 2002, 21.97072, 3467013 ], [ \"Chile\", 2003, 20.3831, 3252063 ], [ \"Chile\", 2004, 20.57604, 3318260 ], [ \"Chile\", 2005, 21.08231, 3435888 ], [ \"Chile\", 2006, 20.54742, 3383597 ], [ \"Chile\", 2007, 20.79576, 3459611 ], [ \"Chile\", 2008, 21.00485, 3529645 ], [ \"Chile\", 2009, 21.10048, 3580808 ], [ \"China\", 1975, 0.1823654, 1692000 ], [ \"China\", 1976, 0.1900095, 1761000 ], [ \"China\", 1977, 0.1947703, 1833000 ], [ \"China\", 1978, 0.2016715, 1925000 ], [ \"China\", 1979, 0.2100991, 2033000 ], [ \"China\", 1980, 0.218232, 2140700 ], [ \"China\", 1981, 0.2233328, 2220900 ], [ \"China\", 1982, 0.2323625, 2342500 ], [ \"China\", 1983, 0.2453326, 2508000 ], [ \"China\", 1984, 0.2674368, 2774000 ], [ \"China\", 1985, 0.2962346, 3120000 ], [ \"China\", 1986, 0.3273656, 3504000 ], [ \"China\", 1987, 0.3589302, 3907000 ], [ \"China\", 1988, 0.4269904, 4727000 ], [ \"China\", 1989, 0.504871, 5680400 ], [ \"China\", 1990, 0.5998039, 6850300 ], [ \"China\", 1991, 0.7299248, 8450600 ], [ \"China\", 1992, 0.9784262, 11469100 ], [ \"China\", 1993, 1.461783, 17332000 ], [ \"China\", 1994, 2.277431, 27295300 ], [ \"China\", 1995, 3.361415, 40705700 ], [ \"China\", 1996, 4.492498, 54947000 ], [ \"China\", 1997, 5.694207, 70310000 ], [ \"China\", 1998, 7.016167, 87420940 ], [ \"China\", 1999, 8.650696, 108715800 ], [ \"China\", 2000, 11.43128, 144829000 ], [ \"China\", 2001, 14.12785, 180368000 ], [ \"China\", 2002, 16.65822, 214222000 ], [ \"China\", 2003, 20.29028, 262747000 ], [ \"China\", 2004, 23.91378, 311756000 ], [ \"China\", 2005, 26.7056, 350445000 ], [ \"China\", 2006, 27.84731, 367786000 ], [ \"China\", 2007, 27.51033, 365637000 ], [ \"China\", 2008, 25.44909, 340359000 ], [ \"China\", 2009, 23.31278, 313732000 ], [ \"Colombia\", 1960, 1.630986, 274937 ], [ \"Colombia\", 1965, 2.006009, 393000 ], [ \"Colombia\", 1970, 2.641781, 596000 ], [ \"Colombia\", 1975, 3.300112, 837600 ], [ \"Colombia\", 1976, 3.511177, 861200 ], [ \"Colombia\", 1977, 3.731197, 936600 ], [ \"Colombia\", 1978, 3.934635, 1010800 ], [ \"Colombia\", 1979, 3.888977, 1022300 ], [ \"Colombia\", 1980, 4.00027, 1075700 ], [ \"Colombia\", 1981, 4.125292, 1134460 ], [ \"Colombia\", 1982, 4.598887, 1293030 ], [ \"Colombia\", 1983, 4.519592, 1298843 ], [ \"Colombia\", 1984, 5.129989, 1506427 ], [ \"Colombia\", 1985, 5.674936, 1702291 ], [ \"Colombia\", 1986, 5.872226, 1798793 ], [ \"Colombia\", 1987, 6.134364, 1918297 ], [ \"Colombia\", 1988, 6.487439, 2070360 ], [ \"Colombia\", 1989, 6.685182, 2176541 ], [ \"Colombia\", 1990, 7.272429, 2414726 ], [ \"Colombia\", 1991, 7.778975, 2633273 ], [ \"Colombia\", 1992, 8.178959, 2821700 ], [ \"Colombia\", 1993, 8.931734, 3139468 ], [ \"Colombia\", 1994, 9.812152, 3513000 ], [ \"Colombia\", 1995, 10.62246, 3872845 ], [ \"Colombia\", 1996, 12.51496, 4645453 ], [ \"Colombia\", 1997, 14.2785, 5394757 ], [ \"Colombia\", 1998, 16.56031, 6366944 ], [ \"Colombia\", 1999, 17.04231, 6665422 ], [ \"Colombia\", 2000, 18.08462, 7192778 ], [ \"Colombia\", 2001, 18.23212, 7371545 ], [ \"Colombia\", 2002, 18.90116, 7766000 ], [ \"Colombia\", 2003, 18.80216, 7848266 ], [ \"Colombia\", 2004, 17.89997, 7588676 ], [ \"Colombia\", 2005, 17.83726, 7678804 ], [ \"Colombia\", 2006, 17.98489, 7860205 ], [ \"Colombia\", 2007, 17.86338, 7924098 ], [ \"Colombia\", 2008, 17.61514, 7928944 ], [ \"Colombia\", 2009, 16.36863, 7473867 ], [ \"Comoros\", 1960, 0, 0 ], [ \"Comoros\", 1965, 0.04715202, 100 ], [ \"Comoros\", 1970, 0.1091842, 300 ], [ \"Comoros\", 1975, 0.1417144, 450 ], [ \"Comoros\", 1976, 0.1783008, 500 ], [ \"Comoros\", 1977, 0.2056379, 600 ], [ \"Comoros\", 1978, 0.2302412, 700 ], [ \"Comoros\", 1979, 0.2527335, 800 ], [ \"Comoros\", 1980, 0.2737077, 900 ], [ \"Comoros\", 1981, 0.2934858, 1000 ], [ \"Comoros\", 1982, 0.3121798, 1100 ], [ \"Comoros\", 1983, 0.329945, 1200 ], [ \"Comoros\", 1984, 0.3735425, 1400 ], [ \"Comoros\", 1985, 0.4132874, 1594 ], [ \"Comoros\", 1986, 0.4470931, 1772 ], [ \"Comoros\", 1987, 0.4949314, 2013 ], [ \"Comoros\", 1988, 0.5549427, 2314 ], [ \"Comoros\", 1989, 0.676109, 2889 ], [ \"Comoros\", 1990, 0.7457454, 3265 ], [ \"Comoros\", 1991, 0.8116416, 3641 ], [ \"Comoros\", 1992, 0.8378752, 3851 ], [ \"Comoros\", 1993, 0.8517037, 4010 ], [ \"Comoros\", 1994, 0.8860607, 4272 ], [ \"Comoros\", 1995, 0.8869337, 4377 ], [ \"Comoros\", 1996, 0.9862949, 4980 ], [ \"Comoros\", 1997, 1.066322, 5507 ], [ \"Comoros\", 1998, 1.178923, 6226 ], [ \"Comoros\", 1999, 1.207713, 6521 ], [ \"Comoros\", 2000, 1.226999, 6773 ], [ \"Comoros\", 2001, 1.57307, 8876 ], [ \"Comoros\", 2002, 1.778704, 10258 ], [ \"Comoros\", 2003, 2.246854, 13245 ], [ \"Comoros\", 2004, 2.50251, 15083 ], [ \"Comoros\", 2005, 2.747772, 16939 ], [ \"Comoros\", 2006, 3.021867, 19061 ], [ \"Comoros\", 2007, 3.415447, 22049 ], [ \"Comoros\", 2008, 3.382815, 22351 ], [ \"Comoros\", 2009, 3.177059, 21478 ], [ \"Congo (Democratic Republic of the)\", 1970, 0.1085552, 22300 ], [ \"Congo (Democratic Republic of the)\", 1975, 0.1124967, 26900 ], [ \"Congo (Democratic Republic of the)\", 1976, 0.1114548, 26900 ], [ \"Congo (Democratic Republic of the)\", 1977, 0.1017427, 25300 ], [ \"Congo (Democratic Republic of the)\", 1978, 0.09874617, 25300 ], [ \"Congo (Democratic Republic of the)\", 1979, 0.09586739, 25300 ], [ \"Congo (Democratic Republic of the)\", 1980, 0.09790201, 26600 ], [ \"Congo (Democratic Republic of the)\", 1981, 0.0859441, 24030 ], [ \"Congo (Democratic Republic of the)\", 1982, 0.08680272, 24971 ], [ \"Congo (Democratic Republic of the)\", 1983, 0.08658157, 25630 ], [ \"Congo (Democratic Republic of the)\", 1984, 0.0940719, 28670 ], [ \"Congo (Democratic Republic of the)\", 1985, 0.09238148, 29010 ], [ \"Congo (Democratic Republic of the)\", 1986, 0.08958422, 29000 ], [ \"Congo (Democratic Republic of the)\", 1987, 0.086862, 29000 ], [ \"Congo (Democratic Republic of the)\", 1988, 0.08465685, 29186 ], [ \"Congo (Democratic Republic of the)\", 1989, 0.08968998, 32000 ], [ \"Congo (Democratic Republic of the)\", 1990, 0.09185186, 34000 ], [ \"Congo (Democratic Republic of the)\", 1991, 0.09087726, 35000 ], [ \"Congo (Democratic Republic of the)\", 1992, 0.08967032, 36000 ], [ \"Congo (Democratic Republic of the)\", 1993, 0.08605967, 36000 ], [ \"Congo (Democratic Republic of the)\", 1994, 0.08285502, 36000 ], [ \"Congo (Democratic Republic of the)\", 1995, 0.08014072, 36000 ], [ \"Congo (Democratic Republic of the)\", 1996, 0.07790884, 36000 ], [ \"Congo (Democratic Republic of the)\", 1997, 0.0192204, 9100 ], [ \"Congo (Democratic Republic of the)\", 1998, 0.0193108, 9350 ], [ \"Congo (Democratic Republic of the)\", 1999, 0.01927335, 9550 ], [ \"Congo (Democratic Republic of the)\", 2000, 0.01929991, 9810 ], [ \"Congo (Democratic Republic of the)\", 2001, 0.01908805, 9980 ], [ \"Congo (Democratic Republic of the)\", 2002, 0.01855814, 10000 ], [ \"Congo (Democratic Republic of the)\", 2003, 0.01750835, 9733 ], [ \"Congo (Democratic Republic of the)\", 2004, 0.01835464, 10524 ], [ \"Congo (Democratic Republic of the)\", 2005, 0.01790721, 10579 ], [ \"Congo (Democratic Republic of the)\", 2006, 0.015954, 9700 ], [ \"Congo (Democratic Republic of the)\", 2007, 0.005597959, 3500 ], [ \"Congo (Democratic Republic of the)\", 2008, 0.0580796, 37320 ], [ \"Congo (Democratic Republic of the)\", 2009, 0.06410144, 42320 ], [ \"Congo\", 1965, 0.3411071, 3900 ], [ \"Congo\", 1970, 0.3704776, 4900 ], [ \"Congo\", 1975, 0.3627864, 5600 ], [ \"Congo\", 1976, 0.3936538, 6299 ], [ \"Congo\", 1977, 0.3947358, 6518 ], [ \"Congo\", 1978, 0.4070117, 6936 ], [ \"Congo\", 1979, 0.4374256, 7693 ], [ \"Congo\", 1980, 0.4679241, 8492 ], [ \"Congo\", 1981, 0.4743601, 8882 ], [ \"Congo\", 1982, 0.4640605, 8963 ], [ \"Congo\", 1983, 0.4792085, 9545 ], [ \"Congo\", 1984, 0.4748272, 9751 ], [ \"Congo\", 1985, 0.4799545, 10159 ], [ \"Congo\", 1986, 0.4724489, 10303 ], [ \"Congo\", 1987, 0.4855928, 10905 ], [ \"Congo\", 1988, 0.6493414, 15010 ], [ \"Congo\", 1989, 0.6629352, 15768 ], [ \"Congo\", 1990, 0.6479508, 15852 ], [ \"Congo\", 1991, 0.6718873, 16905 ], [ \"Congo\", 1992, 0.6925585, 17915 ], [ \"Congo\", 1993, 0.7218862, 19177 ], [ \"Congo\", 1994, 0.7549813, 20553 ], [ \"Congo\", 1995, 0.7694804, 21410 ], [ \"Congo\", 1996, 0.7759093, 22000 ], [ \"Congo\", 1997, 0.7632028, 22000 ], [ \"Congo\", 1998, 0.7513315, 22000 ], [ \"Congo\", 1999, 0.7388062, 22000 ], [ \"Congo\", 2000, 0.7247551, 22000 ], [ \"Congo\", 2001, 0.7089196, 22000 ], [ \"Congo\", 2002, 0.6918979, 22000 ], [ \"Congo\", 2003, 0.2146733, 7000 ], [ \"Congo\", 2004, 0.4136422, 13820 ], [ \"Congo\", 2005, 0.4655724, 15907 ], [ \"Congo\", 2006, 0.5163403, 18000 ], [ \"Congo\", 2007, 0.566021, 20100 ], [ \"Congo\", 2008, 0.614082, 22200 ], [ \"Congo\", 2009, 0.6597556, 24300 ], [ \"Costa Rica\", 1960, 0.7498939, 10000 ], [ \"Costa Rica\", 1965, 1.264012, 20000 ], [ \"Costa Rica\", 1970, 2.196529, 40000 ], [ \"Costa Rica\", 1975, 3.949545, 81000 ], [ \"Costa Rica\", 1976, 4.312675, 90800 ], [ \"Costa Rica\", 1977, 4.911794, 106200 ], [ \"Costa Rica\", 1978, 5.540179, 123100 ], [ \"Costa Rica\", 1979, 5.848706, 133600 ], [ \"Costa Rica\", 1980, 6.701768, 157400 ], [ \"Costa Rica\", 1981, 7.064097, 170600 ], [ \"Costa Rica\", 1982, 7.592403, 188559 ], [ \"Costa Rica\", 1983, 7.62991, 194855 ], [ \"Costa Rica\", 1984, 7.710908, 202459 ], [ \"Costa Rica\", 1985, 7.779207, 209930 ], [ \"Costa Rica\", 1986, 7.743476, 214706 ], [ \"Costa Rica\", 1987, 8.442648, 240444 ], [ \"Costa Rica\", 1988, 8.772627, 256521 ], [ \"Costa Rica\", 1989, 9.06389, 272000 ], [ \"Costa Rica\", 1990, 9.142514, 281433 ], [ \"Costa Rica\", 1991, 9.660381, 304863 ], [ \"Costa Rica\", 1992, 10.10618, 326789 ], [ \"Costa Rica\", 1993, 10.99232, 364119 ], [ \"Costa Rica\", 1994, 12.66972, 430000 ], [ \"Costa Rica\", 1995, 13.76798, 478939 ], [ \"Costa Rica\", 1996, 14.73762, 525682 ], [ \"Costa Rica\", 1997, 18.71591, 684636 ], [ \"Costa Rica\", 1998, 19.7956, 742415 ], [ \"Costa Rica\", 1999, 20.89065, 802597 ], [ \"Costa Rica\", 2000, 22.86353, 898734 ], [ \"Costa Rica\", 2001, 23.52404, 944950 ], [ \"Costa Rica\", 2002, 25.31499, 1037986 ], [ \"Costa Rica\", 2003, 27.73082, 1159223 ], [ \"Costa Rica\", 2004, 31.55715, 1343193 ], [ \"Costa Rica\", 2005, 32.07918, 1388503 ], [ \"Costa Rica\", 2006, 30.24544, 1329505 ], [ \"Costa Rica\", 2007, 32.22169, 1436695 ], [ \"Costa Rica\", 2008, 31.8144, 1437733 ], [ \"Costa Rica\", 2009, 32.74992, 1499601 ], [ \"Cote d'Ivoire\", 1960, 0.1037315, 3690 ], [ \"Cote d'Ivoire\", 1965, 0.2004565, 8600 ], [ \"Cote d'Ivoire\", 1970, 0.3201426, 17000 ], [ \"Cote d'Ivoire\", 1975, 0.3644005, 24022 ], [ \"Cote d'Ivoire\", 1976, 0.3770597, 26206 ], [ \"Cote d'Ivoire\", 1977, 0.3795739, 27696 ], [ \"Cote d'Ivoire\", 1978, 0.3985292, 30521 ], [ \"Cote d'Ivoire\", 1979, 0.4065064, 32656 ], [ \"Cote d'Ivoire\", 1980, 0.4449841, 37465 ], [ \"Cote d'Ivoire\", 1981, 0.4830775, 42590 ], [ \"Cote d'Ivoire\", 1982, 0.5098339, 47025 ], [ \"Cote d'Ivoire\", 1983, 0.5288407, 50970 ], [ \"Cote d'Ivoire\", 1984, 0.5144981, 51739 ], [ \"Cote d'Ivoire\", 1985, 0.5449627, 57088 ], [ \"Cote d'Ivoire\", 1986, 0.5609664, 61111 ], [ \"Cote d'Ivoire\", 1987, 0.5625989, 63640 ], [ \"Cote d'Ivoire\", 1988, 0.5681443, 66663 ], [ \"Cote d'Ivoire\", 1989, 0.5620648, 68375 ], [ \"Cote d'Ivoire\", 1990, 0.5769354, 72753 ], [ \"Cote d'Ivoire\", 1991, 0.6219142, 81284 ], [ \"Cote d'Ivoire\", 1992, 0.619357, 83869 ], [ \"Cote d'Ivoire\", 1993, 0.6430997, 90165 ], [ \"Cote d'Ivoire\", 1994, 0.7121075, 103268 ], [ \"Cote d'Ivoire\", 1995, 0.7729199, 115790 ], [ \"Cote d'Ivoire\", 1996, 0.8397359, 129808 ], [ \"Cote d'Ivoire\", 1997, 0.89323, 142322 ], [ \"Cote d'Ivoire\", 1998, 1.036572, 170001 ], [ \"Cote d'Ivoire\", 1999, 1.30129, 219283 ], [ \"Cote d'Ivoire\", 2000, 1.52572, 263667 ], [ \"Cote d'Ivoire\", 2001, 1.659698, 293568 ], [ \"Cote d'Ivoire\", 2002, 1.797187, 324839 ], [ \"Cote d'Ivoire\", 2003, 1.289738, 238000 ], [ \"Cote d'Ivoire\", 2004, 1.369107, 257932 ], [ \"Cote d'Ivoire\", 2005, 1.343293, 258515 ], [ \"Cote d'Ivoire\", 2006, 1.375323, 270573 ], [ \"Cote d'Ivoire\", 2007, 1.230311, 247573 ], [ \"Cote d'Ivoire\", 2008, 1.731323, 356502 ], [ \"Cote d'Ivoire\", 2009, 1.33841, 282070 ], [ \"Croatia\", 1970, 3.166063, 132000 ], [ \"Croatia\", 1975, 5.136872, 219000 ], [ \"Croatia\", 1976, 5.714914, 244914 ], [ \"Croatia\", 1977, 6.192608, 266799 ], [ \"Croatia\", 1978, 6.983425, 302480 ], [ \"Croatia\", 1979, 7.616123, 331627 ], [ \"Croatia\", 1980, 8.271244, 362000 ], [ \"Croatia\", 1981, 9.002842, 396000 ], [ \"Croatia\", 1982, 10.02224, 443000 ], [ \"Croatia\", 1983, 11.26059, 500000 ], [ \"Croatia\", 1984, 12.1142, 540000 ], [ \"Croatia\", 1985, 12.97132, 580000 ], [ \"Croatia\", 1986, 13.83887, 620000 ], [ \"Croatia\", 1987, 14.71754, 660000 ], [ \"Croatia\", 1988, 15.69812, 704619 ], [ \"Croatia\", 1989, 16.76028, 753924 ], [ \"Croatia\", 1990, 18.21899, 822988 ], [ \"Croatia\", 1991, 19.59545, 891217 ], [ \"Croatia\", 1992, 20.80594, 954616 ], [ \"Croatia\", 1993, 22.19555, 1027430 ], [ \"Croatia\", 1994, 25.87067, 1205220 ], [ \"Croatia\", 1995, 27.56609, 1287061 ], [ \"Croatia\", 1996, 29.82872, 1389026 ], [ \"Croatia\", 1997, 32.17214, 1488065 ], [ \"Croatia\", 1998, 33.99717, 1557969 ], [ \"Croatia\", 1999, 35.98218, 1633564 ], [ \"Croatia\", 2000, 38.2015, 1721139 ], [ \"Croatia\", 2001, 39.74096, 1781000 ], [ \"Croatia\", 2002, 40.86478, 1825000 ], [ \"Croatia\", 2003, 41.98895, 1871300 ], [ \"Croatia\", 2004, 42.41887, 1887600 ], [ \"Croatia\", 2005, 42.37054, 1882500 ], [ \"Croatia\", 2006, 41.2807, 1831050 ], [ \"Croatia\", 2007, 41.69656, 1846700 ], [ \"Croatia\", 2008, 42.4664, 1878080 ], [ \"Croatia\", 2009, 42.09964, 1859190 ], [ \"Cuba\", 1960, 2.227554, 155402 ], [ \"Cuba\", 1976, 2.064056, 197000 ], [ \"Cuba\", 1977, 2.04469, 197000 ], [ \"Cuba\", 1978, 2.018242, 196000 ], [ \"Cuba\", 1979, 2.158054, 211000 ], [ \"Cuba\", 1981, 2.348159, 232100 ], [ \"Cuba\", 1982, 2.458241, 244000 ], [ \"Cuba\", 1983, 2.558433, 255000 ], [ \"Cuba\", 1984, 2.560481, 256500 ], [ \"Cuba\", 1985, 2.663609, 268600 ], [ \"Cuba\", 1986, 2.829973, 287800 ], [ \"Cuba\", 1987, 3.606021, 370400 ], [ \"Cuba\", 1988, 3.402902, 353300 ], [ \"Cuba\", 1989, 2.898955, 304107 ], [ \"Cuba\", 1990, 3.17979, 336648 ], [ \"Cuba\", 1991, 3.177479, 339057 ], [ \"Cuba\", 1992, 3.136469, 336945 ], [ \"Cuba\", 1993, 3.229982, 349000 ], [ \"Cuba\", 1994, 3.217947, 349471 ], [ \"Cuba\", 1995, 3.237022, 353163 ], [ \"Cuba\", 1996, 3.251112, 356158 ], [ \"Cuba\", 1997, 3.372807, 370800 ], [ \"Cuba\", 1998, 3.515125, 387642 ], [ \"Cuba\", 1999, 3.922437, 433762 ], [ \"Cuba\", 2000, 4.407084, 488606 ], [ \"Cuba\", 2001, 5.168547, 574415 ], [ \"Cuba\", 2002, 5.97583, 665639 ], [ \"Cuba\", 2003, 6.488969, 724261 ], [ \"Cuba\", 2004, 6.871255, 768196 ], [ \"Cuba\", 2005, 7.64713, 855958 ], [ \"Cuba\", 2006, 8.584617, 961573 ], [ \"Cuba\", 2007, 9.416965, 1055118 ], [ \"Cuba\", 2008, 9.710975, 1088089 ], [ \"Cuba\", 2009, 9.994359, 1119786 ], [ \"Cyprus\", 1960, 1.855161, 10630 ], [ \"Cyprus\", 1965, 3.529084, 20550 ], [ \"Cyprus\", 1970, 5.424289, 33359 ], [ \"Cyprus\", 1975, 7.033774, 42852 ], [ \"Cyprus\", 1976, 7.848871, 47699 ], [ \"Cyprus\", 1977, 7.145012, 43348 ], [ \"Cyprus\", 1978, 8.794709, 53348 ], [ \"Cyprus\", 1979, 9.94695, 60469 ], [ \"Cyprus\", 1980, 10.92278, 66735 ], [ \"Cyprus\", 1981, 12.53163, 77204 ], [ \"Cyprus\", 1982, 13.67277, 85192 ], [ \"Cyprus\", 1983, 15.83584, 99965 ], [ \"Cyprus\", 1984, 18.67797, 119460 ], [ \"Cyprus\", 1985, 21.01879, 136054 ], [ \"Cyprus\", 1986, 23.83647, 155921 ], [ \"Cyprus\", 1987, 27.27709, 180118 ], [ \"Cyprus\", 1988, 30.35056, 202244 ], [ \"Cyprus\", 1989, 33.15521, 223117 ], [ \"Cyprus\", 1990, 36.13617, 245941 ], [ \"Cyprus\", 1991, 39.0043, 268898 ], [ \"Cyprus\", 1992, 41.6005, 290852 ], [ \"Cyprus\", 1993, 43.82431, 310990 ], [ \"Cyprus\", 1994, 45.8523, 330364 ], [ \"Cyprus\", 1995, 47.48418, 347343 ], [ \"Cyprus\", 1996, 49.33763, 366363 ], [ \"Cyprus\", 1997, 51.21424, 386013 ], [ \"Cyprus\", 1998, 52.91309, 404710 ], [ \"Cyprus\", 1999, 54.65747, 424060 ], [ \"Cyprus\", 2000, 55.94801, 440091 ], [ \"Cyprus\", 2001, 54.57164, 434978 ], [ \"Cyprus\", 2002, 52.94899, 427427 ], [ \"Cyprus\", 2003, 51.90331, 424104 ], [ \"Cyprus\", 2004, 50.60779, 418365 ], [ \"Cyprus\", 2005, 50.24294, 420030 ], [ \"Cyprus\", 2006, 48.31966, 408319 ], [ \"Cyprus\", 2007, 47.93538, 409279 ], [ \"Cyprus\", 2008, 47.92517, 413323 ], [ \"Cyprus\", 2009, 47.58839, 414512 ], [ \"Czech Republic\", 1979, 11.25039, 1153004 ], [ \"Czech Republic\", 1980, 11.46229, 1178732 ], [ \"Czech Republic\", 1981, 11.68808, 1204495 ], [ \"Czech Republic\", 1982, 11.93184, 1230784 ], [ \"Czech Republic\", 1983, 12.3027, 1269169 ], [ \"Czech Republic\", 1984, 12.61834, 1301376 ], [ \"Czech Republic\", 1985, 12.92224, 1332331 ], [ \"Czech Republic\", 1986, 13.39111, 1380327 ], [ \"Czech Republic\", 1987, 13.94509, 1437034 ], [ \"Czech Republic\", 1988, 14.51526, 1495474 ], [ \"Czech Republic\", 1989, 15.11808, 1557478 ], [ \"Czech Republic\", 1990, 15.75848, 1623642 ], [ \"Czech Republic\", 1991, 16.56454, 1707398 ], [ \"Czech Republic\", 1992, 17.63178, 1818638 ], [ \"Czech Republic\", 1993, 19.10887, 1972293 ], [ \"Czech Republic\", 1994, 21.09627, 2177951 ], [ \"Czech Republic\", 1995, 23.68511, 2444156 ], [ \"Czech Republic\", 1996, 27.33231, 2817215 ], [ \"Czech Republic\", 1997, 31.8761, 3279773 ], [ \"Czech Republic\", 1998, 36.44125, 3741492 ], [ \"Czech Republic\", 1999, 37.15226, 3806137 ], [ \"Czech Republic\", 2000, 37.86679, 3871651 ], [ \"Czech Republic\", 2001, 37.82898, 3860843 ], [ \"Czech Republic\", 2002, 36.06967, 3675470 ], [ \"Czech Republic\", 2003, 35.62243, 3626294 ], [ \"Czech Republic\", 2004, 33.66917, 3427666 ], [ \"Czech Republic\", 2005, 31.55889, 3217340 ], [ \"Czech Republic\", 2006, 28.24127, 2887583 ], [ \"Czech Republic\", 2007, 23.39991, 2402774 ], [ \"Czech Republic\", 2008, 21.94185, 2264249 ], [ \"Czech Republic\", 2009, 20.38089, 2113283 ], [ \"Dem. People's Rep. of Korea\", 1983, 2.76079, 500000 ], [ \"Dem. People's Rep. of Korea\", 1984, 2.714357, 500000 ], [ \"Dem. People's Rep. of Korea\", 1985, 2.670814, 500000 ], [ \"Dem. People's Rep. of Korea\", 1986, 2.630468, 500000 ], [ \"Dem. People's Rep. of Korea\", 1987, 2.592529, 500000 ], [ \"Dem. People's Rep. of Korea\", 1988, 2.555968, 500000 ], [ \"Dem. People's Rep. of Korea\", 1989, 2.519448, 500000 ], [ \"Dem. People's Rep. of Korea\", 1990, 2.482226, 500000 ], [ \"Dem. People's Rep. of Korea\", 1991, 2.444177, 500000 ], [ \"Dem. People's Rep. of Korea\", 1992, 2.406013, 500000 ], [ \"Dem. People's Rep. of Korea\", 1993, 2.368826, 500000 ], [ \"Dem. People's Rep. of Korea\", 1994, 2.333968, 500000 ], [ \"Dem. People's Rep. of Korea\", 1995, 2.302299, 500000 ], [ \"Dem. People's Rep. of Korea\", 1996, 2.273892, 500000 ], [ \"Dem. People's Rep. of Korea\", 1997, 2.248392, 500000 ], [ \"Dem. People's Rep. of Korea\", 1998, 2.22564, 500000 ], [ \"Dem. People's Rep. of Korea\", 1999, 2.205374, 500000 ], [ \"Dem. People's Rep. of Korea\", 2000, 2.18735, 500000 ], [ \"Dem. People's Rep. of Korea\", 2001, 3.735023, 860000 ], [ \"Dem. People's Rep. of Korea\", 2002, 3.953069, 916000 ], [ \"Dem. People's Rep. of Korea\", 2003, 4.205681, 980000 ], [ \"Dem. People's Rep. of Korea\", 2004, 4.269917, 1000000 ], [ \"Dem. People's Rep. of Korea\", 2005, 4.25006, 1000000 ], [ \"Dem. People's Rep. of Korea\", 2006, 4.231624, 1000000 ], [ \"Dem. People's Rep. of Korea\", 2007, 4.973095, 1180000 ], [ \"Dem. People's Rep. of Korea\", 2008, 4.95408, 1180000 ], [ \"Dem. People's Rep. of Korea\", 2009, 4.935985, 1180000 ], [ \"Denmark\", 1960, 18.20536, 833987 ], [ \"Denmark\", 1965, 21.66593, 1030865 ], [ \"Denmark\", 1970, 25.34114, 1249003 ], [ \"Denmark\", 1975, 33.72939, 1706661 ], [ \"Denmark\", 1976, 36.13636, 1835243 ], [ \"Denmark\", 1977, 38.3587, 1954316 ], [ \"Denmark\", 1978, 40.23416, 2055144 ], [ \"Denmark\", 1979, 42.1159, 2155253 ], [ \"Denmark\", 1980, 43.44645, 2225774 ], [ \"Denmark\", 1981, 44.65979, 2288634 ], [ \"Denmark\", 1982, 45.90202, 2351452 ], [ \"Denmark\", 1983, 46.94704, 2403245 ], [ \"Denmark\", 1984, 48.20628, 2465993 ], [ \"Denmark\", 1985, 49.73506, 2543291 ], [ \"Denmark\", 1986, 51.39455, 2628371 ], [ \"Denmark\", 1987, 52.99649, 2711691 ], [ \"Denmark\", 1988, 54.50645, 2791740 ], [ \"Denmark\", 1989, 55.51868, 2847873 ], [ \"Denmark\", 1990, 56.63868, 2911198 ], [ \"Denmark\", 1991, 57.26134, 2950756 ], [ \"Denmark\", 1992, 58.13274, 3004944 ], [ \"Denmark\", 1993, 58.98592, 3059806 ], [ \"Denmark\", 1994, 59.97583, 3123026 ], [ \"Denmark\", 1995, 61.08448, 3193412 ], [ \"Denmark\", 1996, 61.93378, 3251124 ], [ \"Denmark\", 1997, 63.36933, 3340501 ], [ \"Denmark\", 1998, 66.03893, 3495858 ], [ \"Denmark\", 1999, 68.44864, 3638119 ], [ \"Denmark\", 2000, 71.8786, 3835000 ], [ \"Denmark\", 2001, 72.18431, 3864839 ], [ \"Denmark\", 2002, 68.90028, 3700867 ], [ \"Denmark\", 2003, 67.08848, 3614249 ], [ \"Denmark\", 2004, 64.62462, 3491307 ], [ \"Denmark\", 2005, 61.80721, 3348177 ], [ \"Denmark\", 2006, 57.04911, 3098580 ], [ \"Denmark\", 2007, 51.88258, 2825095 ], [ \"Denmark\", 2008, 45.63658, 2490938 ], [ \"Denmark\", 2009, 37.69451, 2062000 ], [ \"Djibouti\", 1970, 0.722158, 1167 ], [ \"Djibouti\", 1975, 0.6926179, 1551 ], [ \"Djibouti\", 1976, 0.6666014, 1635 ], [ \"Djibouti\", 1977, 0.614387, 1660 ], [ \"Djibouti\", 1978, 0.6480291, 1920 ], [ \"Djibouti\", 1979, 0.7087393, 2270 ], [ \"Djibouti\", 1980, 0.7717125, 2624 ], [ \"Djibouti\", 1981, 0.8444372, 2990 ], [ \"Djibouti\", 1982, 0.9406898, 3420 ], [ \"Djibouti\", 1983, 0.9746599, 3624 ], [ \"Djibouti\", 1984, 0.956626, 3670 ], [ \"Djibouti\", 1985, 1.006359, 4048 ], [ \"Djibouti\", 1986, 1.00168, 4299 ], [ \"Djibouti\", 1987, 0.9619602, 4452 ], [ \"Djibouti\", 1988, 0.9616039, 4801 ], [ \"Djibouti\", 1989, 0.9016023, 4806 ], [ \"Djibouti\", 1990, 1.019135, 5710 ], [ \"Djibouti\", 1991, 1.075196, 6230 ], [ \"Djibouti\", 1992, 1.146734, 6789 ], [ \"Djibouti\", 1993, 1.222883, 7349 ], [ \"Djibouti\", 1994, 1.231072, 7516 ], [ \"Djibouti\", 1995, 1.21129, 7556 ], [ \"Djibouti\", 1996, 1.27018, 8151 ], [ \"Djibouti\", 1997, 1.249099, 8283 ], [ \"Djibouti\", 1998, 1.155583, 7932 ], [ \"Djibouti\", 1999, 1.245311, 8831 ], [ \"Djibouti\", 2000, 1.330115, 9704 ], [ \"Djibouti\", 2001, 1.32914, 9932 ], [ \"Djibouti\", 2002, 1.327211, 10125 ], [ \"Djibouti\", 2003, 1.308632, 10169 ], [ \"Djibouti\", 2004, 1.403943, 11103 ], [ \"Djibouti\", 2005, 1.314135, 10578 ], [ \"Djibouti\", 2006, 1.37901, 11301 ], [ \"Djibouti\", 2007, 1.691616, 14113 ], [ \"Djibouti\", 2008, 1.755677, 14910 ], [ \"Djibouti\", 2009, 1.94885, 16842 ], [ \"Dominica\", 1970, 1.841542, 1300 ], [ \"Dominica\", 1975, 3.00947, 2180 ], [ \"Dominica\", 1976, 3.6818, 2540 ], [ \"Dominica\", 1977, 4.173908, 2930 ], [ \"Dominica\", 1978, 4.397328, 3140 ], [ \"Dominica\", 1979, 0.5524404, 400 ], [ \"Dominica\", 1980, 1.65649, 1210 ], [ \"Dominica\", 1982, 4.237462, 3100 ], [ \"Dominica\", 1983, 4.27415, 3110 ], [ \"Dominica\", 1984, 5.399942, 3900 ], [ \"Dominica\", 1985, 6.716824, 4812 ], [ \"Dominica\", 1986, 8.447611, 6000 ], [ \"Dominica\", 1987, 9.946714, 7000 ], [ \"Dominica\", 1988, 11.47036, 8000 ], [ \"Dominica\", 1989, 14.44878, 10000 ], [ \"Dominica\", 1990, 16.90231, 11632 ], [ \"Dominica\", 1991, 18.08005, 12404 ], [ \"Dominica\", 1992, 19.98279, 13700 ], [ \"Dominica\", 1993, 23.1721, 15900 ], [ \"Dominica\", 1994, 24.31354, 16700 ], [ \"Dominica\", 1995, 25.90975, 17800 ], [ \"Dominica\", 1996, 27.29789, 18737 ], [ \"Dominica\", 1997, 28.0202, 19200 ], [ \"Dominica\", 1998, 29.35584, 20070 ], [ \"Dominica\", 1999, 31.27447, 21332 ], [ \"Dominica\", 2000, 33.34949, 22700 ], [ \"Dominica\", 2001, 34.21684, 23250 ], [ \"Dominica\", 2002, 34.94539, 23708 ], [ \"Dominica\", 2003, 33.16898, 22468 ], [ \"Dominica\", 2004, 31.00439, 20963 ], [ \"Dominica\", 2005, 28.16651, 19000 ], [ \"Dominica\", 2006, 26.01766, 17500 ], [ \"Dominica\", 2007, 26.02924, 17450 ], [ \"Dominica\", 2008, 26.19055, 17500 ], [ \"Dominica\", 2009, 26.26287, 17500 ], [ \"Dominican Rep.\", 1980, 1.830652, 108500 ], [ \"Dominican Rep.\", 1981, 1.87794, 113900 ], [ \"Dominican Rep.\", 1982, 1.907946, 118400 ], [ \"Dominican Rep.\", 1983, 1.973856, 125300 ], [ \"Dominican Rep.\", 1984, 2.065703, 134100 ], [ \"Dominican Rep.\", 1985, 2.165292, 143700 ], [ \"Dominican Rep.\", 1986, 2.185157, 148200 ], [ \"Dominican Rep.\", 1987, 2.791348, 193400 ], [ \"Dominican Rep.\", 1988, 3.208081, 227000 ], [ \"Dominican Rep.\", 1989, 3.931202, 284000 ], [ \"Dominican Rep.\", 1990, 4.627291, 341201 ], [ \"Dominican Rep.\", 1991, 5.45627, 410542 ], [ \"Dominican Rep.\", 1992, 6.246829, 479480 ], [ \"Dominican Rep.\", 1993, 6.771425, 529981 ], [ \"Dominican Rep.\", 1994, 6.963663, 555449 ], [ \"Dominican Rep.\", 1995, 7.171775, 582611 ], [ \"Dominican Rep.\", 1996, 7.48118, 618551 ], [ \"Dominican Rep.\", 1997, 8.375629, 704389 ], [ \"Dominican Rep.\", 1998, 9.031193, 772180 ], [ \"Dominican Rep.\", 1999, 9.513986, 826746 ], [ \"Dominican Rep.\", 2000, 10.12663, 894164 ], [ \"Dominican Rep.\", 2001, 10.64777, 955145 ], [ \"Dominican Rep.\", 2002, 9.976329, 908957 ], [ \"Dominican Rep.\", 2003, 9.822803, 908809 ], [ \"Dominican Rep.\", 2004, 9.605775, 902258 ], [ \"Dominican Rep.\", 2005, 9.401137, 896252 ], [ \"Dominican Rep.\", 2006, 9.272779, 897026 ], [ \"Dominican Rep.\", 2007, 9.236947, 906485 ], [ \"Dominican Rep.\", 2008, 9.903945, 985711 ], [ \"Dominican Rep.\", 2009, 9.567974, 965423 ], [ \"Ecuador\", 1965, 0.9330881, 48000 ], [ \"Ecuador\", 1970, 1.507558, 90000 ], [ \"Ecuador\", 1975, 2.388814, 165000 ], [ \"Ecuador\", 1976, 2.474763, 176000 ], [ \"Ecuador\", 1977, 2.52778, 185000 ], [ \"Ecuador\", 1978, 2.656042, 200000 ], [ \"Ecuador\", 1979, 2.801679, 217000 ], [ \"Ecuador\", 1980, 2.850207, 227000 ], [ \"Ecuador\", 1981, 2.952391, 241700 ], [ \"Ecuador\", 1982, 3.087438, 259710 ], [ \"Ecuador\", 1983, 3.066016, 264898 ], [ \"Ecuador\", 1984, 2.977195, 264086 ], [ \"Ecuador\", 1985, 2.950011, 268538 ], [ \"Ecuador\", 1986, 3.06747, 286413 ], [ \"Ecuador\", 1987, 3.504384, 335444 ], [ \"Ecuador\", 1988, 3.91113, 383589 ], [ \"Ecuador\", 1989, 4.522011, 454158 ], [ \"Ecuador\", 1990, 4.772182, 490508 ], [ \"Ecuador\", 1991, 4.674073, 491394 ], [ \"Ecuador\", 1992, 4.944478, 531349 ], [ \"Ecuador\", 1993, 5.451309, 598287 ], [ \"Ecuador\", 1994, 5.878078, 658115 ], [ \"Ecuador\", 1995, 6.118554, 697929 ], [ \"Ecuador\", 1996, 6.899476, 800763 ], [ \"Ecuador\", 1997, 7.63373, 900384 ], [ \"Ecuador\", 1998, 8.275035, 990842 ], [ \"Ecuador\", 1999, 9.300213, 1129528 ], [ \"Ecuador\", 2000, 9.946383, 1224431 ], [ \"Ecuador\", 2001, 10.71202, 1335772 ], [ \"Ecuador\", 2002, 11.1776, 1411055 ], [ \"Ecuador\", 2003, 11.98341, 1530700 ], [ \"Ecuador\", 2004, 12.31296, 1590755 ], [ \"Ecuador\", 2005, 12.85793, 1679568 ], [ \"Ecuador\", 2006, 13.44563, 1775232 ], [ \"Ecuador\", 2007, 13.66471, 1823120 ], [ \"Ecuador\", 2008, 14.12445, 1904177 ], [ \"Ecuador\", 2009, 14.70986, 2004228 ], [ \"Egypt\", 1960, 0.7920362, 220503 ], [ \"Egypt\", 1970, 0.823296, 290500 ], [ \"Egypt\", 1975, 0.8779674, 345000 ], [ \"Egypt\", 1976, 0.8720878, 353000 ], [ \"Egypt\", 1977, 0.8745806, 362000 ], [ \"Egypt\", 1978, 0.8831356, 374000 ], [ \"Egypt\", 1979, 0.9040418, 392000 ], [ \"Egypt\", 1981, 0.9437003, 430000 ], [ \"Egypt\", 1982, 1.02109, 477407 ], [ \"Egypt\", 1983, 1.21535, 583377 ], [ \"Egypt\", 1984, 1.299352, 640610 ], [ \"Egypt\", 1985, 1.761946, 892512 ], [ \"Egypt\", 1986, 2.067608, 1076450 ], [ \"Egypt\", 1987, 2.089094, 1118000 ], [ \"Egypt\", 1988, 2.183686, 1200623 ], [ \"Egypt\", 1989, 2.471475, 1394276 ], [ \"Egypt\", 1990, 2.772469, 1602067 ], [ \"Egypt\", 1991, 3.074789, 1816530 ], [ \"Egypt\", 1992, 3.362368, 2027680 ], [ \"Egypt\", 1993, 3.634359, 2234715 ], [ \"Egypt\", 1994, 3.919585, 2456161 ], [ \"Egypt\", 1995, 4.253541, 2716213 ], [ \"Egypt\", 1996, 4.648353, 3024947 ], [ \"Egypt\", 1997, 5.206696, 3452707 ], [ \"Egypt\", 1998, 5.877345, 3971518 ], [ \"Egypt\", 1999, 6.805657, 4686361 ], [ \"Egypt\", 2000, 7.814315, 5483601 ], [ \"Egypt\", 2001, 9.361087, 6694894 ], [ \"Egypt\", 2002, 10.69328, 7794763 ], [ \"Egypt\", 2003, 11.75785, 8735653 ], [ \"Egypt\", 2004, 12.59274, 9535016 ], [ \"Egypt\", 2005, 13.57573, 10474270 ], [ \"Egypt\", 2006, 13.85466, 10890050 ], [ \"Egypt\", 2007, 14.02545, 11228850 ], [ \"Egypt\", 2008, 14.53815, 11852540 ], [ \"Egypt\", 2009, 12.42486, 10312560 ], [ \"El Salvador\", 1965, 0.4050256, 12200 ], [ \"El Salvador\", 1970, 0.7976133, 28700 ], [ \"El Salvador\", 1975, 1.167608, 48100 ], [ \"El Salvador\", 1976, 1.270921, 55000 ], [ \"El Salvador\", 1977, 1.403671, 62000 ], [ \"El Salvador\", 1978, 1.424876, 64162 ], [ \"El Salvador\", 1979, 1.463377, 67095 ], [ \"El Salvador\", 1980, 1.476305, 68833 ], [ \"El Salvador\", 1981, 1.534973, 72690 ], [ \"El Salvador\", 1982, 1.656807, 79603 ], [ \"El Salvador\", 1983, 1.651709, 80448 ], [ \"El Salvador\", 1984, 1.747874, 86257 ], [ \"El Salvador\", 1985, 1.810315, 90496 ], [ \"El Salvador\", 1986, 1.800063, 91122 ], [ \"El Salvador\", 1987, 1.914352, 98107 ], [ \"El Salvador\", 1988, 2.036528, 105672 ], [ \"El Salvador\", 1989, 2.28029, 119867 ], [ \"El Salvador\", 1990, 2.344765, 124969 ], [ \"El Salvador\", 1991, 2.402695, 129964 ], [ \"El Salvador\", 1992, 3.002669, 164949 ], [ \"El Salvador\", 1993, 3.110271, 173503 ], [ \"El Salvador\", 1994, 4.166224, 235730 ], [ \"El Salvador\", 1995, 4.97137, 284777 ], [ \"El Salvador\", 1996, 5.619798, 325259 ], [ \"El Salvador\", 1997, 6.17408, 360410 ], [ \"El Salvador\", 1998, 6.577127, 386659 ], [ \"El Salvador\", 1999, 8.375493, 495340 ], [ \"El Salvador\", 2000, 10.51727, 625285 ], [ \"El Salvador\", 2001, 10.88111, 649879 ], [ \"El Salvador\", 2002, 11.13603, 667699 ], [ \"El Salvador\", 2003, 12.50912, 752645 ], [ \"El Salvador\", 2004, 14.70577, 887816 ], [ \"El Salvador\", 2005, 16.03437, 971455 ], [ \"El Salvador\", 2006, 17.04748, 1036777 ], [ \"El Salvador\", 2007, 17.68668, 1080083 ], [ \"El Salvador\", 2008, 17.56105, 1077179 ], [ \"El Salvador\", 2009, 17.83416, 1099128 ], [ \"Equatorial Guinea\", 1981, 0.2149382, 500 ], [ \"Equatorial Guinea\", 1982, 0.2391153, 600 ], [ \"Equatorial Guinea\", 1983, 0.2566142, 700 ], [ \"Equatorial Guinea\", 1984, 0.2714469, 800 ], [ \"Equatorial Guinea\", 1985, 0.2864509, 900 ], [ \"Equatorial Guinea\", 1986, 0.302756, 1000 ], [ \"Equatorial Guinea\", 1987, 0.3491397, 1200 ], [ \"Equatorial Guinea\", 1988, 0.3658468, 1300 ], [ \"Equatorial Guinea\", 1989, 0.3544127, 1300 ], [ \"Equatorial Guinea\", 1990, 0.3427782, 1300 ], [ \"Equatorial Guinea\", 1991, 0.3309252, 1300 ], [ \"Equatorial Guinea\", 1992, 0.3193342, 1300 ], [ \"Equatorial Guinea\", 1993, 0.3081423, 1300 ], [ \"Equatorial Guinea\", 1994, 0.5756269, 2515 ], [ \"Equatorial Guinea\", 1995, 0.5564319, 2515 ], [ \"Equatorial Guinea\", 1996, 0.7852641, 3668 ], [ \"Equatorial Guinea\", 1997, 0.7877836, 3800 ], [ \"Equatorial Guinea\", 1998, 1.121031, 5580 ], [ \"Equatorial Guinea\", 1999, 1.130025, 5800 ], [ \"Equatorial Guinea\", 2000, 1.153376, 6100 ], [ \"Equatorial Guinea\", 2001, 1.266997, 6900 ], [ \"Equatorial Guinea\", 2002, 1.570301, 8800 ], [ \"Equatorial Guinea\", 2003, 1.665678, 9600 ], [ \"Equatorial Guinea\", 2004, 1.772254, 10500 ], [ \"Equatorial Guinea\", 2005, 1.642557, 10000 ], [ \"Equatorial Guinea\", 2006, 1.598992, 10000 ], [ \"Equatorial Guinea\", 2007, 1.557123, 10000 ], [ \"Equatorial Guinea\", 2008, 1.516997, 10000 ], [ \"Equatorial Guinea\", 2009, 1.478693, 10000 ], [ \"Eritrea\", 1992, 0.4089523, 13011 ], [ \"Eritrea\", 1993, 0.419775, 13335 ], [ \"Eritrea\", 1994, 0.477605, 15192 ], [ \"Eritrea\", 1995, 0.5470808, 17540 ], [ \"Eritrea\", 1996, 0.5811264, 18919 ], [ \"Eritrea\", 1997, 0.6606681, 21979 ], [ \"Eritrea\", 1998, 0.7109471, 24308 ], [ \"Eritrea\", 1999, 0.7754738, 27375 ], [ \"Eritrea\", 2000, 0.8354194, 30554 ], [ \"Eritrea\", 2001, 0.8219283, 31249 ], [ \"Eritrea\", 2002, 0.9057617, 35897 ], [ \"Eritrea\", 2003, 0.9210094, 38078 ], [ \"Eritrea\", 2004, 0.9118928, 39271 ], [ \"Eritrea\", 2005, 0.84308, 37712 ], [ \"Eritrea\", 2006, 0.810654, 37541 ], [ \"Eritrea\", 2007, 0.7824864, 37412 ], [ \"Eritrea\", 2008, 0.8202965, 40415 ], [ \"Eritrea\", 2009, 0.955457, 48473 ], [ \"Estonia\", 1975, 8.379894, 120000 ], [ \"Estonia\", 1976, 9.017945, 130000 ], [ \"Estonia\", 1977, 11.03711, 160000 ], [ \"Estonia\", 1978, 11.66815, 170000 ], [ \"Estonia\", 1979, 12.97395, 190000 ], [ \"Estonia\", 1980, 13.57867, 200000 ], [ \"Estonia\", 1981, 15.51893, 230000 ], [ \"Estonia\", 1982, 16.0899, 240000 ], [ \"Estonia\", 1983, 16.64624, 250000 ], [ \"Estonia\", 1984, 17.18396, 260000 ], [ \"Estonia\", 1985, 17.70299, 270000 ], [ \"Estonia\", 1986, 18.1938, 280000 ], [ \"Estonia\", 1987, 18.6644, 290000 ], [ \"Estonia\", 1988, 19.02752, 298000 ], [ \"Estonia\", 1989, 19.72379, 310000 ], [ \"Estonia\", 1990, 20.41487, 320000 ], [ \"Estonia\", 1991, 21.39136, 332007 ], [ \"Estonia\", 1992, 22.22358, 339370 ], [ \"Estonia\", 1993, 23.36994, 349720 ], [ \"Estonia\", 1994, 25.77949, 377884 ], [ \"Estonia\", 1995, 28.60101, 411678 ], [ \"Estonia\", 1996, 30.93715, 438811 ], [ \"Estonia\", 1997, 33.42402, 468593 ], [ \"Estonia\", 1998, 35.88285, 498556 ], [ \"Estonia\", 1999, 37.37505, 515486 ], [ \"Estonia\", 2000, 38.15242, 522816 ], [ \"Estonia\", 2001, 37.15092, 506292 ], [ \"Estonia\", 2002, 35.00206, 475000 ], [ \"Estonia\", 2003, 34.07817, 461000 ], [ \"Estonia\", 2004, 32.90376, 444031 ], [ \"Estonia\", 2005, 32.82083, 442045 ], [ \"Estonia\", 2006, 33.60805, 451912 ], [ \"Estonia\", 2007, 36.89845, 495492 ], [ \"Estonia\", 2008, 37.13534, 498129 ], [ \"Estonia\", 2009, 36.76584, 492759 ], [ \"Ethiopia\", 1960, 0.03764124, 8636 ], [ \"Ethiopia\", 1965, 0.06515957, 17000 ], [ \"Ethiopia\", 1970, 0.1106534, 33000 ], [ \"Ethiopia\", 1975, 0.1326426, 45250 ], [ \"Ethiopia\", 1976, 0.1556554, 52100 ], [ \"Ethiopia\", 1977, 0.1687603, 57190 ], [ \"Ethiopia\", 1978, 0.173072, 59326 ], [ \"Ethiopia\", 1979, 0.1759785, 61165 ], [ \"Ethiopia\", 1980, 0.1809305, 64065 ], [ \"Ethiopia\", 1981, 0.1897012, 68792 ], [ \"Ethiopia\", 1982, 0.1999078, 74562 ], [ \"Ethiopia\", 1983, 0.2177845, 83798 ], [ \"Ethiopia\", 1984, 0.2260659, 89844 ], [ \"Ethiopia\", 1985, 0.2328239, 95573 ], [ \"Ethiopia\", 1986, 0.2434347, 103186 ], [ \"Ethiopia\", 1987, 0.2424749, 106131 ], [ \"Ethiopia\", 1988, 0.2344523, 105985 ], [ \"Ethiopia\", 1989, 0.248005, 115843 ], [ \"Ethiopia\", 1990, 0.2596639, 125398 ], [ \"Ethiopia\", 1991, 0.2664188, 133091 ], [ \"Ethiopia\", 1992, 0.2457953, 127041 ], [ \"Ethiopia\", 1993, 0.2478272, 132478 ], [ \"Ethiopia\", 1994, 0.249377, 137731 ], [ \"Ethiopia\", 1995, 0.2499908, 142452 ], [ \"Ethiopia\", 1996, 0.2533692, 148739 ], [ \"Ethiopia\", 1997, 0.2591602, 156538 ], [ \"Ethiopia\", 1998, 0.2643616, 164140 ], [ \"Ethiopia\", 1999, 0.3049082, 194494 ], [ \"Ethiopia\", 2000, 0.3540354, 231945 ], [ \"Ethiopia\", 2001, 0.4216934, 283683 ], [ \"Ethiopia\", 2002, 0.5123416, 353816 ], [ \"Ethiopia\", 2003, 0.5710867, 404790 ], [ \"Ethiopia\", 2004, 0.6658325, 484368 ], [ \"Ethiopia\", 2005, 0.8174921, 610347 ], [ \"Ethiopia\", 2006, 0.9461931, 725046 ], [ \"Ethiopia\", 2007, 1.119048, 880088 ], [ \"Ethiopia\", 2008, 1.111695, 897287 ], [ \"Ethiopia\", 2009, 1.104813, 915058 ], [ \"Faroe Islands\", 1960, 9.344597, 3208 ], [ \"Faroe Islands\", 1965, 13.08311, 4765 ], [ \"Faroe Islands\", 1970, 17.86499, 6910 ], [ \"Faroe Islands\", 1975, 25.8127, 10529 ], [ \"Faroe Islands\", 1976, 27.60959, 11400 ], [ \"Faroe Islands\", 1977, 28.90993, 12091 ], [ \"Faroe Islands\", 1978, 29.99457, 12709 ], [ \"Faroe Islands\", 1979, 30.94689, 13279 ], [ \"Faroe Islands\", 1980, 31.73956, 13781 ], [ \"Faroe Islands\", 1981, 33.36144, 14639 ], [ \"Faroe Islands\", 1982, 35.03421, 15517 ], [ \"Faroe Islands\", 1983, 35.6302, 15921 ], [ \"Faroe Islands\", 1984, 37.78354, 17040 ], [ \"Faroe Islands\", 1985, 38.78975, 17673 ], [ \"Faroe Islands\", 1986, 39.70984, 18311 ], [ \"Faroe Islands\", 1987, 41.61173, 19441 ], [ \"Faroe Islands\", 1988, 44.05782, 20816 ], [ \"Faroe Islands\", 1989, 46.42443, 22053 ], [ \"Faroe Islands\", 1990, 48.18451, 22825 ], [ \"Faroe Islands\", 1991, 50.7023, 23716 ], [ \"Faroe Islands\", 1992, 51.83285, 23741 ], [ \"Faroe Islands\", 1993, 52.04548, 23256 ], [ \"Faroe Islands\", 1994, 51.7571, 22637 ], [ \"Faroe Islands\", 1995, 51.5061, 22246 ], [ \"Faroe Islands\", 1996, 52.99819, 22856 ], [ \"Faroe Islands\", 1997, 54.19638, 23557 ], [ \"Faroe Islands\", 1998, 54.49433, 24032 ], [ \"Faroe Islands\", 1999, 55.41161, 24851 ], [ \"Faroe Islands\", 2000, 54.75532, 24952 ], [ \"Faroe Islands\", 2001, 50.07136, 23156 ], [ \"Faroe Islands\", 2002, 52.0371, 24408 ], [ \"Faroe Islands\", 2003, 51.11092, 24292 ], [ \"Faroe Islands\", 2004, 49.81287, 23958 ], [ \"Faroe Islands\", 2005, 49.01953, 23823 ], [ \"Faroe Islands\", 2006, 47.00734, 23043 ], [ \"Faroe Islands\", 2007, 45.50686, 22459 ], [ \"Faroe Islands\", 2008, 43.97292, 21822 ], [ \"Faroe Islands\", 2009, 41.94616, 20924 ], [ \"Fiji\", 1960, 1.310677, 5164 ], [ \"Fiji\", 1965, 1.530288, 7100 ], [ \"Fiji\", 1970, 1.845075, 9600 ], [ \"Fiji\", 1975, 2.808011, 16174 ], [ \"Fiji\", 1976, 2.95887, 17362 ], [ \"Fiji\", 1977, 3.098115, 18506 ], [ \"Fiji\", 1978, 3.22386, 19608 ], [ \"Fiji\", 1979, 3.44107, 21341 ], [ \"Fiji\", 1980, 3.775309, 23923 ], [ \"Fiji\", 1981, 3.773329, 24494 ], [ \"Fiji\", 1982, 3.866518, 25756 ], [ \"Fiji\", 1983, 3.883998, 26530 ], [ \"Fiji\", 1984, 4.130604, 28821 ], [ \"Fiji\", 1985, 4.208903, 29829 ], [ \"Fiji\", 1986, 4.646045, 33230 ], [ \"Fiji\", 1987, 4.735436, 34001 ], [ \"Fiji\", 1988, 4.960503, 35655 ], [ \"Fiji\", 1989, 5.440599, 39174 ], [ \"Fiji\", 1990, 5.86337, 42425 ], [ \"Fiji\", 1991, 6.246404, 45596 ], [ \"Fiji\", 1992, 6.716634, 49610 ], [ \"Fiji\", 1993, 7.212323, 53997 ], [ \"Fiji\", 1994, 7.837682, 59471 ], [ \"Fiji\", 1995, 8.434557, 64772 ], [ \"Fiji\", 1996, 9.02352, 70018 ], [ \"Fiji\", 1997, 9.167139, 71793 ], [ \"Fiji\", 1998, 9.742301, 76933 ], [ \"Fiji\", 1999, 10.24368, 81518 ], [ \"Fiji\", 2000, 10.77735, 86400 ], [ \"Fiji\", 2001, 11.4231, 92222 ], [ \"Fiji\", 2002, 11.99951, 97515 ], [ \"Fiji\", 2003, 12.47544, 102023 ], [ \"Fiji\", 2004, 12.75998, 105000 ], [ \"Fiji\", 2005, 13.58536, 112493 ], [ \"Fiji\", 2006, 13.80006, 115000 ], [ \"Fiji\", 2007, 14.52786, 121845 ], [ \"Fiji\", 2008, 15.29537, 129100 ], [ \"Fiji\", 2009, 16.10682, 136782 ], [ \"Finland\", 1960, 9.667786, 428283 ], [ \"Finland\", 1965, 13.29973, 607000 ], [ \"Finland\", 1970, 18.73643, 863000 ], [ \"Finland\", 1975, 28.71739, 1353000 ], [ \"Finland\", 1976, 30.25268, 1430000 ], [ \"Finland\", 1977, 31.50428, 1493000 ], [ \"Finland\", 1978, 32.8629, 1561000 ], [ \"Finland\", 1979, 34.55915, 1646000 ], [ \"Finland\", 1980, 36.40424, 1739954 ], [ \"Finland\", 1981, 38.28391, 1838000 ], [ \"Finland\", 1982, 39.94863, 1928000 ], [ \"Finland\", 1983, 41.64226, 2021000 ], [ \"Finland\", 1984, 43.12143, 2104000 ], [ \"Finland\", 1985, 44.66718, 2189677 ], [ \"Finland\", 1986, 46.16735, 2272000 ], [ \"Finland\", 1987, 47.90238, 2365000 ], [ \"Finland\", 1988, 49.88204, 2470000 ], [ \"Finland\", 1989, 51.97758, 2582000 ], [ \"Finland\", 1990, 53.53913, 2669697 ], [ \"Finland\", 1991, 54.25259, 2717600 ], [ \"Finland\", 1992, 54.46222, 2742046 ], [ \"Finland\", 1993, 54.59229, 2763132 ], [ \"Finland\", 1994, 55.06876, 2801000 ], [ \"Finland\", 1995, 55.01388, 2810000 ], [ \"Finland\", 1996, 55.45229, 2842000 ], [ \"Finland\", 1997, 55.67129, 2861000 ], [ \"Finland\", 1998, 55.16649, 2841497 ], [ \"Finland\", 1999, 55.21947, 2850305 ], [ \"Finland\", 2000, 55.06681, 2848809 ], [ \"Finland\", 2001, 54.11353, 2806172 ], [ \"Finland\", 2002, 52.42976, 2725607 ], [ \"Finland\", 2003, 49.25924, 2567592 ], [ \"Finland\", 2004, 45.29821, 2368000 ], [ \"Finland\", 2005, 40.4245, 2120000 ], [ \"Finland\", 2006, 36.29141, 1910000 ], [ \"Finland\", 2007, 32.93435, 1740000 ], [ \"Finland\", 2008, 31.10588, 1650000 ], [ \"Finland\", 2009, 26.8515, 1430000 ], [ \"France\", 1960, 4.801924, 2193711 ], [ \"France\", 1965, 6.286175, 3065000 ], [ \"France\", 1970, 8.406176, 4268000 ], [ \"France\", 1975, 13.4708, 7099000 ], [ \"France\", 1976, 15.92688, 8444000 ], [ \"France\", 1977, 18.88697, 10060000 ], [ \"France\", 1978, 22.4542, 12010000 ], [ \"France\", 1979, 25.98997, 13959000 ], [ \"France\", 1980, 29.46816, 15898000 ], [ \"France\", 1981, 32.72799, 17743000 ], [ \"France\", 1982, 35.74235, 19478000 ], [ \"France\", 1983, 38.22136, 20942000 ], [ \"France\", 1984, 40.08941, 22086290 ], [ \"France\", 1985, 41.57689, 23030560 ], [ \"France\", 1986, 42.93441, 23911100 ], [ \"France\", 1987, 44.29839, 24803610 ], [ \"France\", 1988, 45.88451, 25827280 ], [ \"France\", 1989, 47.62481, 26942450 ], [ \"France\", 1990, 49.40874, 28084920 ], [ \"France\", 1991, 50.96643, 29100000 ], [ \"France\", 1992, 52.49618, 30100000 ], [ \"France\", 1993, 53.67688, 30900000 ], [ \"France\", 1994, 54.8573, 31700000 ], [ \"France\", 1995, 55.86262, 32400000 ], [ \"France\", 1996, 56.52574, 32900000 ], [ \"France\", 1997, 57.70367, 33700000 ], [ \"France\", 1998, 58.17958, 34098850 ], [ \"France\", 1999, 57.58635, 33888000 ], [ \"France\", 2000, 57.48049, 33987100 ], [ \"France\", 2001, 57.32386, 34083940 ], [ \"France\", 2002, 57.03364, 34124180 ], [ \"France\", 2003, 56.3054, 33913000 ], [ \"France\", 2004, 55.5876, 33703000 ], [ \"France\", 2005, 55.24543, 33707000 ], [ \"France\", 2006, 55.60233, 34125000 ], [ \"France\", 2007, 56.38914, 34800000 ], [ \"France\", 2008, 56.58005, 35100000 ], [ \"France\", 2009, 56.94334, 35500000 ], [ \"French Guiana\", 1970, 3.956273, 1900 ], [ \"French Guiana\", 1975, 6.789837, 3800 ], [ \"French Guiana\", 1976, 7.07421, 4100 ], [ \"French Guiana\", 1977, 9.143047, 5500 ], [ \"French Guiana\", 1978, 10.70493, 6700 ], [ \"French Guiana\", 1979, 11.33457, 7400 ], [ \"French Guiana\", 1980, 13.47551, 9200 ], [ \"French Guiana\", 1981, 15.69617, 11227 ], [ \"French Guiana\", 1982, 17.34595, 13019 ], [ \"French Guiana\", 1983, 19.17775, 15137 ], [ \"French Guiana\", 1984, 20.99902, 17480 ], [ \"French Guiana\", 1985, 21.71913, 19120 ], [ \"French Guiana\", 1986, 21.99884, 20539 ], [ \"French Guiana\", 1987, 21.47749, 21296 ], [ \"French Guiana\", 1988, 24.1925, 25436 ], [ \"French Guiana\", 1989, 24.93286, 27666 ], [ \"French Guiana\", 1990, 26.11819, 30394 ], [ \"French Guiana\", 1991, 27.73472, 33635 ], [ \"French Guiana\", 1992, 28.96762, 36432 ], [ \"French Guiana\", 1993, 29.59297, 38475 ], [ \"French Guiana\", 1994, 30.13094, 40455 ], [ \"French Guiana\", 1995, 30.0439, 41676 ], [ \"French Guiana\", 1996, 30.81231, 44175 ], [ \"French Guiana\", 1997, 31.54418, 46745 ], [ \"French Guiana\", 1998, 30.21562, 46329 ], [ \"French Guiana\", 1999, 30.94079, 49181 ], [ \"French Guiana\", 2000, 30.27294, 50000 ], [ \"French Guiana\", 2001, 29.64117, 51000 ], [ \"French Guiana\", 2002, 28.40545, 51000 ], [ \"French Guiana\", 2003, 27.22904, 51000 ], [ \"French Guiana\", 2004, 26.16888, 51000 ], [ \"French Guiana\", 2005, 25.24903, 51000 ], [ \"French Guiana\", 2006, 24.46254, 51000 ], [ \"French Guiana\", 2007, 23.78021, 51000 ], [ \"French Guiana\", 2008, 23.17139, 51000 ], [ \"French Guiana\", 2009, 21.34136, 48157 ], [ \"French Polynesia\", 1960, 1.042428, 827 ], [ \"French Polynesia\", 1965, 2.046113, 1900 ], [ \"French Polynesia\", 1970, 3.607764, 4000 ], [ \"French Polynesia\", 1975, 5.238546, 6800 ], [ \"French Polynesia\", 1976, 5.975991, 8000 ], [ \"French Polynesia\", 1977, 6.520275, 9000 ], [ \"French Polynesia\", 1978, 7.027654, 10000 ], [ \"French Polynesia\", 1979, 7.500648, 11000 ], [ \"French Polynesia\", 1980, 8.272613, 12500 ], [ \"French Polynesia\", 1981, 8.481165, 13200 ], [ \"French Polynesia\", 1982, 9.797009, 15700 ], [ \"French Polynesia\", 1983, 10.9161, 18000 ], [ \"French Polynesia\", 1984, 12.0767, 20470 ], [ \"French Polynesia\", 1985, 13.67627, 23800 ], [ \"French Polynesia\", 1986, 15.01855, 26800 ], [ \"French Polynesia\", 1987, 15.97593, 29200 ], [ \"French Polynesia\", 1988, 16.93107, 31665 ], [ \"French Polynesia\", 1989, 17.84584, 34125 ], [ \"French Polynesia\", 1990, 19.54081, 38180 ], [ \"French Polynesia\", 1991, 20.6651, 41231 ], [ \"French Polynesia\", 1992, 21.3829, 43539 ], [ \"French Polynesia\", 1993, 21.63998, 44943 ], [ \"French Polynesia\", 1994, 22.23366, 47078 ], [ \"French Polynesia\", 1995, 22.54676, 48655 ], [ \"French Polynesia\", 1996, 23.30519, 51236 ], [ \"French Polynesia\", 1997, 23.35772, 52297 ], [ \"French Polynesia\", 1998, 23.29129, 53089 ], [ \"French Polynesia\", 1999, 22.53511, 52272 ], [ \"French Polynesia\", 2000, 22.75363, 53689 ], [ \"French Polynesia\", 2001, 22.23482, 53350 ], [ \"French Polynesia\", 2002, 21.79864, 53166 ], [ \"French Polynesia\", 2003, 21.59726, 53518 ], [ \"French Polynesia\", 2004, 21.17331, 53275 ], [ \"French Polynesia\", 2005, 20.9112, 53389 ], [ \"French Polynesia\", 2006, 20.72373, 53650 ], [ \"French Polynesia\", 2007, 20.62234, 54099 ], [ \"French Polynesia\", 2008, 20.53165, 54553 ], [ \"French Polynesia\", 2009, 20.19008, 54320 ], [ \"Gabon\", 1981, 1.487879, 10440 ], [ \"Gabon\", 1982, 1.452795, 10500 ], [ \"Gabon\", 1983, 1.472734, 10969 ], [ \"Gabon\", 1984, 1.432586, 11000 ], [ \"Gabon\", 1985, 1.515442, 12000 ], [ \"Gabon\", 1986, 1.591692, 13000 ], [ \"Gabon\", 1987, 1.661709, 14000 ], [ \"Gabon\", 1988, 1.955664, 17000 ], [ \"Gabon\", 1989, 2.103967, 18877 ], [ \"Gabon\", 1990, 2.240285, 20754 ], [ \"Gabon\", 1991, 2.747268, 26288 ], [ \"Gabon\", 1992, 2.795322, 27630 ], [ \"Gabon\", 1993, 2.92316, 29834 ], [ \"Gabon\", 1994, 2.982418, 31398 ], [ \"Gabon\", 1995, 2.950813, 32000 ], [ \"Gabon\", 1996, 3.137702, 35000 ], [ \"Gabon\", 1997, 3.251104, 37253 ], [ \"Gabon\", 1998, 3.291746, 38698 ], [ \"Gabon\", 1999, 3.152295, 37978 ], [ \"Gabon\", 2000, 3.159858, 38974 ], [ \"Gabon\", 2001, 2.951526, 37233 ], [ \"Gabon\", 2002, 2.488417, 32075 ], [ \"Gabon\", 2003, 2.919086, 38415 ], [ \"Gabon\", 2004, 2.878824, 38654 ], [ \"Gabon\", 2005, 2.857667, 39128 ], [ \"Gabon\", 2006, 2.613619, 36476 ], [ \"Gabon\", 2007, 1.863516, 26497 ], [ \"Gabon\", 2008, 1.82991, 26500 ], [ \"Gabon\", 2009, 1.797115, 26500 ], [ \"Gambia\", 1965, 0.1912688, 780 ], [ \"Gambia\", 1970, 0.2111266, 990 ], [ \"Gambia\", 1975, 0.2648873, 1470 ], [ \"Gambia\", 1976, 0.2983833, 1600 ], [ \"Gambia\", 1977, 0.3060763, 1700 ], [ \"Gambia\", 1978, 0.3130108, 1800 ], [ \"Gambia\", 1979, 0.3326244, 1980 ], [ \"Gambia\", 1980, 0.3489393, 2150 ], [ \"Gambia\", 1981, 0.3606734, 2300 ], [ \"Gambia\", 1982, 0.3484986, 2300 ], [ \"Gambia\", 1983, 0.3365816, 2300 ], [ \"Gambia\", 1984, 0.3416844, 2420 ], [ \"Gambia\", 1985, 0.340118, 2500 ], [ \"Gambia\", 1986, 0.3927488, 3000 ], [ \"Gambia\", 1987, 0.5159913, 4100 ], [ \"Gambia\", 1988, 0.6257444, 5175 ], [ \"Gambia\", 1989, 0.6622093, 5700 ], [ \"Gambia\", 1990, 0.6887549, 6168 ], [ \"Gambia\", 1991, 1.077087, 10030 ], [ \"Gambia\", 1992, 1.446469, 14000 ], [ \"Gambia\", 1993, 1.618329, 16274 ], [ \"Gambia\", 1994, 1.752475, 18306 ], [ \"Gambia\", 1995, 1.769952, 19202 ], [ \"Gambia\", 1996, 1.892454, 21319 ], [ \"Gambia\", 1997, 2.123691, 24833 ], [ \"Gambia\", 1998, 2.111149, 25609 ], [ \"Gambia\", 1999, 2.323734, 29216 ], [ \"Gambia\", 2000, 2.557981, 33300 ], [ \"Gambia\", 2001, 2.60147, 35029 ], [ \"Gambia\", 2002, 2.75626, 38350 ], [ \"Gambia\", 2003, 2.923163, 41986 ], [ \"Gambia\", 2004, 2.902469, 42993 ], [ \"Gambia\", 2005, 2.883095, 44000 ], [ \"Gambia\", 2006, 2.947514, 46302 ], [ \"Gambia\", 2007, 3.014528, 48700 ], [ \"Gambia\", 2008, 2.943501, 48868 ], [ \"Gambia\", 2009, 2.873543, 49000 ], [ \"Georgia\", 1975, 4.48248, 220000 ], [ \"Georgia\", 1976, 4.957787, 245000 ], [ \"Georgia\", 1977, 5.227973, 260000 ], [ \"Georgia\", 1978, 5.395417, 270000 ], [ \"Georgia\", 1979, 5.856677, 295000 ], [ \"Georgia\", 1980, 6.307905, 320000 ], [ \"Georgia\", 1981, 6.651603, 340000 ], [ \"Georgia\", 1982, 6.988116, 360000 ], [ \"Georgia\", 1983, 7.316372, 380000 ], [ \"Georgia\", 1984, 7.634952, 400000 ], [ \"Georgia\", 1985, 7.944011, 420000 ], [ \"Georgia\", 1986, 8.24021, 440000 ], [ \"Georgia\", 1987, 8.527169, 460000 ], [ \"Georgia\", 1988, 8.913406, 485000 ], [ \"Georgia\", 1989, 9.330198, 510000 ], [ \"Georgia\", 1990, 9.890112, 540000 ], [ \"Georgia\", 1991, 10.276, 556800 ], [ \"Georgia\", 1992, 10.71261, 572700 ], [ \"Georgia\", 1993, 10.8665, 570896 ], [ \"Georgia\", 1994, 10.19106, 525596 ], [ \"Georgia\", 1995, 10.93531, 554300 ], [ \"Georgia\", 1996, 11.36656, 567400 ], [ \"Georgia\", 1997, 12.52153, 616517 ], [ \"Georgia\", 1998, 12.9314, 628770 ], [ \"Georgia\", 1999, 13.97896, 671511 ], [ \"Georgia\", 2000, 10.72238, 508750 ], [ \"Georgia\", 2001, 12.14373, 569040 ], [ \"Georgia\", 2002, 13.83504, 640400 ], [ \"Georgia\", 2003, 14.58757, 667120 ], [ \"Georgia\", 2004, 15.12063, 683230 ], [ \"Georgia\", 2005, 12.77174, 570200 ], [ \"Georgia\", 2006, 12.53962, 553105 ], [ \"Georgia\", 2007, 12.76086, 556100 ], [ \"Georgia\", 2008, 14.34935, 618028 ], [ \"Georgia\", 2009, 14.55285, 620000 ], [ \"Germany\", 1960, 4.423532, 3220990 ], [ \"Germany\", 1965, 6.378047, 4845000 ], [ \"Germany\", 1970, 10.98513, 8587000 ], [ \"Germany\", 1975, 16.31298, 12834000 ], [ \"Germany\", 1976, 18.06999, 14212000 ], [ \"Germany\", 1977, 20.03478, 15748000 ], [ \"Germany\", 1978, 22.03584, 17305000 ], [ \"Germany\", 1979, 24.12071, 18917000 ], [ \"Germany\", 1980, 26.09781, 20431600 ], [ \"Germany\", 1981, 27.71094, 21645900 ], [ \"Germany\", 1982, 28.96899, 22571600 ], [ \"Germany\", 1983, 30.08057, 23385600 ], [ \"Germany\", 1984, 31.4486, 24420600 ], [ \"Germany\", 1985, 32.68564, 25391800 ], [ \"Germany\", 1986, 33.63884, 26189300 ], [ \"Germany\", 1987, 34.56015, 27007100 ], [ \"Germany\", 1988, 35.42949, 27823200 ], [ \"Germany\", 1989, 36.52926, 28847800 ], [ \"Germany\", 1990, 40.14325, 31887000 ], [ \"Germany\", 1991, 41.99565, 33559720 ], [ \"Germany\", 1992, 44.05192, 35420840 ], [ \"Germany\", 1993, 45.74533, 37000000 ], [ \"Germany\", 1994, 47.72612, 38800000 ], [ \"Germany\", 1995, 51.45666, 42000000 ], [ \"Germany\", 1996, 53.88676, 44100000 ], [ \"Germany\", 1997, 55.15294, 45200000 ], [ \"Germany\", 1998, 56.74277, 46530000 ], [ \"Germany\", 1999, 58.77104, 48210000 ], [ \"Germany\", 2000, 61.1881, 50220000 ], [ \"Germany\", 2001, 63.7036, 52330000 ], [ \"Germany\", 2002, 65.26641, 53670000 ], [ \"Germany\", 2003, 65.88158, 54233000 ], [ \"Germany\", 2004, 66.18584, 54526000 ], [ \"Germany\", 2005, 66.48692, 54791000 ], [ \"Germany\", 2006, 66.02527, 54400000 ], [ \"Germany\", 2007, 64.48665, 53100000 ], [ \"Germany\", 2008, 62.11689, 51100000 ], [ \"Germany\", 2009, 59.26978, 48700000 ], [ \"Ghana\", 1965, 0.211332, 17300 ], [ \"Ghana\", 1970, 0.2605039, 23400 ], [ \"Ghana\", 1975, 0.3052465, 31259 ], [ \"Ghana\", 1976, 0.323268, 32979 ], [ \"Ghana\", 1977, 0.3260534, 33839 ], [ \"Ghana\", 1978, 0.3353756, 35396 ], [ \"Ghana\", 1979, 0.3382712, 36406 ], [ \"Ghana\", 1980, 0.3418597, 37694 ], [ \"Ghana\", 1981, 0.3267521, 37103 ], [ \"Ghana\", 1982, 0.3164564, 37151 ], [ \"Ghana\", 1983, 0.305319, 37129 ], [ \"Ghana\", 1984, 0.3026622, 38104 ], [ \"Ghana\", 1985, 0.2940234, 38240 ], [ \"Ghana\", 1986, 0.2870532, 38472 ], [ \"Ghana\", 1987, 0.2873166, 39610 ], [ \"Ghana\", 1988, 0.2854842, 40442 ], [ \"Ghana\", 1989, 0.2955441, 43021 ], [ \"Ghana\", 1990, 0.2955936, 44243 ], [ \"Ghana\", 1991, 0.3026564, 46613 ], [ \"Ghana\", 1992, 0.3012774, 47761 ], [ \"Ghana\", 1993, 0.2983607, 48681 ], [ \"Ghana\", 1994, 0.2979713, 50007 ], [ \"Ghana\", 1995, 0.365702, 63067 ], [ \"Ghana\", 1996, 0.4399596, 77886 ], [ \"Ghana\", 1997, 0.5812294, 105534 ], [ \"Ghana\", 1998, 0.7169522, 133426 ], [ \"Ghana\", 1999, 0.8428246, 160698 ], [ \"Ghana\", 2000, 1.088354, 212548 ], [ \"Ghana\", 2001, 1.223209, 244632 ], [ \"Ghana\", 2002, 1.343297, 275039 ], [ \"Ghana\", 2003, 1.388863, 291030 ], [ \"Ghana\", 2004, 1.461732, 313326 ], [ \"Ghana\", 2005, 1.467139, 321526 ], [ \"Ghana\", 2006, 1.591344, 356355 ], [ \"Ghana\", 2007, 1.646231, 376509 ], [ \"Ghana\", 2008, 0.6162496, 143900 ], [ \"Ghana\", 2009, 1.121727, 267389 ], [ \"Gibraltar\", 1960, 9.11077, 1960 ], [ \"Gibraltar\", 1970, 14.61691, 3600 ], [ \"Gibraltar\", 1983, 23.39729, 6500 ], [ \"Gibraltar\", 1984, 25.19526, 7000 ], [ \"Gibraltar\", 1985, 28.10229, 7813 ], [ \"Gibraltar\", 1986, 28.73047, 8000 ], [ \"Gibraltar\", 1987, 30.4594, 8500 ], [ \"Gibraltar\", 1988, 32.80803, 9181 ], [ \"Gibraltar\", 1989, 34.59661, 9713 ], [ \"Gibraltar\", 1990, 38.15575, 10750 ], [ \"Gibraltar\", 1991, 40.79533, 11541 ], [ \"Gibraltar\", 1992, 45.14302, 12831 ], [ \"Gibraltar\", 1993, 47.8305, 13658 ], [ \"Gibraltar\", 1994, 52.86422, 15153 ], [ \"Gibraltar\", 1995, 57.48042, 16517 ], [ \"Gibraltar\", 1996, 60.86533, 17500 ], [ \"Gibraltar\", 1997, 64.85658, 18632 ], [ \"Gibraltar\", 1998, 70.99561, 20380 ], [ \"Gibraltar\", 1999, 76.22427, 21916 ], [ \"Gibraltar\", 2000, 81.44266, 23541 ], [ \"Gibraltar\", 2001, 83.98547, 24512 ], [ \"Gibraltar\", 2002, 83.02168, 24552 ], [ \"Gibraltar\", 2003, 83.31112, 25000 ], [ \"Gibraltar\", 2004, 83.37937, 25354 ], [ \"Gibraltar\", 2005, 81.3961, 25000 ], [ \"Gibraltar\", 2006, 77.65482, 24000 ], [ \"Gibraltar\", 2007, 77.41436, 24000 ], [ \"Gibraltar\", 2008, 77.33952, 24000 ], [ \"Gibraltar\", 2009, 77.30714, 24000 ], [ \"Greece\", 1960, 2.180764, 181734 ], [ \"Greece\", 1965, 4.853232, 415000 ], [ \"Greece\", 1970, 10.08757, 887000 ], [ \"Greece\", 1975, 18.64801, 1687000 ], [ \"Greece\", 1976, 19.73773, 1806000 ], [ \"Greece\", 1977, 20.53773, 1904742 ], [ \"Greece\", 1978, 21.52742, 2025307 ], [ \"Greece\", 1979, 22.61269, 2156046 ], [ \"Greece\", 1980, 23.54581, 2270406 ], [ \"Greece\", 1981, 24.68251, 2401169 ], [ \"Greece\", 1982, 25.87333, 2534413 ], [ \"Greece\", 1983, 27.56277, 2714395 ], [ \"Greece\", 1984, 29.58685, 2926885 ], [ \"Greece\", 1985, 31.37413, 3116798 ], [ \"Greece\", 1986, 33.01051, 3291971 ], [ \"Greece\", 1987, 34.63428, 3465815 ], [ \"Greece\", 1988, 36.02081, 3618065 ], [ \"Greece\", 1989, 37.52984, 3788146 ], [ \"Greece\", 1990, 38.86279, 3948654 ], [ \"Greece\", 1991, 40.88586, 4190087 ], [ \"Greece\", 1992, 43.42906, 4496544 ], [ \"Greece\", 1993, 45.32012, 4744016 ], [ \"Greece\", 1994, 47.04682, 4976205 ], [ \"Greece\", 1995, 48.37624, 5162772 ], [ \"Greece\", 1996, 49.5706, 5328794 ], [ \"Greece\", 1997, 50.22549, 5430855 ], [ \"Greece\", 1998, 50.9556, 5535521 ], [ \"Greece\", 1999, 51.45068, 5610931 ], [ \"Greece\", 2000, 51.71918, 5659274 ], [ \"Greece\", 2001, 51.10101, 5607779 ], [ \"Greece\", 2002, 57.21857, 6293806 ], [ \"Greece\", 2003, 57.16508, 6300432 ], [ \"Greece\", 2004, 57.52756, 6352302 ], [ \"Greece\", 2005, 57.04849, 6311656 ], [ \"Greece\", 2006, 55.65528, 6170455 ], [ \"Greece\", 2007, 49.22227, 5469425 ], [ \"Greece\", 2008, 47.1732, 5253695 ], [ \"Greece\", 2009, 47.01997, 5248056 ], [ \"Greenland\", 1965, 1.479026, 580 ], [ \"Greenland\", 1970, 3.359752, 1560 ], [ \"Greenland\", 1975, 9.424411, 4673 ], [ \"Greenland\", 1976, 10.95731, 5454 ], [ \"Greenland\", 1977, 12.02351, 5993 ], [ \"Greenland\", 1978, 14.26223, 7113 ], [ \"Greenland\", 1979, 16.68435, 8337 ], [ \"Greenland\", 1980, 19.0388, 9559 ], [ \"Greenland\", 1981, 19.95891, 10103 ], [ \"Greenland\", 1982, 20.94764, 10721 ], [ \"Greenland\", 1983, 21.33405, 11060 ], [ \"Greenland\", 1984, 22.40752, 11770 ], [ \"Greenland\", 1985, 23.17906, 12325 ], [ \"Greenland\", 1986, 24.73176, 13300 ], [ \"Greenland\", 1987, 27.10127, 14729 ], [ \"Greenland\", 1988, 28.72534, 15757 ], [ \"Greenland\", 1989, 29.96761, 16561 ], [ \"Greenland\", 1990, 29.89091, 16605 ], [ \"Greenland\", 1991, 30.10502, 16770 ], [ \"Greenland\", 1992, 30.25029, 16860 ], [ \"Greenland\", 1993, 31.52385, 17555 ], [ \"Greenland\", 1994, 33.2099, 18475 ], [ \"Greenland\", 1995, 35.23923, 19599 ], [ \"Greenland\", 1996, 37.93952, 21116 ], [ \"Greenland\", 1997, 41.90915, 23361 ], [ \"Greenland\", 1998, 44.69186, 24968 ], [ \"Greenland\", 1999, 45.72749, 25617 ], [ \"Greenland\", 2000, 46.58694, 26180 ], [ \"Greenland\", 2001, 42.94175, 24217 ], [ \"Greenland\", 2002, 44.73763, 25330 ], [ \"Greenland\", 2003, 44.41552, 25248 ], [ \"Greenland\", 2004, 44.05175, 25128 ], [ \"Greenland\", 2005, 56.21885, 32151 ], [ \"Greenland\", 2006, 62.82387, 35983 ], [ \"Greenland\", 2007, 40.41076, 23159 ], [ \"Greenland\", 2008, 39.81712, 22818 ], [ \"Greenland\", 2009, 38.46758, 22040 ], [ \"Grenada\", 1960, 1.175774, 1053 ], [ \"Grenada\", 1975, 3.30158, 3050 ], [ \"Grenada\", 1980, 3.400465, 3024 ], [ \"Grenada\", 1981, 3.3151, 3000 ], [ \"Grenada\", 1982, 3.225564, 3000 ], [ \"Grenada\", 1983, 3.265098, 3131 ], [ \"Grenada\", 1984, 3.656404, 3596 ], [ \"Grenada\", 1985, 3.911392, 3904 ], [ \"Grenada\", 1986, 4.997701, 5000 ], [ \"Grenada\", 1987, 7.051121, 7000 ], [ \"Grenada\", 1988, 9.187986, 9000 ], [ \"Grenada\", 1989, 12.40169, 12000 ], [ \"Grenada\", 1990, 15.8037, 15200 ], [ \"Grenada\", 1991, 16.81195, 16200 ], [ \"Grenada\", 1992, 19.05625, 18508 ], [ \"Grenada\", 1993, 20.46072, 20100 ], [ \"Grenada\", 1994, 21.13995, 21000 ], [ \"Grenada\", 1995, 23.16178, 23200 ], [ \"Grenada\", 1996, 23.94198, 24100 ], [ \"Grenada\", 1997, 26.25842, 26500 ], [ \"Grenada\", 1998, 27.20649, 27484 ], [ \"Grenada\", 1999, 29.11312, 29429 ], [ \"Grenada\", 2000, 30.98075, 31355 ], [ \"Grenada\", 2001, 32.29719, 32750 ], [ \"Grenada\", 2002, 33.0047, 33544 ], [ \"Grenada\", 2003, 32.03439, 32644 ], [ \"Grenada\", 2004, 32.00286, 32705 ], [ \"Grenada\", 2005, 26.75707, 27426 ], [ \"Grenada\", 2006, 26.94144, 27702 ], [ \"Grenada\", 2007, 27.65366, 28530 ], [ \"Grenada\", 2008, 27.60243, 28579 ], [ \"Grenada\", 2009, 27.51852, 28600 ], [ \"Guam\", 1960, 3.920696, 2644 ], [ \"Guam\", 1965, 6.576035, 4992 ], [ \"Guam\", 1970, 7.939387, 6785 ], [ \"Guam\", 1975, 13.02187, 12420 ], [ \"Guam\", 1976, 11.74305, 11449 ], [ \"Guam\", 1977, 11.85424, 11815 ], [ \"Guam\", 1978, 12.1017, 12332 ], [ \"Guam\", 1979, 21.07981, 21966 ], [ \"Guam\", 1980, 23.48928, 25033 ], [ \"Guam\", 1981, 25.1172, 27378 ], [ \"Guam\", 1982, 26.06176, 29056 ], [ \"Guam\", 1983, 26.78036, 30543 ], [ \"Guam\", 1984, 27.56951, 32175 ], [ \"Guam\", 1985, 27.55809, 32922 ], [ \"Guam\", 1986, 22.40769, 27412 ], [ \"Guam\", 1987, 23.14667, 29000 ], [ \"Guam\", 1988, 24.94932, 32000 ], [ \"Guam\", 1989, 27.10721, 35553 ], [ \"Guam\", 1990, 29.15005, 39036 ], [ \"Guam\", 1991, 31.65124, 43209 ], [ \"Guam\", 1992, 33.30335, 46285 ], [ \"Guam\", 1993, 46.59562, 65841 ], [ \"Guam\", 1994, 44.31219, 63584 ], [ \"Guam\", 1995, 47.54531, 69206 ], [ \"Guam\", 1996, 47.41085, 69922 ], [ \"Guam\", 1997, 47.65241, 71136 ], [ \"Guam\", 1998, 49.68027, 75051 ], [ \"Guam\", 1999, 50.72749, 77609 ], [ \"Guam\", 2000, 47.9314, 74367 ], [ \"Guam\", 2001, 50.76046, 80000 ], [ \"Guam\", 2002, 43.66921, 70000 ], [ \"Guam\", 2003, 40.17251, 65531 ], [ \"Guam\", 2004, 39.47662, 65500 ], [ \"Guam\", 2005, 38.85649, 65500 ], [ \"Guam\", 2006, 38.29693, 65500 ], [ \"Guam\", 2007, 37.7857, 65500 ], [ \"Guam\", 2008, 37.31088, 65500 ], [ \"Guam\", 2009, 36.85614, 65500 ], [ \"Guatemala\", 1960, 0.4305158, 17821 ], [ \"Guatemala\", 1965, 0.5132691, 24306 ], [ \"Guatemala\", 1970, 0.6990333, 37871 ], [ \"Guatemala\", 1975, 0.7671394, 47583 ], [ \"Guatemala\", 1976, 0.8290885, 52770 ], [ \"Guatemala\", 1977, 0.9885753, 64486 ], [ \"Guatemala\", 1978, 1.11087, 74237 ], [ \"Guatemala\", 1979, 1.148391, 78623 ], [ \"Guatemala\", 1980, 1.182704, 82975 ], [ \"Guatemala\", 1981, 1.231813, 88587 ], [ \"Guatemala\", 1982, 1.338199, 98670 ], [ \"Guatemala\", 1983, 1.403862, 106125 ], [ \"Guatemala\", 1984, 1.512033, 117151 ], [ \"Guatemala\", 1985, 1.614934, 128179 ], [ \"Guatemala\", 1986, 1.611626, 130971 ], [ \"Guatemala\", 1987, 1.595684, 132718 ], [ \"Guatemala\", 1988, 1.624166, 138222 ], [ \"Guatemala\", 1989, 1.824175, 158840 ], [ \"Guatemala\", 1990, 2.134853, 190218 ], [ \"Guatemala\", 1991, 2.217458, 202209 ], [ \"Guatemala\", 1992, 2.297117, 214409 ], [ \"Guatemala\", 1993, 2.418762, 231090 ], [ \"Guatemala\", 1994, 2.506449, 245094 ], [ \"Guatemala\", 1995, 2.861616, 286352 ], [ \"Guatemala\", 1996, 3.301735, 338035 ], [ \"Guatemala\", 1997, 4.102719, 429712 ], [ \"Guatemala\", 1998, 4.824545, 517000 ], [ \"Guatemala\", 1999, 5.568212, 610701 ], [ \"Guatemala\", 2000, 6.024832, 676631 ], [ \"Guatemala\", 2001, 6.571141, 756085 ], [ \"Guatemala\", 2002, 7.173272, 845968 ], [ \"Guatemala\", 2003, 7.808647, 944140 ], [ \"Guatemala\", 2004, 9.132266, 1132121 ], [ \"Guatemala\", 2005, 9.820509, 1248161 ], [ \"Guatemala\", 2006, 10.39965, 1354926 ], [ \"Guatemala\", 2007, 10.58649, 1413695 ], [ \"Guatemala\", 2008, 10.58657, 1448891 ], [ \"Guatemala\", 2009, 10.07514, 1413234 ], [ \"Guernsey\", 1965, 24.84076, 11700 ], [ \"Guernsey\", 1970, 28.463, 15000 ], [ \"Guernsey\", 1975, 33.68984, 18900 ], [ \"Guernsey\", 1980, 41.01091, 22556 ], [ \"Guernsey\", 1986, 50.01434, 27908 ], [ \"Guernsey\", 1987, 51.80674, 29219 ], [ \"Guernsey\", 1988, 54.37895, 30996 ], [ \"Guernsey\", 1989, 55.32292, 31866 ], [ \"Guernsey\", 1990, 57.85395, 33671 ], [ \"Guernsey\", 1991, 59.79107, 35199 ], [ \"Guernsey\", 1992, 61.57479, 36637 ], [ \"Guernsey\", 1993, 63.61333, 38168 ], [ \"Guernsey\", 1994, 65.83967, 39833 ], [ \"Guernsey\", 1995, 68.85738, 42003 ], [ \"Guernsey\", 1996, 71.6, 44034 ], [ \"Guernsey\", 1997, 74.03548, 45902 ], [ \"Guernsey\", 1998, 77.58387, 48102 ], [ \"Guernsey\", 1999, 81.1824, 50739 ], [ \"Guernsey\", 2000, 84.65231, 53077 ], [ \"Guernsey\", 2001, 97.73758, 54951 ], [ \"Guernsey\", 2002, 99.49643, 55718 ], [ \"Guernsey\", 2003, 81.86201, 45679 ], [ \"Guernsey\", 2004, 80.88531, 45134 ], [ \"Guernsey\", 2005, 85.07829, 45100 ], [ \"Guernsey\", 2006, 89.80486, 45100 ], [ \"Guinea-Bissau\", 1960, 0.05870272, 325 ], [ \"Guinea-Bissau\", 1981, 0.2170939, 1860 ], [ \"Guinea-Bissau\", 1982, 0.3593417, 3140 ], [ \"Guinea-Bissau\", 1983, 0.4344073, 3860 ], [ \"Guinea-Bissau\", 1984, 0.5470042, 4940 ], [ \"Guinea-Bissau\", 1985, 0.5984734, 5500 ], [ \"Guinea-Bissau\", 1986, 0.5872605, 5500 ], [ \"Guinea-Bissau\", 1987, 0.5756595, 5500 ], [ \"Guinea-Bissau\", 1988, 0.5635771, 5500 ], [ \"Guinea-Bissau\", 1989, 0.5710261, 5700 ], [ \"Guinea-Bissau\", 1990, 0.5824576, 5955 ], [ \"Guinea-Bissau\", 1991, 0.5887563, 6175 ], [ \"Guinea-Bissau\", 1992, 0.5963414, 6425 ], [ \"Guinea-Bissau\", 1993, 0.6019505, 6665 ], [ \"Guinea-Bissau\", 1994, 0.6099089, 6935 ], [ \"Guinea-Bissau\", 1995, 0.6314811, 7363 ], [ \"Guinea-Bissau\", 1996, 0.6640243, 7926 ], [ \"Guinea-Bissau\", 1997, 0.6254886, 7633 ], [ \"Guinea-Bissau\", 1998, 0.6479471, 8079 ], [ \"Guinea-Bissau\", 1999, 0.4784997, 6098 ], [ \"Guinea-Bissau\", 2000, 0.8531458, 11123 ], [ \"Guinea-Bissau\", 2001, 0.7415085, 9901 ], [ \"Guinea-Bissau\", 2002, 0.8181754, 11197 ], [ \"Guinea-Bissau\", 2003, 0.7525061, 10558 ], [ \"Guinea-Bissau\", 2004, 0.6758975, 9719 ], [ \"Guinea-Bissau\", 2005, 0.6528473, 9614 ], [ \"Guinea-Bissau\", 2006, 0.4501943, 6784 ], [ \"Guinea-Bissau\", 2007, 0.2968125, 4574 ], [ \"Guinea-Bissau\", 2008, 0.2949641, 4647 ], [ \"Guinea-Bissau\", 2009, 0.3007302, 4844 ], [ \"Guinea\", 1960, 0.06323584, 2054 ], [ \"Guinea\", 1970, 0.117279, 4700 ], [ \"Guinea\", 1976, 0.1600086, 6600 ], [ \"Guinea\", 1977, 0.1557695, 6600 ], [ \"Guinea\", 1981, 0.2184028, 10380 ], [ \"Guinea\", 1982, 0.237535, 11580 ], [ \"Guinea\", 1983, 0.2610729, 13050 ], [ \"Guinea\", 1984, 0.2852955, 14630 ], [ \"Guinea\", 1985, 0.2754041, 14506 ], [ \"Guinea\", 1986, 0.2402311, 13007 ], [ \"Guinea\", 1987, 0.2174836, 12112 ], [ \"Guinea\", 1988, 0.1742789, 10000 ], [ \"Guinea\", 1989, 0.1864227, 11053 ], [ \"Guinea\", 1990, 0.1838279, 11300 ], [ \"Guinea\", 1991, 0.1806312, 11553 ], [ \"Guinea\", 1992, 0.1617288, 10788 ], [ \"Guinea\", 1993, 0.1664763, 11579 ], [ \"Guinea\", 1994, 0.1287468, 9308 ], [ \"Guinea\", 1995, 0.1451508, 10855 ], [ \"Guinea\", 1996, 0.2105637, 16206 ], [ \"Guinea\", 1997, 0.2508277, 19786 ], [ \"Guinea\", 1998, 0.1887437, 15213 ], [ \"Guinea\", 1999, 0.2561758, 21064 ], [ \"Guinea\", 2000, 0.2899844, 24311 ], [ \"Guinea\", 2001, 0.2983041, 25490 ], [ \"Guinea\", 2002, 0.2985191, 25989 ], [ \"Guinea\", 2003, 0.2949845, 26165 ], [ \"Guinea\", 2004, 0.2898058, 26200 ], [ \"Guinea\", 2005, 0.2711271, 25000 ], [ \"Guinea\", 2006, 0.244372, 23000 ], [ \"Guinea\", 2007, 0.2288074, 22000 ], [ \"Guinea\", 2008, 0.2135654, 21000 ], [ \"Guinea\", 2009, 0.2184984, 22000 ], [ \"Guyana\", 1960, 0.9363236, 5323 ], [ \"Guyana\", 1965, 0.9457364, 6100 ], [ \"Guyana\", 1970, 1.029069, 7300 ], [ \"Guyana\", 1975, 1.934916, 14200 ], [ \"Guyana\", 1976, 2.062509, 15300 ], [ \"Guyana\", 1981, 2.085114, 16243 ], [ \"Guyana\", 1982, 2.117043, 16500 ], [ \"Guyana\", 1983, 2.185964, 17000 ], [ \"Guyana\", 1984, 2.259158, 17500 ], [ \"Guyana\", 1985, 2.335194, 18000 ], [ \"Guyana\", 1986, 2.610213, 20000 ], [ \"Guyana\", 1987, 2.102795, 16000 ], [ \"Guyana\", 1988, 2.117393, 16000 ], [ \"Guyana\", 1989, 2.129038, 16000 ], [ \"Guyana\", 1990, 2.135646, 16000 ], [ \"Guyana\", 1991, 2.135831, 16000 ], [ \"Guyana\", 1992, 3.777717, 28373 ], [ \"Guyana\", 1993, 5.474785, 41287 ], [ \"Guyana\", 1994, 5.820494, 44063 ], [ \"Guyana\", 1995, 5.879268, 44615 ], [ \"Guyana\", 1996, 6.610436, 50190 ], [ \"Guyana\", 1997, 7.264779, 55108 ], [ \"Guyana\", 1998, 7.910759, 59910 ], [ \"Guyana\", 1999, 8.466052, 64034 ], [ \"Guyana\", 2000, 9.04452, 68400 ], [ \"Guyana\", 2001, 10.5541, 79913 ], [ \"Guyana\", 2002, 10.60061, 80441 ], [ \"Guyana\", 2003, 12.13538, 92332 ], [ \"Guyana\", 2004, 13.46456, 102688 ], [ \"Guyana\", 2005, 14.41884, 110136 ], [ \"Guyana\", 2006, 15.43951, 118000 ], [ \"Guyana\", 2007, 16.8033, 128394 ], [ \"Guyana\", 2008, 17.47479, 133409 ], [ \"Guyana\", 2009, 18.29815, 139523 ], [ \"Haiti\", 1981, 0.3436061, 20000 ], [ \"Haiti\", 1982, 0.4029078, 24000 ], [ \"Haiti\", 1983, 0.4263926, 26000 ], [ \"Haiti\", 1984, 0.4486454, 28000 ], [ \"Haiti\", 1985, 0.4855246, 31000 ], [ \"Haiti\", 1986, 0.5207958, 34000 ], [ \"Haiti\", 1987, 0.5545434, 37000 ], [ \"Haiti\", 1988, 0.5868372, 40000 ], [ \"Haiti\", 1989, 0.6062101, 42200 ], [ \"Haiti\", 1990, 0.6330983, 45000 ], [ \"Haiti\", 1991, 0.62033, 45010 ], [ \"Haiti\", 1992, 0.6078568, 45010 ], [ \"Haiti\", 1993, 0.5957729, 45010 ], [ \"Haiti\", 1994, 0.6487757, 50000 ], [ \"Haiti\", 1995, 0.7632884, 60000 ], [ \"Haiti\", 1996, 0.7484253, 60000 ], [ \"Haiti\", 1997, 0.733964, 60000 ], [ \"Haiti\", 1998, 0.779983, 65000 ], [ \"Haiti\", 1999, 0.8243489, 70000 ], [ \"Haiti\", 2000, 0.8383563, 72500 ], [ \"Haiti\", 2001, 0.9088862, 80000 ], [ \"Haiti\", 2002, 1.451829, 130000 ], [ \"Haiti\", 2003, 1.537534, 140000 ], [ \"Haiti\", 2004, 1.512353, 140000 ], [ \"Haiti\", 2005, 1.544104, 145300 ], [ \"Haiti\", 2006, 1.568308, 150000 ], [ \"Haiti\", 2007, 1.114599, 108340 ], [ \"Haiti\", 2008, 1.093516, 108000 ], [ \"Haiti\", 2009, 1.079479, 108300 ], [ \"Honduras\", 1975, 0.5637577, 17003 ], [ \"Honduras\", 1976, 0.5349675, 17140 ], [ \"Honduras\", 1977, 0.5378523, 17781 ], [ \"Honduras\", 1978, 0.591311, 20177 ], [ \"Honduras\", 1979, 0.764538, 26927 ], [ \"Honduras\", 1980, 0.7963723, 28944 ], [ \"Honduras\", 1981, 0.8392845, 31468 ], [ \"Honduras\", 1982, 0.8525201, 32965 ], [ \"Honduras\", 1983, 0.8870552, 35365 ], [ \"Honduras\", 1984, 1.048658, 43097 ], [ \"Honduras\", 1985, 1.083709, 45903 ], [ \"Honduras\", 1986, 1.148465, 50126 ], [ \"Honduras\", 1987, 1.206818, 54258 ], [ \"Honduras\", 1988, 1.435939, 66476 ], [ \"Honduras\", 1989, 1.651511, 78689 ], [ \"Honduras\", 1990, 1.796253, 88038 ], [ \"Honduras\", 1991, 1.874002, 94432 ], [ \"Honduras\", 1992, 2.023043, 104751 ], [ \"Honduras\", 1993, 2.202987, 117123 ], [ \"Honduras\", 1994, 2.405317, 131176 ], [ \"Honduras\", 1995, 2.877936, 160819 ], [ \"Honduras\", 1996, 3.326181, 190236 ], [ \"Honduras\", 1997, 3.994358, 233593 ], [ \"Honduras\", 1998, 4.175571, 249497 ], [ \"Honduras\", 1999, 4.575444, 279197 ], [ \"Honduras\", 2000, 4.794766, 298713 ], [ \"Honduras\", 2001, 4.870174, 309702 ], [ \"Honduras\", 2002, 4.969474, 322497 ], [ \"Honduras\", 2003, 5.050096, 334400 ], [ \"Honduras\", 2004, 5.732958, 387314 ], [ \"Honduras\", 2005, 7.16237, 493680 ], [ \"Honduras\", 2006, 10.16917, 715106 ], [ \"Honduras\", 2007, 11.44731, 821245 ], [ \"Honduras\", 2008, 11.28286, 825769 ], [ \"Honduras\", 2009, 9.594631, 716335 ], [ \"Hong Kong, China\", 1960, 2.57374, 79145 ], [ \"Hong Kong, China\", 1970, 12.00022, 473000 ], [ \"Hong Kong, China\", 1975, 19.04144, 837023 ], [ \"Hong Kong, China\", 1976, 20.12963, 909679 ], [ \"Hong Kong, China\", 1977, 21.36439, 993882 ], [ \"Hong Kong, China\", 1978, 22.60559, 1082408 ], [ \"Hong Kong, China\", 1979, 23.83606, 1172530 ], [ \"Hong Kong, China\", 1980, 25.38187, 1278866 ], [ \"Hong Kong, China\", 1981, 26.89467, 1383667 ], [ \"Hong Kong, China\", 1982, 28.19079, 1476960 ], [ \"Hong Kong, China\", 1983, 29.56567, 1573420 ], [ \"Hong Kong, China\", 1984, 30.85801, 1664372 ], [ \"Hong Kong, China\", 1985, 32.33637, 1764338 ], [ \"Hong Kong, China\", 1986, 34.08351, 1877322 ], [ \"Hong Kong, China\", 1987, 36.41906, 2021394 ], [ \"Hong Kong, China\", 1988, 39.1881, 2190997 ], [ \"Hong Kong, China\", 1989, 41.58226, 2345236 ], [ \"Hong Kong, China\", 1990, 43.3868, 2474998 ], [ \"Hong Kong, China\", 1991, 45.65919, 2642414 ], [ \"Hong Kong, China\", 1992, 47.90992, 2819797 ], [ \"Hong Kong, China\", 1993, 49.91378, 2992056 ], [ \"Hong Kong, China\", 1994, 51.57776, 3149280 ], [ \"Hong Kong, China\", 1995, 52.75109, 3277854 ], [ \"Hong Kong, China\", 1996, 54.63129, 3451241 ], [ \"Hong Kong, China\", 1997, 56.82491, 3646516 ], [ \"Hong Kong, China\", 1998, 57.28061, 3729191 ], [ \"Hong Kong, China\", 1999, 58.66938, 3868794 ], [ \"Hong Kong, China\", 2000, 58.88714, 3925843 ], [ \"Hong Kong, China\", 2001, 57.94181, 3897558 ], [ \"Hong Kong, China\", 2002, 56.55897, 3831829 ], [ \"Hong Kong, China\", 2003, 55.85929, 3806444 ], [ \"Hong Kong, China\", 2004, 54.94641, 3763350 ], [ \"Hong Kong, China\", 2005, 55.10782, 3792912 ], [ \"Hong Kong, China\", 2006, 55.46817, 3835936 ], [ \"Hong Kong, China\", 2007, 60.58175, 4209125 ], [ \"Hong Kong, China\", 2008, 59.90898, 4183017 ], [ \"Hong Kong, China\", 2009, 60.91204, 4277297 ], [ \"Hungary\", 1960, 2.4379, 243400 ], [ \"Hungary\", 1965, 2.991776, 303753 ], [ \"Hungary\", 1970, 3.860548, 399065 ], [ \"Hungary\", 1975, 4.823696, 508023 ], [ \"Hungary\", 1976, 4.888439, 517000 ], [ \"Hungary\", 1977, 4.924107, 523000 ], [ \"Hungary\", 1978, 4.998867, 533000 ], [ \"Hungary\", 1979, 5.246548, 561000 ], [ \"Hungary\", 1980, 5.764199, 617200 ], [ \"Hungary\", 1981, 5.946667, 636600 ], [ \"Hungary\", 1982, 6.130406, 655200 ], [ \"Hungary\", 1983, 6.346395, 676400 ], [ \"Hungary\", 1984, 6.641837, 705400 ], [ \"Hungary\", 1985, 6.983585, 738800 ], [ \"Hungary\", 1986, 7.310832, 770100 ], [ \"Hungary\", 1987, 7.751266, 812700 ], [ \"Hungary\", 1988, 8.222805, 858200 ], [ \"Hungary\", 1989, 8.810461, 915900 ], [ \"Hungary\", 1990, 9.607857, 995839 ], [ \"Hungary\", 1991, 10.90298, 1128129 ], [ \"Hungary\", 1992, 12.48614, 1291133 ], [ \"Hungary\", 1993, 14.48265, 1497577 ], [ \"Hungary\", 1994, 17.15842, 1774100 ], [ \"Hungary\", 1995, 20.8782, 2157202 ], [ \"Hungary\", 1996, 25.69662, 2651215 ], [ \"Hungary\", 1997, 30.06232, 3095300 ], [ \"Hungary\", 1998, 33.32841, 3423000 ], [ \"Hungary\", 1999, 36.37503, 3725779 ], [ \"Hungary\", 2000, 37.18398, 3798254 ], [ \"Hungary\", 2001, 36.73518, 3742152 ], [ \"Hungary\", 2002, 36.11984, 3669200 ], [ \"Hungary\", 2003, 35.56605, 3602912 ], [ \"Hungary\", 2004, 35.2765, 3564000 ], [ \"Hungary\", 2005, 33.89441, 3415715 ], [ \"Hungary\", 2006, 33.42323, 3360371 ], [ \"Hungary\", 2007, 32.40139, 3250635 ], [ \"Hungary\", 2008, 30.90222, 3093996 ], [ \"Hungary\", 2009, 30.70938, 3068685 ], [ \"Iceland\", 1960, 18.75021, 33000 ], [ \"Iceland\", 1965, 23.62812, 45366 ], [ \"Iceland\", 1970, 28.21789, 57593 ], [ \"Iceland\", 1975, 34.62811, 75500 ], [ \"Iceland\", 1976, 33.55126, 73900 ], [ \"Iceland\", 1977, 33.65761, 74800 ], [ \"Iceland\", 1978, 34.67264, 77700 ], [ \"Iceland\", 1979, 35.70401, 80700 ], [ \"Iceland\", 1980, 37.18312, 84837 ], [ \"Iceland\", 1981, 38.11306, 87867 ], [ \"Iceland\", 1982, 39.11964, 91200 ], [ \"Iceland\", 1983, 39.82727, 93937 ], [ \"Iceland\", 1984, 40.74949, 97245 ], [ \"Iceland\", 1985, 42.52604, 102657 ], [ \"Iceland\", 1986, 46.29961, 113028 ], [ \"Iceland\", 1987, 47.55019, 117371 ], [ \"Iceland\", 1988, 48.75283, 121650 ], [ \"Iceland\", 1989, 49.62209, 125136 ], [ \"Iceland\", 1990, 51.20706, 130472 ], [ \"Iceland\", 1991, 52.67291, 135559 ], [ \"Iceland\", 1992, 53.88253, 140031 ], [ \"Iceland\", 1993, 54.72739, 143597 ], [ \"Iceland\", 1994, 55.99302, 148330 ], [ \"Iceland\", 1995, 55.58401, 148675 ], [ \"Iceland\", 1996, 58.04399, 156807 ], [ \"Iceland\", 1997, 60.5964, 165390 ], [ \"Iceland\", 1998, 62.98114, 173673 ], [ \"Iceland\", 1999, 66.42069, 184973 ], [ \"Iceland\", 2000, 69.84933, 196336 ], [ \"Iceland\", 2001, 69.33648, 196528 ], [ \"Iceland\", 2002, 65.81307, 187999 ], [ \"Iceland\", 2003, 66.83025, 192552 ], [ \"Iceland\", 2004, 65.37436, 190478 ], [ \"Iceland\", 2005, 65.54989, 193852 ], [ \"Iceland\", 2006, 62.56823, 188575 ], [ \"Iceland\", 2007, 60.57974, 186668 ], [ \"Iceland\", 2008, 61.34085, 193512 ], [ \"Iceland\", 2009, 57.39639, 185213 ], [ \"India\", 1960, 0.07514489, 332399 ], [ \"India\", 1965, 0.1258984, 623394 ], [ \"India\", 1970, 0.1768493, 981356 ], [ \"India\", 1975, 0.2360904, 1465415 ], [ \"India\", 1976, 0.2554569, 1613644 ], [ \"India\", 1977, 0.2671438, 1726746 ], [ \"India\", 1978, 0.2823685, 1867828 ], [ \"India\", 1979, 0.2978257, 2016066 ], [ \"India\", 1980, 0.3103313, 2149470 ], [ \"India\", 1981, 0.3239579, 2295530 ], [ \"India\", 1982, 0.3402895, 2466364 ], [ \"India\", 1983, 0.3599821, 2668240 ], [ \"India\", 1984, 0.3823644, 2897862 ], [ \"India\", 1985, 0.4085335, 3165214 ], [ \"India\", 1986, 0.4404614, 3487908 ], [ \"India\", 1987, 0.4697435, 3800986 ], [ \"India\", 1988, 0.5049724, 4174278 ], [ \"India\", 1989, 0.5435055, 4588832 ], [ \"India\", 1990, 0.5886059, 5074734 ], [ \"India\", 1991, 0.6600626, 5809929 ], [ \"India\", 1992, 0.7565306, 6796748 ], [ \"India\", 1993, 0.8754938, 8025586 ], [ \"India\", 1994, 1.047669, 9795304 ], [ \"India\", 1995, 1.256678, 11978000 ], [ \"India\", 1996, 1.497375, 14542650 ], [ \"India\", 1997, 1.799697, 17801700 ], [ \"India\", 1998, 2.144366, 21593690 ], [ \"India\", 1999, 2.58698, 26511340 ], [ \"India\", 2000, 3.111111, 32436130 ], [ \"India\", 2001, 3.634218, 38536190 ], [ \"India\", 2002, 3.841906, 41420000 ], [ \"India\", 2003, 3.832932, 42000000 ], [ \"India\", 2004, 4.149709, 46198020 ], [ \"India\", 2005, 4.437973, 50176510 ], [ \"India\", 2006, 3.552181, 40770000 ], [ \"India\", 2007, 3.370052, 39250000 ], [ \"India\", 2008, 3.208026, 37900000 ], [ \"India\", 2009, 3.093481, 37060000 ], [ \"Indonesia\", 1960, 0.08637658, 82862 ], [ \"Indonesia\", 1965, 0.1135592, 121000 ], [ \"Indonesia\", 1970, 0.1192303, 143000 ], [ \"Indonesia\", 1975, 0.1543961, 207500 ], [ \"Indonesia\", 1976, 0.1633372, 219400 ], [ \"Indonesia\", 1977, 0.1754727, 241000 ], [ \"Indonesia\", 1978, 0.1959532, 275100 ], [ \"Indonesia\", 1979, 0.221022, 317100 ], [ \"Indonesia\", 1980, 0.2563752, 375800 ], [ \"Indonesia\", 1981, 0.285311, 427185 ], [ \"Indonesia\", 1982, 0.3109751, 475459 ], [ \"Indonesia\", 1983, 0.3224622, 503253 ], [ \"Indonesia\", 1984, 0.3366992, 536102 ], [ \"Indonesia\", 1985, 0.3710285, 602356 ], [ \"Indonesia\", 1986, 0.4093955, 677279 ], [ \"Indonesia\", 1987, 0.4505688, 759127 ], [ \"Indonesia\", 1988, 0.4833015, 828812 ], [ \"Indonesia\", 1989, 0.4951441, 863814 ], [ \"Indonesia\", 1990, 0.6010774, 1066222 ], [ \"Indonesia\", 1991, 0.7183591, 1295002 ], [ \"Indonesia\", 1992, 0.9023505, 1652378 ], [ \"Indonesia\", 1993, 1.002481, 1863947 ], [ \"Indonesia\", 1994, 1.304986, 2462831 ], [ \"Indonesia\", 1995, 1.71845, 3290854 ], [ \"Indonesia\", 1996, 2.154816, 4186030 ], [ \"Indonesia\", 1997, 2.528994, 4982466 ], [ \"Indonesia\", 1998, 2.789172, 5571644 ], [ \"Indonesia\", 1999, 3.002372, 6080193 ], [ \"Indonesia\", 2000, 3.245614, 6662605 ], [ \"Indonesia\", 2001, 3.469583, 7218938 ], [ \"Indonesia\", 2002, 3.675472, 7750035 ], [ \"Indonesia\", 2003, 3.771556, 8058139 ], [ \"Indonesia\", 2004, 4.794043, 10376380 ], [ \"Indonesia\", 2005, 6.162042, 13507830 ], [ \"Indonesia\", 2006, 6.677399, 14820730 ], [ \"Indonesia\", 2007, 8.692546, 19529510 ], [ \"Indonesia\", 2008, 13.3621, 30378070 ], [ \"Indonesia\", 2009, 14.76657, 33957890 ], [ \"Iran (Islamic Rep. of)\", 1960, 0.5363929, 116417 ], [ \"Iran (Islamic Rep. of)\", 1965, 0.8036699, 200000 ], [ \"Iran (Islamic Rep. of)\", 1970, 0.9894162, 285000 ], [ \"Iran (Islamic Rep. of)\", 1975, 2.05437, 685000 ], [ \"Iran (Islamic Rep. of)\", 1976, 2.368567, 814000 ], [ \"Iran (Islamic Rep. of)\", 1977, 2.342328, 830000 ], [ \"Iran (Islamic Rep. of)\", 1978, 2.325416, 850800 ], [ \"Iran (Islamic Rep. of)\", 1979, 2.251743, 852840 ], [ \"Iran (Islamic Rep. of)\", 1980, 2.326806, 915122 ], [ \"Iran (Islamic Rep. of)\", 1981, 2.502356, 1025043 ], [ \"Iran (Islamic Rep. of)\", 1982, 2.469643, 1055757 ], [ \"Iran (Islamic Rep. of)\", 1983, 2.510763, 1120670 ], [ \"Iran (Islamic Rep. of)\", 1984, 2.582865, 1202166 ], [ \"Iran (Islamic Rep. of)\", 1985, 2.723472, 1318638 ], [ \"Iran (Islamic Rep. of)\", 1986, 2.946268, 1480235 ], [ \"Iran (Islamic Rep. of)\", 1987, 3.193856, 1661228 ], [ \"Iran (Islamic Rep. of)\", 1988, 3.500037, 1879682 ], [ \"Iran (Islamic Rep. of)\", 1989, 3.670167, 2029038 ], [ \"Iran (Islamic Rep. of)\", 1990, 3.876541, 2199285 ], [ \"Iran (Islamic Rep. of)\", 1991, 4.232941, 2456437 ], [ \"Iran (Islamic Rep. of)\", 1992, 5.065198, 2997852 ], [ \"Iran (Islamic Rep. of)\", 1993, 5.97344, 3597900 ], [ \"Iran (Islamic Rep. of)\", 1994, 7.055813, 4319900 ], [ \"Iran (Islamic Rep. of)\", 1995, 8.183252, 5090363 ], [ \"Iran (Islamic Rep. of)\", 1996, 9.218641, 5824968 ], [ \"Iran (Islamic Rep. of)\", 1997, 10.13589, 6503466 ], [ \"Iran (Islamic Rep. of)\", 1998, 11.29446, 7354992 ], [ \"Iran (Islamic Rep. of)\", 1999, 12.67626, 8371167 ], [ \"Iran (Islamic Rep. of)\", 2000, 14.17915, 9486260 ], [ \"Iran (Islamic Rep. of)\", 2001, 16.09246, 10896570 ], [ \"Iran (Islamic Rep. of)\", 2002, 18.81943, 12887530 ], [ \"Iran (Islamic Rep. of)\", 2003, 22.16018, 15340810 ], [ \"Iran (Islamic Rep. of)\", 2004, 23.3519, 16342050 ], [ \"Iran (Islamic Rep. of)\", 2005, 28.74165, 20339000 ], [ \"Iran (Islamic Rep. of)\", 2006, 31.60859, 22626940 ], [ \"Iran (Islamic Rep. of)\", 2007, 32.90462, 23835000 ], [ \"Iran (Islamic Rep. of)\", 2008, 33.82812, 24800000 ], [ \"Iran (Islamic Rep. of)\", 2009, 34.77841, 25804100 ], [ \"Iraq\", 1970, 0.9098311, 92000 ], [ \"Iraq\", 1980, 1.782684, 250000 ], [ \"Iraq\", 1981, 1.904378, 275000 ], [ \"Iraq\", 1982, 2.018548, 300000 ], [ \"Iraq\", 1983, 2.129467, 325446 ], [ \"Iraq\", 1984, 2.484893, 390000 ], [ \"Iraq\", 1985, 2.920438, 470000 ], [ \"Iraq\", 1986, 3.398886, 560000 ], [ \"Iraq\", 1987, 4.000172, 673965 ], [ \"Iraq\", 1988, 3.934697, 677809 ], [ \"Iraq\", 1989, 3.828368, 675000 ], [ \"Iraq\", 1990, 3.938784, 712109 ], [ \"Iraq\", 1991, 3.606268, 669830 ], [ \"Iraq\", 1992, 3.73787, 714389 ], [ \"Iraq\", 1993, 3.454031, 680210 ], [ \"Iraq\", 1994, 3.195834, 649207 ], [ \"Iraq\", 1995, 3.045068, 638593 ], [ \"Iraq\", 1996, 2.95262, 639699 ], [ \"Iraq\", 1997, 2.905373, 650616 ], [ \"Iraq\", 1998, 2.808372, 649963 ], [ \"Iraq\", 1999, 2.824183, 675000 ], [ \"Iraq\", 2000, 2.738077, 675000 ], [ \"Iraq\", 2001, 2.657734, 675000 ], [ \"Iraq\", 2002, 4.316901, 1128300 ], [ \"Iraq\", 2003, 4.405129, 1183300 ], [ \"Iraq\", 2004, 3.752196, 1034240 ], [ \"Iraq\", 2005, 3.948624, 1115000 ], [ \"Iraq\", 2006, 4.320221, 1247512 ], [ \"Iraq\", 2007, 4.627681, 1364512 ], [ \"Iraq\", 2008, 3.596129, 1082300 ], [ \"Iraq\", 2009, 3.604857, 1108396 ], [ \"Ireland\", 1960, 3.903497, 110625 ], [ \"Ireland\", 1965, 5.737163, 165000 ], [ \"Ireland\", 1970, 7.922254, 234000 ], [ \"Ireland\", 1975, 10.38629, 330000 ], [ \"Ireland\", 1976, 11.06813, 357000 ], [ \"Ireland\", 1977, 11.79541, 386000 ], [ \"Ireland\", 1978, 12.41844, 412000 ], [ \"Ireland\", 1979, 12.9737, 436000 ], [ \"Ireland\", 1980, 14.20171, 483000 ], [ \"Ireland\", 1981, 15.58613, 536000 ], [ \"Ireland\", 1982, 16.68418, 579600 ], [ \"Ireland\", 1983, 17.50808, 613459 ], [ \"Ireland\", 1984, 18.98088, 669267 ], [ \"Ireland\", 1985, 19.86521, 703000 ], [ \"Ireland\", 1986, 21.201, 750805 ], [ \"Ireland\", 1987, 22.52218, 796204 ], [ \"Ireland\", 1988, 23.90681, 842677 ], [ \"Ireland\", 1989, 26.04892, 916000 ], [ \"Ireland\", 1990, 27.9687, 983000 ], [ \"Ireland\", 1991, 29.76113, 1048000 ], [ \"Ireland\", 1992, 31.47682, 1113000 ], [ \"Ireland\", 1993, 32.8935, 1170000 ], [ \"Ireland\", 1994, 34.61939, 1240000 ], [ \"Ireland\", 1995, 36.29965, 1310000 ], [ \"Ireland\", 1996, 38.21287, 1390000 ], [ \"Ireland\", 1997, 42.46334, 1558000 ], [ \"Ireland\", 1998, 44.06928, 1633000 ], [ \"Ireland\", 1999, 46.32201, 1737000 ], [ \"Ireland\", 2000, 48.16209, 1832000 ], [ \"Ireland\", 2001, 48.08736, 1860000 ], [ \"Ireland\", 2002, 50.11522, 1975000 ], [ \"Ireland\", 2003, 48.6264, 1955000 ], [ \"Ireland\", 2004, 49.1059, 2015000 ], [ \"Ireland\", 2005, 49.00753, 2052000 ], [ \"Ireland\", 2006, 50.96314, 2176646 ], [ \"Ireland\", 2007, 51.86437, 2258626 ], [ \"Ireland\", 2008, 49.62836, 2201995 ], [ \"Ireland\", 2009, 46.05229, 2079468 ], [ \"Israel\", 1960, 3.06577, 64811 ], [ \"Israel\", 1965, 6.711776, 172000 ], [ \"Israel\", 1970, 12.73381, 369000 ], [ \"Israel\", 1975, 17.77711, 597000 ], [ \"Israel\", 1976, 18.62163, 641800 ], [ \"Israel\", 1977, 19.42579, 686000 ], [ \"Israel\", 1978, 20.22958, 730800 ], [ \"Israel\", 1979, 21.31457, 786500 ], [ \"Israel\", 1980, 22.83535, 859500 ], [ \"Israel\", 1981, 24.05246, 922400 ], [ \"Israel\", 1982, 25.03745, 977400 ], [ \"Israel\", 1983, 26.19871, 1040300 ], [ \"Israel\", 1984, 26.90306, 1086000 ], [ \"Israel\", 1985, 28.76224, 1180000 ], [ \"Israel\", 1986, 30.78867, 1283000 ], [ \"Israel\", 1987, 32.91572, 1393000 ], [ \"Israel\", 1988, 34.1892, 1471900 ], [ \"Israel\", 1989, 34.8793, 1533584 ], [ \"Israel\", 1990, 36.03361, 1626449 ], [ \"Israel\", 1991, 36.56029, 1703457 ], [ \"Israel\", 1992, 37.35233, 1804000 ], [ \"Israel\", 1993, 39.04778, 1958100 ], [ \"Israel\", 1994, 41.11655, 2137900 ], [ \"Israel\", 1995, 43.59251, 2342618 ], [ \"Israel\", 1996, 45.88116, 2539117 ], [ \"Israel\", 1997, 47.07364, 2675000 ], [ \"Israel\", 1998, 48.21991, 2807000 ], [ \"Israel\", 1999, 48.33645, 2878000 ], [ \"Israel\", 2000, 48.88083, 2974000 ], [ \"Israel\", 2001, 48.83124, 3033000 ], [ \"Israel\", 2002, 47.45853, 3006000 ], [ \"Israel\", 2003, 45.13579, 2913000 ], [ \"Israel\", 2004, 44.06136, 2896000 ], [ \"Israel\", 2005, 43.88046, 2936295 ], [ \"Israel\", 2006, 44.11285, 3004653 ], [ \"Israel\", 2007, 44.35691, 3074602 ], [ \"Israel\", 2008, 45.72154, 3224000 ], [ \"Israel\", 2009, 45.33056, 3250000 ], [ \"Italy\", 1960, 6.090963, 3057645 ], [ \"Italy\", 1965, 8.711946, 4540000 ], [ \"Italy\", 1970, 12.00442, 6461000 ], [ \"Italy\", 1975, 17.42392, 9660000 ], [ \"Italy\", 1976, 18.33347, 10166000 ], [ \"Italy\", 1977, 19.34841, 10778000 ], [ \"Italy\", 1978, 20.48296, 11456000 ], [ \"Italy\", 1979, 21.68575, 12172000 ], [ \"Italy\", 1980, 23.11779, 13017000 ], [ \"Italy\", 1981, 24.54586, 13860000 ], [ \"Italy\", 1982, 25.96612, 14697780 ], [ \"Italy\", 1983, 27.5053, 15601030 ], [ \"Italy\", 1984, 29.07909, 16520760 ], [ \"Italy\", 1985, 30.5824, 17396110 ], [ \"Italy\", 1986, 32.06354, 18252970 ], [ \"Italy\", 1987, 33.54619, 19104830 ], [ \"Italy\", 1988, 35.27158, 20091530 ], [ \"Italy\", 1989, 37.32426, 21265520 ], [ \"Italy\", 1990, 39.2121, 22350000 ], [ \"Italy\", 1991, 40.44722, 23071000 ], [ \"Italy\", 1992, 41.52242, 23709000 ], [ \"Italy\", 1993, 42.27915, 24167000 ], [ \"Italy\", 1994, 42.90491, 24542000 ], [ \"Italy\", 1995, 43.43012, 24845000 ], [ \"Italy\", 1996, 44.18338, 25259000 ], [ \"Italy\", 1997, 45.00585, 25698000 ], [ \"Italy\", 1998, 45.56086, 25986120 ], [ \"Italy\", 1999, 46.47032, 26502000 ], [ \"Italy\", 2000, 47.54012, 27153000 ], [ \"Italy\", 2001, 47.73119, 27353000 ], [ \"Italy\", 2002, 47.13321, 27142000 ], [ \"Italy\", 2003, 45.91276, 26596000 ], [ \"Italy\", 2004, 44.53025, 25957000 ], [ \"Italy\", 2005, 42.71311, 25049000 ], [ \"Italy\", 2006, 45.59082, 26890340 ], [ \"Italy\", 2007, 37.79968, 22417000 ], [ \"Italy\", 2008, 36.97589, 22039000 ], [ \"Italy\", 2009, 36.24345, 21699000 ], [ \"Jamaica\", 1960, 1.22357, 19932 ], [ \"Jamaica\", 1965, 1.493943, 26300 ], [ \"Jamaica\", 1970, 1.872657, 35000 ], [ \"Jamaica\", 1975, 2.469198, 49700 ], [ \"Jamaica\", 1976, 2.498074, 50900 ], [ \"Jamaica\", 1977, 2.597016, 53500 ], [ \"Jamaica\", 1978, 2.569661, 53500 ], [ \"Jamaica\", 1979, 2.514205, 52945 ], [ \"Jamaica\", 1980, 2.465124, 52586 ], [ \"Jamaica\", 1981, 2.596006, 56204 ], [ \"Jamaica\", 1982, 2.749371, 60493 ], [ \"Jamaica\", 1983, 2.871613, 64213 ], [ \"Jamaica\", 1984, 2.948758, 66901 ], [ \"Jamaica\", 1985, 3.340284, 76678 ], [ \"Jamaica\", 1986, 3.512347, 81322 ], [ \"Jamaica\", 1987, 3.508113, 81713 ], [ \"Jamaica\", 1988, 3.640439, 85179 ], [ \"Jamaica\", 1989, 3.790279, 89091 ], [ \"Jamaica\", 1990, 4.453705, 105285 ], [ \"Jamaica\", 1991, 5.525671, 131566 ], [ \"Jamaica\", 1992, 6.966609, 167251 ], [ \"Jamaica\", 1993, 8.606319, 208480 ], [ \"Jamaica\", 1994, 10.2487, 250531 ], [ \"Jamaica\", 1995, 11.77044, 290262 ], [ \"Jamaica\", 1996, 14.36693, 357262 ], [ \"Jamaica\", 1997, 16.57863, 415610 ], [ \"Jamaica\", 1998, 18.31604, 462824 ], [ \"Jamaica\", 1999, 19.1331, 487325 ], [ \"Jamaica\", 2000, 19.22135, 493523 ], [ \"Jamaica\", 2001, 19.7517, 511302 ], [ \"Jamaica\", 2002, 16.65833, 434772 ], [ \"Jamaica\", 2003, 17.43502, 458675 ], [ \"Jamaica\", 2004, 15.96091, 423000 ], [ \"Jamaica\", 2005, 11.95796, 319000 ], [ \"Jamaica\", 2006, 12.77345, 342692 ], [ \"Jamaica\", 2007, 13.71136, 369656 ], [ \"Jamaica\", 2008, 11.69239, 316591 ], [ \"Jamaica\", 2009, 11.12458, 302451 ], [ \"Japan\", 1960, 3.860885, 3632938 ], [ \"Japan\", 1965, 7.482732, 7399000 ], [ \"Japan\", 1970, 15.72208, 16403000 ], [ \"Japan\", 1975, 29.03142, 32377000 ], [ \"Japan\", 1976, 30.52939, 34444000 ], [ \"Japan\", 1977, 31.46023, 35837000 ], [ \"Japan\", 1978, 32.38461, 37214000 ], [ \"Japan\", 1979, 33.32442, 38611000 ], [ \"Japan\", 1980, 34.19177, 39934000 ], [ \"Japan\", 1981, 34.21507, 40275770 ], [ \"Japan\", 1982, 34.98956, 41500870 ], [ \"Japan\", 1983, 35.89438, 42879290 ], [ \"Japan\", 1984, 36.5612, 43958540 ], [ \"Japan\", 1985, 37.46623, 45299760 ], [ \"Japan\", 1986, 38.50296, 46771990 ], [ \"Japan\", 1987, 39.70368, 48419270 ], [ \"Japan\", 1988, 41.13817, 50339600 ], [ \"Japan\", 1989, 42.72536, 52453640 ], [ \"Japan\", 1990, 44.26292, 54527950 ], [ \"Japan\", 1991, 45.50082, 56259920 ], [ \"Japan\", 1992, 46.4477, 57652440 ], [ \"Japan\", 1993, 47.21437, 58830080 ], [ \"Japan\", 1994, 48.53284, 60690000 ], [ \"Japan\", 1995, 49.65804, 62292000 ], [ \"Japan\", 1996, 50.91503, 64037000 ], [ \"Japan\", 1997, 52.15021, 65735000 ], [ \"Japan\", 1998, 49.42234, 62413290 ], [ \"Japan\", 1999, 49.05418, 62053580 ], [ \"Japan\", 2000, 48.8984, 61957100 ], [ \"Japan\", 2001, 48.32329, 61325780 ], [ \"Japan\", 2002, 47.81567, 60772460 ], [ \"Japan\", 2003, 47.31868, 60219000 ], [ \"Japan\", 2004, 46.79388, 59608000 ], [ \"Japan\", 2005, 45.55011, 58053000 ], [ \"Japan\", 2006, 43.96124, 56029000 ], [ \"Japan\", 2007, 40.21712, 51235000 ], [ \"Japan\", 2008, 37.17484, 47321000 ], [ \"Japan\", 2009, 34.08327, 43339000 ], [ \"Jersey\", 1965, 24.64, 15400 ], [ \"Jersey\", 1970, 30.21148, 20000 ], [ \"Jersey\", 1975, 34.90028, 24500 ], [ \"Jersey\", 1976, 36.0472, 25600 ], [ \"Jersey\", 1977, 37.5, 27000 ], [ \"Jersey\", 1978, 39.31507, 28700 ], [ \"Jersey\", 1979, 40.81081, 30200 ], [ \"Jersey\", 1980, 42, 31500 ], [ \"Jersey\", 1981, 42.99803, 32700 ], [ \"Jersey\", 1982, 44.08323, 33900 ], [ \"Jersey\", 1983, 45.3166, 35211 ], [ \"Jersey\", 1984, 46.53376, 36529 ], [ \"Jersey\", 1985, 47.91814, 38047 ], [ \"Jersey\", 1986, 49.66214, 39835 ], [ \"Jersey\", 1987, 51.93958, 42123 ], [ \"Jersey\", 1988, 54.2442, 44426 ], [ \"Jersey\", 1989, 57.53843, 47647 ], [ \"Jersey\", 1990, 59.93405, 49985 ], [ \"Jersey\", 1991, 61.7314, 51905 ], [ \"Jersey\", 1992, 63.26297, 53647 ], [ \"Jersey\", 1993, 64.95205, 55534 ], [ \"Jersey\", 1994, 67.52209, 58069 ], [ \"Jersey\", 1995, 68.8827, 59308 ], [ \"Jersey\", 1996, 73.39154, 64473 ], [ \"Jersey\", 1997, 73.03916, 65465 ], [ \"Jersey\", 1998, 79.9444, 68721 ], [ \"Jersey\", 1999, 81.46347, 70360 ], [ \"Jersey\", 2000, 84.1127, 72993 ], [ \"Jersey\", 2001, 84.79458, 73929 ], [ \"Jersey\", 2002, 84.47488, 74000 ], [ \"Jersey\", 2003, 84.09091, 74000 ], [ \"Jersey\", 2004, 84.09091, 74000 ], [ \"Jersey\", 2005, 84.09091, 74000 ], [ \"Jersey\", 2006, 84.09091, 74000 ], [ \"Jersey\", 2007, 84.09091, 74000 ], [ \"Jordan\", 1960, 1.295172, 11606 ], [ \"Jordan\", 1970, 1.109199, 18000 ], [ \"Jordan\", 1977, 2.009877, 41012 ], [ \"Jordan\", 1978, 2.12493, 44508 ], [ \"Jordan\", 1979, 2.4293, 52356 ], [ \"Jordan\", 1980, 2.720279, 60533 ], [ \"Jordan\", 1981, 3.104562, 71641 ], [ \"Jordan\", 1982, 3.583657, 86074 ], [ \"Jordan\", 1983, 3.994208, 100000 ], [ \"Jordan\", 1984, 4.36089, 113666 ], [ \"Jordan\", 1985, 5.46378, 147873 ], [ \"Jordan\", 1986, 5.573548, 156024 ], [ \"Jordan\", 1987, 7.030523, 203059 ], [ \"Jordan\", 1988, 7.469436, 222908 ], [ \"Jordan\", 1989, 7.679597, 238292 ], [ \"Jordan\", 1990, 7.553217, 245782 ], [ \"Jordan\", 1991, 7.701605, 265211 ], [ \"Jordan\", 1992, 7.593132, 278265 ], [ \"Jordan\", 1993, 7.441421, 290086 ], [ \"Jordan\", 1994, 7.688739, 316593 ], [ \"Jordan\", 1995, 7.365315, 317007 ], [ \"Jordan\", 1996, 7.763741, 345527 ], [ \"Jordan\", 1997, 8.859158, 404333 ], [ \"Jordan\", 1998, 10.9699, 510875 ], [ \"Jordan\", 1999, 11.90354, 565273 ], [ \"Jordan\", 2000, 12.77466, 620000 ], [ \"Jordan\", 2001, 13.27254, 660000 ], [ \"Jordan\", 2002, 13.21853, 674511 ], [ \"Jordan\", 2003, 11.8699, 622572 ], [ \"Jordan\", 2004, 11.81222, 637811 ], [ \"Jordan\", 2005, 11.28298, 628000 ], [ \"Jordan\", 2006, 10.68414, 614000 ], [ \"Jordan\", 2007, 9.409904, 559000 ], [ \"Jordan\", 2008, 8.458695, 518990 ], [ \"Jordan\", 2009, 7.935461, 501238 ], [ \"Kazakhstan\", 1975, 3.324843, 470000 ], [ \"Kazakhstan\", 1976, 3.679566, 526360 ], [ \"Kazakhstan\", 1977, 3.872411, 560000 ], [ \"Kazakhstan\", 1978, 4.038106, 590000 ], [ \"Kazakhstan\", 1979, 4.200113, 620000 ], [ \"Kazakhstan\", 1980, 4.423892, 660000 ], [ \"Kazakhstan\", 1981, 4.624781, 697518 ], [ \"Kazakhstan\", 1982, 4.932689, 752159 ], [ \"Kazakhstan\", 1983, 5.259803, 811033 ], [ \"Kazakhstan\", 1984, 5.502868, 858278 ], [ \"Kazakhstan\", 1985, 5.762566, 909333 ], [ \"Kazakhstan\", 1986, 6.012351, 960314 ], [ \"Kazakhstan\", 1987, 6.332362, 1023811 ], [ \"Kazakhstan\", 1988, 6.846054, 1118939 ], [ \"Kazakhstan\", 1989, 7.440198, 1225536 ], [ \"Kazakhstan\", 1990, 8.066873, 1333454 ], [ \"Kazakhstan\", 1991, 8.63057, 1425213 ], [ \"Kazakhstan\", 1992, 9.070504, 1490384 ], [ \"Kazakhstan\", 1993, 12.12609, 1975840 ], [ \"Kazakhstan\", 1994, 12.326, 1987001 ], [ \"Kazakhstan\", 1995, 12.32547, 1962940 ], [ \"Kazakhstan\", 1996, 12.19892, 1916592 ], [ \"Kazakhstan\", 1997, 11.66185, 1805330 ], [ \"Kazakhstan\", 1998, 11.63493, 1775382 ], [ \"Kazakhstan\", 1999, 11.67172, 1759769 ], [ \"Kazakhstan\", 2000, 12.26353, 1834226 ], [ \"Kazakhstan\", 2001, 13.01005, 1939628 ], [ \"Kazakhstan\", 2002, 13.94654, 2081858 ], [ \"Kazakhstan\", 2003, 14.85908, 2228400 ], [ \"Kazakhstan\", 2004, 16.89627, 2550000 ], [ \"Kazakhstan\", 2005, 17.8229, 2708000 ], [ \"Kazakhstan\", 2006, 19.14218, 2928400 ], [ \"Kazakhstan\", 2007, 21.0077, 3236900 ], [ \"Kazakhstan\", 2008, 22.28162, 3458440 ], [ \"Kazakhstan\", 2009, 24.66268, 3856500 ], [ \"Kenya\", 1965, 0.2939803, 28000 ], [ \"Kenya\", 1970, 0.3459594, 39000 ], [ \"Kenya\", 1975, 0.3922421, 53000 ], [ \"Kenya\", 1976, 0.4074073, 57000 ], [ \"Kenya\", 1977, 0.4296911, 62400 ], [ \"Kenya\", 1978, 0.4331295, 65300 ], [ \"Kenya\", 1979, 0.4452041, 69700 ], [ \"Kenya\", 1980, 0.454448, 73900 ], [ \"Kenya\", 1981, 0.4747261, 80200 ], [ \"Kenya\", 1982, 0.5019419, 88100 ], [ \"Kenya\", 1983, 0.5248892, 95700 ], [ \"Kenya\", 1984, 0.5604266, 106100 ], [ \"Kenya\", 1985, 0.6024202, 118361 ], [ \"Kenya\", 1986, 0.6352879, 129453 ], [ \"Kenya\", 1987, 0.6510687, 137505 ], [ \"Kenya\", 1988, 0.6946486, 151964 ], [ \"Kenya\", 1989, 0.719257, 162894 ], [ \"Kenya\", 1990, 0.7470117, 175050 ], [ \"Kenya\", 1991, 0.8252519, 200000 ], [ \"Kenya\", 1992, 0.8281099, 207442 ], [ \"Kenya\", 1993, 0.8301228, 214759 ], [ \"Kenya\", 1994, 0.8563053, 228522 ], [ \"Kenya\", 1995, 0.9327558, 256434 ], [ \"Kenya\", 1996, 0.9432396, 266780 ], [ \"Kenya\", 1997, 0.9352115, 271816 ], [ \"Kenya\", 1998, 0.9658597, 288251 ], [ \"Kenya\", 1999, 0.9466928, 290000 ], [ \"Kenya\", 2000, 0.9277993, 291706 ], [ \"Kenya\", 2001, 0.9587381, 309379 ], [ \"Kenya\", 2002, 0.9706939, 321482 ], [ \"Kenya\", 2003, 0.9659973, 328358 ], [ \"Kenya\", 2004, 0.8577009, 299255 ], [ \"Kenya\", 2005, 0.8005437, 286729 ], [ \"Kenya\", 2006, 0.7978002, 293364 ], [ \"Kenya\", 2007, 1.228366, 463766 ], [ \"Kenya\", 2008, 1.667357, 646356 ], [ \"Kenya\", 2009, 1.668506, 664099 ], [ \"Kiribati\", 1979, 0.9089717, 485 ], [ \"Kiribati\", 1982, 0.8114434, 468 ], [ \"Kiribati\", 1983, 0.8661152, 513 ], [ \"Kiribati\", 1984, 0.9856101, 600 ], [ \"Kiribati\", 1985, 1.068246, 669 ], [ \"Kiribati\", 1986, 1.240349, 800 ], [ \"Kiribati\", 1987, 1.369162, 910 ], [ \"Kiribati\", 1988, 1.461475, 1000 ], [ \"Kiribati\", 1989, 1.565859, 1100 ], [ \"Kiribati\", 1990, 1.670262, 1200 ], [ \"Kiribati\", 1991, 1.738346, 1272 ], [ \"Kiribati\", 1992, 1.849907, 1374 ], [ \"Kiribati\", 1993, 2.329971, 1753 ], [ \"Kiribati\", 1994, 2.523622, 1923 ], [ \"Kiribati\", 1995, 2.621054, 2025 ], [ \"Kiribati\", 1996, 2.692435, 2112 ], [ \"Kiribati\", 1997, 3.119473, 2487 ], [ \"Kiribati\", 1998, 3.455122, 2802 ], [ \"Kiribati\", 1999, 3.734083, 3082 ], [ \"Kiribati\", 2000, 3.990574, 3353 ], [ \"Kiribati\", 2001, 4.24015, 3628 ], [ \"Kiribati\", 2002, 5.133029, 4474 ], [ \"Kiribati\", 2003, 4.955569, 4400 ], [ \"Kiribati\", 2004, 4.756006, 4300 ], [ \"Kiribati\", 2005, 4.565019, 4200 ], [ \"Kiribati\", 2006, 4.275606, 4000 ], [ \"Kiribati\", 2007, 4.207515, 4000 ], [ \"Kiribati\", 2008, 4.142588, 4000 ], [ \"Kiribati\", 2009, 4.079759, 4000 ], [ \"Korea (Rep. of)\", 1965, 0.7733491, 220635 ], [ \"Korea (Rep. of)\", 1970, 1.507423, 481207 ], [ \"Korea (Rep. of)\", 1975, 2.999002, 1058075 ], [ \"Korea (Rep. of)\", 1976, 3.600146, 1270837 ], [ \"Korea (Rep. of)\", 1977, 4.288724, 1537139 ], [ \"Korea (Rep. of)\", 1978, 5.167717, 1879263 ], [ \"Korea (Rep. of)\", 1979, 6.213477, 2292686 ], [ \"Korea (Rep. of)\", 1980, 7.219836, 2704504 ], [ \"Korea (Rep. of)\", 1981, 8.575651, 3263322 ], [ \"Korea (Rep. of)\", 1982, 10.54936, 4079590 ], [ \"Korea (Rep. of)\", 1983, 12.23914, 4809897 ], [ \"Korea (Rep. of)\", 1984, 14.01694, 5594973 ], [ \"Korea (Rep. of)\", 1985, 16.09045, 6517395 ], [ \"Korea (Rep. of)\", 1986, 18.31457, 7520699 ], [ \"Korea (Rep. of)\", 1987, 20.73616, 8625496 ], [ \"Korea (Rep. of)\", 1988, 24.48185, 10306030 ], [ \"Korea (Rep. of)\", 1989, 27.70629, 11791670 ], [ \"Korea (Rep. of)\", 1990, 30.88778, 13276450 ], [ \"Korea (Rep. of)\", 1991, 33.60761, 14572590 ], [ \"Korea (Rep. of)\", 1992, 35.6852, 15593450 ], [ \"Korea (Rep. of)\", 1993, 37.91475, 16686060 ], [ \"Korea (Rep. of)\", 1994, 39.81477, 17646610 ], [ \"Korea (Rep. of)\", 1995, 41.65666, 18600200 ], [ \"Korea (Rep. of)\", 1996, 43.55211, 19600950 ], [ \"Korea (Rep. of)\", 1997, 45.00322, 20421910 ], [ \"Korea (Rep. of)\", 1998, 43.90487, 20088540 ], [ \"Korea (Rep. of)\", 1999, 55.56019, 25619000 ], [ \"Korea (Rep. of)\", 2000, 55.70403, 25863000 ], [ \"Korea (Rep. of)\", 2001, 55.18502, 25775000 ], [ \"Korea (Rep. of)\", 2002, 54.81567, 25735040 ], [ \"Korea (Rep. of)\", 2003, 53.27741, 25127610 ], [ \"Korea (Rep. of)\", 2004, 49.75623, 23567740 ], [ \"Korea (Rep. of)\", 2005, 50.25635, 23905150 ], [ \"Korea (Rep. of)\", 2006, 46.96113, 22431480 ], [ \"Korea (Rep. of)\", 2007, 47.96846, 23006670 ], [ \"Korea (Rep. of)\", 2008, 48.5756, 23390260 ], [ \"Korea (Rep. of)\", 2009, 53.68908, 25949440 ], [ \"Kuwait\", 1960, 1.192892, 3316 ], [ \"Kuwait\", 1965, 2.76266, 13000 ], [ \"Kuwait\", 1970, 5.105736, 38000 ], [ \"Kuwait\", 1975, 8.84205, 89000 ], [ \"Kuwait\", 1976, 9.593782, 103000 ], [ \"Kuwait\", 1977, 9.938711, 114000 ], [ \"Kuwait\", 1978, 10.2931, 126000 ], [ \"Kuwait\", 1979, 10.68415, 139000 ], [ \"Kuwait\", 1980, 11.41881, 157000 ], [ \"Kuwait\", 1981, 11.79957, 170213 ], [ \"Kuwait\", 1982, 12.73604, 191605 ], [ \"Kuwait\", 1983, 13.02131, 203969 ], [ \"Kuwait\", 1984, 12.84361, 210226 ], [ \"Kuwait\", 1985, 12.89899, 221882 ], [ \"Kuwait\", 1986, 12.91384, 235447 ], [ \"Kuwait\", 1987, 13.13015, 254826 ], [ \"Kuwait\", 1988, 13.73696, 281771 ], [ \"Kuwait\", 1989, 14.62815, 310837 ], [ \"Kuwait\", 1990, 15.46455, 331406 ], [ \"Kuwait\", 1991, 15.37061, 321909 ], [ \"Kuwait\", 1992, 17.35618, 345583 ], [ \"Kuwait\", 1993, 19.18064, 357996 ], [ \"Kuwait\", 1994, 21.09628, 372719 ], [ \"Kuwait\", 1995, 22.16155, 382287 ], [ \"Kuwait\", 1996, 22.35224, 391841 ], [ \"Kuwait\", 1997, 22.37755, 411629 ], [ \"Kuwait\", 1998, 21.73755, 427288 ], [ \"Kuwait\", 1999, 21.67139, 455643 ], [ \"Kuwait\", 2000, 20.96008, 467067 ], [ \"Kuwait\", 2001, 20.19993, 472414 ], [ \"Kuwait\", 2002, 19.75554, 481891 ], [ \"Kuwait\", 2003, 19.23824, 486904 ], [ \"Kuwait\", 2004, 18.99026, 496973 ], [ \"Kuwait\", 2005, 18.69665, 504806 ], [ \"Kuwait\", 2006, 18.60566, 516982 ], [ \"Kuwait\", 2007, 18.55414, 529000 ], [ \"Kuwait\", 2008, 18.53305, 541000 ], [ \"Kuwait\", 2009, 18.54243, 553500 ], [ \"Kyrgyzstan\", 1975, 2.335496, 77048 ], [ \"Kyrgyzstan\", 1976, 2.676213, 90000 ], [ \"Kyrgyzstan\", 1977, 2.918306, 100000 ], [ \"Kyrgyzstan\", 1978, 3.29405, 115000 ], [ \"Kyrgyzstan\", 1979, 3.653951, 130000 ], [ \"Kyrgyzstan\", 1980, 4.032007, 146261 ], [ \"Kyrgyzstan\", 1981, 4.298286, 159050 ], [ \"Kyrgyzstan\", 1982, 4.533493, 171174 ], [ \"Kyrgyzstan\", 1983, 4.704252, 181279 ], [ \"Kyrgyzstan\", 1984, 5.010422, 197060 ], [ \"Kyrgyzstan\", 1985, 5.330786, 213951 ], [ \"Kyrgyzstan\", 1986, 5.76932, 236304 ], [ \"Kyrgyzstan\", 1987, 6.211556, 259611 ], [ \"Kyrgyzstan\", 1988, 6.353835, 270694 ], [ \"Kyrgyzstan\", 1989, 6.644459, 287912 ], [ \"Kyrgyzstan\", 1990, 7.146475, 314052 ], [ \"Kyrgyzstan\", 1991, 7.468959, 331776 ], [ \"Kyrgyzstan\", 1992, 7.563695, 338699 ], [ \"Kyrgyzstan\", 1993, 8.148125, 367400 ], [ \"Kyrgyzstan\", 1994, 7.456788, 338899 ], [ \"Kyrgyzstan\", 1995, 7.774162, 357000 ], [ \"Kyrgyzstan\", 1996, 7.349269, 342023 ], [ \"Kyrgyzstan\", 1997, 7.422757, 350900 ], [ \"Kyrgyzstan\", 1998, 7.664221, 368430 ], [ \"Kyrgyzstan\", 1999, 7.587339, 370636 ], [ \"Kyrgyzstan\", 2000, 7.590361, 376092 ], [ \"Kyrgyzstan\", 2001, 7.741088, 388222 ], [ \"Kyrgyzstan\", 2002, 7.789605, 394770 ], [ \"Kyrgyzstan\", 2003, 7.74264, 396168 ], [ \"Kyrgyzstan\", 2004, 8.060035, 416430 ], [ \"Kyrgyzstan\", 2005, 8.434377, 440383 ], [ \"Kyrgyzstan\", 2006, 8.688222, 458876 ], [ \"Kyrgyzstan\", 2007, 9.015993, 482005 ], [ \"Kyrgyzstan\", 2008, 9.134381, 494503 ], [ \"Kyrgyzstan\", 2009, 9.089928, 498328 ], [ \"Lao P.D.R.\", 1960, 0.03380655, 736 ], [ \"Lao P.D.R.\", 1965, 0.04111337, 1000 ], [ \"Lao P.D.R.\", 1970, 0.04055147, 1100 ], [ \"Lao P.D.R.\", 1975, 0.1785538, 5400 ], [ \"Lao P.D.R.\", 1976, 0.1842327, 5700 ], [ \"Lao P.D.R.\", 1977, 0.1822866, 5700 ], [ \"Lao P.D.R.\", 1978, 0.1742857, 5500 ], [ \"Lao P.D.R.\", 1979, 0.1724033, 5500 ], [ \"Lao P.D.R.\", 1980, 0.169883, 5500 ], [ \"Lao P.D.R.\", 1981, 0.1666647, 5500 ], [ \"Lao P.D.R.\", 1982, 0.15996, 5400 ], [ \"Lao P.D.R.\", 1983, 0.1617208, 5600 ], [ \"Lao P.D.R.\", 1984, 0.1630612, 5800 ], [ \"Lao P.D.R.\", 1985, 0.1630712, 5961 ], [ \"Lao P.D.R.\", 1986, 0.1623248, 6100 ], [ \"Lao P.D.R.\", 1987, 0.1612185, 6231 ], [ \"Lao P.D.R.\", 1988, 0.1626813, 6468 ], [ \"Lao P.D.R.\", 1989, 0.1531793, 6265 ], [ \"Lao P.D.R.\", 1990, 0.164266, 6910 ], [ \"Lao P.D.R.\", 1991, 0.1680025, 7266 ], [ \"Lao P.D.R.\", 1992, 0.1914749, 8510 ], [ \"Lao P.D.R.\", 1993, 0.1883483, 8598 ], [ \"Lao P.D.R.\", 1994, 0.386777, 18126 ], [ \"Lao P.D.R.\", 1995, 0.3452527, 16602 ], [ \"Lao P.D.R.\", 1996, 0.394734, 19468 ], [ \"Lao P.D.R.\", 1997, 0.4856647, 24553 ], [ \"Lao P.D.R.\", 1998, 0.5499545, 28472 ], [ \"Lao P.D.R.\", 1999, 0.6631837, 35107 ], [ \"Lao P.D.R.\", 2000, 0.756506, 40876 ], [ \"Lao P.D.R.\", 2001, 0.9560092, 52625 ], [ \"Lao P.D.R.\", 2002, 1.105709, 61910 ], [ \"Lao P.D.R.\", 2003, 1.225986, 69760 ], [ \"Lao P.D.R.\", 2004, 1.297014, 75000 ], [ \"Lao P.D.R.\", 2005, 1.544351, 90806 ], [ \"Lao P.D.R.\", 2006, 1.540098, 92151 ], [ \"Lao P.D.R.\", 2007, 1.556514, 94828 ], [ \"Lao P.D.R.\", 2008, 2.0595, 127799 ], [ \"Lao P.D.R.\", 2009, 2.09163, 132200 ], [ \"Latvia\", 1975, 10.17861, 250000 ], [ \"Latvia\", 1976, 11.33661, 280000 ], [ \"Latvia\", 1977, 13.29953, 330000 ], [ \"Latvia\", 1978, 14.45052, 360000 ], [ \"Latvia\", 1979, 15.59328, 390000 ], [ \"Latvia\", 1980, 16.32349, 410000 ], [ \"Latvia\", 1981, 18.63053, 470000 ], [ \"Latvia\", 1982, 18.94379, 480000 ], [ \"Latvia\", 1983, 19.24553, 490000 ], [ \"Latvia\", 1984, 19.91512, 510000 ], [ \"Latvia\", 1985, 20.55161, 530000 ], [ \"Latvia\", 1986, 21.14249, 550000 ], [ \"Latvia\", 1987, 21.69742, 570000 ], [ \"Latvia\", 1988, 22.03463, 584000 ], [ \"Latvia\", 1989, 22.52199, 600000 ], [ \"Latvia\", 1990, 23.2806, 620000 ], [ \"Latvia\", 1991, 24.30775, 643042 ], [ \"Latvia\", 1992, 24.96789, 652466 ], [ \"Latvia\", 1993, 26.99446, 694296 ], [ \"Latvia\", 1994, 26.37225, 667124 ], [ \"Latvia\", 1995, 28.27051, 704504 ], [ \"Latvia\", 1996, 30.03802, 739200 ], [ \"Latvia\", 1997, 30.39581, 740114 ], [ \"Latvia\", 1998, 30.76146, 742298 ], [ \"Latvia\", 1999, 30.56674, 731527 ], [ \"Latvia\", 2000, 30.95047, 734693 ], [ \"Latvia\", 2001, 30.65046, 721752 ], [ \"Latvia\", 2002, 30.00398, 701211 ], [ \"Latvia\", 2003, 28.17557, 653853 ], [ \"Latvia\", 2004, 28.21178, 650455 ], [ \"Latvia\", 2005, 31.89732, 731094 ], [ \"Latvia\", 2006, 28.83472, 657380 ], [ \"Latvia\", 2007, 28.38651, 644043 ], [ \"Latvia\", 2008, 28.51078, 644000 ], [ \"Latvia\", 2009, 28.63034, 644000 ], [ \"Lebanon\", 1982, 11.33074, 320000 ], [ \"Lebanon\", 1983, 11.51968, 328400 ], [ \"Lebanon\", 1984, 11.72778, 337100 ], [ \"Lebanon\", 1985, 11.96742, 346000 ], [ \"Lebanon\", 1986, 12.25185, 355100 ], [ \"Lebanon\", 1987, 12.57213, 364500 ], [ \"Lebanon\", 1988, 12.88256, 374100 ], [ \"Lebanon\", 1989, 13.12399, 384000 ], [ \"Lebanon\", 1990, 13.25007, 394100 ], [ \"Lebanon\", 1991, 13.24632, 404500 ], [ \"Lebanon\", 1992, 13.14339, 415200 ], [ \"Lebanon\", 1993, 12.99914, 426100 ], [ \"Lebanon\", 1994, 12.88936, 437300 ], [ \"Lebanon\", 1995, 12.85686, 448800 ], [ \"Lebanon\", 1996, 12.91159, 460579 ], [ \"Lebanon\", 1997, 15.49008, 561651 ], [ \"Lebanon\", 1998, 15.40851, 566000 ], [ \"Lebanon\", 1999, 15.35079, 571000 ], [ \"Lebanon\", 2000, 15.26927, 576000 ], [ \"Lebanon\", 2001, 16.33191, 626000 ], [ \"Lebanon\", 2002, 17.41233, 678840 ], [ \"Lebanon\", 2003, 17.65261, 700000 ], [ \"Lebanon\", 2004, 15.64157, 630000 ], [ \"Lebanon\", 2005, 15.55128, 634740 ], [ \"Lebanon\", 2006, 16.51474, 681381 ], [ \"Lebanon\", 2007, 16.75792, 697540 ], [ \"Lebanon\", 2008, 17.88372, 750000 ], [ \"Lebanon\", 2009, 19.02995, 803740 ], [ \"Lesotho\", 1960, 0.04698001, 400 ], [ \"Lesotho\", 1965, 0.1285566, 1200 ], [ \"Lesotho\", 1970, 0.1261989, 1300 ], [ \"Lesotho\", 1975, 0.1674226, 1917 ], [ \"Lesotho\", 1976, 0.1658125, 1950 ], [ \"Lesotho\", 1977, 0.1677509, 2019 ], [ \"Lesotho\", 1978, 0.2101457, 2590 ], [ \"Lesotho\", 1979, 0.2442247, 3085 ], [ \"Lesotho\", 1980, 0.2659238, 3446 ], [ \"Lesotho\", 1981, 0.3358945, 4470 ], [ \"Lesotho\", 1982, 0.3561293, 4870 ], [ \"Lesotho\", 1983, 0.3702114, 5200 ], [ \"Lesotho\", 1984, 0.3754103, 5407 ], [ \"Lesotho\", 1985, 0.4994454, 7358 ], [ \"Lesotho\", 1986, 0.5942163, 8931 ], [ \"Lesotho\", 1987, 0.6728855, 10295 ], [ \"Lesotho\", 1988, 0.7367857, 11456 ], [ \"Lesotho\", 1989, 0.7745633, 12228 ], [ \"Lesotho\", 1990, 0.7711861, 12357 ], [ \"Lesotho\", 1991, 0.7550715, 12275 ], [ \"Lesotho\", 1992, 0.6902596, 11380 ], [ \"Lesotho\", 1993, 0.874331, 14621 ], [ \"Lesotho\", 1994, 0.9254967, 15712 ], [ \"Lesotho\", 1995, 1.030998, 17792 ], [ \"Lesotho\", 1996, 0.9092777, 15975 ], [ \"Lesotho\", 1997, 1.139224, 20400 ], [ \"Lesotho\", 1998, 1.150436, 21000 ], [ \"Lesotho\", 1999, 1.162176, 21600 ], [ \"Lesotho\", 2000, 1.175524, 22200 ], [ \"Lesotho\", 2001, 1.116782, 21382 ], [ \"Lesotho\", 2002, 1.476382, 28603 ], [ \"Lesotho\", 2003, 1.793072, 35101 ], [ \"Lesotho\", 2004, 1.883599, 37230 ], [ \"Lesotho\", 2005, 2.404019, 47964 ], [ \"Lesotho\", 2006, 2.638829, 53136 ], [ \"Lesotho\", 2007, 2.342007, 47582 ], [ \"Lesotho\", 2008, 2.009828, 41190 ], [ \"Lesotho\", 2009, 1.935248, 40000 ], [ \"Liberia\", 1981, 0.3538583, 7000 ], [ \"Liberia\", 1982, 0.3414954, 7000 ], [ \"Liberia\", 1983, 0.3304498, 7000 ], [ \"Liberia\", 1984, 0.3351299, 7290 ], [ \"Liberia\", 1985, 0.3720724, 8240 ], [ \"Liberia\", 1986, 0.3592607, 8037 ], [ \"Liberia\", 1987, 0.357983, 8037 ], [ \"Liberia\", 1988, 0.3843449, 8597 ], [ \"Liberia\", 1989, 0.395759, 8748 ], [ \"Liberia\", 1990, 0.4328808, 9380 ], [ \"Liberia\", 1991, 0.1570684, 3300 ], [ \"Liberia\", 1992, 0.2229235, 4500 ], [ \"Liberia\", 1993, 0.23139, 4500 ], [ \"Liberia\", 1994, 0.2352698, 4500 ], [ \"Liberia\", 1995, 0.2313904, 4500 ], [ \"Liberia\", 1996, 0.2191736, 4500 ], [ \"Liberia\", 1997, 0.2860224, 6371 ], [ \"Liberia\", 1998, 0.2664602, 6500 ], [ \"Liberia\", 1999, 0.2492321, 6600 ], [ \"Liberia\", 2000, 0.2372163, 6700 ], [ \"Liberia\", 2001, 0.2299231, 6800 ], [ \"Liberia\", 2002, 0.2257218, 6900 ], [ \"Liberia\", 2007, 0.05646096, 2048 ], [ \"Liberia\", 2008, 0.05272315, 2000 ], [ \"Liberia\", 2009, 0.05056917, 2000 ], [ \"Libya\", 1960, 0.6246831, 8427 ], [ \"Libya\", 1981, 2.777043, 89300 ], [ \"Libya\", 1982, 2.951548, 99750 ], [ \"Libya\", 1983, 3.140936, 111400 ], [ \"Libya\", 1984, 3.355317, 124350 ], [ \"Libya\", 1985, 3.607979, 138900 ], [ \"Libya\", 1986, 3.899425, 155000 ], [ \"Libya\", 1987, 4.238612, 173100 ], [ \"Libya\", 1988, 4.766926, 199300 ], [ \"Libya\", 1989, 5.051789, 215850 ], [ \"Libya\", 1990, 5.04056, 220000 ], [ \"Libya\", 1991, 5.226685, 232980 ], [ \"Libya\", 1992, 5.181973, 235803 ], [ \"Libya\", 1993, 5.167934, 240000 ], [ \"Libya\", 1994, 5.571384, 264000 ], [ \"Libya\", 1995, 6.578181, 318000 ], [ \"Libya\", 1996, 7.705379, 380000 ], [ \"Libya\", 1997, 7.949963, 400000 ], [ \"Libya\", 1998, 9.739238, 500000 ], [ \"Libya\", 1999, 10.4985, 550000 ], [ \"Libya\", 2000, 11.31608, 605000 ], [ \"Libya\", 2001, 12.09559, 660000 ], [ \"Libya\", 2002, 12.92785, 720000 ], [ \"Libya\", 2003, 13.19305, 750000 ], [ \"Libya\", 2004, 13.77807, 799500 ], [ \"Libya\", 2005, 14.39008, 852300 ], [ \"Libya\", 2006, 15.03714, 909000 ], [ \"Libya\", 2007, 15.70758, 969000 ], [ \"Libya\", 2008, 16.41198, 1033000 ], [ \"Libya\", 2009, 17.14506, 1100700 ], [ \"Liechtenstein\", 1970, 24.91218, 5319 ], [ \"Liechtenstein\", 1975, 33.23883, 7738 ], [ \"Liechtenstein\", 1976, 34.85649, 8246 ], [ \"Liechtenstein\", 1977, 36.29368, 8725 ], [ \"Liechtenstein\", 1978, 37.48977, 9158 ], [ \"Liechtenstein\", 1979, 38.43178, 9538 ], [ \"Liechtenstein\", 1980, 39.82227, 10038 ], [ \"Liechtenstein\", 1981, 41.41272, 10600 ], [ \"Liechtenstein\", 1982, 42.27498, 10986 ], [ \"Liechtenstein\", 1983, 43.52442, 11480 ], [ \"Liechtenstein\", 1984, 44.68483, 11959 ], [ \"Liechtenstein\", 1985, 46.18502, 12536 ], [ \"Liechtenstein\", 1986, 47.81044, 13156 ], [ \"Liechtenstein\", 1987, 49.53023, 13812 ], [ \"Liechtenstein\", 1988, 51.7184, 14612 ], [ \"Liechtenstein\", 1989, 54.21704, 15518 ], [ \"Liechtenstein\", 1990, 57.03152, 16538 ], [ \"Liechtenstein\", 1991, 59.55687, 17499 ], [ \"Liechtenstein\", 1992, 61.98777, 18455 ], [ \"Liechtenstein\", 1993, 62.70636, 18916 ], [ \"Liechtenstein\", 1994, 60.71335, 18554 ], [ \"Liechtenstein\", 1995, 63.42929, 19632 ], [ \"Liechtenstein\", 1996, 63.55224, 19916 ], [ \"Liechtenstein\", 1997, 62.33291, 19772 ], [ \"Liechtenstein\", 1998, 61.56195, 19762 ], [ \"Liechtenstein\", 1999, 60.8448, 19763 ], [ \"Liechtenstein\", 2000, 61.07781, 20072 ], [ \"Liechtenstein\", 2001, 60.45658, 20100 ], [ \"Liechtenstein\", 2002, 59.24175, 19923 ], [ \"Liechtenstein\", 2003, 58.51564, 19900 ], [ \"Liechtenstein\", 2004, 58.13331, 19981 ], [ \"Liechtenstein\", 2005, 57.63913, 20010 ], [ \"Liechtenstein\", 2006, 56.38004, 19755 ], [ \"Liechtenstein\", 2007, 55.39742, 19578 ], [ \"Liechtenstein\", 2008, 55.01137, 19600 ], [ \"Liechtenstein\", 2009, 54.57938, 19600 ], [ \"Lithuania\", 1960, 1.453561, 40388 ], [ \"Lithuania\", 1965, 2.417643, 71839 ], [ \"Lithuania\", 1970, 4.561819, 143225 ], [ \"Lithuania\", 1975, 7.762303, 256284 ], [ \"Lithuania\", 1976, 8.530804, 283812 ], [ \"Lithuania\", 1977, 9.291356, 311202 ], [ \"Lithuania\", 1978, 10.01639, 337573 ], [ \"Lithuania\", 1979, 10.75613, 364748 ], [ \"Lithuania\", 1980, 11.54294, 393984 ], [ \"Lithuania\", 1981, 12.23142, 420316 ], [ \"Lithuania\", 1982, 12.93313, 447510 ], [ \"Lithuania\", 1983, 13.67342, 476594 ], [ \"Lithuania\", 1984, 14.50125, 509508 ], [ \"Lithuania\", 1985, 15.34974, 544080 ], [ \"Lithuania\", 1986, 16.5704, 593129 ], [ \"Lithuania\", 1987, 17.484, 632393 ], [ \"Lithuania\", 1988, 18.63881, 680842 ], [ \"Lithuania\", 1989, 19.94504, 734204 ], [ \"Lithuania\", 1990, 21.11944, 780965 ], [ \"Lithuania\", 1991, 21.99154, 814009 ], [ \"Lithuania\", 1992, 22.53433, 832292 ], [ \"Lithuania\", 1993, 23.35051, 858450 ], [ \"Lithuania\", 1994, 24.564, 897627 ], [ \"Lithuania\", 1995, 25.92076, 940977 ], [ \"Lithuania\", 1996, 27.53759, 992627 ], [ \"Lithuania\", 1997, 29.47458, 1054361 ], [ \"Lithuania\", 1998, 31.35249, 1112882 ], [ \"Lithuania\", 1999, 32.70935, 1152583 ], [ \"Lithuania\", 2000, 33.92512, 1187657 ], [ \"Lithuania\", 2001, 33.07309, 1151673 ], [ \"Lithuania\", 2002, 26.99106, 935899 ], [ \"Lithuania\", 2003, 23.86358, 824219 ], [ \"Lithuania\", 2004, 23.85429, 820039 ], [ \"Lithuania\", 2005, 23.44972, 801110 ], [ \"Lithuania\", 2006, 23.38245, 792357 ], [ \"Lithuania\", 2007, 23.82007, 799436 ], [ \"Lithuania\", 2008, 23.63568, 784935 ], [ \"Lithuania\", 2009, 22.74156, 747412 ], [ \"Luxembourg\", 1960, 11.61963, 36486 ], [ \"Luxembourg\", 1965, 17.79773, 59000 ], [ \"Luxembourg\", 1970, 24.17652, 82000 ], [ \"Luxembourg\", 1975, 29.809, 107000 ], [ \"Luxembourg\", 1976, 30.72741, 111000 ], [ \"Luxembourg\", 1977, 32.26029, 117000 ], [ \"Luxembourg\", 1978, 33.56776, 122000 ], [ \"Luxembourg\", 1979, 34.90411, 127000 ], [ \"Luxembourg\", 1980, 36.15464, 131660 ], [ \"Luxembourg\", 1981, 37.04832, 135000 ], [ \"Luxembourg\", 1982, 38.07664, 138808 ], [ \"Luxembourg\", 1983, 38.95779, 142134 ], [ \"Luxembourg\", 1984, 40.23869, 147074 ], [ \"Luxembourg\", 1985, 41.31944, 151525 ], [ \"Luxembourg\", 1986, 42.62907, 157112 ], [ \"Luxembourg\", 1987, 43.57759, 161682 ], [ \"Luxembourg\", 1988, 44.68357, 167159 ], [ \"Luxembourg\", 1989, 46.69085, 176363 ], [ \"Luxembourg\", 1990, 48.10664, 183700 ], [ \"Luxembourg\", 1991, 49.61346, 191760 ], [ \"Luxembourg\", 1992, 52.65059, 206205 ], [ \"Luxembourg\", 1993, 54.09105, 214821 ], [ \"Luxembourg\", 1994, 55.31997, 222846 ], [ \"Luxembourg\", 1995, 56.16465, 229468 ], [ \"Luxembourg\", 1996, 59.88931, 248116 ], [ \"Luxembourg\", 1997, 60.89036, 255745 ], [ \"Luxembourg\", 1998, 59.90491, 255011 ], [ \"Luxembourg\", 1999, 58.325, 251575 ], [ \"Luxembourg\", 2000, 56.96198, 248880 ], [ \"Luxembourg\", 2001, 58.00975, 256656 ], [ \"Luxembourg\", 2002, 55.48909, 248514 ], [ \"Luxembourg\", 2003, 54.05596, 245000 ], [ \"Luxembourg\", 2004, 53.42218, 245000 ], [ \"Luxembourg\", 2005, 52.69022, 244500 ], [ \"Luxembourg\", 2006, 52.90588, 248400 ], [ \"Luxembourg\", 2007, 52.24834, 248200 ], [ \"Luxembourg\", 2008, 54.22366, 260600 ], [ \"Luxembourg\", 2009, 54.21815, 263600 ], [ \"Macao, China\", 1960, 1.334816, 2304 ], [ \"Macao, China\", 1982, 5.948963, 15955 ], [ \"Macao, China\", 1983, 6.3282, 17712 ], [ \"Macao, China\", 1984, 9.465524, 27716 ], [ \"Macao, China\", 1985, 12.41965, 38026 ], [ \"Macao, China\", 1986, 14.87902, 47591 ], [ \"Macao, China\", 1987, 16.66831, 55643 ], [ \"Macao, China\", 1988, 18.81083, 65381 ], [ \"Macao, China\", 1989, 21.86746, 78830 ], [ \"Macao, China\", 1990, 25.03144, 93155 ], [ \"Macao, China\", 1991, 27.9031, 106685 ], [ \"Macao, China\", 1992, 30.87994, 120777 ], [ \"Macao, China\", 1993, 33.73146, 134489 ], [ \"Macao, China\", 1994, 35.83499, 145303 ], [ \"Macao, China\", 1995, 37.22342, 153273 ], [ \"Macao, China\", 1996, 38.67098, 161485 ], [ \"Macao, China\", 1997, 40.09348, 169591 ], [ \"Macao, China\", 1998, 40.5943, 173893 ], [ \"Macao, China\", 1999, 41.09591, 178445 ], [ \"Macao, China\", 2000, 40.10837, 176837 ], [ \"Macao, China\", 2001, 39.34523, 176450 ], [ \"Macao, China\", 2002, 38.54712, 176106 ], [ \"Macao, China\", 2003, 37.45929, 174621 ], [ \"Macao, China\", 2004, 36.50644, 173928 ], [ \"Macao, China\", 2005, 35.763, 174389 ], [ \"Macao, China\", 2006, 35.33908, 176665 ], [ \"Macao, China\", 2007, 34.69525, 178013 ], [ \"Macao, China\", 2008, 33.43355, 175920 ], [ \"Macao, China\", 2009, 31.6905, 170486 ], [ \"Madagascar\", 1965, 0.1560098, 9500 ], [ \"Madagascar\", 1970, 0.1803504, 12500 ], [ \"Madagascar\", 1976, 0.1958483, 15100 ], [ \"Madagascar\", 1977, 0.1904399, 15100 ], [ \"Madagascar\", 1979, 0.2208, 18500 ], [ \"Madagascar\", 1980, 0.2219834, 19100 ], [ \"Madagascar\", 1981, 0.2185999, 19300 ], [ \"Madagascar\", 1982, 0.2147146, 19441 ], [ \"Madagascar\", 1983, 0.2115917, 19645 ], [ \"Madagascar\", 1984, 0.2219244, 21137 ], [ \"Madagascar\", 1985, 0.2272954, 22226 ], [ \"Madagascar\", 1986, 0.2334519, 23457 ], [ \"Madagascar\", 1987, 0.2419607, 25000 ], [ \"Madagascar\", 1988, 0.2398514, 25500 ], [ \"Madagascar\", 1989, 0.2535332, 27750 ], [ \"Madagascar\", 1990, 0.2798102, 31543 ], [ \"Madagascar\", 1991, 0.3125851, 36306 ], [ \"Madagascar\", 1992, 0.305601, 36583 ], [ \"Madagascar\", 1993, 0.2820368, 34806 ], [ \"Madagascar\", 1994, 0.2646441, 33675 ], [ \"Madagascar\", 1995, 0.2825467, 37074 ], [ \"Madagascar\", 1996, 0.2912258, 39406 ], [ \"Madagascar\", 1997, 0.3095853, 43197 ], [ \"Madagascar\", 1998, 0.3280492, 47193 ], [ \"Madagascar\", 1999, 0.3387418, 50226 ], [ \"Madagascar\", 2000, 0.3600242, 54995 ], [ \"Madagascar\", 2001, 0.3712701, 58399 ], [ \"Madagascar\", 2002, 0.3674599, 59491 ], [ \"Madagascar\", 2003, 0.3578014, 59598 ], [ \"Madagascar\", 2004, 0.342659, 58702 ], [ \"Madagascar\", 2005, 0.5243819, 92366 ], [ \"Madagascar\", 2006, 0.7169613, 129809 ], [ \"Madagascar\", 2007, 0.7196913, 133894 ], [ \"Madagascar\", 2008, 0.8626001, 164851 ], [ \"Madagascar\", 2009, 0.9485336, 186150 ], [ \"Malawi\", 1960, 0.09918102, 3500 ], [ \"Malawi\", 1965, 0.09812321, 3900 ], [ \"Malawi\", 1970, 0.1328079, 6000 ], [ \"Malawi\", 1975, 0.165904, 8700 ], [ \"Malawi\", 1976, 0.1749171, 9540 ], [ \"Malawi\", 1977, 0.1901065, 10727 ], [ \"Malawi\", 1978, 0.2020379, 11792 ], [ \"Malawi\", 1979, 0.2183643, 13164 ], [ \"Malawi\", 1980, 0.2341995, 14555 ], [ \"Malawi\", 1981, 0.2417341, 15438 ], [ \"Malawi\", 1982, 0.2511444, 16445 ], [ \"Malawi\", 1983, 0.2542158, 17100 ], [ \"Malawi\", 1984, 0.2620232, 18233 ], [ \"Malawi\", 1985, 0.2732491, 19856 ], [ \"Malawi\", 1986, 0.2768343, 21228 ], [ \"Malawi\", 1987, 0.2757861, 22466 ], [ \"Malawi\", 1988, 0.2728976, 23600 ], [ \"Malawi\", 1989, 0.2852789, 25960 ], [ \"Malawi\", 1990, 0.2818603, 26640 ], [ \"Malawi\", 1991, 0.2950651, 28564 ], [ \"Malawi\", 1992, 0.3140307, 30804 ], [ \"Malawi\", 1993, 0.3314637, 32767 ], [ \"Malawi\", 1994, 0.3314671, 33081 ], [ \"Malawi\", 1995, 0.3385045, 34338 ], [ \"Malawi\", 1996, 0.3413037, 35471 ], [ \"Malawi\", 1997, 0.3431734, 36754 ], [ \"Malawi\", 1998, 0.3374109, 37371 ], [ \"Malawi\", 1999, 0.362748, 41562 ], [ \"Malawi\", 2000, 0.3925476, 46444 ], [ \"Malawi\", 2001, 0.447834, 54607 ], [ \"Malawi\", 2002, 0.5823491, 73100 ], [ \"Malawi\", 2003, 0.6583135, 85000 ], [ \"Malawi\", 2004, 0.7004334, 93000 ], [ \"Malawi\", 2005, 0.7523102, 102724 ], [ \"Malawi\", 2006, 0.92576, 130000 ], [ \"Malawi\", 2007, 1.213401, 175209 ], [ \"Malawi\", 2008, 1.178754, 175000 ], [ \"Malawi\", 2009, 1.146532, 175000 ], [ \"Malaysia\", 1960, 0.5899092, 48021 ], [ \"Malaysia\", 1965, 0.831386, 79000 ], [ \"Malaysia\", 1970, 0.9583041, 104000 ], [ \"Malaysia\", 1975, 1.378714, 169000 ], [ \"Malaysia\", 1976, 1.548674, 194259 ], [ \"Malaysia\", 1977, 1.773327, 227564 ], [ \"Malaysia\", 1978, 2.064218, 271010 ], [ \"Malaysia\", 1979, 2.419689, 325154 ], [ \"Malaysia\", 1980, 2.874572, 395640 ], [ \"Malaysia\", 1981, 3.464189, 488670 ], [ \"Malaysia\", 1982, 4.046512, 585390 ], [ \"Malaysia\", 1983, 4.715505, 700097 ], [ \"Malaysia\", 1984, 5.568142, 849129 ], [ \"Malaysia\", 1985, 6.114604, 958598 ], [ \"Malaysia\", 1986, 6.464801, 1042827 ], [ \"Malaysia\", 1987, 6.81403, 1131719 ], [ \"Malaysia\", 1988, 7.295094, 1247687 ], [ \"Malaysia\", 1989, 7.885689, 1388183 ], [ \"Malaysia\", 1990, 8.759399, 1585744 ], [ \"Malaysia\", 1991, 9.769479, 1816860 ], [ \"Malaysia\", 1992, 10.95801, 2091578 ], [ \"Malaysia\", 1993, 12.31323, 2410721 ], [ \"Malaysia\", 1994, 14.26256, 2863755 ], [ \"Malaysia\", 1995, 16.18168, 3332447 ], [ \"Malaysia\", 1996, 17.85182, 3771314 ], [ \"Malaysia\", 1997, 19.48844, 4223042 ], [ \"Malaysia\", 1998, 19.73384, 4384148 ], [ \"Malaysia\", 1999, 19.47257, 4430799 ], [ \"Malaysia\", 2000, 19.91244, 4634345 ], [ \"Malaysia\", 2001, 19.81191, 4709564 ], [ \"Malaysia\", 2002, 19.25737, 4669903 ], [ \"Malaysia\", 2003, 18.49737, 4571561 ], [ \"Malaysia\", 2004, 17.66227, 4446265 ], [ \"Malaysia\", 2005, 17.0311, 4365647 ], [ \"Malaysia\", 2006, 16.63975, 4342100 ], [ \"Malaysia\", 2007, 17.1263, 4548000 ], [ \"Malaysia\", 2008, 16.50975, 4460000 ], [ \"Malaysia\", 2009, 17.57328, 4827000 ], [ \"Maldives\", 1970, 0.214168, 260 ], [ \"Maldives\", 1976, 0.3331939, 470 ], [ \"Maldives\", 1977, 0.3723214, 540 ], [ \"Maldives\", 1978, 0.5696478, 850 ], [ \"Maldives\", 1979, 0.5209215, 800 ], [ \"Maldives\", 1981, 0.9461319, 1540 ], [ \"Maldives\", 1982, 1.01435, 1700 ], [ \"Maldives\", 1983, 1.100613, 1900 ], [ \"Maldives\", 1984, 1.1801, 2100 ], [ \"Maldives\", 1985, 1.237507, 2272 ], [ \"Maldives\", 1986, 1.477089, 2800 ], [ \"Maldives\", 1987, 1.736404, 3400 ], [ \"Maldives\", 1988, 2.076443, 4200 ], [ \"Maldives\", 1989, 2.441757, 5100 ], [ \"Maldives\", 1990, 2.895269, 6240 ], [ \"Maldives\", 1991, 3.433876, 7631 ], [ \"Maldives\", 1992, 3.722777, 8523 ], [ \"Maldives\", 1993, 4.232791, 9970 ], [ \"Maldives\", 1994, 4.903298, 11860 ], [ \"Maldives\", 1995, 5.595949, 13869 ], [ \"Maldives\", 1996, 6.025684, 15268 ], [ \"Maldives\", 1997, 6.949731, 17967 ], [ \"Maldives\", 1998, 7.589336, 19985 ], [ \"Maldives\", 1999, 8.279485, 22179 ], [ \"Maldives\", 2000, 8.974171, 24432 ], [ \"Maldives\", 2001, 9.854223, 27242 ], [ \"Maldives\", 2002, 10.21459, 28651 ], [ \"Maldives\", 2003, 10.56662, 30056 ], [ \"Maldives\", 2004, 10.92367, 31503 ], [ \"Maldives\", 2005, 11.04499, 32296 ], [ \"Maldives\", 2006, 10.85322, 32181 ], [ \"Maldives\", 2007, 10.99469, 33063 ], [ \"Maldives\", 2008, 15.38388, 46925 ], [ \"Maldives\", 2009, 15.84365, 49025 ], [ \"Mali\", 1960, 0.03817129, 1648 ], [ \"Mali\", 1965, 0.05410692, 2600 ], [ \"Mali\", 1970, 0.05254892, 2854 ], [ \"Mali\", 1975, 0.05742773, 3567 ], [ \"Mali\", 1976, 0.05617942, 3771 ], [ \"Mali\", 1977, 0.05813776, 3969 ], [ \"Mali\", 1978, 0.05749935, 3992 ], [ \"Mali\", 1979, 0.0593106, 4188 ], [ \"Mali\", 1980, 0.06849255, 4920 ], [ \"Mali\", 1981, 0.07365896, 5384 ], [ \"Mali\", 1982, 0.07836615, 5830 ], [ \"Mali\", 1983, 0.08566242, 6488 ], [ \"Mali\", 1984, 0.09167384, 7071 ], [ \"Mali\", 1985, 0.09217814, 7243 ], [ \"Mali\", 1986, 0.09174073, 7346 ], [ \"Mali\", 1987, 0.1044057, 8522 ], [ \"Mali\", 1988, 0.1054032, 8772 ], [ \"Mali\", 1989, 0.1139094, 9667 ], [ \"Mali\", 1990, 0.1290522, 11169 ], [ \"Mali\", 1991, 0.1412013, 12464 ], [ \"Mali\", 1992, 0.1425673, 12837 ], [ \"Mali\", 1993, 0.1503837, 13812 ], [ \"Mali\", 1994, 0.1623144, 15203 ], [ \"Mali\", 1995, 0.1797472, 17164 ], [ \"Mali\", 1996, 0.2188201, 21294 ], [ \"Mali\", 1997, 0.2440288, 24195 ], [ \"Mali\", 1998, 0.267841, 27063 ], [ \"Mali\", 1999, 0.3277702, 33778 ], [ \"Mali\", 2000, 0.3727382, 39223 ], [ \"Mali\", 2001, 0.4746983, 51071 ], [ \"Mali\", 2002, 0.5140584, 56603 ], [ \"Mali\", 2003, 0.5402558, 60925 ], [ \"Mali\", 2004, 0.569885, 65834 ], [ \"Mali\", 2005, 0.6414686, 75904 ], [ \"Mali\", 2006, 0.6809728, 82521 ], [ \"Mali\", 2007, 0.6447428, 80005 ], [ \"Mali\", 2008, 0.6381055, 81076 ], [ \"Mali\", 2009, 0.6517651, 84796 ], [ \"Malta\", 1960, 2.970503, 9268 ], [ \"Malta\", 1965, 4.720999, 14399 ], [ \"Malta\", 1970, 7.371766, 22315 ], [ \"Malta\", 1975, 9.383937, 28548 ], [ \"Malta\", 1976, 11.02055, 33829 ], [ \"Malta\", 1977, 12.46008, 38708 ], [ \"Malta\", 1978, 13.52715, 42612 ], [ \"Malta\", 1979, 14.54782, 46496 ], [ \"Malta\", 1980, 15.77843, 51142 ], [ \"Malta\", 1981, 17.55362, 57661 ], [ \"Malta\", 1982, 19.7158, 65600 ], [ \"Malta\", 1983, 22.85972, 76992 ], [ \"Malta\", 1984, 23.46199, 79931 ], [ \"Malta\", 1985, 24.58619, 84665 ], [ \"Malta\", 1986, 28.04335, 97523 ], [ \"Malta\", 1987, 31.46057, 110386 ], [ \"Malta\", 1988, 32.97282, 116672 ], [ \"Malta\", 1989, 34.19702, 122043 ], [ \"Malta\", 1990, 35.61226, 128249 ], [ \"Malta\", 1991, 38.16499, 138787 ], [ \"Malta\", 1992, 40.95116, 150448 ], [ \"Malta\", 1993, 42.44136, 157519 ], [ \"Malta\", 1994, 43.47521, 162889 ], [ \"Malta\", 1995, 45.18893, 170717 ], [ \"Malta\", 1996, 47.47857, 180608 ], [ \"Malta\", 1997, 48.87505, 186993 ], [ \"Malta\", 1998, 49.80849, 191548 ], [ \"Malta\", 1999, 51.15362, 197764 ], [ \"Malta\", 2000, 52.50446, 204193 ], [ \"Malta\", 2001, 53.05762, 207745 ], [ \"Malta\", 2002, 52.54806, 207269 ], [ \"Malta\", 2003, 52.40854, 208271 ], [ \"Malta\", 2004, 51.61019, 206529 ], [ \"Malta\", 2005, 50.20692, 202116 ], [ \"Malta\", 2006, 51.5077, 208361 ], [ \"Malta\", 2007, 56.74026, 230433 ], [ \"Malta\", 2008, 59.177, 241122 ], [ \"Malta\", 2009, 59.92386, 244916 ], [ \"Marshall Islands\", 1983, 1.003153, 350 ], [ \"Marshall Islands\", 1990, 1.057284, 500 ], [ \"Marshall Islands\", 1991, 1.443745, 700 ], [ \"Marshall Islands\", 1992, 1.720195, 850 ], [ \"Marshall Islands\", 1993, 4.590269, 2300 ], [ \"Marshall Islands\", 1994, 5.878983, 2976 ], [ \"Marshall Islands\", 1995, 6.243996, 3185 ], [ \"Marshall Islands\", 1996, 6.586826, 3377 ], [ \"Marshall Islands\", 1997, 6.632048, 3410 ], [ \"Marshall Islands\", 1998, 7.26412, 3744 ], [ \"Marshall Islands\", 1999, 7.494783, 3879 ], [ \"Marshall Islands\", 2000, 7.669441, 3999 ], [ \"Marshall Islands\", 2001, 7.937652, 4186 ], [ \"Marshall Islands\", 2002, 8.181529, 4379 ], [ \"Marshall Islands\", 2003, 8.188326, 4461 ], [ \"Marshall Islands\", 2004, 7.919509, 4400 ], [ \"Marshall Islands\", 2005, 7.757405, 4400 ], [ \"Marshall Islands\", 2006, 7.59118, 4400 ], [ \"Marshall Islands\", 2007, 7.421651, 4400 ], [ \"Marshall Islands\", 2008, 7.253544, 4400 ], [ \"Marshall Islands\", 2009, 7.092084, 4400 ], [ \"Mauritania\", 1970, 0.04753379, 600 ], [ \"Mauritania\", 1975, 0.09337757, 1329 ], [ \"Mauritania\", 1976, 0.1125648, 1534 ], [ \"Mauritania\", 1977, 0.1579312, 2214 ], [ \"Mauritania\", 1978, 0.1780152, 2567 ], [ \"Mauritania\", 1979, 0.2015308, 2989 ], [ \"Mauritania\", 1980, 0.2134731, 3256 ], [ \"Mauritania\", 1981, 0.213594, 3350 ], [ \"Mauritania\", 1982, 0.2177273, 3511 ], [ \"Mauritania\", 1983, 0.2240665, 3714 ], [ \"Mauritania\", 1984, 0.2217234, 3776 ], [ \"Mauritania\", 1985, 0.2260367, 3953 ], [ \"Mauritania\", 1986, 0.2289819, 4110 ], [ \"Mauritania\", 1987, 0.2340586, 4310 ], [ \"Mauritania\", 1988, 0.2391511, 4517 ], [ \"Mauritania\", 1989, 0.2342756, 4539 ], [ \"Mauritania\", 1990, 0.295786, 5880 ], [ \"Mauritania\", 1991, 0.3127993, 6382 ], [ \"Mauritania\", 1992, 0.3222662, 6750 ], [ \"Mauritania\", 1993, 0.3486616, 7499 ], [ \"Mauritania\", 1994, 0.3814195, 8426 ], [ \"Mauritania\", 1995, 0.4075257, 9249 ], [ \"Mauritania\", 1996, 0.4375536, 10204 ], [ \"Mauritania\", 1997, 0.5443062, 13045 ], [ \"Mauritania\", 1998, 0.6101398, 15030 ], [ \"Mauritania\", 1999, 0.6525418, 16525 ], [ \"Mauritania\", 2000, 0.728529, 18969 ], [ \"Mauritania\", 2001, 0.9283665, 24856 ], [ \"Mauritania\", 2002, 1.145226, 31529 ], [ \"Mauritania\", 2003, 1.348972, 38178 ], [ \"Mauritania\", 2004, 1.341239, 39000 ], [ \"Mauritania\", 2005, 1.373431, 41000 ], [ \"Mauritania\", 2006, 1.138693, 34870 ], [ \"Mauritania\", 2007, 1.282829, 40267 ], [ \"Mauritania\", 2008, 2.374898, 76354 ], [ \"Mauritania\", 2009, 2.26291, 74464 ], [ \"Mauritius\", 1960, 0.9159748, 6047 ], [ \"Mauritius\", 1965, 1.221502, 9200 ], [ \"Mauritius\", 1970, 1.35673, 11211 ], [ \"Mauritius\", 1975, 1.730188, 15434 ], [ \"Mauritius\", 1976, 1.709339, 15500 ], [ \"Mauritius\", 1977, 1.823207, 16814 ], [ \"Mauritius\", 1978, 2.126666, 19943 ], [ \"Mauritius\", 1979, 2.357432, 22456 ], [ \"Mauritius\", 1980, 2.445771, 23627 ], [ \"Mauritius\", 1981, 2.544813, 24890 ], [ \"Mauritius\", 1982, 2.956086, 29232 ], [ \"Mauritius\", 1983, 3.161949, 31575 ], [ \"Mauritius\", 1984, 3.508385, 35346 ], [ \"Mauritius\", 1985, 3.897441, 39589 ], [ \"Mauritius\", 1986, 4.0872, 41828 ], [ \"Mauritius\", 1987, 4.595525, 47355 ], [ \"Mauritius\", 1988, 4.807018, 49883 ], [ \"Mauritius\", 1989, 5.027712, 52595 ], [ \"Mauritius\", 1990, 5.259396, 55554 ], [ \"Mauritius\", 1991, 5.991377, 64022 ], [ \"Mauritius\", 1992, 7.33555, 79422 ], [ \"Mauritius\", 1993, 9.738127, 106926 ], [ \"Mauritius\", 1994, 11.62458, 129443 ], [ \"Mauritius\", 1995, 13.13104, 148185 ], [ \"Mauritius\", 1996, 16.08952, 183861 ], [ \"Mauritius\", 1997, 19.26272, 222747 ], [ \"Mauritius\", 1998, 20.98117, 245367 ], [ \"Mauritius\", 1999, 21.7469, 257099 ], [ \"Mauritius\", 2000, 23.5089, 280885 ], [ \"Mauritius\", 2001, 25.41268, 306773 ], [ \"Mauritius\", 2002, 26.06562, 317792 ], [ \"Mauritius\", 2003, 28.2905, 348202 ], [ \"Mauritius\", 2004, 28.49005, 353808 ], [ \"Mauritius\", 2005, 28.54695, 357490 ], [ \"Mauritius\", 2006, 28.31472, 357340 ], [ \"Mauritius\", 2007, 28.38087, 360762 ], [ \"Mauritius\", 2008, 28.48383, 364536 ], [ \"Mauritius\", 2009, 29.63021, 381702 ], [ \"Mexico\", 1960, 0.9162182, 338450 ], [ \"Mexico\", 1965, 1.147277, 494946 ], [ \"Mexico\", 1970, 1.696848, 858796 ], [ \"Mexico\", 1975, 2.773789, 1644499 ], [ \"Mexico\", 1976, 2.974322, 1849373 ], [ \"Mexico\", 1977, 3.252918, 2079483 ], [ \"Mexico\", 1978, 3.525792, 2314593 ], [ \"Mexico\", 1979, 3.79907, 2556918 ], [ \"Mexico\", 1980, 3.919915, 2699732 ], [ \"Mexico\", 1981, 4.185293, 2943882 ], [ \"Mexico\", 1982, 4.345183, 3116239 ], [ \"Mexico\", 1983, 4.53741, 3314409 ], [ \"Mexico\", 1984, 4.705391, 3499957 ], [ \"Mexico\", 1985, 4.889373, 3704432 ], [ \"Mexico\", 1986, 5.050292, 3899168 ], [ \"Mexico\", 1987, 5.238595, 4122681 ], [ \"Mexico\", 1988, 5.468222, 4387436 ], [ \"Mexico\", 1989, 5.925135, 4847166 ], [ \"Mexico\", 1990, 6.419958, 5354500 ], [ \"Mexico\", 1991, 7.086002, 6024800 ], [ \"Mexico\", 1992, 7.792728, 6753652 ], [ \"Mexico\", 1993, 8.628373, 7620880 ], [ \"Mexico\", 1994, 9.437405, 8492521 ], [ \"Mexico\", 1995, 9.602878, 8801030 ], [ \"Mexico\", 1996, 9.458906, 8826148 ], [ \"Mexico\", 1997, 9.744775, 9253715 ], [ \"Mexico\", 1998, 10.27936, 9926879 ], [ \"Mexico\", 1999, 11.1387, 10927390 ], [ \"Mexico\", 2000, 12.38983, 12331680 ], [ \"Mexico\", 2001, 13.65935, 13774150 ], [ \"Mexico\", 2002, 14.67534, 14975090 ], [ \"Mexico\", 2003, 15.82905, 16330070 ], [ \"Mexico\", 2004, 17.33636, 18073240 ], [ \"Mexico\", 2005, 18.52472, 19512020 ], [ \"Mexico\", 2006, 18.66475, 19861300 ], [ \"Mexico\", 2007, 18.60499, 19997900 ], [ \"Mexico\", 2008, 18.87642, 20491380 ], [ \"Mexico\", 2009, 17.63809, 19333120 ], [ \"Micronesia (Fed. States of)\", 1983, 1.239695, 1000 ], [ \"Micronesia (Fed. States of)\", 1984, 1.321671, 1100 ], [ \"Micronesia (Fed. States of)\", 1985, 1.482277, 1270 ], [ \"Micronesia (Fed. States of)\", 1986, 1.517977, 1335 ], [ \"Micronesia (Fed. States of)\", 1987, 1.620517, 1459 ], [ \"Micronesia (Fed. States of)\", 1988, 1.927528, 1774 ], [ \"Micronesia (Fed. States of)\", 1989, 2.224253, 2093 ], [ \"Micronesia (Fed. States of)\", 1990, 2.534445, 2441 ], [ \"Micronesia (Fed. States of)\", 1991, 2.712091, 2678 ], [ \"Micronesia (Fed. States of)\", 1992, 2.960279, 2999 ], [ \"Micronesia (Fed. States of)\", 1993, 5.918631, 6142 ], [ \"Micronesia (Fed. States of)\", 1994, 6.815411, 7212 ], [ \"Micronesia (Fed. States of)\", 1995, 7.350692, 7882 ], [ \"Micronesia (Fed. States of)\", 1996, 7.632137, 8235 ], [ \"Micronesia (Fed. States of)\", 1997, 7.792148, 8411 ], [ \"Micronesia (Fed. States of)\", 1998, 8.462747, 9106 ], [ \"Micronesia (Fed. States of)\", 1999, 9.197556, 9863 ], [ \"Micronesia (Fed. States of)\", 2000, 9.007554, 9647 ], [ \"Micronesia (Fed. States of)\", 2001, 9.393759, 10078 ], [ \"Micronesia (Fed. States of)\", 2002, 9.381905, 10106 ], [ \"Micronesia (Fed. States of)\", 2003, 10.2887, 11144 ], [ \"Micronesia (Fed. States of)\", 2004, 11.01695, 11999 ], [ \"Micronesia (Fed. States of)\", 2005, 11.37778, 12449 ], [ \"Micronesia (Fed. States of)\", 2006, 8.121056, 8917 ], [ \"Micronesia (Fed. States of)\", 2007, 7.897533, 8697 ], [ \"Micronesia (Fed. States of)\", 2008, 7.879436, 8700 ], [ \"Micronesia (Fed. States of)\", 2009, 7.857091, 8700 ], [ \"Moldova\", 1960, 0.682537, 20500 ], [ \"Moldova\", 1965, 0.8394548, 28000 ], [ \"Moldova\", 1970, 1.441062, 51799 ], [ \"Moldova\", 1975, 3.550666, 136310 ], [ \"Moldova\", 1976, 4.05001, 157021 ], [ \"Moldova\", 1977, 4.510249, 176385 ], [ \"Moldova\", 1978, 4.874489, 192166 ], [ \"Moldova\", 1979, 5.245888, 208506 ], [ \"Moldova\", 1980, 5.638133, 226089 ], [ \"Moldova\", 1981, 5.927723, 240000 ], [ \"Moldova\", 1982, 6.25671, 255900 ], [ \"Moldova\", 1983, 6.521356, 269500 ], [ \"Moldova\", 1984, 6.857438, 286280 ], [ \"Moldova\", 1985, 7.346863, 309670 ], [ \"Moldova\", 1986, 7.809666, 332140 ], [ \"Moldova\", 1987, 8.429606, 361480 ], [ \"Moldova\", 1988, 9.144596, 395000 ], [ \"Moldova\", 1989, 9.822421, 426800 ], [ \"Moldova\", 1990, 10.58862, 462082 ], [ \"Moldova\", 1991, 11.33353, 495890 ], [ \"Moldova\", 1992, 11.66834, 510997 ], [ \"Moldova\", 1993, 11.9755, 523925 ], [ \"Moldova\", 1994, 12.51199, 545719 ], [ \"Moldova\", 1995, 13.05593, 566464 ], [ \"Moldova\", 1996, 13.77678, 593328 ], [ \"Moldova\", 1997, 14.70049, 627136 ], [ \"Moldova\", 1998, 15.58877, 657456 ], [ \"Moldova\", 1999, 13.34243, 555291 ], [ \"Moldova\", 2000, 14.2384, 583811 ], [ \"Moldova\", 2001, 15.8493, 639165 ], [ \"Moldova\", 2002, 18.16074, 719286 ], [ \"Moldova\", 2003, 20.3484, 791131 ], [ \"Moldova\", 2004, 22.60379, 863374 ], [ \"Moldova\", 2005, 24.7225, 929400 ], [ \"Moldova\", 2006, 27.44982, 1018072 ], [ \"Moldova\", 2007, 29.44467, 1079874 ], [ \"Moldova\", 2008, 30.67577, 1114564 ], [ \"Moldova\", 2009, 31.60059, 1138729 ], [ \"Mongolia\", 1982, 2.446853, 42902 ], [ \"Mongolia\", 1983, 2.49939, 45000 ], [ \"Mongolia\", 1984, 2.537971, 47000 ], [ \"Mongolia\", 1985, 2.566869, 49000 ], [ \"Mongolia\", 1986, 2.584628, 51000 ], [ \"Mongolia\", 1987, 2.594421, 53000 ], [ \"Mongolia\", 1988, 2.604554, 55000 ], [ \"Mongolia\", 1989, 2.625112, 57000 ], [ \"Mongolia\", 1990, 2.994341, 66357 ], [ \"Mongolia\", 1991, 3.052538, 68480 ], [ \"Mongolia\", 1992, 3.068734, 69225 ], [ \"Mongolia\", 1993, 2.93914, 66399 ], [ \"Mongolia\", 1994, 3.055798, 69114 ], [ \"Mongolia\", 1995, 3.425143, 77745 ], [ \"Mongolia\", 1996, 3.662257, 83688 ], [ \"Mongolia\", 1997, 3.785938, 87309 ], [ \"Mongolia\", 1998, 4.43234, 103353 ], [ \"Mongolia\", 1999, 4.38133, 103400 ], [ \"Mongolia\", 2000, 4.91797, 117500 ], [ \"Mongolia\", 2001, 5.138058, 124315 ], [ \"Mongolia\", 2002, 5.221306, 128000 ], [ \"Mongolia\", 2003, 5.56005, 138137 ], [ \"Mongolia\", 2004, 5.798769, 145981 ], [ \"Mongolia\", 2005, 6.11993, 156045 ], [ \"Mongolia\", 2006, 7.559669, 195122 ], [ \"Mongolia\", 2007, 7.024442, 183440 ], [ \"Mongolia\", 2008, 7.590973, 200494 ], [ \"Mongolia\", 2009, 7.071412, 188875 ], [ \"Montenegro\", 2005, 27.36596, 170933 ], [ \"Montenegro\", 2006, 27.07265, 168233 ], [ \"Montenegro\", 2007, 28.39062, 176289 ], [ \"Montenegro\", 2008, 27.96621, 174046 ], [ \"Montenegro\", 2009, 27.51449, 171749 ], [ \"Morocco\", 1960, 0.6768451, 78690 ], [ \"Morocco\", 1965, 0.6304887, 84000 ], [ \"Morocco\", 1970, 0.5943828, 91000 ], [ \"Morocco\", 1975, 0.6356546, 110000 ], [ \"Morocco\", 1976, 0.6938784, 123000 ], [ \"Morocco\", 1977, 0.7489901, 136000 ], [ \"Morocco\", 1978, 0.8008885, 149000 ], [ \"Morocco\", 1979, 0.8074335, 154000 ], [ \"Morocco\", 1980, 0.8534813, 167000 ], [ \"Morocco\", 1981, 0.8830738, 177400 ], [ \"Morocco\", 1982, 0.9277575, 191440 ], [ \"Morocco\", 1983, 0.950518, 201452 ], [ \"Morocco\", 1984, 0.9903351, 215421 ], [ \"Morocco\", 1985, 1.078265, 240443 ], [ \"Morocco\", 1986, 1.102424, 251687 ], [ \"Morocco\", 1987, 1.140135, 266187 ], [ \"Morocco\", 1988, 1.201314, 286493 ], [ \"Morocco\", 1989, 1.374944, 334593 ], [ \"Morocco\", 1990, 1.624493, 403000 ], [ \"Morocco\", 1991, 1.967139, 497000 ], [ \"Morocco\", 1992, 2.544137, 654000 ], [ \"Morocco\", 1993, 3.164639, 827000 ], [ \"Morocco\", 1994, 3.793317, 1007000 ], [ \"Morocco\", 1995, 4.185435, 1128000 ], [ \"Morocco\", 1996, 4.417485, 1208000 ], [ \"Morocco\", 1997, 4.689531, 1300528 ], [ \"Morocco\", 1998, 4.956887, 1393355 ], [ \"Morocco\", 1999, 5.166015, 1471000 ], [ \"Morocco\", 2000, 4.943263, 1425000 ], [ \"Morocco\", 2001, 4.084606, 1191335 ], [ \"Morocco\", 2002, 3.822453, 1127447 ], [ \"Morocco\", 2003, 4.088468, 1219213 ], [ \"Morocco\", 2004, 4.339938, 1308569 ], [ \"Morocco\", 2005, 4.397955, 1341156 ], [ \"Morocco\", 2006, 4.103718, 1266119 ], [ \"Morocco\", 2007, 7.666399, 2393767 ], [ \"Morocco\", 2008, 9.464008, 2991158 ], [ \"Morocco\", 2009, 10.99092, 3516281 ], [ \"Mozambique\", 1960, 0.1235727, 9403 ], [ \"Mozambique\", 1965, 0.2020069, 17000 ], [ \"Mozambique\", 1970, 0.2557466, 24000 ], [ \"Mozambique\", 1975, 0.2942496, 31100 ], [ \"Mozambique\", 1976, 0.2724101, 29700 ], [ \"Mozambique\", 1977, 0.2515946, 28200 ], [ \"Mozambique\", 1978, 0.2542624, 29300 ], [ \"Mozambique\", 1979, 0.2585211, 30600 ], [ \"Mozambique\", 1980, 0.271871, 33000 ], [ \"Mozambique\", 1981, 0.2847168, 35400 ], [ \"Mozambique\", 1982, 0.2867014, 36474 ], [ \"Mozambique\", 1983, 0.2839095, 36859 ], [ \"Mozambique\", 1984, 0.2847836, 37558 ], [ \"Mozambique\", 1985, 0.2876953, 38332 ], [ \"Mozambique\", 1986, 0.2978967, 39840 ], [ \"Mozambique\", 1987, 0.3008006, 40174 ], [ \"Mozambique\", 1988, 0.3060095, 40786 ], [ \"Mozambique\", 1989, 0.3086863, 41278 ], [ \"Mozambique\", 1990, 0.3502785, 47439 ], [ \"Mozambique\", 1991, 0.3813299, 52874 ], [ \"Mozambique\", 1992, 0.391971, 56125 ], [ \"Mozambique\", 1993, 0.3732919, 55463 ], [ \"Mozambique\", 1994, 0.3729163, 57490 ], [ \"Mozambique\", 1995, 0.375148, 59819 ], [ \"Mozambique\", 1996, 0.3723085, 61175 ], [ \"Mozambique\", 1997, 0.3884732, 65606 ], [ \"Mozambique\", 1998, 0.4348368, 75354 ], [ \"Mozambique\", 1999, 0.4391599, 78072 ], [ \"Mozambique\", 2000, 0.4696807, 85714 ], [ \"Mozambique\", 2001, 0.4773646, 89488 ], [ \"Mozambique\", 2002, 0.434794, 83739 ], [ \"Mozambique\", 2003, 0.3921222, 77576 ], [ \"Mozambique\", 2004, 0.3430522, 69676 ], [ \"Mozambique\", 2005, 0.3347112, 69735 ], [ \"Mozambique\", 2006, 0.3413357, 72887 ], [ \"Mozambique\", 2007, 0.3476965, 76039 ], [ \"Mozambique\", 2008, 0.3580694, 80145 ], [ \"Mozambique\", 2009, 0.3238623, 74146 ], [ \"Myanmar\", 1960, 0.05314076, 11476 ], [ \"Myanmar\", 1965, 0.07338171, 17600 ], [ \"Myanmar\", 1970, 0.07712843, 20700 ], [ \"Myanmar\", 1975, 0.08427899, 25400 ], [ \"Myanmar\", 1976, 0.08461865, 25900 ], [ \"Myanmar\", 1977, 0.08457924, 26500 ], [ \"Myanmar\", 1978, 0.08483832, 27200 ], [ \"Myanmar\", 1979, 0.08596792, 28200 ], [ \"Myanmar\", 1982, 0.1110327, 39000 ], [ \"Myanmar\", 1983, 0.1177087, 42274 ], [ \"Myanmar\", 1984, 0.1171971, 43000 ], [ \"Myanmar\", 1985, 0.1268917, 47512 ], [ \"Myanmar\", 1986, 0.1554794, 59343 ], [ \"Myanmar\", 1987, 0.1687311, 65580 ], [ \"Myanmar\", 1988, 0.1686982, 66707 ], [ \"Myanmar\", 1989, 0.1667058, 67016 ], [ \"Myanmar\", 1990, 0.1715923, 70086 ], [ \"Myanmar\", 1991, 0.2072347, 85947 ], [ \"Myanmar\", 1992, 0.2354132, 99073 ], [ \"Myanmar\", 1993, 0.2749007, 117337 ], [ \"Myanmar\", 1994, 0.3173562, 137337 ], [ \"Myanmar\", 1995, 0.3598486, 157843 ], [ \"Myanmar\", 1996, 0.4018304, 178631 ], [ \"Myanmar\", 1997, 0.4740223, 213516 ], [ \"Myanmar\", 1998, 0.5027447, 229320 ], [ \"Myanmar\", 1999, 0.5398317, 249083 ], [ \"Myanmar\", 2000, 0.5821863, 271356 ], [ \"Myanmar\", 2001, 0.6279744, 295234 ], [ \"Myanmar\", 2002, 0.7227524, 342317 ], [ \"Myanmar\", 2003, 0.761261, 362976 ], [ \"Myanmar\", 2004, 0.885144, 424871 ], [ \"Myanmar\", 2005, 1.042353, 503930 ], [ \"Myanmar\", 2006, 1.172525, 571293 ], [ \"Myanmar\", 2007, 0.944627, 464090 ], [ \"Myanmar\", 2008, 1.017785, 504445 ], [ \"Myanmar\", 2009, 1.104185, 552311 ], [ \"Namibia\", 1960, 1.835772, 11000 ], [ \"Namibia\", 1965, 2.216001, 15000 ], [ \"Namibia\", 1970, 2.464054, 19000 ], [ \"Namibia\", 1975, 2.694915, 24000 ], [ \"Namibia\", 1976, 2.693034, 25000 ], [ \"Namibia\", 1977, 2.737194, 26000 ], [ \"Namibia\", 1978, 2.781234, 27000 ], [ \"Namibia\", 1979, 2.823386, 28000 ], [ \"Namibia\", 1980, 2.8619, 29000 ], [ \"Namibia\", 1981, 3.187827, 33000 ], [ \"Namibia\", 1982, 3.592901, 38000 ], [ \"Namibia\", 1983, 3.971156, 43000 ], [ \"Namibia\", 1984, 3.951582, 44000 ], [ \"Namibia\", 1985, 3.908262, 45000 ], [ \"Namibia\", 1986, 3.840666, 46000 ], [ \"Namibia\", 1987, 3.756391, 47000 ], [ \"Namibia\", 1988, 3.727067, 48769 ], [ \"Namibia\", 1989, 3.712254, 50668 ], [ \"Namibia\", 1990, 3.740568, 53000 ], [ \"Namibia\", 1991, 3.891248, 56939 ], [ \"Namibia\", 1992, 4.051652, 60974 ], [ \"Namibia\", 1993, 4.324783, 66749 ], [ \"Namibia\", 1994, 4.413259, 69784 ], [ \"Namibia\", 1995, 4.844998, 78499 ], [ \"Namibia\", 1996, 5.151273, 85549 ], [ \"Namibia\", 1997, 5.869428, 99904 ], [ \"Namibia\", 1998, 6.071942, 105877 ], [ \"Namibia\", 1999, 6.062734, 108193 ], [ \"Namibia\", 2000, 6.040361, 110176 ], [ \"Namibia\", 2001, 6.305523, 117398 ], [ \"Namibia\", 2002, 6.395308, 121413 ], [ \"Namibia\", 2003, 6.584252, 127380 ], [ \"Namibia\", 2004, 6.490084, 127935 ], [ \"Namibia\", 2005, 6.918616, 138997 ], [ \"Namibia\", 2006, 6.647763, 136163 ], [ \"Namibia\", 2007, 6.612865, 138121 ], [ \"Namibia\", 2008, 6.573221, 140000 ], [ \"Namibia\", 2009, 6.544958, 142100 ], [ \"Nauru\", 1975, 16.98273, 1200 ], [ \"Nauru\", 1976, 20.97315, 1500 ], [ \"Nauru\", 1977, 20.74689, 1500 ], [ \"Nauru\", 1978, 21.89981, 1600 ], [ \"Nauru\", 1979, 21.65674, 1600 ], [ \"Nauru\", 1981, 15.80611, 1200 ], [ \"Nauru\", 1982, 15.55613, 1200 ], [ \"Nauru\", 1983, 15.28468, 1200 ], [ \"Nauru\", 1984, 14.99438, 1200 ], [ \"Nauru\", 1985, 14.68968, 1200 ], [ \"Nauru\", 1986, 14.36954, 1200 ], [ \"Nauru\", 1987, 14.04494, 1200 ], [ \"Nauru\", 1988, 13.49188, 1180 ], [ \"Nauru\", 1989, 13.40932, 1200 ], [ \"Nauru\", 1990, 13.11475, 1200 ], [ \"Nauru\", 1991, 12.83834, 1200 ], [ \"Nauru\", 1992, 12.58125, 1200 ], [ \"Nauru\", 1993, 14.41367, 1400 ], [ \"Nauru\", 1994, 15.21607, 1500 ], [ \"Nauru\", 1995, 15.55444, 1550 ], [ \"Nauru\", 1996, 15.95373, 1600 ], [ \"Nauru\", 1997, 16.41138, 1650 ], [ \"Nauru\", 1998, 16.91038, 1700 ], [ \"Nauru\", 1999, 17.42507, 1750 ], [ \"Nauru\", 2000, 17.93186, 1800 ], [ \"Nauru\", 2001, 18.42079, 1850 ], [ \"Nauru\", 2002, 17.90154, 1800 ], [ \"Nauru\", 2003, 17.87133, 1800 ], [ \"Nauru\", 2004, 17.83591, 1800 ], [ \"Nauru\", 2005, 17.80239, 1800 ], [ \"Nauru\", 2006, 17.769, 1800 ], [ \"Nauru\", 2007, 17.7305, 1800 ], [ \"Nauru\", 2008, 17.68694, 1800 ], [ \"Nauru\", 2009, 18.60921, 1900 ], [ \"Nepal\", 1975, 0.05240741, 7100 ], [ \"Nepal\", 1976, 0.05629365, 7700 ], [ \"Nepal\", 1977, 0.06138365, 8600 ], [ \"Nepal\", 1978, 0.06340885, 9100 ], [ \"Nepal\", 1979, 0.06938495, 10200 ], [ \"Nepal\", 1980, 0.07570972, 11400 ], [ \"Nepal\", 1981, 0.08299747, 12800 ], [ \"Nepal\", 1982, 0.09047245, 14290 ], [ \"Nepal\", 1983, 0.1019804, 16496 ], [ \"Nepal\", 1984, 0.1122393, 18592 ], [ \"Nepal\", 1985, 0.1219842, 20691 ], [ \"Nepal\", 1986, 0.1497035, 26000 ], [ \"Nepal\", 1987, 0.1709804, 30404 ], [ \"Nepal\", 1988, 0.2087006, 38000 ], [ \"Nepal\", 1989, 0.2437634, 45457 ], [ \"Nepal\", 1990, 0.3000317, 57320 ], [ \"Nepal\", 1991, 0.331463, 64894 ], [ \"Nepal\", 1992, 0.3432742, 68886 ], [ \"Nepal\", 1993, 0.3533088, 72683 ], [ \"Nepal\", 1994, 0.3586134, 75637 ], [ \"Nepal\", 1995, 0.3871214, 83713 ], [ \"Nepal\", 1996, 0.5080822, 112645 ], [ \"Nepal\", 1997, 0.6159196, 139989 ], [ \"Nepal\", 1998, 0.8945859, 208387 ], [ \"Nepal\", 1999, 1.060353, 253035 ], [ \"Nepal\", 2000, 1.09239, 266890 ], [ \"Nepal\", 2001, 1.192324, 298062 ], [ \"Nepal\", 2002, 1.281841, 327673 ], [ \"Nepal\", 2003, 1.423352, 371816 ], [ \"Nepal\", 2004, 1.566745, 417944 ], [ \"Nepal\", 2005, 1.780355, 484640 ], [ \"Nepal\", 2006, 2.203105, 611544 ], [ \"Nepal\", 2007, 2.478639, 701126 ], [ \"Nepal\", 2008, 2.794426, 805061 ], [ \"Nepal\", 2009, 2.770545, 812615 ], [ \"Netherlands Antilles\", 1960, 7.330629, 9866 ], [ \"Netherlands Antilles\", 1975, 18.65223, 31000 ], [ \"Netherlands Antilles\", 1976, 19.09445, 32000 ], [ \"Netherlands Antilles\", 1977, 20.11311, 34000 ], [ \"Netherlands Antilles\", 1978, 20.52064, 35000 ], [ \"Netherlands Antilles\", 1979, 21.49863, 37000 ], [ \"Netherlands Antilles\", 1980, 21.88184, 38000 ], [ \"Netherlands Antilles\", 1981, 23.93183, 41930 ], [ \"Netherlands Antilles\", 1982, 23.68659, 41867 ], [ \"Netherlands Antilles\", 1983, 25.50227, 45481 ], [ \"Netherlands Antilles\", 1984, 25.91157, 46646 ], [ \"Netherlands Antilles\", 1985, 25.98891, 47252 ], [ \"Netherlands Antilles\", 1986, 25.57962, 47000 ], [ \"Netherlands Antilles\", 1987, 25.30514, 47000 ], [ \"Netherlands Antilles\", 1988, 25.04543, 47000 ], [ \"Netherlands Antilles\", 1989, 25.02416, 47380 ], [ \"Netherlands Antilles\", 1990, 24.65535, 47000 ], [ \"Netherlands Antilles\", 1991, 25.32029, 48500 ], [ \"Netherlands Antilles\", 1992, 25.50595, 49000 ], [ \"Netherlands Antilles\", 1993, 35.36707, 67984 ], [ \"Netherlands Antilles\", 1994, 36.97336, 70899 ], [ \"Netherlands Antilles\", 1995, 39.79188, 75868 ], [ \"Netherlands Antilles\", 1996, 40.24017, 76000 ], [ \"Netherlands Antilles\", 1997, 41.28576, 77000 ], [ \"Netherlands Antilles\", 1998, 42.39177, 78000 ], [ \"Netherlands Antilles\", 1999, 43.42735, 79000 ], [ \"Netherlands Antilles\", 2000, 44.28085, 80000 ], [ \"Netherlands Antilles\", 2001, 44.90495, 81000 ], [ \"Netherlands Antilles\", 2002, 45.31363, 82000 ], [ \"Netherlands Antilles\", 2003, 45.5301, 83000 ], [ \"Netherlands Antilles\", 2004, 45.60632, 84000 ], [ \"Netherlands Antilles\", 2005, 45.58839, 85000 ], [ \"Netherlands Antilles\", 2006, 45.4781, 86000 ], [ \"Netherlands Antilles\", 2007, 45.28467, 87000 ], [ \"Netherlands Antilles\", 2008, 45.06973, 88000 ], [ \"Netherlands Antilles\", 2009, 44.90459, 89000 ], [ \"Netherlands\", 1960, 9.085833, 1043656 ], [ \"Netherlands\", 1965, 12.23288, 1504000 ], [ \"Netherlands\", 1970, 16.88841, 2202000 ], [ \"Netherlands\", 1975, 24.40669, 3335500 ], [ \"Netherlands\", 1976, 26.22086, 3612100 ], [ \"Netherlands\", 1977, 28.33454, 3932800 ], [ \"Netherlands\", 1978, 30.61921, 4279900 ], [ \"Netherlands\", 1979, 32.73241, 4604800 ], [ \"Netherlands\", 1980, 34.57361, 4892100 ], [ \"Netherlands\", 1981, 35.88192, 5103300 ], [ \"Netherlands\", 1982, 37.03205, 5291000 ], [ \"Netherlands\", 1983, 38.06337, 5462000 ], [ \"Netherlands\", 1984, 39.14692, 5643000 ], [ \"Netherlands\", 1985, 40.19322, 5823000 ], [ \"Netherlands\", 1986, 41.38172, 6029000 ], [ \"Netherlands\", 1987, 42.5268, 6234000 ], [ \"Netherlands\", 1988, 43.82288, 6466000 ], [ \"Netherlands\", 1989, 45.03963, 6690000 ], [ \"Netherlands\", 1990, 46.41291, 6940000 ], [ \"Netherlands\", 1991, 47.66856, 7175000 ], [ \"Netherlands\", 1992, 48.8073, 7395000 ], [ \"Netherlands\", 1993, 50.05582, 7634000 ], [ \"Netherlands\", 1994, 51.19838, 7859000 ], [ \"Netherlands\", 1995, 52.58793, 8124000 ], [ \"Netherlands\", 1996, 54.2342, 8431000 ], [ \"Netherlands\", 1997, 56.64565, 8860000 ], [ \"Netherlands\", 1998, 59.34018, 9337000 ], [ \"Netherlands\", 1999, 60.74177, 9613000 ], [ \"Netherlands\", 2000, 62.13732, 9889000 ], [ \"Netherlands\", 2001, 50.9855, 8158000 ], [ \"Netherlands\", 2002, 49.90198, 8026000 ], [ \"Netherlands\", 2003, 48.54113, 7846000 ], [ \"Netherlands\", 2004, 48.40175, 7861000 ], [ \"Netherlands\", 2005, 46.57911, 7600000 ], [ \"Netherlands\", 2006, 45.45659, 7450000 ], [ \"Netherlands\", 2007, 44.98411, 7404300 ], [ \"Netherlands\", 2008, 44.27254, 7317200 ], [ \"Netherlands\", 2009, 44.11703, 7320000 ], [ \"New Caledonia\", 1960, 3.068995, 2394 ], [ \"New Caledonia\", 1965, 3.394433, 3100 ], [ \"New Caledonia\", 1970, 4.462548, 4700 ], [ \"New Caledonia\", 1975, 6.903399, 8900 ], [ \"New Caledonia\", 1976, 7.018603, 9300 ], [ \"New Caledonia\", 1977, 7.897903, 10700 ], [ \"New Caledonia\", 1978, 8.26045, 11400 ], [ \"New Caledonia\", 1979, 8.663869, 12160 ], [ \"New Caledonia\", 1980, 9.277036, 13240 ], [ \"New Caledonia\", 1981, 9.790142, 14210 ], [ \"New Caledonia\", 1982, 10.52161, 15530 ], [ \"New Caledonia\", 1983, 11.13865, 16720 ], [ \"New Caledonia\", 1984, 11.7956, 18010 ], [ \"New Caledonia\", 1985, 12.03136, 18690 ], [ \"New Caledonia\", 1986, 12.84756, 20312 ], [ \"New Caledonia\", 1987, 13.61307, 21915 ], [ \"New Caledonia\", 1988, 14.60302, 23958 ], [ \"New Caledonia\", 1989, 15.9152, 26643 ], [ \"New Caledonia\", 1990, 16.59135, 28382 ], [ \"New Caledonia\", 1991, 17.97924, 31475 ], [ \"New Caledonia\", 1992, 19.57651, 35114 ], [ \"New Caledonia\", 1993, 21.07175, 38748 ], [ \"New Caledonia\", 1994, 22.07256, 41605 ], [ \"New Caledonia\", 1995, 22.64523, 43725 ], [ \"New Caledonia\", 1996, 23.05898, 45574 ], [ \"New Caledonia\", 1997, 23.48632, 47479 ], [ \"New Caledonia\", 1998, 23.84188, 49259 ], [ \"New Caledonia\", 1999, 24.00967, 50652 ], [ \"New Caledonia\", 2000, 23.69956, 51005 ], [ \"New Caledonia\", 2001, 23.11964, 50709 ], [ \"New Caledonia\", 2002, 23.28539, 52000 ], [ \"New Caledonia\", 2003, 22.85553, 51928 ], [ \"New Caledonia\", 2004, 23.0724, 53306 ], [ \"New Caledonia\", 2005, 23.5497, 55310 ], [ \"New Caledonia\", 2006, 24.2151, 57800 ], [ \"New Caledonia\", 2007, 24.82712, 60209 ], [ \"New Caledonia\", 2008, 25.58027, 63006 ], [ \"New Caledonia\", 2009, 26.96447, 67426 ], [ \"New Zealand\", 1960, 22.64061, 537035 ], [ \"New Zealand\", 1965, 27.20698, 715000 ], [ \"New Zealand\", 1970, 29.82689, 841000 ], [ \"New Zealand\", 1975, 32.01319, 987000 ], [ \"New Zealand\", 1976, 33.93565, 1054996 ], [ \"New Zealand\", 1977, 34.29166, 1070702 ], [ \"New Zealand\", 1978, 34.90753, 1092148 ], [ \"New Zealand\", 1979, 35.17287, 1102740 ], [ \"New Zealand\", 1980, 36.11016, 1136453 ], [ \"New Zealand\", 1981, 37.04926, 1173276 ], [ \"New Zealand\", 1982, 37.51651, 1197726 ], [ \"New Zealand\", 1983, 38.04198, 1225569 ], [ \"New Zealand\", 1984, 38.76516, 1259761 ], [ \"New Zealand\", 1985, 39.55482, 1295022 ], [ \"New Zealand\", 1986, 40.32154, 1327766 ], [ \"New Zealand\", 1987, 41.40838, 1370000 ], [ \"New Zealand\", 1988, 42.28243, 1406000 ], [ \"New Zealand\", 1989, 43.1102, 1444000 ], [ \"New Zealand\", 1990, 43.38955, 1469000 ], [ \"New Zealand\", 1991, 43.45657, 1493000 ], [ \"New Zealand\", 1992, 43.86339, 1534000 ], [ \"New Zealand\", 1993, 44.69005, 1593000 ], [ \"New Zealand\", 1994, 45.68466, 1658000 ], [ \"New Zealand\", 1995, 46.6445, 1719000 ], [ \"New Zealand\", 1996, 46.28381, 1726600 ], [ \"New Zealand\", 1997, 47.16027, 1776400 ], [ \"New Zealand\", 1998, 47.62955, 1809000 ], [ \"New Zealand\", 1999, 47.8636, 1833400 ], [ \"New Zealand\", 2000, 47.33467, 1831000 ], [ \"New Zealand\", 2001, 46.59446, 1823000 ], [ \"New Zealand\", 2002, 44.55329, 1765000 ], [ \"New Zealand\", 2003, 44.80335, 1798000 ], [ \"New Zealand\", 2004, 44.3079, 1800500 ], [ \"New Zealand\", 2005, 42.06217, 1729000 ], [ \"New Zealand\", 2006, 42.41512, 1761645 ], [ \"New Zealand\", 2007, 41.6635, 1746874 ], [ \"New Zealand\", 2008, 41.37112, 1750000 ], [ \"New Zealand\", 2009, 43.82986, 1870000 ], [ \"Nicaragua\", 1970, 0.7630124, 17000 ], [ \"Nicaragua\", 1975, 0.83709, 21947 ], [ \"Nicaragua\", 1976, 0.8800867, 25393 ], [ \"Nicaragua\", 1977, 0.9554186, 28421 ], [ \"Nicaragua\", 1978, 0.9899123, 30349 ], [ \"Nicaragua\", 1979, 0.928359, 29317 ], [ \"Nicaragua\", 1980, 0.9483839, 30827 ], [ \"Nicaragua\", 1981, 0.9869177, 32998 ], [ \"Nicaragua\", 1982, 1.045848, 35946 ], [ \"Nicaragua\", 1983, 1.120361, 39548 ], [ \"Nicaragua\", 1984, 1.155821, 41853 ], [ \"Nicaragua\", 1985, 1.168935, 43364 ], [ \"Nicaragua\", 1986, 1.162556, 44118 ], [ \"Nicaragua\", 1987, 1.184351, 45921 ], [ \"Nicaragua\", 1988, 1.14867, 45483 ], [ \"Nicaragua\", 1989, 1.141212, 46169 ], [ \"Nicaragua\", 1990, 1.119636, 46328 ], [ \"Nicaragua\", 1991, 1.140038, 48305 ], [ \"Nicaragua\", 1992, 1.250027, 54280 ], [ \"Nicaragua\", 1993, 1.501227, 66810 ], [ \"Nicaragua\", 1994, 1.870789, 85254 ], [ \"Nicaragua\", 1995, 2.073443, 96611 ], [ \"Nicaragua\", 1996, 2.341935, 111397 ], [ \"Nicaragua\", 1997, 2.532693, 122817 ], [ \"Nicaragua\", 1998, 2.860523, 141233 ], [ \"Nicaragua\", 1999, 2.992548, 150258 ], [ \"Nicaragua\", 2000, 3.224599, 164484 ], [ \"Nicaragua\", 2001, 3.047366, 157753 ], [ \"Nicaragua\", 2002, 3.270027, 171632 ], [ \"Nicaragua\", 2003, 3.854921, 205004 ], [ \"Nicaragua\", 2004, 3.981889, 214480 ], [ \"Nicaragua\", 2005, 4.048767, 220869 ], [ \"Nicaragua\", 2006, 4.486419, 247862 ], [ \"Nicaragua\", 2007, 4.450361, 249000 ], [ \"Nicaragua\", 2008, 4.446542, 252000 ], [ \"Nicaragua\", 2009, 4.440343, 255000 ], [ \"Niger\", 1960, 0.02199359, 758 ], [ \"Niger\", 1970, 0.04796589, 2200 ], [ \"Niger\", 1975, 0.06384537, 3400 ], [ \"Niger\", 1976, 0.07241879, 3800 ], [ \"Niger\", 1977, 0.09056044, 4900 ], [ \"Niger\", 1978, 0.09320864, 5200 ], [ \"Niger\", 1979, 0.09739523, 5600 ], [ \"Niger\", 1980, 0.09911893, 5870 ], [ \"Niger\", 1981, 0.10433, 6360 ], [ \"Niger\", 1982, 0.1115866, 6999 ], [ \"Niger\", 1983, 0.1153934, 7445 ], [ \"Niger\", 1984, 0.118953, 7894 ], [ \"Niger\", 1985, 0.1192511, 8141 ], [ \"Niger\", 1986, 0.1181689, 8300 ], [ \"Niger\", 1987, 0.1175967, 8500 ], [ \"Niger\", 1988, 0.1169132, 8700 ], [ \"Niger\", 1989, 0.1188216, 9109 ], [ \"Niger\", 1990, 0.1173085, 9272 ], [ \"Niger\", 1991, 0.1210287, 9871 ], [ \"Niger\", 1992, 0.1217982, 10258 ], [ \"Niger\", 1993, 0.1206921, 10503 ], [ \"Niger\", 1994, 0.1384327, 12453 ], [ \"Niger\", 1995, 0.1477452, 13743 ], [ \"Niger\", 1996, 0.1595644, 15353 ], [ \"Niger\", 1997, 0.164759, 16404 ], [ \"Niger\", 1998, 0.1757965, 18114 ], [ \"Niger\", 1999, 0.1771725, 18891 ], [ \"Niger\", 2000, 0.1812249, 19991 ], [ \"Niger\", 2001, 0.1899386, 21669 ], [ \"Niger\", 2002, 0.1898725, 22399 ], [ \"Niger\", 2003, 0.1882725, 22975 ], [ \"Niger\", 2004, 0.1902503, 24040 ], [ \"Niger\", 2005, 0.1828279, 23954 ], [ \"Niger\", 2006, 0.2199742, 29925 ], [ \"Niger\", 2007, 0.2948156, 41686 ], [ \"Niger\", 2008, 0.4402652, 64738 ], [ \"Niger\", 2009, 0.4251116, 65000 ], [ \"Nigeria\", 1960, 0.05027109, 20544 ], [ \"Nigeria\", 1981, 0.2131429, 163360 ], [ \"Nigeria\", 1982, 0.1925644, 151600 ], [ \"Nigeria\", 1983, 0.2259088, 182550 ], [ \"Nigeria\", 1984, 0.2321798, 192560 ], [ \"Nigeria\", 1985, 0.2395519, 203980 ], [ \"Nigeria\", 1986, 0.2465432, 215630 ], [ \"Nigeria\", 1987, 0.2531456, 227460 ], [ \"Nigeria\", 1988, 0.2551463, 235530 ], [ \"Nigeria\", 1989, 0.2636787, 250000 ], [ \"Nigeria\", 1990, 0.2970979, 289190 ], [ \"Nigeria\", 1991, 0.2944994, 294166 ], [ \"Nigeria\", 1992, 0.3132119, 320934 ], [ \"Nigeria\", 1993, 0.3257399, 342287 ], [ \"Nigeria\", 1994, 0.3422306, 368715 ], [ \"Nigeria\", 1995, 0.3667501, 405073 ], [ \"Nigeria\", 1996, 0.3646069, 412779 ], [ \"Nigeria\", 1997, 0.3483481, 404177 ], [ \"Nigeria\", 1998, 0.3688999, 438619 ], [ \"Nigeria\", 1999, 0.3884857, 473316 ], [ \"Nigeria\", 2000, 0.4432582, 553374 ], [ \"Nigeria\", 2001, 0.4693016, 600321 ], [ \"Nigeria\", 2002, 0.5356293, 702000 ], [ \"Nigeria\", 2003, 0.661752, 888534 ], [ \"Nigeria\", 2004, 0.7470497, 1027519 ], [ \"Nigeria\", 2005, 0.8683066, 1223258 ], [ \"Nigeria\", 2006, 1.169983, 1687972 ], [ \"Nigeria\", 2007, 1.06935, 1579664 ], [ \"Nigeria\", 2008, 0.8647613, 1307625 ], [ \"Nigeria\", 2009, 0.9170582, 1418954 ], [ \"Northern Marianas Islands\", 1992, 26.20192, 12971 ], [ \"Northern Marianas Islands\", 1993, 25.78797, 13500 ], [ \"Northern Marianas Islands\", 1994, 26.05942, 14359 ], [ \"Northern Marianas Islands\", 1995, 26.78958, 15460 ], [ \"Northern Marianas Islands\", 1996, 31.31931, 18837 ], [ \"Northern Marianas Islands\", 1997, 33.06155, 20639 ], [ \"Northern Marianas Islands\", 1998, 31.94397, 20639 ], [ \"Northern Marianas Islands\", 1999, 30.73836, 20528 ], [ \"Northern Marianas Islands\", 2000, 30.41941, 20990 ], [ \"Northern Marianas Islands\", 2001, 30.01697, 21400 ], [ \"Northern Marianas Islands\", 2002, 29.74493, 21900 ], [ \"Northern Marianas Islands\", 2003, 29.49619, 22400 ], [ \"Northern Marianas Islands\", 2004, 29.17317, 22800 ], [ \"Northern Marianas Islands\", 2005, 29.05201, 23300 ], [ \"Northern Marianas Islands\", 2006, 29.0014, 23800 ], [ \"Northern Marianas Islands\", 2007, 28.88725, 24200 ], [ \"Northern Marianas Islands\", 2008, 28.93491, 24700 ], [ \"Northern Marianas Islands\", 2009, 28.88544, 25100 ], [ \"Norway\", 1960, 12.70316, 454900 ], [ \"Norway\", 1965, 15.64867, 582600 ], [ \"Norway\", 1970, 19.14435, 742300 ], [ \"Norway\", 1975, 22.80582, 913900 ], [ \"Norway\", 1976, 23.73971, 955900 ], [ \"Norway\", 1977, 24.84271, 1004500 ], [ \"Norway\", 1978, 25.98064, 1054400 ], [ \"Norway\", 1979, 27.36074, 1114200 ], [ \"Norway\", 1980, 29.3049, 1197287 ], [ \"Norway\", 1981, 31.66012, 1297653 ], [ \"Norway\", 1982, 34.67077, 1425512 ], [ \"Norway\", 1983, 37.68117, 1554194 ], [ \"Norway\", 1984, 40.05178, 1657403 ], [ \"Norway\", 1985, 42.32705, 1757656 ], [ \"Norway\", 1986, 44.6598, 1861412 ], [ \"Norway\", 1987, 46.56902, 1948680 ], [ \"Norway\", 1988, 47.9797, 2016213 ], [ \"Norway\", 1989, 49.04397, 2070249 ], [ \"Norway\", 1990, 50.27225, 2132290 ], [ \"Norway\", 1991, 51.56327, 2198243 ], [ \"Norway\", 1992, 52.92416, 2268486 ], [ \"Norway\", 1993, 54.16802, 2334836 ], [ \"Norway\", 1994, 55.22759, 2394000 ], [ \"Norway\", 1995, 56.06554, 2444000 ], [ \"Norway\", 1996, 56.66721, 2484000 ], [ \"Norway\", 1997, 62.95514, 2775000 ], [ \"Norway\", 1998, 55.83628, 2475000 ], [ \"Norway\", 1999, 54.86933, 2446000 ], [ \"Norway\", 2000, 53.54641, 2401000 ], [ \"Norway\", 2001, 51.82973, 2337856 ], [ \"Norway\", 2002, 51.0556, 2316919 ], [ \"Norway\", 2003, 48.96085, 2236113 ], [ \"Norway\", 2004, 47.40733, 2180429 ], [ \"Norway\", 2005, 45.48891, 2108628 ], [ \"Norway\", 2006, 43.9487, 2055057 ], [ \"Norway\", 2007, 42.11906, 1988166 ], [ \"Norway\", 2008, 39.7752, 1895917 ], [ \"Norway\", 2009, 37.06059, 1783426 ], [ \"Oman\", 1965, 0.03115158, 200 ], [ \"Oman\", 1970, 0.07460128, 557 ], [ \"Oman\", 1975, 0.4036013, 3701 ], [ \"Oman\", 1976, 0.6903569, 6649 ], [ \"Oman\", 1977, 0.9570403, 9699 ], [ \"Oman\", 1978, 1.040664, 11112 ], [ \"Oman\", 1979, 0.9914735, 11163 ], [ \"Oman\", 1980, 1.455735, 17286 ], [ \"Oman\", 1981, 1.380137, 17286 ], [ \"Oman\", 1982, 1.487352, 19642 ], [ \"Oman\", 1983, 1.537067, 21370 ], [ \"Oman\", 1984, 1.602462, 23391 ], [ \"Oman\", 1985, 2.705307, 41320 ], [ \"Oman\", 1986, 3.112654, 49565 ], [ \"Oman\", 1987, 3.438139, 56899 ], [ \"Oman\", 1988, 4.737992, 81321 ], [ \"Oman\", 1989, 5.14229, 91462 ], [ \"Oman\", 1990, 5.679821, 104679 ], [ \"Oman\", 1991, 6.102309, 116558 ], [ \"Oman\", 1992, 6.574853, 130107 ], [ \"Oman\", 1993, 7.218691, 147784 ], [ \"Oman\", 1994, 7.472589, 157840 ], [ \"Oman\", 1995, 7.824688, 169939 ], [ \"Oman\", 1996, 8.88324, 197687 ], [ \"Oman\", 1997, 8.820353, 200557 ], [ \"Oman\", 1998, 9.48808, 219956 ], [ \"Oman\", 1999, 9.335751, 220373 ], [ \"Oman\", 2000, 9.233556, 221807 ], [ \"Oman\", 2001, 9.434068, 230507 ], [ \"Oman\", 2002, 9.163334, 227625 ], [ \"Oman\", 2003, 9.350803, 236178 ], [ \"Oman\", 2004, 9.445467, 242745 ], [ \"Oman\", 2005, 10.13193, 265237 ], [ \"Oman\", 2006, 10.10092, 269700 ], [ \"Oman\", 2007, 10.81762, 294921 ], [ \"Oman\", 2008, 10.94102, 304747 ], [ \"Oman\", 2009, 10.53716, 299826 ], [ \"Pakistan\", 1960, 0.1443516, 66776 ], [ \"Pakistan\", 1965, 0.1834624, 96000 ], [ \"Pakistan\", 1970, 0.2350377, 140000 ], [ \"Pakistan\", 1975, 0.3045662, 208000 ], [ \"Pakistan\", 1976, 0.3096875, 227000 ], [ \"Pakistan\", 1977, 0.3208908, 242000 ], [ \"Pakistan\", 1978, 0.3349137, 260000 ], [ \"Pakistan\", 1979, 0.3574317, 286000 ], [ \"Pakistan\", 1980, 0.3667872, 303000 ], [ \"Pakistan\", 1981, 0.3827294, 326930 ], [ \"Pakistan\", 1982, 0.3819104, 337710 ], [ \"Pakistan\", 1983, 0.4196761, 384430 ], [ \"Pakistan\", 1984, 0.4647576, 441091 ], [ \"Pakistan\", 1985, 0.4635152, 455675 ], [ \"Pakistan\", 1986, 0.5102898, 519540 ], [ \"Pakistan\", 1987, 0.553984, 583930 ], [ \"Pakistan\", 1988, 0.5840322, 636590 ], [ \"Pakistan\", 1989, 0.7043085, 792211 ], [ \"Pakistan\", 1990, 0.7284291, 843346 ], [ \"Pakistan\", 1991, 0.939202, 1116113 ], [ \"Pakistan\", 1992, 1.02185, 1243569 ], [ \"Pakistan\", 1993, 1.227924, 1528470 ], [ \"Pakistan\", 1994, 1.437137, 1830000 ], [ \"Pakistan\", 1995, 1.631432, 2127344 ], [ \"Pakistan\", 1996, 1.777676, 2376786 ], [ \"Pakistan\", 1997, 1.864033, 2557619 ], [ \"Pakistan\", 1998, 1.889255, 2661000 ], [ \"Pakistan\", 1999, 1.988709, 2874000 ], [ \"Pakistan\", 2000, 2.061305, 3053460 ], [ \"Pakistan\", 2001, 2.143964, 3252000 ], [ \"Pakistan\", 2002, 2.355429, 3655474 ], [ \"Pakistan\", 2003, 2.550462, 4047423 ], [ \"Pakistan\", 2004, 2.775319, 4502230 ], [ \"Pakistan\", 2005, 3.152795, 5227831 ], [ \"Pakistan\", 2006, 3.092005, 5240012 ], [ \"Pakistan\", 2007, 2.775306, 4806206 ], [ \"Pakistan\", 2008, 2.495826, 4416417 ], [ \"Pakistan\", 2009, 1.948609, 3523242 ], [ \"Palau\", 2002, 35.0625, 6928 ], [ \"Palau\", 2003, 37.02401, 7370 ], [ \"Palau\", 2004, 38.71242, 7751 ], [ \"Palau\", 2005, 39.63727, 7977 ], [ \"Palau\", 2006, 36.23325, 7326 ], [ \"Palau\", 2007, 36.81048, 7474 ], [ \"Palau\", 2008, 36.06927, 7352 ], [ \"Palau\", 2009, 34.50653, 7059 ], [ \"Palestinian Authority\", 1992, 3.133881, 73000 ], [ \"Palestinian Authority\", 1993, 3.095963, 75000 ], [ \"Palestinian Authority\", 1994, 3.112844, 78400 ], [ \"Palestinian Authority\", 1995, 3.056747, 80000 ], [ \"Palestinian Authority\", 1996, 3.0678, 83381 ], [ \"Palestinian Authority\", 1997, 3.930861, 110893 ], [ \"Palestinian Authority\", 1998, 5.714732, 167271 ], [ \"Palestinian Authority\", 1999, 7.317953, 222198 ], [ \"Palestinian Authority\", 2000, 8.643168, 272212 ], [ \"Palestinian Authority\", 2001, 8.940034, 292022 ], [ \"Palestinian Authority\", 2002, 8.904026, 301579 ], [ \"Palestinian Authority\", 2003, 7.179809, 252038 ], [ \"Palestinian Authority\", 2004, 7.976915, 290010 ], [ \"Palestinian Authority\", 2005, 9.276117, 348968 ], [ \"Palestinian Authority\", 2006, 8.776204, 341330 ], [ \"Palestinian Authority\", 2007, 8.660942, 347953 ], [ \"Palestinian Authority\", 2008, 8.392046, 348000 ], [ \"Palestinian Authority\", 2009, 8.135859, 348000 ], [ \"Panama\", 1978, 5.952544, 110700 ], [ \"Panama\", 1979, 6.324752, 120500 ], [ \"Panama\", 1980, 6.495484, 126700 ], [ \"Panama\", 1981, 6.855932, 136830 ], [ \"Panama\", 1982, 7.142542, 145772 ], [ \"Panama\", 1983, 7.190984, 150005 ], [ \"Panama\", 1984, 7.37753, 157237 ], [ \"Panama\", 1985, 7.721033, 168078 ], [ \"Panama\", 1986, 7.947389, 176654 ], [ \"Panama\", 1987, 8.492462, 192700 ], [ \"Panama\", 1988, 8.525757, 197452 ], [ \"Panama\", 1989, 8.50545, 201044 ], [ \"Panama\", 1990, 8.954246, 216026 ], [ \"Panama\", 1991, 9.315074, 229389 ], [ \"Panama\", 1992, 9.654895, 242692 ], [ \"Panama\", 1993, 10.18963, 261447 ], [ \"Panama\", 1994, 10.97106, 287317 ], [ \"Panama\", 1995, 11.3724, 303950 ], [ \"Panama\", 1996, 11.927, 325284 ], [ \"Panama\", 1997, 13.1436, 365733 ], [ \"Panama\", 1998, 14.75313, 418756 ], [ \"Panama\", 1999, 15.97747, 462476 ], [ \"Panama\", 2000, 14.543, 429135 ], [ \"Panama\", 2001, 12.70052, 381912 ], [ \"Panama\", 2002, 12.63036, 386904 ], [ \"Panama\", 2003, 12.22718, 381421 ], [ \"Panama\", 2004, 13.37747, 424811 ], [ \"Panama\", 2005, 14.55779, 470453 ], [ \"Panama\", 2006, 14.85314, 488308 ], [ \"Panama\", 2007, 14.81303, 495250 ], [ \"Panama\", 2008, 15.41707, 523999 ], [ \"Panama\", 2009, 15.55052, 537099 ], [ \"Papua New Guinea\", 1965, 0.1862237, 4263 ], [ \"Papua New Guinea\", 1970, 0.4111662, 10500 ], [ \"Papua New Guinea\", 1975, 0.6105858, 17500 ], [ \"Papua New Guinea\", 1976, 0.6076548, 17800 ], [ \"Papua New Guinea\", 1977, 0.6148779, 18400 ], [ \"Papua New Guinea\", 1978, 0.6771008, 20700 ], [ \"Papua New Guinea\", 1979, 0.7294837, 22800 ], [ \"Papua New Guinea\", 1980, 0.7946818, 25422 ], [ \"Papua New Guinea\", 1981, 0.7794729, 25554 ], [ \"Papua New Guinea\", 1982, 0.7502685, 25232 ], [ \"Papua New Guinea\", 1983, 0.7986315, 27569 ], [ \"Papua New Guinea\", 1984, 0.7904027, 28009 ], [ \"Papua New Guinea\", 1985, 0.8249728, 30002 ], [ \"Papua New Guinea\", 1986, 0.797096, 29740 ], [ \"Papua New Guinea\", 1987, 0.795072, 30428 ], [ \"Papua New Guinea\", 1988, 0.7895714, 30993 ], [ \"Papua New Guinea\", 1989, 0.7696883, 30991 ], [ \"Papua New Guinea\", 1990, 0.7307302, 30187 ], [ \"Papua New Guinea\", 1991, 0.79909, 33875 ], [ \"Papua New Guinea\", 1992, 0.8381171, 36464 ], [ \"Papua New Guinea\", 1993, 0.8804584, 39321 ], [ \"Papua New Guinea\", 1994, 0.8726986, 40017 ], [ \"Papua New Guinea\", 1995, 0.9268372, 43648 ], [ \"Papua New Guinea\", 1996, 0.967284, 46796 ], [ \"Papua New Guinea\", 1997, 1.088104, 54087 ], [ \"Papua New Guinea\", 1998, 1.114839, 56938 ], [ \"Papua New Guinea\", 1999, 1.139296, 59773 ], [ \"Papua New Guinea\", 2000, 1.203409, 64835 ], [ \"Papua New Guinea\", 2001, 1.114036, 61610 ], [ \"Papua New Guinea\", 2002, 1.093609, 62059 ], [ \"Papua New Guinea\", 2003, 1.080368, 62885 ], [ \"Papua New Guinea\", 2004, 1.063179, 63456 ], [ \"Papua New Guinea\", 2005, 1.041482, 63720 ], [ \"Papua New Guinea\", 2006, 0.9809179, 61500 ], [ \"Papua New Guinea\", 2007, 0.9342049, 60000 ], [ \"Papua New Guinea\", 2008, 0.9122947, 60000 ], [ \"Papua New Guinea\", 2009, 0.8912445, 60000 ], [ \"Paraguay\", 1960, 0.4444618, 8189 ], [ \"Paraguay\", 1965, 0.4704367, 9790 ], [ \"Paraguay\", 1970, 0.778549, 18299 ], [ \"Paraguay\", 1975, 1.127433, 29977 ], [ \"Paraguay\", 1976, 1.111028, 31957 ], [ \"Paraguay\", 1977, 1.195406, 35271 ], [ \"Paraguay\", 1978, 1.325823, 40153 ], [ \"Paraguay\", 1979, 1.473805, 45852 ], [ \"Paraguay\", 1980, 1.547688, 49508 ], [ \"Paraguay\", 1981, 1.662878, 54741 ], [ \"Paraguay\", 1982, 1.795941, 60884 ], [ \"Paraguay\", 1983, 1.936613, 67632 ], [ \"Paraguay\", 1984, 2.024618, 72828 ], [ \"Paraguay\", 1985, 2.082732, 77134 ], [ \"Paraguay\", 1986, 2.117905, 80714 ], [ \"Paraguay\", 1987, 2.184761, 85636 ], [ \"Paraguay\", 1988, 2.342406, 94380 ], [ \"Paraguay\", 1989, 2.496162, 103323 ], [ \"Paraguay\", 1990, 2.646095, 112452 ], [ \"Paraguay\", 1991, 2.757512, 120237 ], [ \"Paraguay\", 1992, 2.864086, 128051 ], [ \"Paraguay\", 1993, 3.105552, 142277 ], [ \"Paraguay\", 1994, 3.221512, 151143 ], [ \"Paraguay\", 1995, 3.475663, 166895 ], [ \"Paraguay\", 1996, 3.589807, 176320 ], [ \"Paraguay\", 1997, 4.341306, 217988 ], [ \"Paraguay\", 1998, 5.081874, 260736 ], [ \"Paraguay\", 1999, 5.115735, 268080 ], [ \"Paraguay\", 2000, 5.287786, 282909 ], [ \"Paraguay\", 2001, 5.289191, 288818 ], [ \"Paraguay\", 2002, 4.90418, 273218 ], [ \"Paraguay\", 2003, 4.941769, 280790 ], [ \"Paraguay\", 2004, 5.237781, 303425 ], [ \"Paraguay\", 2005, 5.424891, 320294 ], [ \"Paraguay\", 2006, 5.503576, 331061 ], [ \"Paraguay\", 2007, 6.437718, 394416 ], [ \"Paraguay\", 2008, 5.937634, 370381 ], [ \"Paraguay\", 2009, 6.100536, 387318 ], [ \"Peru\", 1965, 0.723802, 83000 ], [ \"Peru\", 1970, 1.061195, 140000 ], [ \"Peru\", 1975, 1.576399, 239000 ], [ \"Peru\", 1976, 1.629678, 254000 ], [ \"Peru\", 1977, 1.668985, 267300 ], [ \"Peru\", 1978, 1.700774, 279800 ], [ \"Peru\", 1979, 1.699263, 287000 ], [ \"Peru\", 1980, 1.747499, 302815 ], [ \"Peru\", 1981, 1.810457, 321651 ], [ \"Peru\", 1982, 1.821083, 331497 ], [ \"Peru\", 1983, 1.939938, 361620 ], [ \"Peru\", 1984, 2.01394, 384281 ], [ \"Peru\", 1985, 2.114264, 412819 ], [ \"Peru\", 1986, 2.229471, 445317 ], [ \"Peru\", 1987, 2.223175, 454100 ], [ \"Peru\", 1988, 2.344057, 489400 ], [ \"Peru\", 1989, 2.488024, 530674 ], [ \"Peru\", 1990, 2.592314, 564504 ], [ \"Peru\", 1991, 2.430077, 539914 ], [ \"Peru\", 1992, 2.70895, 613711 ], [ \"Peru\", 1993, 2.915089, 673021 ], [ \"Peru\", 1994, 3.284426, 772390 ], [ \"Peru\", 1995, 4.632746, 1109231 ], [ \"Peru\", 1996, 5.889666, 1435147 ], [ \"Peru\", 1997, 6.64013, 1645920 ], [ \"Peru\", 1998, 6.170507, 1555093 ], [ \"Peru\", 1999, 6.591632, 1688000 ], [ \"Peru\", 2000, 6.603239, 1717117 ], [ \"Peru\", 2001, 5.952951, 1570956 ], [ \"Peru\", 2002, 6.189527, 1656624 ], [ \"Peru\", 2003, 6.778903, 1839165 ], [ \"Peru\", 2004, 7.457304, 2049822 ], [ \"Peru\", 2005, 8.086391, 2250922 ], [ \"Peru\", 2006, 8.520037, 2400604 ], [ \"Peru\", 2007, 9.377392, 2673352 ], [ \"Peru\", 2008, 9.981049, 2878205 ], [ \"Peru\", 2009, 10.16735, 2965297 ], [ \"Philippines\", 1965, 0.2629369, 83000 ], [ \"Philippines\", 1970, 0.4842497, 177000 ], [ \"Philippines\", 1975, 0.6758895, 284000 ], [ \"Philippines\", 1976, 0.7037553, 304000 ], [ \"Philippines\", 1977, 0.8202244, 364000 ], [ \"Philippines\", 1978, 0.8138256, 371000 ], [ \"Philippines\", 1979, 0.8306575, 389000 ], [ \"Philippines\", 1980, 0.8729658, 420000 ], [ \"Philippines\", 1981, 0.8958405, 442840 ], [ \"Philippines\", 1982, 0.9465072, 480740 ], [ \"Philippines\", 1983, 0.9397159, 490355 ], [ \"Philippines\", 1984, 0.9423426, 505065 ], [ \"Philippines\", 1985, 0.9272222, 510268 ], [ \"Philippines\", 1986, 0.9476887, 535303 ], [ \"Philippines\", 1987, 0.9421306, 546017 ], [ \"Philippines\", 1988, 0.9600475, 570643 ], [ \"Philippines\", 1989, 0.9703589, 591248 ], [ \"Philippines\", 1990, 0.9771851, 610032 ], [ \"Philippines\", 1991, 1.013573, 647939 ], [ \"Philippines\", 1992, 1.009657, 660587 ], [ \"Philippines\", 1993, 1.284543, 859762 ], [ \"Philippines\", 1994, 1.621272, 1109652 ], [ \"Philippines\", 1995, 2.014776, 1409639 ], [ \"Philippines\", 1996, 2.499389, 1787000 ], [ \"Philippines\", 1997, 2.845051, 2078000 ], [ \"Philippines\", 1998, 3.340525, 2491605 ], [ \"Philippines\", 1999, 3.798932, 2892435 ], [ \"Philippines\", 2000, 3.940548, 3061387 ], [ \"Philippines\", 2001, 4.183654, 3315091 ], [ \"Philippines\", 2002, 4.09825, 3310933 ], [ \"Philippines\", 2003, 4.056156, 3340000 ], [ \"Philippines\", 2004, 4.096574, 3437491 ], [ \"Philippines\", 2005, 3.938494, 3367252 ], [ \"Philippines\", 2006, 4.171326, 3633188 ], [ \"Philippines\", 2007, 4.441121, 3940082 ], [ \"Philippines\", 2008, 4.511578, 4076140 ], [ \"Philippines\", 2009, 7.374585, 6783372 ], [ \"Poland\", 1960, 1.805824, 535202 ], [ \"Poland\", 1965, 2.493246, 784000 ], [ \"Poland\", 1970, 3.275762, 1070000 ], [ \"Poland\", 1975, 4.074647, 1386000 ], [ \"Poland\", 1976, 4.570022, 1568000 ], [ \"Poland\", 1977, 4.827659, 1671000 ], [ \"Poland\", 1978, 5.039546, 1760000 ], [ \"Poland\", 1979, 5.254759, 1852000 ], [ \"Poland\", 1980, 5.461831, 1943000 ], [ \"Poland\", 1981, 5.632786, 2023000 ], [ \"Poland\", 1982, 5.814936, 2108590 ], [ \"Poland\", 1983, 6.057157, 2217048 ], [ \"Poland\", 1984, 6.363074, 2349218 ], [ \"Poland\", 1985, 6.686357, 2487451 ], [ \"Poland\", 1986, 7.010949, 2625111 ], [ \"Poland\", 1987, 7.369819, 2774410 ], [ \"Poland\", 1988, 7.808146, 2952807 ], [ \"Poland\", 1989, 8.228759, 3124400 ], [ \"Poland\", 1990, 8.640599, 3293000 ], [ \"Poland\", 1991, 9.322296, 3565294 ], [ \"Poland\", 1992, 10.26422, 3938144 ], [ \"Poland\", 1993, 11.4777, 4415800 ], [ \"Poland\", 1994, 12.98575, 5006094 ], [ \"Poland\", 1995, 14.84259, 5728497 ], [ \"Poland\", 1996, 16.92152, 6532394 ], [ \"Poland\", 1997, 19.46466, 7510000 ], [ \"Poland\", 1998, 22.86567, 8812342 ], [ \"Poland\", 1999, 26.43828, 10175200 ], [ \"Poland\", 2000, 28.4797, 10945570 ], [ \"Poland\", 2001, 29.70201, 11400000 ], [ \"Poland\", 2002, 30.94431, 11861270 ], [ \"Poland\", 2003, 32.10899, 12292450 ], [ \"Poland\", 2004, 32.82877, 12553480 ], [ \"Poland\", 2005, 30.98623, 11836240 ], [ \"Poland\", 2006, 30.07032, 11475610 ], [ \"Poland\", 2007, 27.51108, 10490570 ], [ \"Poland\", 2008, 25.52342, 9725452 ], [ \"Poland\", 2009, 25.18022, 9587054 ], [ \"Portugal\", 1960, 1.08038, 95697 ], [ \"Portugal\", 1965, 4.545153, 409000 ], [ \"Portugal\", 1970, 6.243932, 542000 ], [ \"Portugal\", 1975, 8.555655, 778000 ], [ \"Portugal\", 1976, 8.892084, 820602 ], [ \"Portugal\", 1977, 9.220772, 864257 ], [ \"Portugal\", 1978, 9.50107, 904284 ], [ \"Portugal\", 1979, 9.735165, 939599 ], [ \"Portugal\", 1980, 10.13146, 989470 ], [ \"Portugal\", 1981, 10.72499, 1057305 ], [ \"Portugal\", 1982, 11.57604, 1149305 ], [ \"Portugal\", 1983, 12.51692, 1248906 ], [ \"Portugal\", 1984, 13.23397, 1324736 ], [ \"Portugal\", 1985, 13.96416, 1400418 ], [ \"Portugal\", 1986, 15.05634, 1510599 ], [ \"Portugal\", 1987, 16.5238, 1656306 ], [ \"Portugal\", 1988, 18.47965, 1849247 ], [ \"Portugal\", 1989, 21.91151, 2189000 ], [ \"Portugal\", 1990, 23.84197, 2379265 ], [ \"Portugal\", 1991, 27.00352, 2694140 ], [ \"Portugal\", 1992, 30.19315, 3014173 ], [ \"Portugal\", 1993, 32.6149, 3260319 ], [ \"Portugal\", 1994, 34.6912, 3474400 ], [ \"Portugal\", 1995, 36.29132, 3642891 ], [ \"Portugal\", 1996, 37.97529, 3821890 ], [ \"Portugal\", 1997, 39.64856, 4002478 ], [ \"Portugal\", 1998, 40.63564, 4116900 ], [ \"Portugal\", 1999, 41.5719, 4229848 ], [ \"Portugal\", 2000, 42.25452, 4321000 ], [ \"Portugal\", 2001, 42.63616, 4385454 ], [ \"Portugal\", 2002, 42.02569, 4350528 ], [ \"Portugal\", 2003, 41.08162, 4281119 ], [ \"Portugal\", 2004, 40.41372, 4238270 ], [ \"Portugal\", 2005, 40.14271, 4233701 ], [ \"Portugal\", 2006, 40.02534, 4241779 ], [ \"Portugal\", 2007, 39.5056, 4203800 ], [ \"Portugal\", 2008, 38.49844, 4110493 ], [ \"Portugal\", 2009, 39.73933, 4254942 ], [ \"Puerto Rico\", 1975, 8.265279, 242900 ], [ \"Puerto Rico\", 1976, 9.23487, 276200 ], [ \"Puerto Rico\", 1977, 10.07731, 306800 ], [ \"Puerto Rico\", 1978, 10.98141, 340200 ], [ \"Puerto Rico\", 1979, 11.98412, 377400 ], [ \"Puerto Rico\", 1980, 12.92656, 413200 ], [ \"Puerto Rico\", 1981, 13.941, 451600 ], [ \"Puerto Rico\", 1982, 14.45347, 473792 ], [ \"Puerto Rico\", 1983, 15.13297, 501400 ], [ \"Puerto Rico\", 1984, 16.36011, 547462 ], [ \"Puerto Rico\", 1985, 17.56892, 593500 ], [ \"Puerto Rico\", 1986, 18.75743, 639368 ], [ \"Puerto Rico\", 1987, 20.24893, 696100 ], [ \"Puerto Rico\", 1988, 22.02765, 763584 ], [ \"Puerto Rico\", 1989, 23.25361, 812998 ], [ \"Puerto Rico\", 1990, 27.84138, 982187 ], [ \"Puerto Rico\", 1991, 28.9955, 1032758 ], [ \"Puerto Rico\", 1992, 30.46975, 1096225 ], [ \"Puerto Rico\", 1993, 30.14257, 1095446 ], [ \"Puerto Rico\", 1994, 30.80425, 1130238 ], [ \"Puerto Rico\", 1995, 32.31445, 1195921 ], [ \"Puerto Rico\", 1996, 33.62968, 1254088 ], [ \"Puerto Rico\", 1997, 33.47258, 1256646 ], [ \"Puerto Rico\", 1998, 33.40623, 1261733 ], [ \"Puerto Rico\", 1999, 34.0875, 1294704 ], [ \"Puerto Rico\", 2000, 34.02404, 1299291 ], [ \"Puerto Rico\", 2001, 33.5639, 1288439 ], [ \"Puerto Rico\", 2002, 33.08633, 1276493 ], [ \"Puerto Rico\", 2003, 31.28307, 1212779 ], [ \"Puerto Rico\", 2004, 28.54644, 1111894 ], [ \"Puerto Rico\", 2005, 26.52005, 1037700 ], [ \"Puerto Rico\", 2006, 26.40923, 1038000 ], [ \"Puerto Rico\", 2007, 25.65784, 1012909 ], [ \"Puerto Rico\", 2008, 23.94502, 949377 ], [ \"Puerto Rico\", 2009, 22.7481, 905735 ], [ \"Qatar\", 1960, 1.333333, 600 ], [ \"Qatar\", 1965, 4.285714, 3000 ], [ \"Qatar\", 1970, 7.275667, 8100 ], [ \"Qatar\", 1975, 7.185881, 12300 ], [ \"Qatar\", 1976, 7.891484, 14300 ], [ \"Qatar\", 1977, 8.986048, 17100 ], [ \"Qatar\", 1978, 9.04896, 18100 ], [ \"Qatar\", 1979, 10.3489, 22000 ], [ \"Qatar\", 1980, 13.3367, 30600 ], [ \"Qatar\", 1981, 16.40467, 41200 ], [ \"Qatar\", 1982, 18.74959, 51918 ], [ \"Qatar\", 1983, 19.79387, 60400 ], [ \"Qatar\", 1984, 19.43278, 64833 ], [ \"Qatar\", 1985, 19.27184, 69501 ], [ \"Qatar\", 1986, 19.25091, 74281 ], [ \"Qatar\", 1987, 18.91691, 77474 ], [ \"Qatar\", 1988, 19.29578, 83215 ], [ \"Qatar\", 1989, 19.73183, 88913 ], [ \"Qatar\", 1990, 19.69736, 92071 ], [ \"Qatar\", 1991, 20.06385, 96662 ], [ \"Qatar\", 1992, 21.36114, 105527 ], [ \"Qatar\", 1993, 21.8495, 110300 ], [ \"Qatar\", 1994, 22.4753, 115766 ], [ \"Qatar\", 1995, 23.3389, 122701 ], [ \"Qatar\", 1996, 24.83838, 133513 ], [ \"Qatar\", 1997, 25.7406, 141902 ], [ \"Qatar\", 1998, 26.48963, 150508 ], [ \"Qatar\", 1999, 26.27384, 154904 ], [ \"Qatar\", 2000, 25.97059, 160191 ], [ \"Qatar\", 2001, 25.82967, 167446 ], [ \"Qatar\", 2002, 25.78723, 176519 ], [ \"Qatar\", 2003, 25.22283, 184508 ], [ \"Qatar\", 2004, 23.94817, 190876 ], [ \"Qatar\", 2005, 23.19595, 205386 ], [ \"Qatar\", 2006, 22.81885, 228327 ], [ \"Qatar\", 2007, 20.86654, 237368 ], [ \"Qatar\", 2008, 20.56139, 263363 ], [ \"Qatar\", 2009, 20.2402, 285270 ], [ \"Romania\", 1965, 1.607818, 306000 ], [ \"Romania\", 1970, 2.172567, 440000 ], [ \"Romania\", 1975, 4.03387, 857000 ], [ \"Romania\", 1976, 4.588011, 984000 ], [ \"Romania\", 1977, 5.232537, 1133000 ], [ \"Romania\", 1978, 5.94849, 1300000 ], [ \"Romania\", 1979, 6.715155, 1480000 ], [ \"Romania\", 1980, 7.287832, 1618000 ], [ \"Romania\", 1981, 7.611803, 1700000 ], [ \"Romania\", 1982, 7.79865, 1750000 ], [ \"Romania\", 1983, 7.98913, 1800000 ], [ \"Romania\", 1984, 8.398815, 1900000 ], [ \"Romania\", 1985, 8.638126, 1963000 ], [ \"Romania\", 1986, 9.118531, 2083115 ], [ \"Romania\", 1987, 9.450326, 2171222 ], [ \"Romania\", 1988, 9.768908, 2256205 ], [ \"Romania\", 1989, 10.08609, 2337882 ], [ \"Romania\", 1990, 10.19459, 2365830 ], [ \"Romania\", 1991, 10.55324, 2445276 ], [ \"Romania\", 1992, 11.15255, 2574070 ], [ \"Romania\", 1993, 11.34316, 2603600 ], [ \"Romania\", 1994, 12.29811, 2805636 ], [ \"Romania\", 1995, 13.08568, 2967957 ], [ \"Romania\", 1996, 14.0754, 3175533 ], [ \"Romania\", 1997, 15.13621, 3398000 ], [ \"Romania\", 1998, 16.1066, 3599000 ], [ \"Romania\", 1999, 16.81492, 3740000 ], [ \"Romania\", 2000, 17.61329, 3899206 ], [ \"Romania\", 2001, 18.68116, 4116000 ], [ \"Romania\", 2002, 19.22139, 4215235 ], [ \"Romania\", 2003, 19.84304, 4331564 ], [ \"Romania\", 2004, 20.19263, 4388000 ], [ \"Romania\", 2005, 20.25915, 4383000 ], [ \"Romania\", 2006, 19.48831, 4198000 ], [ \"Romania\", 2007, 20.58739, 4416000 ], [ \"Romania\", 2008, 24.38524, 5209000 ], [ \"Romania\", 2009, 25.02029, 5323000 ], [ \"Russia\", 1975, 4.395359, 5900000 ], [ \"Russia\", 1976, 4.812443, 6500000 ], [ \"Russia\", 1977, 5.66487, 7700000 ], [ \"Russia\", 1978, 6.139904, 8400000 ], [ \"Russia\", 1979, 6.680204, 9200000 ], [ \"Russia\", 1980, 6.995762, 9700000 ], [ \"Russia\", 1981, 7.900821, 11030000 ], [ \"Russia\", 1982, 8.416018, 11830000 ], [ \"Russia\", 1983, 8.965791, 12690000 ], [ \"Russia\", 1984, 9.548835, 13610000 ], [ \"Russia\", 1985, 10.17131, 14600000 ], [ \"Russia\", 1986, 10.83174, 15660000 ], [ \"Russia\", 1987, 11.53068, 16790000 ], [ \"Russia\", 1988, 12.27926, 18000000 ], [ \"Russia\", 1989, 13.09135, 19300000 ], [ \"Russia\", 1990, 13.98033, 20700000 ], [ \"Russia\", 1991, 15.01629, 22296490 ], [ \"Russia\", 1992, 15.36642, 22848600 ], [ \"Russia\", 1993, 15.78379, 23475150 ], [ \"Russia\", 1994, 16.21068, 24097260 ], [ \"Russia\", 1995, 16.84807, 25018890 ], [ \"Russia\", 1996, 17.47629, 25914510 ], [ \"Russia\", 1997, 19.08777, 28250450 ], [ \"Russia\", 1998, 19.80794, 29246000 ], [ \"Russia\", 1999, 21.02437, 30949000 ], [ \"Russia\", 2000, 21.86544, 32070000 ], [ \"Russia\", 2001, 22.7868, 33278200 ], [ \"Russia\", 2002, 24.42561, 35500000 ], [ \"Russia\", 2003, 24.96574, 36100000 ], [ \"Russia\", 2004, 26.76143, 38500000 ], [ \"Russia\", 2005, 28.0087, 40100000 ], [ \"Russia\", 2006, 30.80045, 43900000 ], [ \"Russia\", 2007, 31.857, 45218220 ], [ \"Russia\", 2008, 32.2073, 45539290 ], [ \"Russia\", 2009, 32.21298, 45379600 ], [ \"Rwanda\", 1960, 0.04730897, 1366 ], [ \"Rwanda\", 1965, 0.01873586, 600 ], [ \"Rwanda\", 1970, 0.03178107, 1200 ], [ \"Rwanda\", 1975, 0.05215373, 2300 ], [ \"Rwanda\", 1976, 0.05049719, 2300 ], [ \"Rwanda\", 1977, 0.05311806, 2500 ], [ \"Rwanda\", 1978, 0.05550088, 2700 ], [ \"Rwanda\", 1979, 0.05568216, 2800 ], [ \"Rwanda\", 1980, 0.0634983, 3300 ], [ \"Rwanda\", 1981, 0.06228702, 3340 ], [ \"Rwanda\", 1982, 0.07304078, 4034 ], [ \"Rwanda\", 1983, 0.08198372, 4666 ], [ \"Rwanda\", 1984, 0.08334883, 4905 ], [ \"Rwanda\", 1985, 0.08456381, 5168 ], [ \"Rwanda\", 1986, 0.08514047, 5444 ], [ \"Rwanda\", 1987, 0.09764469, 6561 ], [ \"Rwanda\", 1988, 0.1165017, 8171 ], [ \"Rwanda\", 1989, 0.1283514, 9213 ], [ \"Rwanda\", 1990, 0.1451828, 10381 ], [ \"Rwanda\", 1991, 0.1640725, 11298 ], [ \"Rwanda\", 1992, 0.182936, 11763 ], [ \"Rwanda\", 1993, 0.1858214, 11000 ], [ \"Rwanda\", 1994, 0.1803221, 10000 ], [ \"Rwanda\", 1995, 0.126828, 6900 ], [ \"Rwanda\", 1996, 0.1811619, 10254 ], [ \"Rwanda\", 1997, 0.1889332, 11621 ], [ \"Rwanda\", 1998, 0.1591758, 10825 ], [ \"Rwanda\", 1999, 0.1699699, 12651 ], [ \"Rwanda\", 2000, 0.2207646, 17568 ], [ \"Rwanda\", 2001, 0.2587228, 21500 ], [ \"Rwanda\", 2002, 0.2940144, 25105 ], [ \"Rwanda\", 2003, 0.2943426, 25565 ], [ \"Rwanda\", 2004, 0.2604627, 22972 ], [ \"Rwanda\", 2005, 0.2624626, 23601 ], [ \"Rwanda\", 2006, 0.2536592, 23362 ], [ \"Rwanda\", 2007, 0.2445705, 23123 ], [ \"Rwanda\", 2008, 0.1725186, 16770 ], [ \"Rwanda\", 2009, 0.3345898, 33451 ], [ \"Saint Kitts and Nevis\", 1983, 5.174036, 2200 ], [ \"Saint Kitts and Nevis\", 1984, 5.558184, 2350 ], [ \"Saint Kitts and Nevis\", 1985, 7.024478, 2950 ], [ \"Saint Kitts and Nevis\", 1986, 10.37115, 4320 ], [ \"Saint Kitts and Nevis\", 1987, 12.7674, 5270 ], [ \"Saint Kitts and Nevis\", 1988, 17.23868, 7057 ], [ \"Saint Kitts and Nevis\", 1989, 19.9504, 8125 ], [ \"Saint Kitts and Nevis\", 1990, 23.85538, 9712 ], [ \"Saint Kitts and Nevis\", 1991, 24.84788, 10168 ], [ \"Saint Kitts and Nevis\", 1992, 27.89634, 11529 ], [ \"Saint Kitts and Nevis\", 1993, 29.20865, 12232 ], [ \"Saint Kitts and Nevis\", 1994, 31.99962, 13596 ], [ \"Saint Kitts and Nevis\", 1995, 33.4362, 14410 ], [ \"Saint Kitts and Nevis\", 1996, 35.80764, 15644 ], [ \"Saint Kitts and Nevis\", 1997, 38.80432, 17181 ], [ \"Saint Kitts and Nevis\", 1998, 40.94608, 18368 ], [ \"Saint Kitts and Nevis\", 1999, 44.13421, 20059 ], [ \"Saint Kitts and Nevis\", 2000, 47.57562, 21910 ], [ \"Saint Kitts and Nevis\", 2001, 48.21704, 22500 ], [ \"Saint Kitts and Nevis\", 2002, 49.7081, 23500 ], [ \"Saint Kitts and Nevis\", 2003, 49.07181, 23500 ], [ \"Saint Kitts and Nevis\", 2004, 41.95098, 20350 ], [ \"Saint Kitts and Nevis\", 2005, 41.31222, 20300 ], [ \"Saint Kitts and Nevis\", 2006, 41.48752, 20650 ], [ \"Saint Kitts and Nevis\", 2007, 40.56171, 20450 ], [ \"Saint Kitts and Nevis\", 2008, 39.94909, 20400 ], [ \"Saint Kitts and Nevis\", 2009, 39.64034, 20500 ], [ \"Saint Lucia\", 1970, 2.014408, 2100 ], [ \"Saint Lucia\", 1975, 3.277077, 3600 ], [ \"Saint Lucia\", 1976, 3.324349, 3700 ], [ \"Saint Lucia\", 1977, 3.453712, 3900 ], [ \"Saint Lucia\", 1978, 3.6631, 4200 ], [ \"Saint Lucia\", 1979, 3.951618, 4600 ], [ \"Saint Lucia\", 1980, 4.063974, 4800 ], [ \"Saint Lucia\", 1981, 4.176063, 5000 ], [ \"Saint Lucia\", 1982, 4.083332, 4953 ], [ \"Saint Lucia\", 1983, 4.068514, 5000 ], [ \"Saint Lucia\", 1984, 5.341956, 6658 ], [ \"Saint Lucia\", 1985, 5.975007, 7564 ], [ \"Saint Lucia\", 1986, 6.373828, 8210 ], [ \"Saint Lucia\", 1987, 6.78351, 8902 ], [ \"Saint Lucia\", 1988, 8.163662, 10918 ], [ \"Saint Lucia\", 1989, 9.195326, 12521 ], [ \"Saint Lucia\", 1990, 12.28377, 17000 ], [ \"Saint Lucia\", 1991, 12.23205, 17170 ], [ \"Saint Lucia\", 1992, 14.27727, 20293 ], [ \"Saint Lucia\", 1993, 16.84715, 24223 ], [ \"Saint Lucia\", 1994, 17.19688, 25012 ], [ \"Saint Lucia\", 1995, 20.76835, 30576 ], [ \"Saint Lucia\", 1996, 22.65035, 33783 ], [ \"Saint Lucia\", 1997, 24.4682, 36992 ], [ \"Saint Lucia\", 1998, 26.34316, 40373 ], [ \"Saint Lucia\", 1999, 28.63703, 44465 ], [ \"Saint Lucia\", 2000, 31.11558, 48900 ], [ \"Saint Lucia\", 2001, 31.46871, 50000 ], [ \"Saint Lucia\", 2002, 31.85129, 51121 ], [ \"Saint Lucia\", 2003, 30.23945, 49000 ], [ \"Saint Lucia\", 2004, 25.67426, 42000 ], [ \"Saint Lucia\", 2005, 23.60818, 39000 ], [ \"Saint Lucia\", 2006, 24.50804, 40900 ], [ \"Saint Lucia\", 2007, 24.25457, 40900 ], [ \"Saint Lucia\", 2008, 24.02455, 40940 ], [ \"Saint Lucia\", 2009, 23.81104, 41000 ], [ \"Samoa\", 1981, 2.232912, 3472 ], [ \"Samoa\", 1982, 2.278036, 3550 ], [ \"Samoa\", 1983, 2.305815, 3600 ], [ \"Samoa\", 1984, 2.332775, 3650 ], [ \"Samoa\", 1985, 2.357769, 3700 ], [ \"Samoa\", 1986, 2.380302, 3750 ], [ \"Samoa\", 1987, 2.400445, 3800 ], [ \"Samoa\", 1988, 2.481093, 3950 ], [ \"Samoa\", 1989, 2.496598, 4000 ], [ \"Samoa\", 1990, 2.541375, 4100 ], [ \"Samoa\", 1991, 2.563897, 4167 ], [ \"Samoa\", 1992, 3.968133, 6500 ], [ \"Samoa\", 1993, 4.298263, 7100 ], [ \"Samoa\", 1994, 4.439725, 7400 ], [ \"Samoa\", 1995, 4.634994, 7800 ], [ \"Samoa\", 1996, 4.852873, 8251 ], [ \"Samoa\", 1997, 4.917689, 8451 ], [ \"Samoa\", 1998, 4.883611, 8480 ], [ \"Samoa\", 1999, 4.850242, 8500 ], [ \"Samoa\", 2000, 4.825665, 8520 ], [ \"Samoa\", 2001, 5.44712, 9670 ], [ \"Samoa\", 2002, 6.614399, 11786 ], [ \"Samoa\", 2003, 7.439738, 13287 ], [ \"Samoa\", 2004, 9.167035, 16393.5 ], [ \"Samoa\", 2005, 10.89592, 19500 ], [ \"Samoa\", 2006, 12.62542, 22600 ], [ \"Samoa\", 2007, 14.36171, 25700 ], [ \"Samoa\", 2008, 16.10117, 28800 ], [ \"Samoa\", 2009, 17.83657, 31900 ], [ \"San Marino\", 1983, 31.41549, 7000 ], [ \"San Marino\", 1984, 31.93613, 7200 ], [ \"San Marino\", 1985, 33.32164, 7600 ], [ \"San Marino\", 1986, 35.54092, 8200 ], [ \"San Marino\", 1987, 36.85609, 8600 ], [ \"San Marino\", 1988, 37.37605, 8820 ], [ \"San Marino\", 1989, 40.46333, 9659 ], [ \"San Marino\", 1990, 42.41596, 10246 ], [ \"San Marino\", 1991, 44.1483, 10800 ], [ \"San Marino\", 1992, 54.47358, 13504 ], [ \"San Marino\", 1993, 56.13281, 14100 ], [ \"San Marino\", 1994, 56.7608, 14432 ], [ \"San Marino\", 1995, 62.6114, 16088 ], [ \"San Marino\", 1996, 65.85742, 17063 ], [ \"San Marino\", 1997, 67.2392, 17538 ], [ \"San Marino\", 1998, 73.5686, 19325 ], [ \"San Marino\", 1999, 74.99623, 19904 ], [ \"San Marino\", 2000, 75.34048, 20302 ], [ \"San Marino\", 2001, 74.51657, 20501 ], [ \"San Marino\", 2002, 73.02988, 20601 ], [ \"San Marino\", 2003, 71.43992, 20689 ], [ \"San Marino\", 2004, 69.96359, 20754 ], [ \"San Marino\", 2005, 68.93826, 20849 ], [ \"San Marino\", 2006, 68.46635, 21000 ], [ \"San Marino\", 2007, 68.05708, 21080 ], [ \"San Marino\", 2008, 68.30426, 21300 ], [ \"San Marino\", 2009, 68.56305, 21500 ], [ \"Sao Tome and Principe\", 1960, 0.5466433, 352 ], [ \"Sao Tome and Principe\", 1975, 0.6088651, 500 ], [ \"Sao Tome and Principe\", 1976, 0.5920733, 500 ], [ \"Sao Tome and Principe\", 1977, 0.6893541, 600 ], [ \"Sao Tome and Principe\", 1978, 0.6685982, 600 ], [ \"Sao Tome and Principe\", 1981, 0.8250535, 798 ], [ \"Sao Tome and Principe\", 1982, 1.240584, 1222 ], [ \"Sao Tome and Principe\", 1983, 1.552485, 1555 ], [ \"Sao Tome and Principe\", 1984, 1.732107, 1765 ], [ \"Sao Tome and Principe\", 1985, 1.804491, 1874 ], [ \"Sao Tome and Principe\", 1986, 1.886579, 2001 ], [ \"Sao Tome and Principe\", 1987, 1.951422, 2117 ], [ \"Sao Tome and Principe\", 1988, 2.017327, 2240 ], [ \"Sao Tome and Principe\", 1989, 1.936449, 2200 ], [ \"Sao Tome and Principe\", 1990, 1.894641, 2200 ], [ \"Sao Tome and Principe\", 1991, 1.87113, 2218 ], [ \"Sao Tome and Principe\", 1992, 1.951962, 2360 ], [ \"Sao Tome and Principe\", 1993, 1.936154, 2386 ], [ \"Sao Tome and Principe\", 1994, 1.959082, 2460 ], [ \"Sao Tome and Principe\", 1995, 1.953336, 2499 ], [ \"Sao Tome and Principe\", 1996, 1.99176, 2596 ], [ \"Sao Tome and Principe\", 1997, 3.238903, 4300 ], [ \"Sao Tome and Principe\", 1998, 3.176658, 4295 ], [ \"Sao Tome and Principe\", 1999, 3.287715, 4526 ], [ \"Sao Tome and Principe\", 2000, 3.292633, 4614 ], [ \"Sao Tome and Principe\", 2001, 3.8153, 5441 ], [ \"Sao Tome and Principe\", 2002, 4.387138, 6366 ], [ \"Sao Tome and Principe\", 2003, 4.72187, 6970 ], [ \"Sao Tome and Principe\", 2004, 4.696306, 7050 ], [ \"Sao Tome and Principe\", 2005, 4.659879, 7112 ], [ \"Sao Tome and Principe\", 2006, 4.894731, 7593 ], [ \"Sao Tome and Principe\", 2007, 4.855459, 7654 ], [ \"Sao Tome and Principe\", 2008, 4.807272, 7700 ], [ \"Sao Tome and Principe\", 2009, 4.79248, 7800 ], [ \"Saudi Arabia\", 1970, 1.629317, 93600 ], [ \"Saudi Arabia\", 1975, 1.90308, 138000 ], [ \"Saudi Arabia\", 1976, 1.843782, 141000 ], [ \"Saudi Arabia\", 1977, 1.89426, 153000 ], [ \"Saudi Arabia\", 1978, 2.304973, 196938 ], [ \"Saudi Arabia\", 1979, 3.06309, 277288 ], [ \"Saudi Arabia\", 1980, 3.327401, 319576 ], [ \"Saudi Arabia\", 1981, 5.023001, 512205 ], [ \"Saudi Arabia\", 1982, 6.408715, 693799 ], [ \"Saudi Arabia\", 1983, 6.884673, 790711 ], [ \"Saudi Arabia\", 1984, 7.313964, 889966 ], [ \"Saudi Arabia\", 1985, 7.040637, 905909 ], [ \"Saudi Arabia\", 1986, 7.047477, 957357 ], [ \"Saudi Arabia\", 1987, 7.014173, 1003982 ], [ \"Saudi Arabia\", 1988, 7.117524, 1069433 ], [ \"Saudi Arabia\", 1989, 7.171779, 1124681 ], [ \"Saudi Arabia\", 1990, 7.589706, 1234000 ], [ \"Saudi Arabia\", 1991, 8.758383, 1466311 ], [ \"Saudi Arabia\", 1992, 9.148585, 1568370 ], [ \"Saudi Arabia\", 1993, 9.227707, 1614676 ], [ \"Saudi Arabia\", 1994, 9.384089, 1675654 ], [ \"Saudi Arabia\", 1995, 9.419054, 1719412 ], [ \"Saudi Arabia\", 1996, 9.602588, 1796041 ], [ \"Saudi Arabia\", 1997, 9.779243, 1877049 ], [ \"Saudi Arabia\", 1998, 10.99012, 2167037 ], [ \"Saudi Arabia\", 1999, 13.35732, 2706182 ], [ \"Saudi Arabia\", 2000, 14.24805, 2964730 ], [ \"Saudi Arabia\", 2001, 15.13349, 3232925 ], [ \"Saudi Arabia\", 2002, 15.58324, 3417000 ], [ \"Saudi Arabia\", 2003, 15.57032, 3502629 ], [ \"Saudi Arabia\", 2004, 16.02456, 3695133 ], [ \"Saudi Arabia\", 2005, 16.27939, 3844000 ], [ \"Saudi Arabia\", 2006, 16.35845, 3951000 ], [ \"Saudi Arabia\", 2007, 16.19102, 3996000 ], [ \"Saudi Arabia\", 2008, 16.26951, 4100000 ], [ \"Saudi Arabia\", 2009, 16.21657, 4171000 ], [ \"Senegal\", 1960, 0.2708307, 9494 ], [ \"Senegal\", 1965, 0.2506813, 10000 ], [ \"Senegal\", 1970, 0.2413191, 11038 ], [ \"Senegal\", 1975, 0.2742555, 14432 ], [ \"Senegal\", 1976, 0.2959735, 14900 ], [ \"Senegal\", 1977, 0.2943819, 15249 ], [ \"Senegal\", 1978, 0.292619, 15589 ], [ \"Senegal\", 1979, 0.3157622, 17300 ], [ \"Senegal\", 1980, 0.3193929, 18001 ], [ \"Senegal\", 1981, 0.3258934, 18900 ], [ \"Senegal\", 1982, 0.3255241, 19430 ], [ \"Senegal\", 1983, 0.3231582, 19856 ], [ \"Senegal\", 1984, 0.333259, 21082 ], [ \"Senegal\", 1985, 0.3402506, 22163 ], [ \"Senegal\", 1986, 0.3698227, 24807 ], [ \"Senegal\", 1987, 0.3966586, 27402 ], [ \"Senegal\", 1988, 0.406701, 28933 ], [ \"Senegal\", 1989, 0.4937874, 36166 ], [ \"Senegal\", 1990, 0.5880527, 44326 ], [ \"Senegal\", 1991, 0.6250471, 48469 ], [ \"Senegal\", 1992, 0.7285043, 58095 ], [ \"Senegal\", 1993, 0.7789646, 63863 ], [ \"Senegal\", 1994, 0.8554796, 72089 ], [ \"Senegal\", 1995, 0.9467539, 81988 ], [ \"Senegal\", 1996, 1.068418, 95070 ], [ \"Senegal\", 1997, 1.267849, 115902 ], [ \"Senegal\", 1998, 1.48613, 139549 ], [ \"Senegal\", 1999, 1.720063, 165874 ], [ \"Senegal\", 2000, 2.079301, 205888 ], [ \"Senegal\", 2001, 2.333166, 237160 ], [ \"Senegal\", 2002, 2.153075, 224623 ], [ \"Senegal\", 2003, 2.137338, 228844 ], [ \"Senegal\", 2004, 2.228937, 244948 ], [ \"Senegal\", 2005, 2.36331, 266612 ], [ \"Senegal\", 2006, 2.439578, 282573 ], [ \"Senegal\", 2007, 2.262511, 269088 ], [ \"Senegal\", 2008, 1.947003, 237752 ], [ \"Senegal\", 2009, 2.224214, 278788 ], [ \"Serbia\", 2004, 27.13778, 2685419 ], [ \"Serbia\", 2005, 25.64289, 2527328 ], [ \"Serbia\", 2006, 27.65029, 2719402 ], [ \"Serbia\", 2007, 30.44703, 2993403 ], [ \"Serbia\", 2008, 31.35193, 3084872 ], [ \"Serbia\", 2009, 31.53073, 3105728 ], [ \"Seychelles\", 1965, 0.4526388, 232 ], [ \"Seychelles\", 1970, 0.8046229, 440 ], [ \"Seychelles\", 1975, 2.475372, 1480 ], [ \"Seychelles\", 1976, 2.748975, 1710 ], [ \"Seychelles\", 1977, 3.558439, 2260 ], [ \"Seychelles\", 1978, 3.822583, 2470 ], [ \"Seychelles\", 1979, 4.352142, 2850 ], [ \"Seychelles\", 1980, 5.294046, 3500 ], [ \"Seychelles\", 1981, 5.267118, 3500 ], [ \"Seychelles\", 1982, 6.066254, 4036 ], [ \"Seychelles\", 1983, 6.783636, 4512 ], [ \"Seychelles\", 1984, 8.394884, 5592 ], [ \"Seychelles\", 1985, 8.798149, 5893 ], [ \"Seychelles\", 1986, 9.928051, 6720 ], [ \"Seychelles\", 1987, 9.900702, 6800 ], [ \"Seychelles\", 1988, 10.33831, 7221 ], [ \"Seychelles\", 1989, 10.71916, 7610.5 ], [ \"Seychelles\", 1990, 12.05216, 8679 ], [ \"Seychelles\", 1991, 12.83586, 9349 ], [ \"Seychelles\", 1992, 13.69498, 10068 ], [ \"Seychelles\", 1993, 14.71386, 10909 ], [ \"Seychelles\", 1994, 16.1814, 12110 ], [ \"Seychelles\", 1995, 17.3206, 13111 ], [ \"Seychelles\", 1996, 20.47193, 15712 ], [ \"Seychelles\", 1997, 22.89307, 17844 ], [ \"Seychelles\", 1998, 23.68291, 18750 ], [ \"Seychelles\", 1999, 24.4615, 19635 ], [ \"Seychelles\", 2000, 25.41755, 20621 ], [ \"Seychelles\", 2001, 26.00421, 21247 ], [ \"Seychelles\", 2002, 25.89889, 21249 ], [ \"Seychelles\", 2003, 25.76915, 21191 ], [ \"Seychelles\", 2004, 25.81099, 21268 ], [ \"Seychelles\", 2005, 25.90217, 21404 ], [ \"Seychelles\", 2006, 24.92317, 20679 ], [ \"Seychelles\", 2007, 27.25049, 22722 ], [ \"Seychelles\", 2008, 26.62802, 22322 ], [ \"Seychelles\", 2009, 30.95385, 26078 ], [ \"Sierra Leone\", 1965, 0.109832, 2700 ], [ \"Sierra Leone\", 1980, 0.3511329, 11450 ], [ \"Sierra Leone\", 1981, 0.3454155, 11500 ], [ \"Sierra Leone\", 1982, 0.3547391, 12050 ], [ \"Sierra Leone\", 1983, 0.366034, 12690 ], [ \"Sierra Leone\", 1984, 0.4133549, 14650 ], [ \"Sierra Leone\", 1985, 0.349478, 12690 ], [ \"Sierra Leone\", 1986, 0.404673, 15100 ], [ \"Sierra Leone\", 1987, 0.3293045, 12650 ], [ \"Sierra Leone\", 1988, 0.3204274, 12650 ], [ \"Sierra Leone\", 1989, 0.3189055, 12860 ], [ \"Sierra Leone\", 1990, 0.3252111, 13280 ], [ \"Sierra Leone\", 1991, 0.3310388, 13560 ], [ \"Sierra Leone\", 1992, 0.3394002, 13839 ], [ \"Sierra Leone\", 1993, 0.3580802, 14470 ], [ \"Sierra Leone\", 1994, 0.3932302, 15754 ], [ \"Sierra Leone\", 1995, 0.4168701, 16627 ], [ \"Sierra Leone\", 1996, 0.4307763, 17189 ], [ \"Sierra Leone\", 1997, 0.4334927, 17382 ], [ \"Sierra Leone\", 1998, 0.4295196, 17407 ], [ \"Sierra Leone\", 1999, 0.4419923, 18230 ], [ \"Sierra Leone\", 2000, 0.4488931, 18980 ], [ \"Sierra Leone\", 2001, 0.520745, 22745 ], [ \"Sierra Leone\", 2002, 0.5285969, 24000 ], [ \"Sierra Leone\", 2003, 0.5345982, 25300 ], [ \"Sierra Leone\", 2004, 0.5379704, 26500 ], [ \"Sierra Leone\", 2005, 0.5443534, 27800 ], [ \"Sierra Leone\", 2006, 0.5502012, 29000 ], [ \"Sierra Leone\", 2007, 0.5589994, 30300 ], [ \"Sierra Leone\", 2008, 0.5665618, 31500 ], [ \"Sierra Leone\", 2009, 0.5757951, 32800 ], [ \"Singapore\", 1960, 2.271297, 37113 ], [ \"Singapore\", 1965, 3.104726, 58378 ], [ \"Singapore\", 1970, 5.13077, 106443 ], [ \"Singapore\", 1975, 9.298582, 210390 ], [ \"Singapore\", 1976, 11.66185, 267263 ], [ \"Singapore\", 1977, 14.66401, 339896 ], [ \"Singapore\", 1978, 17.71966, 415397 ], [ \"Singapore\", 1979, 20.20704, 480003 ], [ \"Singapore\", 1980, 22.22413, 536602 ], [ \"Singapore\", 1981, 23.93624, 589597 ], [ \"Singapore\", 1982, 25.51215, 643014 ], [ \"Singapore\", 1983, 26.8501, 693580 ], [ \"Singapore\", 1984, 28.70013, 759665 ], [ \"Singapore\", 1985, 29.72499, 805128 ], [ \"Singapore\", 1986, 30.40674, 841373 ], [ \"Singapore\", 1987, 31.37921, 886103 ], [ \"Singapore\", 1988, 32.57404, 938719 ], [ \"Singapore\", 1989, 33.89035, 998073 ], [ \"Singapore\", 1990, 34.94062, 1053942 ], [ \"Singapore\", 1991, 35.56584, 1101079 ], [ \"Singapore\", 1992, 36.73809, 1169089 ], [ \"Singapore\", 1993, 38.02868, 1245571 ], [ \"Singapore\", 1994, 39.45929, 1331730 ], [ \"Singapore\", 1995, 41.04986, 1428607 ], [ \"Singapore\", 1996, 43.49443, 1562682 ], [ \"Singapore\", 1997, 45.39799, 1684949 ], [ \"Singapore\", 1998, 46.44057, 1777900 ], [ \"Singapore\", 1999, 47.71589, 1876600 ], [ \"Singapore\", 2000, 48.42799, 1946000 ], [ \"Singapore\", 2001, 47.73715, 1947500 ], [ \"Singapore\", 2002, 46.77039, 1927200 ], [ \"Singapore\", 2003, 45.4849, 1889500 ], [ \"Singapore\", 2004, 44.22744, 1857000 ], [ \"Singapore\", 2005, 43.22513, 1844400 ], [ \"Singapore\", 2006, 42.47026, 1853500 ], [ \"Singapore\", 2007, 41.51583, 1861800 ], [ \"Singapore\", 2008, 40.64985, 1876000 ], [ \"Singapore\", 2009, 40.65125, 1925600 ], [ \"Slovak Republic\", 1960, 1.913725, 79322 ], [ \"Slovak Republic\", 1965, 3.650025, 159203 ], [ \"Slovak Republic\", 1970, 5.814624, 263313 ], [ \"Slovak Republic\", 1975, 8.088762, 383043 ], [ \"Slovak Republic\", 1976, 8.465662, 404969 ], [ \"Slovak Republic\", 1977, 8.832739, 426955 ], [ \"Slovak Republic\", 1978, 9.18823, 448759 ], [ \"Slovak Republic\", 1979, 9.391478, 463204 ], [ \"Slovak Republic\", 1980, 9.443861, 469964 ], [ \"Slovak Republic\", 1981, 9.560272, 479549 ], [ \"Slovak Republic\", 1982, 9.691972, 489592 ], [ \"Slovak Republic\", 1983, 9.910314, 503780 ], [ \"Slovak Republic\", 1984, 10.21863, 522452 ], [ \"Slovak Republic\", 1985, 10.4918, 539320 ], [ \"Slovak Republic\", 1986, 10.90887, 563585 ], [ \"Slovak Republic\", 1987, 11.44118, 593827 ], [ \"Slovak Republic\", 1988, 12.07006, 629190 ], [ \"Slovak Republic\", 1989, 12.77861, 668915 ], [ \"Slovak Republic\", 1990, 13.52405, 710847 ], [ \"Slovak Republic\", 1991, 14.381, 758999 ], [ \"Slovak Republic\", 1992, 15.49048, 820882 ], [ \"Slovak Republic\", 1993, 16.78259, 892766 ], [ \"Slovak Republic\", 1994, 18.8076, 1003829 ], [ \"Slovak Republic\", 1995, 20.90012, 1118486 ], [ \"Slovak Republic\", 1996, 23.24639, 1246471 ], [ \"Slovak Republic\", 1997, 25.9236, 1391864 ], [ \"Slovak Republic\", 1998, 28.64541, 1539283 ], [ \"Slovak Republic\", 1999, 30.78939, 1655380 ], [ \"Slovak Republic\", 2000, 31.56928, 1697982 ], [ \"Slovak Republic\", 2001, 28.926, 1556254 ], [ \"Slovak Republic\", 2002, 26.06771, 1402725 ], [ \"Slovak Republic\", 2003, 24.05562, 1294673 ], [ \"Slovak Republic\", 2004, 23.22702, 1250415 ], [ \"Slovak Republic\", 2005, 22.22568, 1197044 ], [ \"Slovak Republic\", 2006, 21.66058, 1167390 ], [ \"Slovak Republic\", 2007, 24.28576, 1310027 ], [ \"Slovak Republic\", 2008, 23.86466, 1288645 ], [ \"Slovak Republic\", 2009, 22.56202, 1219645 ], [ \"Slovenia\", 1985, 15.21263, 286481 ], [ \"Slovenia\", 1990, 21.8925, 421803 ], [ \"Slovenia\", 1991, 23.70264, 458717 ], [ \"Slovenia\", 1992, 25.42647, 494268 ], [ \"Slovenia\", 1993, 27.03744, 527827 ], [ \"Slovenia\", 1994, 29.45149, 577173 ], [ \"Slovenia\", 1995, 31.26815, 614796 ], [ \"Slovenia\", 1996, 33.65437, 663497 ], [ \"Slovenia\", 1997, 35.93733, 710044 ], [ \"Slovenia\", 1998, 36.53844, 723204 ], [ \"Slovenia\", 1999, 38.21432, 757563 ], [ \"Slovenia\", 2000, 39.55861, 785399 ], [ \"Slovenia\", 2001, 40.32895, 801877 ], [ \"Slovenia\", 2002, 40.56777, 807787 ], [ \"Slovenia\", 2003, 40.73476, 812322 ], [ \"Slovenia\", 2004, 40.60283, 811022 ], [ \"Slovenia\", 2005, 40.79438, 816365 ], [ \"Slovenia\", 2006, 41.76006, 837462 ], [ \"Slovenia\", 2007, 42.64146, 857148 ], [ \"Slovenia\", 2008, 50.10942, 1009767 ], [ \"Slovenia\", 2009, 51.19332, 1034169 ], [ \"Solomon Islands\", 1982, 0.6105105, 1500 ], [ \"Solomon Islands\", 1983, 0.6680604, 1700 ], [ \"Solomon Islands\", 1984, 0.7598091, 2000 ], [ \"Solomon Islands\", 1985, 0.8218765, 2234 ], [ \"Solomon Islands\", 1986, 0.8858496, 2482 ], [ \"Solomon Islands\", 1987, 0.9646692, 2782 ], [ \"Solomon Islands\", 1988, 1.078996, 3200 ], [ \"Solomon Islands\", 1989, 1.229766, 3750 ], [ \"Solomon Islands\", 1990, 1.490615, 4675 ], [ \"Solomon Islands\", 1991, 1.502981, 4850 ], [ \"Solomon Islands\", 1992, 1.548691, 5143 ], [ \"Solomon Islands\", 1993, 1.59751, 5460 ], [ \"Solomon Islands\", 1994, 1.711594, 6020 ], [ \"Solomon Islands\", 1995, 1.796857, 6502 ], [ \"Solomon Islands\", 1996, 1.937209, 7210 ], [ \"Solomon Islands\", 1997, 2.010566, 7695 ], [ \"Solomon Islands\", 1998, 2.009536, 7907 ], [ \"Solomon Islands\", 1999, 2.010806, 8132 ], [ \"Solomon Islands\", 2000, 1.850346, 7689 ], [ \"Solomon Islands\", 2001, 1.731065, 7389 ], [ \"Solomon Islands\", 2002, 1.505988, 6601 ], [ \"Solomon Islands\", 2003, 1.386358, 6238 ], [ \"Solomon Islands\", 2004, 1.507674, 6962 ], [ \"Solomon Islands\", 2005, 1.563447, 7407 ], [ \"Solomon Islands\", 2006, 1.564031, 7600 ], [ \"Solomon Islands\", 2007, 1.565511, 7800 ], [ \"Solomon Islands\", 2008, 1.566563, 8000 ], [ \"Solomon Islands\", 2009, 1.567368, 8200 ], [ \"Somalia\", 1960, 0.04429007, 1249 ], [ \"Somalia\", 1981, 0.1212935, 8000 ], [ \"Somalia\", 1982, 0.1211042, 8000 ], [ \"Somalia\", 1983, 0.1227209, 8000 ], [ \"Somalia\", 1984, 0.1246634, 8000 ], [ \"Somalia\", 1985, 0.1257609, 8000 ], [ \"Somalia\", 1986, 0.2354897, 15000 ], [ \"Somalia\", 1987, 0.2335065, 15000 ], [ \"Somalia\", 1988, 0.2307115, 15000 ], [ \"Somalia\", 1989, 0.2284112, 15000 ], [ \"Somalia\", 1990, 0.227411, 15000 ], [ \"Somalia\", 1991, 0.2279058, 15000 ], [ \"Somalia\", 1992, 0.2293641, 15000 ], [ \"Somalia\", 1993, 0.2309573, 15000 ], [ \"Somalia\", 1994, 0.231468, 15000 ], [ \"Somalia\", 1995, 0.2300368, 15000 ], [ \"Somalia\", 1996, 0.2264326, 15000 ], [ \"Somalia\", 1997, 0.2211535, 15000 ], [ \"Somalia\", 1998, 0.3295633, 23000 ], [ \"Somalia\", 1999, 0.3338495, 24000 ], [ \"Somalia\", 2000, 0.338103, 25000 ], [ \"Somalia\", 2001, 0.4610619, 35000 ], [ \"Somalia\", 2002, 0.4496108, 35000 ], [ \"Somalia\", 2003, 1.253993, 100000 ], [ \"Somalia\", 2004, 1.224947, 100000 ], [ \"Somalia\", 2005, 1.197031, 100000 ], [ \"Somalia\", 2006, 1.170443, 100000 ], [ \"Somalia\", 2007, 1.145138, 100000 ], [ \"Somalia\", 2008, 1.120282, 100000 ], [ \"Somalia\", 2009, 1.094916, 100000 ], [ \"South Africa\", 1960, 3.736463, 650013 ], [ \"South Africa\", 1965, 3.791316, 755000 ], [ \"South Africa\", 1970, 4.041869, 916000 ], [ \"South Africa\", 1975, 4.471343, 1156000 ], [ \"South Africa\", 1976, 4.663483, 1229000 ], [ \"South Africa\", 1977, 4.850088, 1310000 ], [ \"South Africa\", 1978, 5.051535, 1398000 ], [ \"South Africa\", 1979, 5.317235, 1508000 ], [ \"South Africa\", 1980, 5.613017, 1632000 ], [ \"South Africa\", 1981, 5.997191, 1788610 ], [ \"South Africa\", 1982, 6.328301, 1936620 ], [ \"South Africa\", 1983, 6.598884, 2071817 ], [ \"South Africa\", 1984, 6.689052, 2152959 ], [ \"South Africa\", 1985, 6.971605, 2297773 ], [ \"South Africa\", 1986, 7.514441, 2532680 ], [ \"South Africa\", 1987, 7.751142, 2668589 ], [ \"South Africa\", 1988, 8.152361, 2866024 ], [ \"South Africa\", 1989, 8.575365, 3080333 ], [ \"South Africa\", 1990, 9.021626, 3315022 ], [ \"South Africa\", 1991, 9.125264, 3434788 ], [ \"South Africa\", 1992, 8.960951, 3458126 ], [ \"South Africa\", 1993, 9.084231, 3593851 ], [ \"South Africa\", 1994, 9.321561, 3775355 ], [ \"South Africa\", 1995, 9.672985, 4002180 ], [ \"South Africa\", 1996, 10.09937, 4258639 ], [ \"South Africa\", 1997, 10.83026, 4645065 ], [ \"South Africa\", 1998, 11.65109, 5075417 ], [ \"South Africa\", 1999, 12.42302, 5492838 ], [ \"South Africa\", 2000, 11.05757, 4961743 ], [ \"South Africa\", 2001, 10.81441, 4924458 ], [ \"South Africa\", 2002, 10.48542, 4844000 ], [ \"South Africa\", 2003, 10.29061, 4821000 ], [ \"South Africa\", 2004, 10.21546, 4850000 ], [ \"South Africa\", 2005, 9.837032, 4729000 ], [ \"South Africa\", 2006, 9.543877, 4642000 ], [ \"South Africa\", 2007, 9.21641, 4532000 ], [ \"South Africa\", 2008, 8.909224, 4425000 ], [ \"South Africa\", 2009, 8.620666, 4319800 ], [ \"Spain\", 1960, 4.277601, 1302750 ], [ \"Spain\", 1965, 5.537164, 1775000 ], [ \"Spain\", 1970, 8.422477, 2845000 ], [ \"Spain\", 1975, 13.19811, 4698000 ], [ \"Spain\", 1976, 14.18301, 5118000 ], [ \"Spain\", 1977, 15.56584, 5679000 ], [ \"Spain\", 1978, 16.77595, 6185000 ], [ \"Spain\", 1979, 17.99551, 6698000 ], [ \"Spain\", 1980, 19.26298, 7228800 ], [ \"Spain\", 1981, 20.25826, 7654200 ], [ \"Spain\", 1982, 21.1031, 8017690 ], [ \"Spain\", 1983, 22.15157, 8453700 ], [ \"Spain\", 1984, 23.18752, 8881727 ], [ \"Spain\", 1985, 24.30849, 9340458 ], [ \"Spain\", 1986, 25.39847, 9785300 ], [ \"Spain\", 1987, 26.51081, 10236410 ], [ \"Spain\", 1988, 28.35986, 10971640 ], [ \"Spain\", 1989, 30.43595, 11797160 ], [ \"Spain\", 1990, 32.44808, 12602600 ], [ \"Spain\", 1991, 34.07109, 13264360 ], [ \"Spain\", 1992, 35.32882, 13792160 ], [ \"Spain\", 1993, 36.40042, 14253470 ], [ \"Spain\", 1994, 37.39034, 14685410 ], [ \"Spain\", 1995, 38.3222, 15095380 ], [ \"Spain\", 1996, 39.02562, 15412790 ], [ \"Spain\", 1997, 40.04062, 15854450 ], [ \"Spain\", 1998, 40.99777, 16288610 ], [ \"Spain\", 1999, 41.25953, 16480430 ], [ \"Spain\", 2000, 42.47928, 17104000 ], [ \"Spain\", 2001, 43.06514, 17531000 ], [ \"Spain\", 2002, 42.75804, 17640740 ], [ \"Spain\", 2003, 42.41553, 17759160 ], [ \"Spain\", 2004, 42.21339, 17934480 ], [ \"Spain\", 2005, 45.19442, 19460830 ], [ \"Spain\", 2006, 45.58378, 19865040 ], [ \"Spain\", 2007, 45.83864, 20192500 ], [ \"Spain\", 2008, 46.25249, 20576070 ], [ \"Spain\", 2009, 45.28321, 20333820 ], [ \"Sri Lanka\", 1960, 0.226237, 22772 ], [ \"Sri Lanka\", 1965, 0.2440947, 27700 ], [ \"Sri Lanka\", 1970, 0.291345, 37100 ], [ \"Sri Lanka\", 1975, 0.3026688, 42500 ], [ \"Sri Lanka\", 1976, 0.3100152, 43550 ], [ \"Sri Lanka\", 1977, 0.3119096, 44625 ], [ \"Sri Lanka\", 1978, 0.3137668, 45700 ], [ \"Sri Lanka\", 1979, 0.3199051, 47400 ], [ \"Sri Lanka\", 1980, 0.3599007, 54200 ], [ \"Sri Lanka\", 1981, 0.4316935, 66013 ], [ \"Sri Lanka\", 1982, 0.4536591, 70381 ], [ \"Sri Lanka\", 1983, 0.4672337, 73500 ], [ \"Sri Lanka\", 1984, 0.5064686, 80770 ], [ \"Sri Lanka\", 1985, 0.5423334, 87686 ], [ \"Sri Lanka\", 1986, 0.5615987, 92065 ], [ \"Sri Lanka\", 1987, 0.5856058, 97333 ], [ \"Sri Lanka\", 1988, 0.6144227, 103521 ], [ \"Sri Lanka\", 1989, 0.617848, 105483 ], [ \"Sri Lanka\", 1990, 0.7020572, 121388 ], [ \"Sri Lanka\", 1991, 0.718947, 125834 ], [ \"Sri Lanka\", 1992, 0.7651706, 135504 ], [ \"Sri Lanka\", 1993, 0.8812225, 157774 ], [ \"Sri Lanka\", 1994, 0.9995657, 180724 ], [ \"Sri Lanka\", 1995, 1.120744, 204350 ], [ \"Sri Lanka\", 1996, 1.389112, 255049 ], [ \"Sri Lanka\", 1997, 1.850049, 341622 ], [ \"Sri Lanka\", 1998, 2.82088, 523529 ], [ \"Sri Lanka\", 1999, 3.586594, 669113 ], [ \"Sri Lanka\", 2000, 4.089132, 767411 ], [ \"Sri Lanka\", 2001, 4.377636, 827195 ], [ \"Sri Lanka\", 2002, 4.638184, 883108 ], [ \"Sri Lanka\", 2003, 4.891521, 939013 ], [ \"Sri Lanka\", 2004, 5.119608, 991239 ], [ \"Sri Lanka\", 2005, 6.369416, 1243994 ], [ \"Sri Lanka\", 2006, 9.561945, 1884078 ], [ \"Sri Lanka\", 2007, 13.792, 2742059 ], [ \"Sri Lanka\", 2008, 17.17997, 3446411 ], [ \"Sri Lanka\", 2009, 16.97798, 3435958 ], [ \"St. Vincent and the Grenadines\", 1970, 1.768483, 1600 ], [ \"St. Vincent and the Grenadines\", 1975, 3.316455, 3170 ], [ \"St. Vincent and the Grenadines\", 1976, 3.447348, 3330 ], [ \"St. Vincent and the Grenadines\", 1977, 3.565683, 3480 ], [ \"St. Vincent and the Grenadines\", 1978, 3.601319, 3550 ], [ \"St. Vincent and the Grenadines\", 1979, 3.567015, 3550 ], [ \"St. Vincent and the Grenadines\", 1980, 3.534695, 3550 ], [ \"St. Vincent and the Grenadines\", 1981, 3.67332, 3721 ], [ \"St. Vincent and the Grenadines\", 1982, 3.729092, 3808 ], [ \"St. Vincent and the Grenadines\", 1983, 3.790272, 3900 ], [ \"St. Vincent and the Grenadines\", 1984, 3.802292, 3941 ], [ \"St. Vincent and the Grenadines\", 1985, 5.191607, 5419 ], [ \"St. Vincent and the Grenadines\", 1986, 5.708849, 6000 ], [ \"St. Vincent and the Grenadines\", 1987, 6.616507, 7000 ], [ \"St. Vincent and the Grenadines\", 1988, 7.515972, 8000 ], [ \"St. Vincent and the Grenadines\", 1989, 8.434354, 9024 ], [ \"St. Vincent and the Grenadines\", 1990, 12.21154, 13118 ], [ \"St. Vincent and the Grenadines\", 1991, 13.58223, 14632 ], [ \"St. Vincent and the Grenadines\", 1992, 14.46031, 15606 ], [ \"St. Vincent and the Grenadines\", 1993, 15.25231, 16476 ], [ \"St. Vincent and the Grenadines\", 1994, 15.89473, 17176 ], [ \"St. Vincent and the Grenadines\", 1995, 16.87612, 18236 ], [ \"St. Vincent and the Grenadines\", 1996, 17.91444, 19351 ], [ \"St. Vincent and the Grenadines\", 1997, 18.98877, 20498 ], [ \"St. Vincent and the Grenadines\", 1998, 19.50869, 21045 ], [ \"St. Vincent and the Grenadines\", 1999, 21.91383, 23631 ], [ \"St. Vincent and the Grenadines\", 2000, 23.09169, 24906 ], [ \"St. Vincent and the Grenadines\", 2001, 24.15681, 26078 ], [ \"St. Vincent and the Grenadines\", 2002, 25.27193, 27323 ], [ \"St. Vincent and the Grenadines\", 2003, 19.56223, 21190 ], [ \"St. Vincent and the Grenadines\", 2004, 17.52679, 19022 ], [ \"St. Vincent and the Grenadines\", 2005, 20.70073, 22505 ], [ \"St. Vincent and the Grenadines\", 2006, 20.79506, 22640 ], [ \"St. Vincent and the Grenadines\", 2007, 21.03298, 22927 ], [ \"St. Vincent and the Grenadines\", 2008, 20.87392, 22777 ], [ \"St. Vincent and the Grenadines\", 2009, 21.07793, 23019 ], [ \"Sudan\", 1960, 0.1506051, 17339 ], [ \"Sudan\", 1965, 0.2082866, 27000 ], [ \"Sudan\", 1970, 0.2265527, 33300 ], [ \"Sudan\", 1975, 0.2480121, 42300 ], [ \"Sudan\", 1976, 0.2393304, 43200 ], [ \"Sudan\", 1977, 0.2335448, 43500 ], [ \"Sudan\", 1978, 0.2287943, 43984 ], [ \"Sudan\", 1979, 0.2230909, 44286 ], [ \"Sudan\", 1980, 0.221146, 45355 ], [ \"Sudan\", 1981, 0.2163577, 45874 ], [ \"Sudan\", 1982, 0.220199, 48282 ], [ \"Sudan\", 1983, 0.2288618, 51859 ], [ \"Sudan\", 1984, 0.2351869, 54973 ], [ \"Sudan\", 1985, 0.239657, 57642 ], [ \"Sudan\", 1986, 0.2355862, 58150 ], [ \"Sudan\", 1987, 0.2324065, 58745 ], [ \"Sudan\", 1988, 0.2281891, 59000 ], [ \"Sudan\", 1989, 0.22682, 60000 ], [ \"Sudan\", 1990, 0.2288551, 62000 ], [ \"Sudan\", 1991, 0.228959, 63600 ], [ \"Sudan\", 1992, 0.2245245, 64000 ], [ \"Sudan\", 1993, 0.2186914, 64000 ], [ \"Sudan\", 1994, 0.2129993, 64000 ], [ \"Sudan\", 1995, 0.2431807, 75000 ], [ \"Sudan\", 1996, 0.3128021, 99000 ], [ \"Sudan\", 1997, 0.3465846, 112544 ], [ \"Sudan\", 1998, 0.4871891, 162225 ], [ \"Sudan\", 1999, 0.7370445, 251420 ], [ \"Sudan\", 2000, 1.108112, 386775 ], [ \"Sudan\", 2001, 1.25606, 448000 ], [ \"Sudan\", 2002, 1.845372, 671842 ], [ \"Sudan\", 2003, 2.522083, 936756 ], [ \"Sudan\", 2004, 2.71479, 1028899 ], [ \"Sudan\", 2005, 1.472926, 570000 ], [ \"Sudan\", 2006, 1.261852, 499000 ], [ \"Sudan\", 2007, 0.8537581, 345194 ], [ \"Sudan\", 2008, 0.8856594, 366200 ], [ \"Sudan\", 2009, 0.8762755, 370423 ], [ \"Suriname\", 1975, 2.87902, 10494 ], [ \"Suriname\", 1976, 3.033097, 11022 ], [ \"Suriname\", 1977, 3.402168, 12358 ], [ \"Suriname\", 1978, 3.655513, 13300 ], [ \"Suriname\", 1979, 3.928852, 14331 ], [ \"Suriname\", 1980, 4.156676, 15203 ], [ \"Suriname\", 1981, 4.410149, 16174 ], [ \"Suriname\", 1982, 4.498513, 16553 ], [ \"Suriname\", 1983, 5.712191, 21117 ], [ \"Suriname\", 1984, 6.940773, 25838 ], [ \"Suriname\", 1985, 7.352996, 27643 ], [ \"Suriname\", 1986, 7.851874, 29903 ], [ \"Suriname\", 1987, 8.014281, 30999 ], [ \"Suriname\", 1988, 8.147724, 32056 ], [ \"Suriname\", 1989, 8.469761, 33897 ], [ \"Suriname\", 1990, 9.016458, 36673 ], [ \"Suriname\", 1991, 9.817177, 40531 ], [ \"Suriname\", 1992, 10.39513, 43522 ], [ \"Suriname\", 1993, 11.13096, 47230 ], [ \"Suriname\", 1994, 11.77796, 50643 ], [ \"Suriname\", 1995, 12.42426, 54150 ], [ \"Suriname\", 1996, 12.86415, 56844 ], [ \"Suriname\", 1997, 14.26017, 63888 ], [ \"Suriname\", 1998, 14.81671, 67308 ], [ \"Suriname\", 1999, 15.37941, 70846 ], [ \"Suriname\", 2000, 16.12032, 75308 ], [ \"Suriname\", 2001, 16.32811, 77366 ], [ \"Suriname\", 2002, 16.37161, 78680 ], [ \"Suriname\", 2003, 16.37899, 79815 ], [ \"Suriname\", 2004, 16.54893, 81709 ], [ \"Suriname\", 2005, 16.21902, 81056 ], [ \"Suriname\", 2006, 16.12958, 81500 ], [ \"Suriname\", 2007, 16.0669, 82000 ], [ \"Suriname\", 2008, 16.11263, 83000 ], [ \"Suriname\", 2009, 16.11325, 83747 ], [ \"Swaziland\", 1960, 0.3395778, 1200 ], [ \"Swaziland\", 1965, 0.5031092, 2000 ], [ \"Swaziland\", 1970, 0.5506911, 2500 ], [ \"Swaziland\", 1975, 0.6358439, 3358 ], [ \"Swaziland\", 1976, 0.6659663, 3550 ], [ \"Swaziland\", 1977, 0.654624, 3600 ], [ \"Swaziland\", 1978, 0.687387, 3900 ], [ \"Swaziland\", 1979, 0.7861246, 4600 ], [ \"Swaziland\", 1980, 0.8637239, 5210 ], [ \"Swaziland\", 1981, 0.9722008, 6039 ], [ \"Swaziland\", 1982, 1.085528, 6939 ], [ \"Swaziland\", 1983, 1.128404, 7430 ], [ \"Swaziland\", 1984, 1.161258, 7900 ], [ \"Swaziland\", 1985, 1.176209, 8300 ], [ \"Swaziland\", 1986, 1.284139, 9440 ], [ \"Swaziland\", 1987, 1.27817, 9816 ], [ \"Swaziland\", 1988, 1.470964, 11800 ], [ \"Swaziland\", 1989, 1.497028, 12500 ], [ \"Swaziland\", 1990, 1.573406, 13600 ], [ \"Swaziland\", 1991, 1.613493, 14350 ], [ \"Swaziland\", 1992, 1.665882, 15170 ], [ \"Swaziland\", 1993, 1.757487, 16338 ], [ \"Swaziland\", 1994, 1.917382, 18189 ], [ \"Swaziland\", 1995, 2.180088, 21130 ], [ \"Swaziland\", 1996, 2.278237, 22602 ], [ \"Swaziland\", 1997, 2.466793, 25073 ], [ \"Swaziland\", 1998, 2.786793, 28999 ], [ \"Swaziland\", 1999, 2.94801, 31314 ], [ \"Swaziland\", 2000, 2.950662, 31858 ], [ \"Swaziland\", 2001, 3.088541, 33739 ], [ \"Swaziland\", 2002, 3.183805, 35060 ], [ \"Swaziland\", 2003, 4.170014, 46199 ], [ \"Swaziland\", 2004, 3.991641, 44507 ], [ \"Swaziland\", 2005, 3.116479, 35042 ], [ \"Swaziland\", 2006, 3.868174, 43970 ], [ \"Swaziland\", 2007, 3.821438, 44000 ], [ \"Swaziland\", 2008, 3.767659, 44000 ], [ \"Swaziland\", 2009, 3.713281, 44000 ], [ \"Sweden\", 1960, 27.93181, 2089300 ], [ \"Sweden\", 1965, 37.84586, 2927000 ], [ \"Sweden\", 1970, 44.79761, 3603000 ], [ \"Sweden\", 1975, 51.37584, 4209000 ], [ \"Sweden\", 1976, 52.99957, 4356000 ], [ \"Sweden\", 1977, 54.50927, 4495000 ], [ \"Sweden\", 1978, 55.54493, 4595000 ], [ \"Sweden\", 1979, 56.39809, 4678000 ], [ \"Sweden\", 1980, 57.99915, 4820000 ], [ \"Sweden\", 1981, 58.83995, 4895050 ], [ \"Sweden\", 1982, 59.66553, 4965900 ], [ \"Sweden\", 1983, 60.25695, 5016791 ], [ \"Sweden\", 1984, 61.53043, 5127591 ], [ \"Sweden\", 1985, 62.78164, 5242497 ], [ \"Sweden\", 1986, 64.13686, 5373000 ], [ \"Sweden\", 1987, 65.14217, 5480500 ], [ \"Sweden\", 1988, 66.23267, 5601000 ], [ \"Sweden\", 1989, 67.20162, 5716000 ], [ \"Sweden\", 1990, 68.33528, 5848700 ], [ \"Sweden\", 1991, 69.13214, 5957000 ], [ \"Sweden\", 1992, 68.31445, 5929000 ], [ \"Sweden\", 1993, 67.62475, 5910000 ], [ \"Sweden\", 1994, 67.88079, 5967000 ], [ \"Sweden\", 1995, 68.12093, 6013000 ], [ \"Sweden\", 1996, 68.18874, 6032000 ], [ \"Sweden\", 1997, 70.66409, 6254000 ], [ \"Sweden\", 1998, 72.21342, 6389000 ], [ \"Sweden\", 1999, 66.56822, 5890000 ], [ \"Sweden\", 2000, 64.90852, 5751000 ], [ \"Sweden\", 2001, 63.77305, 5667000 ], [ \"Sweden\", 2002, 62.58025, 5584500 ], [ \"Sweden\", 2003, 61.71305, 5535400 ], [ \"Sweden\", 2004, 63.07067, 5688000 ], [ \"Sweden\", 2005, 62.15229, 5635000 ], [ \"Sweden\", 2006, 60.91321, 5551000 ], [ \"Sweden\", 2007, 60.11251, 5505787 ], [ \"Sweden\", 2008, 58.07674, 5345732 ], [ \"Sweden\", 2009, 55.69398, 5151275 ], [ \"Switzerland\", 1960, 20.34644, 1090975 ], [ \"Switzerland\", 1965, 25.02987, 1466000 ], [ \"Switzerland\", 1970, 31.43865, 1945000 ], [ \"Switzerland\", 1975, 38.96729, 2470000 ], [ \"Switzerland\", 1976, 39.7924, 2523000 ], [ \"Switzerland\", 1977, 41.03577, 2599000 ], [ \"Switzerland\", 1978, 42.33738, 2677000 ], [ \"Switzerland\", 1979, 43.61666, 2755000 ], [ \"Switzerland\", 1980, 44.92759, 2839000 ], [ \"Switzerland\", 1981, 46.18471, 2925000 ], [ \"Switzerland\", 1982, 47.3423, 3010000 ], [ \"Switzerland\", 1983, 48.42751, 3095057 ], [ \"Switzerland\", 1984, 49.52989, 3184401 ], [ \"Switzerland\", 1985, 50.65127, 3277026 ], [ \"Switzerland\", 1986, 51.92895, 3381492 ], [ \"Switzerland\", 1987, 53.38014, 3499609 ], [ \"Switzerland\", 1988, 55.01191, 3632765 ], [ \"Switzerland\", 1989, 56.8568, 3784506 ], [ \"Switzerland\", 1990, 58.71807, 3942701 ], [ \"Switzerland\", 1991, 60.18736, 4080651 ], [ \"Switzerland\", 1992, 61.08868, 4184841 ], [ \"Switzerland\", 1993, 61.63454, 4265818 ], [ \"Switzerland\", 1994, 60.95095, 4257596 ], [ \"Switzerland\", 1995, 63.65197, 4480000 ], [ \"Switzerland\", 1996, 64.58534, 4571000 ], [ \"Switzerland\", 1997, 65.9827, 4688000 ], [ \"Switzerland\", 1998, 68.53271, 4884000 ], [ \"Switzerland\", 1999, 70.84376, 5066000 ], [ \"Switzerland\", 2000, 72.87868, 5235733 ], [ \"Switzerland\", 2001, 74.47618, 5383483 ], [ \"Switzerland\", 2002, 73.99126, 5387568 ], [ \"Switzerland\", 2003, 72.54166, 5323452 ], [ \"Switzerland\", 2004, 71.05732, 5253450 ], [ \"Switzerland\", 2005, 69.20756, 5149736 ], [ \"Switzerland\", 2006, 67.1318, 5021743 ], [ \"Switzerland\", 2007, 65.5801, 4927184 ], [ \"Switzerland\", 2008, 64.01922, 4827882 ], [ \"Switzerland\", 2009, 61.75234, 4673208 ], [ \"Syria\", 1960, 0.8417512, 38885 ], [ \"Syria\", 1965, 1.054726, 57000 ], [ \"Syria\", 1970, 1.250963, 79792 ], [ \"Syria\", 1975, 1.698152, 128000 ], [ \"Syria\", 1976, 1.757047, 137000 ], [ \"Syria\", 1977, 1.871788, 151000 ], [ \"Syria\", 1978, 2.023913, 169000 ], [ \"Syria\", 1979, 2.207927, 191000 ], [ \"Syria\", 1980, 2.673223, 239824 ], [ \"Syria\", 1981, 3.274809, 305000 ], [ \"Syria\", 1982, 3.462561, 335000 ], [ \"Syria\", 1983, 3.641689, 366000 ], [ \"Syria\", 1984, 3.987625, 416000 ], [ \"Syria\", 1985, 4.068315, 440000 ], [ \"Syria\", 1986, 4.063438, 455000 ], [ \"Syria\", 1987, 4.024488, 466000 ], [ \"Syria\", 1988, 3.996643, 478000 ], [ \"Syria\", 1989, 3.962544, 489000 ], [ \"Syria\", 1990, 3.901919, 496360 ], [ \"Syria\", 1991, 3.833793, 502314 ], [ \"Syria\", 1992, 3.807387, 513403 ], [ \"Syria\", 1993, 4.089466, 567000 ], [ \"Syria\", 1994, 4.820242, 686431 ], [ \"Syria\", 1995, 6.560124, 958457 ], [ \"Syria\", 1996, 8.007567, 1199000 ], [ \"Syria\", 1997, 8.560105, 1312585 ], [ \"Syria\", 1998, 9.406612, 1477000 ], [ \"Syria\", 1999, 9.945844, 1600355 ], [ \"Syria\", 2000, 10.14633, 1675246 ], [ \"Syria\", 2001, 10.71295, 1816991 ], [ \"Syria\", 2002, 12.01383, 2095000 ], [ \"Syria\", 2003, 13.43035, 2411000 ], [ \"Syria\", 2004, 14.3585, 2658000 ], [ \"Syria\", 2005, 15.18263, 2903139 ], [ \"Syria\", 2006, 16.38772, 3243000 ], [ \"Syria\", 2007, 16.83581, 3452000 ], [ \"Syria\", 2008, 17.11715, 3633443 ], [ \"Syria\", 2009, 17.67135, 3871114 ], [ \"T.F.Y.R. Macedonia\", 1983, 11.56564, 210000 ], [ \"T.F.Y.R. Macedonia\", 1984, 12.08711, 220000 ], [ \"T.F.Y.R. Macedonia\", 1985, 12.58101, 230000 ], [ \"T.F.Y.R. Macedonia\", 1986, 13.03797, 240000 ], [ \"T.F.Y.R. Macedonia\", 1987, 13.46215, 250000 ], [ \"T.F.Y.R. Macedonia\", 1988, 13.86356, 260000 ], [ \"T.F.Y.R. Macedonia\", 1989, 14.25979, 270000 ], [ \"T.F.Y.R. Macedonia\", 1990, 14.96321, 285700 ], [ \"T.F.Y.R. Macedonia\", 1991, 15.08307, 290000 ], [ \"T.F.Y.R. Macedonia\", 1992, 16.14824, 312314 ], [ \"T.F.Y.R. Macedonia\", 1993, 16.68141, 324291 ], [ \"T.F.Y.R. Macedonia\", 1994, 17.26035, 337200 ], [ \"T.F.Y.R. Macedonia\", 1995, 17.87636, 351000 ], [ \"T.F.Y.R. Macedonia\", 1996, 18.60659, 367256 ], [ \"T.F.Y.R. Macedonia\", 1997, 20.55175, 407785 ], [ \"T.F.Y.R. Macedonia\", 1998, 22.02169, 439177 ], [ \"T.F.Y.R. Macedonia\", 1999, 23.50719, 470982 ], [ \"T.F.Y.R. Macedonia\", 2000, 25.21935, 507316 ], [ \"T.F.Y.R. Macedonia\", 2001, 26.6806, 538507 ], [ \"T.F.Y.R. Macedonia\", 2002, 27.67046, 560026 ], [ \"T.F.Y.R. Macedonia\", 2003, 25.88182, 525000 ], [ \"T.F.Y.R. Macedonia\", 2004, 26.42472, 537000 ], [ \"T.F.Y.R. Macedonia\", 2005, 26.21986, 533656 ], [ \"T.F.Y.R. Macedonia\", 2006, 24.08832, 490887 ], [ \"T.F.Y.R. Macedonia\", 2007, 22.72916, 463638 ], [ \"T.F.Y.R. Macedonia\", 2008, 22.39321, 457122 ], [ \"T.F.Y.R. Macedonia\", 2009, 21.41025, 437301 ], [ \"Tajikistan\", 1975, 2.033705, 70000 ], [ \"Tajikistan\", 1976, 2.258651, 80000 ], [ \"Tajikistan\", 1977, 2.471648, 90000 ], [ \"Tajikistan\", 1978, 2.672691, 100000 ], [ \"Tajikistan\", 1979, 2.861, 110000 ], [ \"Tajikistan\", 1980, 3.035906, 120000 ], [ \"Tajikistan\", 1981, 3.444313, 140000 ], [ \"Tajikistan\", 1982, 3.588241, 150000 ], [ \"Tajikistan\", 1983, 3.719775, 160000 ], [ \"Tajikistan\", 1984, 3.837604, 170000 ], [ \"Tajikistan\", 1985, 3.941503, 180000 ], [ \"Tajikistan\", 1986, 4.031015, 190000 ], [ \"Tajikistan\", 1987, 4.108675, 200000 ], [ \"Tajikistan\", 1988, 4.300205, 216000 ], [ \"Tajikistan\", 1989, 4.448502, 230000 ], [ \"Tajikistan\", 1990, 4.52561, 240000 ], [ \"Tajikistan\", 1991, 4.751785, 257500 ], [ \"Tajikistan\", 1992, 4.838926, 267097 ], [ \"Tajikistan\", 1993, 4.725369, 265050 ], [ \"Tajikistan\", 1994, 4.709726, 268118 ], [ \"Tajikistan\", 1995, 4.548983, 262725 ], [ \"Tajikistan\", 1996, 4.209783, 246625 ], [ \"Tajikistan\", 1997, 3.79758, 225600 ], [ \"Tajikistan\", 1998, 3.675628, 221324 ], [ \"Tajikistan\", 1999, 3.484135, 212500 ], [ \"Tajikistan\", 2000, 3.53993, 218516 ], [ \"Tajikistan\", 2001, 3.633808, 226851 ], [ \"Tajikistan\", 2002, 3.765134, 237600 ], [ \"Tajikistan\", 2003, 3.84355, 245192 ], [ \"Tajikistan\", 2004, 4.236601, 273400 ], [ \"Tajikistan\", 2005, 4.287329, 280200 ], [ \"Tajikistan\", 2006, 0.3525238, 23362 ], [ \"Tajikistan\", 2007, 4.351325, 292730 ], [ \"Tajikistan\", 2008, 4.197433, 286940 ], [ \"Tajikistan\", 2009, 4.171328, 290000 ], [ \"Tanzania\", 1960, 0.08119113, 8130 ], [ \"Tanzania\", 1965, 0.08798321, 10231 ], [ \"Tanzania\", 1970, 0.1101746, 14977 ], [ \"Tanzania\", 1975, 0.1686411, 27056 ], [ \"Tanzania\", 1976, 0.1745218, 28766 ], [ \"Tanzania\", 1977, 0.1868748, 31777 ], [ \"Tanzania\", 1978, 0.1996719, 35021 ], [ \"Tanzania\", 1979, 0.2116166, 38283 ], [ \"Tanzania\", 1980, 0.2131133, 39770 ], [ \"Tanzania\", 1981, 0.2114146, 40704 ], [ \"Tanzania\", 1982, 0.2114541, 42007 ], [ \"Tanzania\", 1983, 0.2145942, 43987 ], [ \"Tanzania\", 1984, 0.2246647, 47509 ], [ \"Tanzania\", 1985, 0.2387026, 52064 ], [ \"Tanzania\", 1986, 0.2421739, 54460 ], [ \"Tanzania\", 1987, 0.2541934, 58919 ], [ \"Tanzania\", 1988, 0.2764552, 66058 ], [ \"Tanzania\", 1989, 0.2865686, 70640 ], [ \"Tanzania\", 1990, 0.286828, 73011 ], [ \"Tanzania\", 1991, 0.2902116, 76369 ], [ \"Tanzania\", 1992, 0.2986601, 81306 ], [ \"Tanzania\", 1993, 0.3019023, 85005 ], [ \"Tanzania\", 1994, 0.3036946, 88315 ], [ \"Tanzania\", 1995, 0.3011831, 90270 ], [ \"Tanzania\", 1996, 0.3009421, 92760 ], [ \"Tanzania\", 1997, 0.3321121, 105095 ], [ \"Tanzania\", 1998, 0.3752159, 121769 ], [ \"Tanzania\", 1999, 0.4496163, 149611 ], [ \"Tanzania\", 2000, 0.5085975, 173591 ], [ \"Tanzania\", 2001, 0.5076258, 177802 ], [ \"Tanzania\", 2002, 0.4493907, 161590 ], [ \"Tanzania\", 2003, 0.3980704, 147006 ], [ \"Tanzania\", 2004, 0.3909821, 148360 ], [ \"Tanzania\", 2005, 0.3957202, 154360 ], [ \"Tanzania\", 2006, 0.3920683, 157287 ], [ \"Tanzania\", 2007, 0.3955523, 163269 ], [ \"Tanzania\", 2008, 0.2914255, 123809 ], [ \"Tanzania\", 2009, 0.3953492, 172922 ], [ \"Thailand\", 1960, 0.1396379, 37148 ], [ \"Thailand\", 1965, 0.1730286, 54000 ], [ \"Thailand\", 1970, 0.2620207, 95000 ], [ \"Thailand\", 1975, 0.53037, 219000 ], [ \"Thailand\", 1976, 0.5481772, 237000 ], [ \"Thailand\", 1977, 0.5901686, 261000 ], [ \"Thailand\", 1978, 0.6546092, 296000 ], [ \"Thailand\", 1979, 0.7181776, 332000 ], [ \"Thailand\", 1980, 0.7743767, 366000 ], [ \"Thailand\", 1981, 0.7908931, 382240 ], [ \"Thailand\", 1982, 0.8788707, 434320 ], [ \"Thailand\", 1983, 0.9172298, 463231 ], [ \"Thailand\", 1984, 1.007676, 519491 ], [ \"Thailand\", 1985, 1.192316, 626498 ], [ \"Thailand\", 1986, 1.494242, 798912 ], [ \"Thailand\", 1987, 1.659734, 901622 ], [ \"Thailand\", 1988, 1.824543, 1005872 ], [ \"Thailand\", 1989, 2.071274, 1158014 ], [ \"Thailand\", 1990, 2.337132, 1324522 ], [ \"Thailand\", 1991, 2.704229, 1553160 ], [ \"Thailand\", 1992, 3.076388, 1790029 ], [ \"Thailand\", 1993, 3.759413, 2214519 ], [ \"Thailand\", 1994, 4.618338, 2750839 ], [ \"Thailand\", 1995, 5.789814, 3481997 ], [ \"Thailand\", 1996, 6.862605, 4160158 ], [ \"Thailand\", 1997, 7.909667, 4826684 ], [ \"Thailand\", 1998, 8.20458, 5037549 ], [ \"Thailand\", 1999, 8.436265, 5215636 ], [ \"Thailand\", 2000, 8.967713, 5591084 ], [ \"Thailand\", 2001, 9.603124, 6049129 ], [ \"Thailand\", 2002, 10.28804, 6557023 ], [ \"Thailand\", 2003, 10.27916, 6632409 ], [ \"Thailand\", 2004, 10.43467, 6811615 ], [ \"Thailand\", 2005, 10.66736, 7034662 ], [ \"Thailand\", 2006, 10.63299, 7071633 ], [ \"Thailand\", 2007, 10.48689, 7024049 ], [ \"Thailand\", 2008, 10.97306, 7394349 ], [ \"Thailand\", 2009, 10.63239, 7204936 ], [ \"Timor-Leste\", 2003, 0.2170706, 1970 ], [ \"Timor-Leste\", 2004, 0.2206679, 2098 ], [ \"Timor-Leste\", 2005, 0.2353769, 2334 ], [ \"Timor-Leste\", 2006, 0.2369498, 2438 ], [ \"Timor-Leste\", 2007, 0.2292929, 2440 ], [ \"Timor-Leste\", 2008, 0.2185024, 2400 ], [ \"Timor-Leste\", 2009, 0.211716, 2400 ], [ \"Togo\", 1960, 0.0740377, 1164 ], [ \"Togo\", 1970, 0.1402907, 3000 ], [ \"Togo\", 1976, 0.1914926, 4800 ], [ \"Togo\", 1977, 0.2260307, 5800 ], [ \"Togo\", 1978, 0.2129759, 5600 ], [ \"Togo\", 1979, 0.2110131, 5700 ], [ \"Togo\", 1980, 0.2076788, 5783 ], [ \"Togo\", 1981, 0.2124389, 6120 ], [ \"Togo\", 1982, 0.2484393, 7425 ], [ \"Togo\", 1983, 0.2555956, 7936 ], [ \"Togo\", 1984, 0.2589554, 8351 ], [ \"Togo\", 1985, 0.2508277, 8390 ], [ \"Togo\", 1986, 0.2440057, 8455 ], [ \"Togo\", 1987, 0.2572615, 9225 ], [ \"Togo\", 1988, 0.2589969, 9595 ], [ \"Togo\", 1989, 0.2584472, 9869 ], [ \"Togo\", 1990, 0.2678595, 10516 ], [ \"Togo\", 1991, 0.2666233, 10730 ], [ \"Togo\", 1992, 0.3726401, 15337 ], [ \"Togo\", 1993, 0.4111046, 17298 ], [ \"Togo\", 1994, 0.4964383, 21400 ], [ \"Togo\", 1995, 0.4899565, 21715 ], [ \"Togo\", 1996, 0.5256916, 24050 ], [ \"Togo\", 1997, 0.5306357, 25132 ], [ \"Togo\", 1998, 0.6399946, 31415 ], [ \"Togo\", 1999, 0.7510601, 38166 ], [ \"Togo\", 2000, 0.8149236, 42763 ], [ \"Togo\", 2001, 0.8953562, 48384 ], [ \"Togo\", 2002, 0.9212034, 51156 ], [ \"Togo\", 2003, 1.072268, 61099 ], [ \"Togo\", 2004, 1.128628, 65949 ], [ \"Togo\", 2005, 1.048567, 62831 ], [ \"Togo\", 2006, 1.335368, 82057 ], [ \"Togo\", 2007, 1.578971, 99483 ], [ \"Togo\", 2008, 2.18188, 140919 ], [ \"Togo\", 2009, 2.700158, 178713 ], [ \"Tonga\", 1960, 0.7739349, 529 ], [ \"Tonga\", 1965, 0.6769907, 560 ], [ \"Tonga\", 1970, 0.5900425, 580 ], [ \"Tonga\", 1976, 0.5342223, 500 ], [ \"Tonga\", 1977, 0.5295993, 500 ], [ \"Tonga\", 1978, 0.5335565, 510 ], [ \"Tonga\", 1979, 0.9529334, 920 ], [ \"Tonga\", 1981, 1.751241, 1690 ], [ \"Tonga\", 1983, 2.967139, 2800 ], [ \"Tonga\", 1984, 2.751487, 2567 ], [ \"Tonga\", 1985, 2.806533, 2600 ], [ \"Tonga\", 1986, 2.919329, 2700 ], [ \"Tonga\", 1987, 3.019454, 2800 ], [ \"Tonga\", 1988, 3.645292, 3400 ], [ \"Tonga\", 1989, 4.241547, 3984 ], [ \"Tonga\", 1990, 4.633458, 4382 ], [ \"Tonga\", 1991, 5.336527, 5080 ], [ \"Tonga\", 1992, 5.726302, 5487 ], [ \"Tonga\", 1993, 6.133646, 5914 ], [ \"Tonga\", 1994, 6.667698, 6464 ], [ \"Tonga\", 1995, 6.787981, 6610 ], [ \"Tonga\", 1996, 7.964457, 7780 ], [ \"Tonga\", 1997, 7.458645, 7300 ], [ \"Tonga\", 1998, 8.671523, 8500 ], [ \"Tonga\", 1999, 9.263501, 9100 ], [ \"Tonga\", 2000, 9.839025, 9700 ], [ \"Tonga\", 2001, 10.89786, 10800 ], [ \"Tonga\", 2002, 11.22919, 11201 ], [ \"Tonga\", 2003, 11.94327, 12000 ], [ \"Tonga\", 2004, 12.84521, 13000 ], [ \"Tonga\", 2005, 13.49248, 13746 ], [ \"Tonga\", 2006, 17.99795, 18447 ], [ \"Tonga\", 2007, 20.40828, 21034 ], [ \"Tonga\", 2008, 24.65674, 25536 ], [ \"Tonga\", 2009, 29.81715, 31000 ], [ \"Trinidad and Tobago\", 1965, 2.476573, 22200 ], [ \"Trinidad and Tobago\", 1970, 3.615329, 35100 ], [ \"Trinidad and Tobago\", 1975, 4.032019, 40800 ], [ \"Trinidad and Tobago\", 1976, 4.126199, 42200 ], [ \"Trinidad and Tobago\", 1977, 4.186492, 43334 ], [ \"Trinidad and Tobago\", 1978, 4.194755, 44006 ], [ \"Trinidad and Tobago\", 1979, 4.113379, 43794 ], [ \"Trinidad and Tobago\", 1980, 3.991074, 43174 ], [ \"Trinidad and Tobago\", 1981, 4.102381, 45152 ], [ \"Trinidad and Tobago\", 1982, 4.172986, 46779 ], [ \"Trinidad and Tobago\", 1983, 5.810193, 66323 ], [ \"Trinidad and Tobago\", 1984, 7.13033, 82733 ], [ \"Trinidad and Tobago\", 1985, 10.03926, 118075 ], [ \"Trinidad and Tobago\", 1986, 11.93382, 141819 ], [ \"Trinidad and Tobago\", 1987, 13.26517, 158848 ], [ \"Trinidad and Tobago\", 1988, 13.37512, 161110 ], [ \"Trinidad and Tobago\", 1989, 13.06155, 158208 ], [ \"Trinidad and Tobago\", 1990, 13.53243, 164931 ], [ \"Trinidad and Tobago\", 1991, 14.17228, 173965 ], [ \"Trinidad and Tobago\", 1992, 14.56006, 180108 ], [ \"Trinidad and Tobago\", 1993, 15.43834, 192488 ], [ \"Trinidad and Tobago\", 1994, 16.22483, 203817 ], [ \"Trinidad and Tobago\", 1995, 16.55118, 209310 ], [ \"Trinidad and Tobago\", 1996, 17.26024, 219551 ], [ \"Trinidad and Tobago\", 1997, 19.03593, 243390 ], [ \"Trinidad and Tobago\", 1998, 20.55842, 264070 ], [ \"Trinidad and Tobago\", 1999, 21.6194, 278876 ], [ \"Trinidad and Tobago\", 2000, 24.45888, 316767 ], [ \"Trinidad and Tobago\", 2001, 23.98787, 311842 ], [ \"Trinidad and Tobago\", 2002, 24.38933, 318189 ], [ \"Trinidad and Tobago\", 2003, 24.35838, 318879 ], [ \"Trinidad and Tobago\", 2004, 24.53789, 322338 ], [ \"Trinidad and Tobago\", 2005, 24.44815, 322300 ], [ \"Trinidad and Tobago\", 2006, 24.60005, 325500 ], [ \"Trinidad and Tobago\", 2007, 23.13637, 307301 ], [ \"Trinidad and Tobago\", 2008, 23.60843, 314792 ], [ \"Trinidad and Tobago\", 2009, 22.6528, 303227 ], [ \"Tunisia\", 1960, 0.6211764, 26218 ], [ \"Tunisia\", 1965, 0.712743, 33000 ], [ \"Tunisia\", 1970, 0.8972107, 46000 ], [ \"Tunisia\", 1975, 1.146887, 65000 ], [ \"Tunisia\", 1976, 1.22789, 71300 ], [ \"Tunisia\", 1977, 1.319135, 78600 ], [ \"Tunisia\", 1978, 1.424834, 87200 ], [ \"Tunisia\", 1979, 1.590514, 100000 ], [ \"Tunisia\", 1980, 1.734532, 112000 ], [ \"Tunisia\", 1981, 1.832192, 121440 ], [ \"Tunisia\", 1982, 2.037439, 138560 ], [ \"Tunisia\", 1983, 2.179443, 152014 ], [ \"Tunisia\", 1984, 2.360389, 168800 ], [ \"Tunisia\", 1985, 2.582976, 189337 ], [ \"Tunisia\", 1986, 2.884582, 216661 ], [ \"Tunisia\", 1987, 2.959608, 227663 ], [ \"Tunisia\", 1988, 3.161685, 248885 ], [ \"Tunisia\", 1989, 3.448428, 277490 ], [ \"Tunisia\", 1990, 3.686406, 302836 ], [ \"Tunisia\", 1991, 3.96337, 331947 ], [ \"Tunisia\", 1992, 4.39546, 374848 ], [ \"Tunisia\", 1993, 4.858625, 421362 ], [ \"Tunisia\", 1994, 5.384263, 474253 ], [ \"Tunisia\", 1995, 5.839313, 521742 ], [ \"Tunisia\", 1996, 6.453447, 584226 ], [ \"Tunisia\", 1997, 7.140557, 654242 ], [ \"Tunisia\", 1998, 8.119102, 752180 ], [ \"Tunisia\", 1999, 9.084874, 850381 ], [ \"Tunisia\", 2000, 10.10507, 955131 ], [ \"Tunisia\", 2001, 11.07207, 1056209 ], [ \"Tunisia\", 2002, 11.9355, 1148586 ], [ \"Tunisia\", 2003, 11.99105, 1163849 ], [ \"Tunisia\", 2004, 12.29304, 1203530 ], [ \"Tunisia\", 2005, 12.72956, 1257479 ], [ \"Tunisia\", 2006, 12.72117, 1268462 ], [ \"Tunisia\", 2007, 12.6466, 1273332 ], [ \"Tunisia\", 2008, 12.18452, 1239074 ], [ \"Tunisia\", 2009, 12.44752, 1278548 ], [ \"Turkey\", 1960, 0.6376581, 180030 ], [ \"Turkey\", 1965, 0.7605817, 243361 ], [ \"Turkey\", 1970, 1.041187, 376987 ], [ \"Turkey\", 1975, 1.651483, 680585 ], [ \"Turkey\", 1976, 1.824073, 769907 ], [ \"Turkey\", 1977, 1.971062, 851353 ], [ \"Turkey\", 1978, 2.2341, 986844 ], [ \"Turkey\", 1979, 2.418445, 1092137 ], [ \"Turkey\", 1980, 2.486459, 1147782 ], [ \"Turkey\", 1981, 2.758507, 1301558 ], [ \"Turkey\", 1982, 3.114875, 1501977 ], [ \"Turkey\", 1983, 3.396827, 1673227 ], [ \"Turkey\", 1984, 3.860166, 1941088 ], [ \"Turkey\", 1985, 4.382796, 2247884 ], [ \"Turkey\", 1986, 5.3183, 2779615 ], [ \"Turkey\", 1987, 6.946476, 3696872 ], [ \"Turkey\", 1988, 9.066804, 4910911 ], [ \"Turkey\", 1989, 10.63505, 5861517 ], [ \"Turkey\", 1990, 12.23378, 6861458 ], [ \"Turkey\", 1991, 14.28144, 8151740 ], [ \"Turkey\", 1992, 16.19977, 9410486 ], [ \"Turkey\", 1993, 18.49794, 10935520 ], [ \"Turkey\", 1994, 20.30008, 12212000 ], [ \"Turkey\", 1995, 21.44721, 13127000 ], [ \"Turkey\", 1996, 22.94467, 14286480 ], [ \"Turkey\", 1997, 24.599, 15579000 ], [ \"Turkey\", 1998, 26.0996, 16807000 ], [ \"Turkey\", 1999, 27.37094, 17912000 ], [ \"Turkey\", 2000, 27.67874, 18395170 ], [ \"Turkey\", 2001, 28.02985, 18904490 ], [ \"Turkey\", 2002, 27.61771, 18890000 ], [ \"Turkey\", 2003, 27.28526, 18916720 ], [ \"Turkey\", 2004, 27.22436, 19125160 ], [ \"Turkey\", 2005, 26.6664, 18978220 ], [ \"Turkey\", 2006, 26.12312, 18831620 ], [ \"Turkey\", 2007, 24.93161, 18201010 ], [ \"Turkey\", 2008, 23.67906, 17502200 ], [ \"Turkey\", 2009, 22.10011, 16534360 ], [ \"Turkmenistan\", 1975, 2.38095, 60000 ], [ \"Turkmenistan\", 1976, 2.705401, 70000 ], [ \"Turkmenistan\", 1977, 3.013142, 80000 ], [ \"Turkmenistan\", 1978, 3.305171, 90000 ], [ \"Turkmenistan\", 1979, 3.582207, 100000 ], [ \"Turkmenistan\", 1980, 3.84481, 110000 ], [ \"Turkmenistan\", 1981, 4.093689, 120000 ], [ \"Turkmenistan\", 1982, 4.329321, 130000 ], [ \"Turkmenistan\", 1983, 4.551573, 140000 ], [ \"Turkmenistan\", 1984, 4.760007, 150000 ], [ \"Turkmenistan\", 1985, 4.954329, 160000 ], [ \"Turkmenistan\", 1986, 5.135829, 170000 ], [ \"Turkmenistan\", 1987, 5.30524, 180000 ], [ \"Turkmenistan\", 1988, 5.57606, 194000 ], [ \"Turkmenistan\", 1989, 5.881338, 210000 ], [ \"Turkmenistan\", 1990, 5.997819, 220000 ], [ \"Turkmenistan\", 1991, 6.290809, 237320 ], [ \"Turkmenistan\", 1992, 6.407934, 248789 ], [ \"Turkmenistan\", 1993, 6.640265, 265130 ], [ \"Turkmenistan\", 1994, 7.436433, 304600 ], [ \"Turkmenistan\", 1995, 7.649109, 320300 ], [ \"Turkmenistan\", 1996, 7.930411, 338200 ], [ \"Turkmenistan\", 1997, 8.176428, 354000 ], [ \"Turkmenistan\", 1998, 8.070863, 354036 ], [ \"Turkmenistan\", 1999, 8.078978, 358900 ], [ \"Turkmenistan\", 2000, 8.094671, 364400 ], [ \"Turkmenistan\", 2001, 8.489339, 387620 ], [ \"Turkmenistan\", 2002, 8.071241, 374000 ], [ \"Turkmenistan\", 2003, 7.995559, 376100 ], [ \"Turkmenistan\", 2004, 8.127027, 388000 ], [ \"Turkmenistan\", 2005, 8.219794, 398100 ], [ \"Turkmenistan\", 2006, 8.630375, 423810 ], [ \"Turkmenistan\", 2007, 9.205234, 458180 ], [ \"Turkmenistan\", 2008, 9.47078, 477670 ], [ \"Turkmenistan\", 2009, 9.354425, 478000 ], [ \"Tuvalu\", 1985, 1.386642, 120 ], [ \"Tuvalu\", 1986, 1.374885, 120 ], [ \"Tuvalu\", 1987, 1.366898, 120 ], [ \"Tuvalu\", 1988, 1.360853, 120 ], [ \"Tuvalu\", 1989, 1.355167, 120 ], [ \"Tuvalu\", 1990, 1.348466, 120 ], [ \"Tuvalu\", 1991, 1.340183, 120 ], [ \"Tuvalu\", 1992, 1.397671, 126 ], [ \"Tuvalu\", 1993, 1.651437, 150 ], [ \"Tuvalu\", 1994, 5.387389, 493 ], [ \"Tuvalu\", 1995, 5.46697, 504 ], [ \"Tuvalu\", 1996, 5.426941, 504 ], [ \"Tuvalu\", 1997, 5.430832, 508 ], [ \"Tuvalu\", 1998, 6.370103, 600 ], [ \"Tuvalu\", 1999, 6.644869, 630 ], [ \"Tuvalu\", 2000, 6.918964, 660 ], [ \"Tuvalu\", 2001, 6.777187, 650 ], [ \"Tuvalu\", 2002, 6.848604, 660 ], [ \"Tuvalu\", 2003, 7.231405, 700 ], [ \"Tuvalu\", 2004, 7.715256, 750 ], [ \"Tuvalu\", 2005, 9.116984, 890 ], [ \"Tuvalu\", 2006, 11.22106, 1100 ], [ \"Tuvalu\", 2007, 13.20467, 1300 ], [ \"Tuvalu\", 2008, 15.1699, 1500 ], [ \"Tuvalu\", 2009, 17.12156, 1700 ], [ \"Uganda\", 1960, 0.1057323, 7000 ], [ \"Uganda\", 1965, 0.12786, 10000 ], [ \"Uganda\", 1970, 0.1508998, 14000 ], [ \"Uganda\", 1975, 0.1867018, 20100 ], [ \"Uganda\", 1976, 0.1782995, 20000 ], [ \"Uganda\", 1977, 0.181707, 21000 ], [ \"Uganda\", 1978, 0.1897277, 22600 ], [ \"Uganda\", 1979, 0.168589, 20700 ], [ \"Uganda\", 1980, 0.1548747, 19600 ], [ \"Uganda\", 1981, 0.1570382, 20480 ], [ \"Uganda\", 1982, 0.1708555, 22962 ], [ \"Uganda\", 1983, 0.1736722, 24067 ], [ \"Uganda\", 1984, 0.1465689, 20970 ], [ \"Uganda\", 1985, 0.1728912, 25580 ], [ \"Uganda\", 1986, 0.1685414, 25830 ], [ \"Uganda\", 1987, 0.1635828, 26000 ], [ \"Uganda\", 1988, 0.1633676, 26943 ], [ \"Uganda\", 1989, 0.1602473, 27414.5 ], [ \"Uganda\", 1990, 0.1572737, 27886 ], [ \"Uganda\", 1991, 0.154707, 28405 ], [ \"Uganda\", 1992, 0.1581535, 30047 ], [ \"Uganda\", 1993, 0.1057329, 20770 ], [ \"Uganda\", 1994, 0.1500291, 30449 ], [ \"Uganda\", 1995, 0.185992, 38972 ], [ \"Uganda\", 1996, 0.2217078, 47927 ], [ \"Uganda\", 1997, 0.2426122, 54074 ], [ \"Uganda\", 1998, 0.2477474, 56919 ], [ \"Uganda\", 1999, 0.2416492, 57239 ], [ \"Uganda\", 2000, 0.2524389, 61678 ], [ \"Uganda\", 2001, 0.222673, 56149 ], [ \"Uganda\", 2002, 0.2111592, 54976 ], [ \"Uganda\", 2003, 0.2268281, 60995 ], [ \"Uganda\", 2004, 0.2576343, 71568 ], [ \"Uganda\", 2005, 0.3049313, 87513 ], [ \"Uganda\", 2006, 0.3647004, 108140 ], [ \"Uganda\", 2007, 0.5411269, 165788 ], [ \"Uganda\", 2008, 0.53221, 168481 ], [ \"Uganda\", 2009, 0.7139528, 233533 ], [ \"Ukraine\", 1960, 2.804852, 1200000 ], [ \"Ukraine\", 1965, 3.528854, 1600000 ], [ \"Ukraine\", 1970, 4.438198, 2100000 ], [ \"Ukraine\", 1975, 5.71242, 2800000 ], [ \"Ukraine\", 1976, 6.089156, 3000000 ], [ \"Ukraine\", 1977, 6.466426, 3200000 ], [ \"Ukraine\", 1978, 6.843745, 3400000 ], [ \"Ukraine\", 1979, 7.219791, 3600000 ], [ \"Ukraine\", 1980, 7.593386, 3800000 ], [ \"Ukraine\", 1981, 7.964532, 4000000 ], [ \"Ukraine\", 1982, 8.53217, 4300000 ], [ \"Ukraine\", 1983, 9.115844, 4609900 ], [ \"Ukraine\", 1984, 9.65657, 4900000 ], [ \"Ukraine\", 1985, 10.21318, 5200000 ], [ \"Ukraine\", 1986, 10.76608, 5500000 ], [ \"Ukraine\", 1987, 11.31644, 5800000 ], [ \"Ukraine\", 1988, 12.12609, 6233000 ], [ \"Ukraine\", 1989, 12.97501, 6684200 ], [ \"Ukraine\", 1990, 13.62529, 7028300 ], [ \"Ukraine\", 1991, 14.23227, 7344100 ], [ \"Ukraine\", 1992, 14.69369, 7577900 ], [ \"Ukraine\", 1993, 15.19055, 7820400 ], [ \"Ukraine\", 1994, 15.71861, 8066000 ], [ \"Ukraine\", 1995, 16.27596, 8311000 ], [ \"Ukraine\", 1996, 18.21963, 9241000 ], [ \"Ukraine\", 1997, 18.70914, 9410000 ], [ \"Ukraine\", 1998, 19.46596, 9698200 ], [ \"Ukraine\", 1999, 20.41927, 10074000 ], [ \"Ukraine\", 2000, 21.31568, 10417000 ], [ \"Ukraine\", 2001, 22.02845, 10669600 ], [ \"Ukraine\", 2002, 22.55596, 10833300 ], [ \"Ukraine\", 2003, 23.31608, 11109500 ], [ \"Ukraine\", 2004, 25.67823, 12141960 ], [ \"Ukraine\", 2005, 24.85625, 11666600 ], [ \"Ukraine\", 2006, 26.60144, 12397130 ], [ \"Ukraine\", 2007, 27.88077, 12905860 ], [ \"Ukraine\", 2008, 28.65012, 13176870 ], [ \"Ukraine\", 2009, 28.49888, 13026290 ], [ \"United Arab Emirates\", 1975, 4.869167, 25808 ], [ \"United Arab Emirates\", 1976, 5.817961, 36061 ], [ \"United Arab Emirates\", 1977, 6.938005, 49830 ], [ \"United Arab Emirates\", 1978, 8.783632, 72082 ], [ \"United Arab Emirates\", 1979, 10.46474, 96386 ], [ \"United Arab Emirates\", 1980, 11.87855, 120591 ], [ \"United Arab Emirates\", 1981, 12.94833, 142591 ], [ \"United Arab Emirates\", 1982, 13.81671, 163098 ], [ \"United Arab Emirates\", 1983, 14.16349, 177841 ], [ \"United Arab Emirates\", 1984, 14.18343, 188806 ], [ \"United Arab Emirates\", 1985, 14.68062, 207052 ], [ \"United Arab Emirates\", 1986, 14.76777, 220678 ], [ \"United Arab Emirates\", 1987, 15.65965, 247800 ], [ \"United Arab Emirates\", 1988, 17.68704, 296143 ], [ \"United Arab Emirates\", 1989, 19.93559, 352730 ], [ \"United Arab Emirates\", 1990, 21.23285, 396435 ], [ \"United Arab Emirates\", 1991, 22.24001, 437503 ], [ \"United Arab Emirates\", 1992, 23.73795, 491549 ], [ \"United Arab Emirates\", 1993, 25.37123, 553206 ], [ \"United Arab Emirates\", 1994, 26.74534, 615124 ], [ \"United Arab Emirates\", 1995, 27.65046, 672330 ], [ \"United Arab Emirates\", 1996, 28.65531, 738074 ], [ \"United Arab Emirates\", 1997, 30.57907, 835090 ], [ \"United Arab Emirates\", 1998, 31.61319, 915223 ], [ \"United Arab Emirates\", 1999, 31.81614, 975178 ], [ \"United Arab Emirates\", 2000, 31.5034, 1020097 ], [ \"United Arab Emirates\", 2001, 30.84469, 1052930 ], [ \"United Arab Emirates\", 2002, 30.45688, 1093654 ], [ \"United Arab Emirates\", 2003, 30.162, 1135758 ], [ \"United Arab Emirates\", 2004, 30.20082, 1187734 ], [ \"United Arab Emirates\", 2005, 30.24824, 1236860 ], [ \"United Arab Emirates\", 2006, 30.94321, 1309683 ], [ \"United Arab Emirates\", 2007, 31.74956, 1385523 ], [ \"United Arab Emirates\", 2008, 33.63012, 1508289 ], [ \"United Arab Emirates\", 2009, 33.94938, 1561196 ], [ \"United Kingdom\", 1960, 9.766929, 5037000 ], [ \"United Kingdom\", 1965, 12.20168, 6534000 ], [ \"United Kingdom\", 1970, 16.80223, 9213000 ], [ \"United Kingdom\", 1975, 23.86967, 13230000 ], [ \"United Kingdom\", 1976, 24.81134, 13960000 ], [ \"United Kingdom\", 1977, 26.77448, 15070000 ], [ \"United Kingdom\", 1978, 29.05806, 16358000 ], [ \"United Kingdom\", 1979, 30.77361, 17326000 ], [ \"United Kingdom\", 1980, 32.2494, 18161000 ], [ \"United Kingdom\", 1981, 33.36638, 18797000 ], [ \"United Kingdom\", 1982, 34.13602, 19241000 ], [ \"United Kingdom\", 1983, 35.22609, 19871000 ], [ \"United Kingdom\", 1984, 36.38276, 20546000 ], [ \"United Kingdom\", 1985, 37.44209, 21175000 ], [ \"United Kingdom\", 1986, 38.34693, 21727000 ], [ \"United Kingdom\", 1987, 39.91121, 22664000 ], [ \"United Kingdom\", 1988, 41.70054, 23740000 ], [ \"United Kingdom\", 1989, 43.44088, 24797000 ], [ \"United Kingdom\", 1990, 44.32059, 25368000 ], [ \"United Kingdom\", 1991, 45.14497, 25911000 ], [ \"United Kingdom\", 1992, 46.06633, 26514000 ], [ \"United Kingdom\", 1993, 47.36071, 27336000 ], [ \"United Kingdom\", 1994, 48.9936, 28358000 ], [ \"United Kingdom\", 1995, 50.67234, 29411410 ], [ \"United Kingdom\", 1996, 52.71014, 30677760 ], [ \"United Kingdom\", 1997, 54.62625, 31879000 ], [ \"United Kingdom\", 1998, 56.09649, 32829000 ], [ \"United Kingdom\", 1999, 57.95447, 34021000 ], [ \"United Kingdom\", 2000, 59.80233, 35228000 ], [ \"United Kingdom\", 2001, 58.47186, 34579000 ], [ \"United Kingdom\", 2002, 58.48868, 34737600 ], [ \"United Kingdom\", 2003, 57.90528, 34550320 ], [ \"United Kingdom\", 2004, 57.668, 34576490 ], [ \"United Kingdom\", 2005, 56.53517, 34068430 ], [ \"United Kingdom\", 2006, 55.87914, 33848510 ], [ \"United Kingdom\", 2007, 54.9469, 33462200 ], [ \"United Kingdom\", 2008, 54.27868, 33235330 ], [ \"United Kingdom\", 2009, 52.16713, 32116910 ], [ \"United States\", 1960, 26.46619, 49269000 ], [ \"United States\", 1965, 29.17428, 58289000 ], [ \"United States\", 1970, 32.85833, 69039000 ], [ \"United States\", 1975, 36.5703, 80515000 ], [ \"United States\", 1976, 37.44744, 82802000 ], [ \"United States\", 1977, 38.27868, 85426000 ], [ \"United States\", 1978, 39.2579, 88431000 ], [ \"United States\", 1979, 40.1412, 91265000 ], [ \"United States\", 1980, 41.08706, 94282000 ], [ \"United States\", 1981, 45.58292, 105559200 ], [ \"United States\", 1982, 46.00759, 107519200 ], [ \"United States\", 1983, 46.89401, 110612700 ], [ \"United States\", 1984, 47.25657, 112550700 ], [ \"United States\", 1985, 48.20448, 115985800 ], [ \"United States\", 1986, 48.63407, 118289100 ], [ \"United States\", 1987, 49.91679, 122789200 ], [ \"United States\", 1988, 51.06389, 127086800 ], [ \"United States\", 1989, 52.21581, 131504600 ], [ \"United States\", 1990, 53.40635, 136114200 ], [ \"United States\", 1991, 54.05473, 139412900 ], [ \"United States\", 1992, 54.9222, 143341600 ], [ \"United States\", 1993, 56.0748, 148106200 ], [ \"United States\", 1994, 57.39875, 153448000 ], [ \"United States\", 1995, 58.99137, 159659000 ], [ \"United States\", 1996, 60.7319, 166446000 ], [ \"United States\", 1997, 62.63964, 173867000 ], [ \"United States\", 1998, 63.98455, 179850000 ], [ \"United States\", 1999, 66.60201, 189502000 ], [ \"United States\", 2000, 66.88144, 192513000 ], [ \"United States\", 2001, 65.83292, 191570800 ], [ \"United States\", 2002, 64.36887, 189250100 ], [ \"United States\", 2003, 61.60873, 182933300 ], [ \"United States\", 2004, 59.26557, 177690700 ], [ \"United States\", 2005, 57.85842, 175160900 ], [ \"United States\", 2006, 54.77976, 167459900 ], [ \"United States\", 2007, 51.32216, 158418100 ], [ \"United States\", 2008, 45.23272, 140975000 ], [ \"United States\", 2009, 44.81044, 141000000 ], [ \"Uruguay\", 1960, 4.334451, 110000 ], [ \"Uruguay\", 1965, 5.272172, 142000 ], [ \"Uruguay\", 1970, 5.697127, 160000 ], [ \"Uruguay\", 1975, 6.611161, 187000 ], [ \"Uruguay\", 1976, 6.791872, 193000 ], [ \"Uruguay\", 1977, 7.06975, 202000 ], [ \"Uruguay\", 1978, 7.093081, 204000 ], [ \"Uruguay\", 1979, 7.320351, 212000 ], [ \"Uruguay\", 1980, 7.545218, 220000 ], [ \"Uruguay\", 1981, 7.715495, 226450 ], [ \"Uruguay\", 1982, 7.883682, 232904 ], [ \"Uruguay\", 1983, 8.329768, 247682 ], [ \"Uruguay\", 1984, 8.676013, 259644 ], [ \"Uruguay\", 1985, 9.5629, 288029 ], [ \"Uruguay\", 1986, 10.12596, 306926 ], [ \"Uruguay\", 1987, 10.22892, 311984 ], [ \"Uruguay\", 1988, 11.2536, 345390 ], [ \"Uruguay\", 1989, 12.16662, 375830 ], [ \"Uruguay\", 1990, 13.35704, 415403 ], [ \"Uruguay\", 1991, 14.41322, 451421 ], [ \"Uruguay\", 1992, 15.5991, 492108 ], [ \"Uruguay\", 1993, 16.68913, 530370 ], [ \"Uruguay\", 1994, 18.1847, 582149 ], [ \"Uruguay\", 1995, 19.28987, 621996 ], [ \"Uruguay\", 1996, 20.6003, 669032 ], [ \"Uruguay\", 1997, 23.2702, 761088 ], [ \"Uruguay\", 1998, 25.01678, 823501 ], [ \"Uruguay\", 1999, 27.10323, 896849 ], [ \"Uruguay\", 2000, 27.97792, 929141 ], [ \"Uruguay\", 2001, 28.58107, 950866 ], [ \"Uruguay\", 2002, 28.44449, 946533 ], [ \"Uruguay\", 2003, 28.21132, 938186 ], [ \"Uruguay\", 2004, 29.98512, 996701 ], [ \"Uruguay\", 2005, 30.2526, 1006001 ], [ \"Uruguay\", 2006, 29.63154, 986867 ], [ \"Uruguay\", 2007, 28.90961, 965216 ], [ \"Uruguay\", 2008, 28.64102, 959286 ], [ \"Uruguay\", 2009, 28.36779, 953400 ], [ \"Uzbekistan\", 1975, 2.503397, 350000 ], [ \"Uzbekistan\", 1976, 2.713095, 390000 ], [ \"Uzbekistan\", 1977, 3.116081, 460000 ], [ \"Uzbekistan\", 1978, 3.300563, 500000 ], [ \"Uzbekistan\", 1979, 3.538452, 550000 ], [ \"Uzbekistan\", 1980, 3.635931, 580000 ], [ \"Uzbekistan\", 1981, 4.030347, 660000 ], [ \"Uzbekistan\", 1982, 4.282412, 720000 ], [ \"Uzbekistan\", 1983, 4.51887, 780000 ], [ \"Uzbekistan\", 1984, 4.798002, 850000 ], [ \"Uzbekistan\", 1985, 5.11716, 930000 ], [ \"Uzbekistan\", 1986, 5.420187, 1010000 ], [ \"Uzbekistan\", 1987, 5.760468, 1100000 ], [ \"Uzbekistan\", 1988, 6.134599, 1200000 ], [ \"Uzbekistan\", 1989, 6.738574, 1350000 ], [ \"Uzbekistan\", 1990, 6.838055, 1402844 ], [ \"Uzbekistan\", 1991, 6.942918, 1458455 ], [ \"Uzbekistan\", 1992, 7.110071, 1528900 ], [ \"Uzbekistan\", 1993, 7.01627, 1543300 ], [ \"Uzbekistan\", 1994, 6.929307, 1557100 ], [ \"Uzbekistan\", 1995, 6.737536, 1544200 ], [ \"Uzbekistan\", 1996, 6.561734, 1531300 ], [ \"Uzbekistan\", 1997, 6.494967, 1541000 ], [ \"Uzbekistan\", 1998, 6.378669, 1536700 ], [ \"Uzbekistan\", 1999, 6.54431, 1599380 ], [ \"Uzbekistan\", 2000, 6.680134, 1655044 ], [ \"Uzbekistan\", 2001, 6.62489, 1662963 ], [ \"Uzbekistan\", 2002, 6.614102, 1681127 ], [ \"Uzbekistan\", 2003, 6.674911, 1717068 ], [ \"Uzbekistan\", 2004, 6.72601, 1750400 ], [ \"Uzbekistan\", 2005, 6.814301, 1793500 ], [ \"Uzbekistan\", 2006, 6.921446, 1841870 ], [ \"Uzbekistan\", 2007, 6.773685, 1822146 ], [ \"Uzbekistan\", 2008, 6.802043, 1849563 ], [ \"Uzbekistan\", 2009, 6.754137, 1856592 ], [ \"Vanuatu\", 1970, 0.5813075, 500 ], [ \"Vanuatu\", 1975, 1.000228, 1010 ], [ \"Vanuatu\", 1976, 1.026773, 1070 ], [ \"Vanuatu\", 1977, 1.023303, 1100 ], [ \"Vanuatu\", 1978, 1.110269, 1230 ], [ \"Vanuatu\", 1982, 1.291381, 1590 ], [ \"Vanuatu\", 1983, 1.375059, 1733 ], [ \"Vanuatu\", 1984, 1.385497, 1787 ], [ \"Vanuatu\", 1985, 1.18686, 1567 ], [ \"Vanuatu\", 1986, 1.514378, 2047 ], [ \"Vanuatu\", 1987, 1.589549, 2200 ], [ \"Vanuatu\", 1988, 1.621969, 2300 ], [ \"Vanuatu\", 1989, 1.649859, 2400 ], [ \"Vanuatu\", 1990, 1.739724, 2600 ], [ \"Vanuatu\", 1991, 1.980809, 3047 ], [ \"Vanuatu\", 1992, 2.248587, 3565 ], [ \"Vanuatu\", 1993, 2.496083, 4078 ], [ \"Vanuatu\", 1994, 2.627303, 4414 ], [ \"Vanuatu\", 1995, 2.447451, 4215 ], [ \"Vanuatu\", 1996, 2.541, 4470 ], [ \"Vanuatu\", 1997, 2.678512, 4800 ], [ \"Vanuatu\", 1998, 2.835083, 5170 ], [ \"Vanuatu\", 1999, 2.96065, 5500 ], [ \"Vanuatu\", 2000, 3.499839, 6640 ], [ \"Vanuatu\", 2001, 3.48006, 6762 ], [ \"Vanuatu\", 2002, 3.314981, 6611 ], [ \"Vanuatu\", 2003, 3.190944, 6540 ], [ \"Vanuatu\", 2004, 3.208229, 6759 ], [ \"Vanuatu\", 2005, 3.217579, 6964 ], [ \"Vanuatu\", 2006, 3.375338, 7500 ], [ \"Vanuatu\", 2007, 3.868268, 8820 ], [ \"Vanuatu\", 2008, 4.446991, 10400 ], [ \"Vanuatu\", 2009, 3.010576, 7219 ], [ \"Venezuela\", 1960, 1.649315, 125000 ], [ \"Venezuela\", 1965, 1.957428, 178000 ], [ \"Venezuela\", 1970, 2.602348, 279000 ], [ \"Venezuela\", 1975, 3.934245, 501000 ], [ \"Venezuela\", 1976, 4.380031, 578000 ], [ \"Venezuela\", 1977, 4.513818, 617000 ], [ \"Venezuela\", 1978, 4.650078, 658000 ], [ \"Venezuela\", 1979, 4.791961, 701000 ], [ \"Venezuela\", 1980, 5.299242, 800000 ], [ \"Venezuela\", 1981, 5.529016, 859739 ], [ \"Venezuela\", 1982, 5.978814, 956038 ], [ \"Venezuela\", 1983, 6.216472, 1021133 ], [ \"Venezuela\", 1984, 6.501985, 1096745 ], [ \"Venezuela\", 1985, 7.00533, 1213519 ], [ \"Venezuela\", 1986, 7.428473, 1321772 ], [ \"Venezuela\", 1987, 7.669787, 1401733 ], [ \"Venezuela\", 1988, 7.768126, 1457771 ], [ \"Venezuela\", 1989, 7.608854, 1465169 ], [ \"Venezuela\", 1990, 7.536205, 1487710 ], [ \"Venezuela\", 1991, 7.908191, 1598947 ], [ \"Venezuela\", 1992, 8.852193, 1831670 ], [ \"Venezuela\", 1993, 9.84316, 2082846 ], [ \"Venezuela\", 1994, 10.79323, 2334218 ], [ \"Venezuela\", 1995, 11.14946, 2463165 ], [ \"Venezuela\", 1996, 11.82272, 2666845 ], [ \"Venezuela\", 1997, 12.18046, 2803977 ], [ \"Venezuela\", 1998, 11.03921, 2592317 ], [ \"Venezuela\", 1999, 10.65264, 2550789 ], [ \"Venezuela\", 2000, 10.39003, 2535966 ], [ \"Venezuela\", 2001, 10.87599, 2704921 ], [ \"Venezuela\", 2002, 11.21733, 2841771 ], [ \"Venezuela\", 2003, 11.45926, 2956185 ], [ \"Venezuela\", 2004, 12.74287, 3346462 ], [ \"Venezuela\", 2005, 13.65896, 3650501 ], [ \"Venezuela\", 2006, 15.508, 4216794 ], [ \"Venezuela\", 2007, 18.78447, 5195071 ], [ \"Venezuela\", 2008, 22.8223, 6417775 ], [ \"Venezuela\", 2009, 24.02315, 6866626 ], [ \"Viet Nam\", 1960, 0.02144828, 7217 ], [ \"Viet Nam\", 1982, 0.1164476, 65000 ], [ \"Viet Nam\", 1983, 0.1190067, 68000 ], [ \"Viet Nam\", 1984, 0.1197192, 70000 ], [ \"Viet Nam\", 1985, 0.1204236, 72000 ], [ \"Viet Nam\", 1986, 0.1244155, 76000 ], [ \"Viet Nam\", 1987, 0.1234663, 77000 ], [ \"Viet Nam\", 1988, 0.1225641, 78000 ], [ \"Viet Nam\", 1989, 0.1232093, 80000 ], [ \"Viet Nam\", 1990, 0.1487393, 98536 ], [ \"Viet Nam\", 1991, 0.2028714, 137135 ], [ \"Viet Nam\", 1992, 0.2214469, 152727 ], [ \"Viet Nam\", 1993, 0.3696481, 260000 ], [ \"Viet Nam\", 1994, 0.6166787, 442000 ], [ \"Viet Nam\", 1995, 1.062266, 775000 ], [ \"Viet Nam\", 1996, 1.59938, 1186367 ], [ \"Viet Nam\", 1997, 1.769198, 1332909 ], [ \"Viet Nam\", 1998, 2.280332, 1743567 ], [ \"Viet Nam\", 1999, 2.715055, 2105891 ], [ \"Viet Nam\", 2000, 3.232408, 2542718 ], [ \"Viet Nam\", 2001, 3.823648, 3049925 ], [ \"Viet Nam\", 2002, 4.859035, 3929140 ], [ \"Viet Nam\", 2003, 5.371452, 4402000 ], [ \"Viet Nam\", 2004, 12.19512, 10124900 ], [ \"Viet Nam\", 2006, 10.06749, 8567520 ], [ \"Viet Nam\", 2007, 12.96706, 11165620 ], [ \"Viet Nam\", 2008, 16.95559, 14767630 ], [ \"Viet Nam\", 2009, 19.78833, 17427360 ], [ \"Virgin Islands (U.S.)\", 1981, 28.93518, 29000 ], [ \"Virgin Islands (U.S.)\", 1982, 29.03505, 29569 ], [ \"Virgin Islands (U.S.)\", 1983, 29.02773, 29954 ], [ \"Virgin Islands (U.S.)\", 1984, 35.73918, 37227 ], [ \"Virgin Islands (U.S.)\", 1985, 37.25356, 39000 ], [ \"Virgin Islands (U.S.)\", 1986, 39.15202, 41000 ], [ \"Virgin Islands (U.S.)\", 1987, 40.26298, 42012 ], [ \"Virgin Islands (U.S.)\", 1988, 43.29691, 44937 ], [ \"Virgin Islands (U.S.)\", 1989, 44.86862, 46378 ], [ \"Virgin Islands (U.S.)\", 1990, 45.67802, 47179 ], [ \"Virgin Islands (U.S.)\", 1991, 49.30249, 51104 ], [ \"Virgin Islands (U.S.)\", 1992, 51.86164, 54142 ], [ \"Virgin Islands (U.S.)\", 1993, 53.8344, 56721 ], [ \"Virgin Islands (U.S.)\", 1994, 55.50936, 59012 ], [ \"Virgin Islands (U.S.)\", 1995, 54.46912, 58319 ], [ \"Virgin Islands (U.S.)\", 1996, 55.27362, 59470 ], [ \"Virgin Islands (U.S.)\", 1997, 57.56955, 62140 ], [ \"Virgin Islands (U.S.)\", 1998, 59.95618, 64851 ], [ \"Virgin Islands (U.S.)\", 1999, 62.04456, 67229 ], [ \"Virgin Islands (U.S.)\", 2000, 62.88901, 68283 ], [ \"Virgin Islands (U.S.)\", 2001, 63.76391, 69400 ], [ \"Virgin Islands (U.S.)\", 2002, 63.57537, 69369 ], [ \"Virgin Islands (U.S.)\", 2003, 63.71865, 69691 ], [ \"Virgin Islands (U.S.)\", 2004, 64.69005, 70888 ], [ \"Virgin Islands (U.S.)\", 2005, 65.35292, 71700 ], [ \"Virgin Islands (U.S.)\", 2006, 66.05381, 72500 ], [ \"Virgin Islands (U.S.)\", 2007, 66.89024, 73400 ], [ \"Virgin Islands (U.S.)\", 2008, 67.6748, 74200 ], [ \"Virgin Islands (U.S.)\", 2009, 68.49127, 75000 ], [ \"Yemen\", 1980, 0.2023541, 16960 ], [ \"Yemen\", 1981, 0.2778565, 24171 ], [ \"Yemen\", 1982, 0.4294627, 38809 ], [ \"Yemen\", 1983, 0.5311368, 49879 ], [ \"Yemen\", 1984, 0.594255, 57989 ], [ \"Yemen\", 1985, 0.6657626, 67486 ], [ \"Yemen\", 1986, 0.707494, 74432 ], [ \"Yemen\", 1987, 0.7438425, 81172 ], [ \"Yemen\", 1988, 0.7706043, 87300 ], [ \"Yemen\", 1989, 0.7870246, 92800 ], [ \"Yemen\", 1990, 1.011209, 124516 ], [ \"Yemen\", 1991, 1.014739, 130943 ], [ \"Yemen\", 1992, 1.057999, 143382 ], [ \"Yemen\", 1993, 1.132257, 161112 ], [ \"Yemen\", 1994, 1.160963, 172933 ], [ \"Yemen\", 1995, 1.202471, 186659 ], [ \"Yemen\", 1996, 1.271365, 204702 ], [ \"Yemen\", 1997, 1.323879, 220275 ], [ \"Yemen\", 1998, 1.454875, 249515 ], [ \"Yemen\", 1999, 1.609931, 284296 ], [ \"Yemen\", 2000, 1.906908, 346709 ], [ \"Yemen\", 2001, 2.255255, 422228 ], [ \"Yemen\", 2002, 2.812933, 542204 ], [ \"Yemen\", 2003, 3.496794, 693884 ], [ \"Yemen\", 2004, 3.906755, 798000 ], [ \"Yemen\", 2005, 4.287472, 901385 ], [ \"Yemen\", 2006, 4.475196, 968328 ], [ \"Yemen\", 2007, 4.589276, 1022000 ], [ \"Yemen\", 2008, 4.193305, 961000 ], [ \"Yemen\", 2009, 4.22812, 997000 ], [ \"Zambia\", 1960, 0.4776087, 15000 ], [ \"Zambia\", 1965, 0.4666585, 17100 ], [ \"Zambia\", 1970, 0.5392136, 23200 ], [ \"Zambia\", 1975, 0.5512975, 28400 ], [ \"Zambia\", 1976, 0.5568069, 28200 ], [ \"Zambia\", 1977, 0.5635687, 29500 ], [ \"Zambia\", 1978, 0.5546417, 30000 ], [ \"Zambia\", 1979, 0.5492973, 30698 ], [ \"Zambia\", 1980, 0.5656062, 32659 ], [ \"Zambia\", 1981, 0.5854722, 34927 ], [ \"Zambia\", 1982, 0.5895198, 36330 ], [ \"Zambia\", 1983, 0.5890434, 37493 ], [ \"Zambia\", 1984, 0.6362631, 41819 ], [ \"Zambia\", 1985, 0.6451343, 43772 ], [ \"Zambia\", 1986, 0.6735497, 47164 ], [ \"Zambia\", 1987, 0.7048048, 50919 ], [ \"Zambia\", 1988, 0.7850509, 58492 ], [ \"Zambia\", 1989, 0.8561683, 65750 ], [ \"Zambia\", 1990, 0.8224361, 65057 ], [ \"Zambia\", 1991, 0.8466827, 68935 ], [ \"Zambia\", 1992, 0.9060864, 75880 ], [ \"Zambia\", 1993, 0.905432, 77966 ], [ \"Zambia\", 1994, 0.9010639, 79786 ], [ \"Zambia\", 1995, 0.8428875, 76769 ], [ \"Zambia\", 1996, 0.8315368, 77935 ], [ \"Zambia\", 1997, 0.8021122, 77377 ], [ \"Zambia\", 1998, 0.7828581, 77700 ], [ \"Zambia\", 1999, 0.8145177, 83084 ], [ \"Zambia\", 2000, 0.7960618, 83326 ], [ \"Zambia\", 2001, 0.7988138, 85662 ], [ \"Zambia\", 2002, 0.7990525, 87674 ], [ \"Zambia\", 2003, 0.7881836, 88426 ], [ \"Zambia\", 2004, 0.7994838, 91719 ], [ \"Zambia\", 2005, 0.8064535, 94665 ], [ \"Zambia\", 2006, 0.7772965, 93427 ], [ \"Zambia\", 2007, 0.7454071, 91789 ], [ \"Zambia\", 2008, 0.7178956, 90600 ], [ \"Zambia\", 2009, 0.698403, 90341 ], [ \"Zimbabwe\", 1960, 1.470037, 55000 ], [ \"Zimbabwe\", 1965, 1.475199, 65000 ], [ \"Zimbabwe\", 1970, 1.437969, 75000 ], [ \"Zimbabwe\", 1975, 1.314643, 81672 ], [ \"Zimbabwe\", 1976, 1.329129, 84681 ], [ \"Zimbabwe\", 1977, 1.310974, 86228 ], [ \"Zimbabwe\", 1978, 1.334863, 90675 ], [ \"Zimbabwe\", 1979, 1.323483, 92987 ], [ \"Zimbabwe\", 1980, 1.31297, 95615 ], [ \"Zimbabwe\", 1981, 1.283004, 97039 ], [ \"Zimbabwe\", 1982, 1.255193, 98732 ], [ \"Zimbabwe\", 1983, 1.259063, 103052 ], [ \"Zimbabwe\", 1984, 1.21977, 103840 ], [ \"Zimbabwe\", 1985, 1.183058, 104637 ], [ \"Zimbabwe\", 1986, 1.177869, 108098 ], [ \"Zimbabwe\", 1987, 1.201186, 114235 ], [ \"Zimbabwe\", 1988, 1.179653, 116058 ], [ \"Zimbabwe\", 1989, 1.194828, 121355 ], [ \"Zimbabwe\", 1990, 1.182139, 123665 ], [ \"Zimbabwe\", 1991, 1.173069, 126086 ], [ \"Zimbabwe\", 1992, 1.153412, 127072 ], [ \"Zimbabwe\", 1993, 1.136676, 128069 ], [ \"Zimbabwe\", 1994, 1.172379, 134812 ], [ \"Zimbabwe\", 1995, 1.301703, 152473 ], [ \"Zimbabwe\", 1996, 1.469041, 174985 ], [ \"Zimbabwe\", 1997, 1.750545, 211672 ], [ \"Zimbabwe\", 1998, 1.931231, 236530 ], [ \"Zimbabwe\", 1999, 1.931667, 238956 ], [ \"Zimbabwe\", 2000, 2.002351, 249400 ], [ \"Zimbabwe\", 2001, 2.029513, 253738 ], [ \"Zimbabwe\", 2002, 2.299583, 287854 ], [ \"Zimbabwe\", 2003, 2.405407, 300921 ], [ \"Zimbabwe\", 2004, 2.537564, 317000 ], [ \"Zimbabwe\", 2005, 2.629241, 328000 ], [ \"Zimbabwe\", 2006, 2.693246, 335561 ], [ \"Zimbabwe\", 2007, 2.771258, 345000 ], [ \"Zimbabwe\", 2008, 2.792292, 348000 ], [ \"Zimbabwe\", 2009, 3.075323, 385116 ] ]; data.addColumn('string','Country.or.Area'); data.addColumn('number','Year'); data.addColumn('number','Percentage'); data.addColumn('number','Users'); data.addRows(datajson); return(data); } // jsDrawChart function drawChartMotionChartID483d6724() { var data = gvisDataMotionChartID483d6724(); var options = {}; options[\"width\"] = 1024; options[\"height\"] = 768; var chart = new google.visualization.MotionChart( document.getElementById('MotionChartID483d6724') ); chart.draw(data,options); } // jsDisplayChart function displayChartMotionChartID483d6724() { google.load(\"visualization\", \"1\", { packages:[\"motionchart\"] }); google.setOnLoadCallback(drawChartMotionChartID483d6724); } // jsChart displayChartMotionChartID483d6724() //--   You can also make the motion chart for cell phone. Here is a google case and the data.\nInternational News We can visualize the motion change of international news:\n // jsData function gvisDataMotionChartID1937e74 () { var data = new google.visualization.DataTable(); var datajson = [ [ \"Afghanistan\", new Date(2011,7,10), 298.53 ], [ \"Albania\", new Date(2011,7,10), 462.61 ], [ \"Algeria\", new Date(2011,7,10), 282.96 ], [ \"Angola\", new Date(2011,7,10), 119.8 ], [ \"Argentina\", new Date(2011,7,10), 726.99 ], [ \"Australia\", new Date(2011,7,10), 152.43 ], [ \"Austria\", new Date(2011,7,10), 179.14 ], [ \"Azerbaijan\", new Date(2011,7,10), 100 ], [ \"Bahamas\", new Date(2011,7,10), 404.84 ], [ \"Bahrain\", new Date(2011,7,10), 298.13 ], [ \"Bangladesh\", new Date(2011,7,10), 748.75 ], [ \"Belgium\", new Date(2011,7,10), 284.99 ], [ \"Bermuda\", new Date(2011,7,10), 158.6 ], [ \"Bolivia\", new Date(2011,7,10), 458.31 ], [ \"Botswana\", new Date(2011,7,10), 169.98 ], [ \"Brazil\", new Date(2011,7,10), 347.63 ], [ \"Bulgaria\", new Date(2011,7,10), 269.01 ], [ \"Burkina Faso\", new Date(2011,7,10), 258.88 ], [ \"Burundi\", new Date(2011,7,10), 152.22 ], [ \"Cambodia\", new Date(2011,7,10), 739.53 ], [ \"Cameroon\", new Date(2011,7,10), 650.22 ], [ \"Canada\", new Date(2011,7,10), 239.48 ], [ \"Cape Verde\", new Date(2011,7,10), 64.952 ], [ \"Chad\", new Date(2011,7,10), 303.99 ], [ \"Channel Islands\", new Date(2011,7,10), 175 ], [ \"Chile\", new Date(2011,7,10), 534.73 ], [ \"China\", new Date(2011,7,10), 392.6 ], [ \"Colombia\", new Date(2011,7,10), 428.7 ], [ \"Comoros\", new Date(2011,7,10), 144.44 ], [ \"Congo\", new Date(2011,7,10), 398.78 ], [ \"Cook Islands\", new Date(2011,7,10), 100 ], [ \"Costa Rica\", new Date(2011,7,10), 81.235 ], [ \"Cote d'Ivoire\", new Date(2011,7,10), 260.18 ], [ \"Cuba\", new Date(2011,7,10), 469.15 ], [ \"Czech Republic\", new Date(2011,7,10), 226.68 ], [ \"Denmark\", new Date(2011,7,10), 468.88 ], [ \"Djibouti\", new Date(2011,7,10), 212.59 ], [ \"DR Congo\", new Date(2011,7,10), 169.14 ], [ \"East Timor\", new Date(2011,7,10), 209.41 ], [ \"Ecuador\", new Date(2011,7,10), 766.68 ], [ \"Egypt\", new Date(2011,7,10), 404.88 ], [ \"El Salvador\", new Date(2011,7,10), 100 ], [ \"Eritrea\", new Date(2011,7,10), 1659.3 ], [ \"Estonia\", new Date(2011,7,10), 243.18 ], [ \"Ethiopia\", new Date(2011,7,10), 209.18 ], [ \"Fiji\", new Date(2011,7,10), 179.91 ], [ \"France\", new Date(2011,7,10), 337.98 ], [ \"Gabon\", new Date(2011,7,10), 82.5 ], [ \"Georgia\", new Date(2011,7,10), 296.97 ], [ \"Germany\", new Date(2011,7,10), 436.41 ], [ \"Ghana\", new Date(2011,7,10), 715.46 ], [ \"Gibraltar\", new Date(2011,7,10), 1677.7 ], [ \"Greece\", new Date(2011,7,10), 377.6 ], [ \"Greenland\", new Date(2011,7,10), 161.34 ], [ \"Guatemala\", new Date(2011,7,10), 213.52 ], [ \"Haiti\", new Date(2011,7,10), 609.5 ], [ \"Honduras\", new Date(2011,7,10), 100 ], [ \"Hong Kong\", new Date(2011,7,10), 235.51 ], [ \"Hungary\", new Date(2011,7,10), 266.67 ], [ \"Iceland\", new Date(2011,7,10), 644.05 ], [ \"India\", new Date(2011,7,10), 370.47 ], [ \"Indonesia\", new Date(2011,7,10), 206.46 ], [ \"Iran\", new Date(2011,7,10), 473.02 ], [ \"Iraq\", new Date(2011,7,10), 268.48 ], [ \"Ireland\", new Date(2011,7,10), 452.72 ], [ \"Isle of Man\", new Date(2011,7,10), 31.111 ], [ \"Israel\", new Date(2011,7,10), 443.91 ], [ \"Italy\", new Date(2011,7,10), 380.05 ], [ \"Jamaica\", new Date(2011,7,10), 306.53 ], [ \"Japan\", new Date(2011,7,10), 265.46 ], [ \"Jordan\", new Date(2011,7,10), 126.79 ], [ \"Kazakhstan\", new Date(2011,7,10), 1175.2 ], [ \"Kenya\", new Date(2011,7,10), 367.28 ], [ \"Kiribati\", new Date(2011,7,10), 166.42 ], [ \"Kyrgyzstan\", new Date(2011,7,10), 170.61 ], [ \"Laos\", new Date(2011,7,10), 125 ], [ \"Latvia\", new Date(2011,7,10), 33.333 ], [ \"Lebanon\", new Date(2011,7,10), 402.52 ], [ \"Liberia\", new Date(2011,7,10), 215.9 ], [ \"Libya\", new Date(2011,7,10), 483.69 ], [ \"Lithuania\", new Date(2011,7,10), 230.56 ], [ \"Macedonia\", new Date(2011,7,10), 945.14 ], [ \"Malawi\", new Date(2011,7,10), 213.31 ], [ \"Malaysia\", new Date(2011,7,10), 247.37 ], [ \"Maldives\", new Date(2011,7,10), 157.14 ], [ \"Mauritania\", new Date(2011,7,10), 620.87 ], [ \"Mexico\", new Date(2011,7,10), 246.12 ], [ \"Monaco\", new Date(2011,7,10), 168.51 ], [ \"Mongolia\", new Date(2011,7,10), 211.67 ], [ \"Morocco\", new Date(2011,7,10), 334.42 ], [ \"Mozambique\", new Date(2011,7,10), 209.77 ], [ \"Myanmar\", new Date(2011,7,10), 632.7 ], [ \"Namibia\", new Date(2011,7,10), 158.18 ], [ \"Nauru\", new Date(2011,7,10), 179.76 ], [ \"Nepal\", new Date(2011,7,10), 267.45 ], [ \"Netherlands\", new Date(2011,7,10), 208.01 ], [ \"New Caledonia\", new Date(2011,7,10), 152.14 ], [ \"New Zealand\", new Date(2011,7,10), 139.62 ], [ \"Nicaragua\", new Date(2011,7,10), 80.715 ], [ \"Niger\", new Date(2011,7,10), 316.24 ], [ \"Nigeria\", new Date(2011,7,10), 254.09 ], [ \"North Korea\", new Date(2011,7,10), 331.86 ], [ \"Norway\", new Date(2011,7,10), 297.61 ], [ \"Oman\", new Date(2011,7,10), 664.29 ], [ \"Pakistan\", new Date(2011,7,10), 322.24 ], [ \"Palestine\", new Date(2011,7,10), 623.85 ], [ \"Panama\", new Date(2011,7,10), 160.19 ], [ \"Peru\", new Date(2011,7,10), 759.68 ], [ \"Philippines\", new Date(2011,7,10), 206.58 ], [ \"Poland\", new Date(2011,7,10), 666.18 ], [ \"Portugal\", new Date(2011,7,10), 286.98 ], [ \"Puerto Rico\", new Date(2011,7,10), 126.55 ], [ \"Romania\", new Date(2011,7,10), 545 ], [ \"Russia\", new Date(2011,7,10), 312.85 ], [ \"Rwanda\", new Date(2011,7,10), 576.95 ], [ \"Saint Vincent and the Grenadin\", new Date(2011,7,10), 93.75 ], [ \"Samoa\", new Date(2011,7,10), 234.17 ], [ \"San Marino\", new Date(2011,7,10), 228.63 ], [ \"Saudi Arabia\", new Date(2011,7,10), 408.76 ], [ \"Senegal\", new Date(2011,7,10), 59.333 ], [ \"Serbia\", new Date(2011,7,10), 621.8 ], [ \"Seychelles\", new Date(2011,7,10), 440.04 ], [ \"Sierra Leone\", new Date(2011,7,10), 1695.4 ], [ \"Singapore\", new Date(2011,7,10), 185.4 ], [ \"Slovenia\", new Date(2011,7,10), 87.5 ], [ \"Solomon Islands\", new Date(2011,7,10), 300 ], [ \"Somalia\", new Date(2011,7,10), 399.97 ], [ \"South Africa\", new Date(2011,7,10), 106.95 ], [ \"South Korea\", new Date(2011,7,10), 97.571 ], [ \"Spain\", new Date(2011,7,10), 248.03 ], [ \"Sri Lanka\", new Date(2011,7,10), 241.34 ], [ \"Sudan\", new Date(2011,7,10), 474.09 ], [ \"Swaziland\", new Date(2011,7,10), 190.25 ], [ \"Sweden\", new Date(2011,7,10), 504.54 ], [ \"Switzerland\", new Date(2011,7,10), 624.5 ], [ \"Syria\", new Date(2011,7,10), 384.51 ], [ \"Taiwan\", new Date(2011,7,10), 193.18 ], [ \"Tajikistan\", new Date(2011,7,10), 267.55 ], [ \"Tanzania\", new Date(2011,7,10), 250.79 ], [ \"Thailand\", new Date(2011,7,10), 133.44 ], [ \"Tonga\", new Date(2011,7,10), 200.71 ], [ \"Trinidad and Tobago\", new Date(2011,7,10), 1028.5 ], [ \"Tunisia\", new Date(2011,7,10), 548.77 ], [ \"Turkey\", new Date(2011,7,10), 494.74 ], [ \"Turks and Caicos Islands\", new Date(2011,7,10), 688.28 ], [ \"UAE\", new Date(2011,7,10), 86.147 ], [ \"Uganda\", new Date(2011,7,10), 312.19 ], [ \"UK\", new Date(2011,7,10), 211.16 ], [ \"Ukraine\", new Date(2011,7,10), 654.71 ], [ \"Uruguay\", new Date(2011,7,10), 337.5 ], [ \"US\", new Date(2011,7,10), 248.12 ], [ \"Uzbekistan\", new Date(2011,7,10), 423.33 ], [ \"Vanuatu\", new Date(2011,7,10), 222.38 ], [ \"Vatican\", new Date(2011,7,10), 484.64 ], [ \"Venezuela\", new Date(2011,7,10), 594.13 ], [ \"Viet Nam\", new Date(2011,7,10), 378.08 ], [ \"Yemen\", new Date(2011,7,10), 287.61 ], [ \"Zambia\", new Date(2011,7,10), 355.56 ], [ \"Zimbabwe\", new Date(2011,7,10), 270.58 ], [ \"China\", new Date(2011,7,11), 58.289 ], [ \"UK\", new Date(2011,7,11), 74.741 ], [ \"US\", new Date(2011,7,11), 42.103 ], [ \"US\", new Date(2011,7,12), 13.333 ], [ \"Afghanistan\", new Date(2011,7,19), 181.33 ], [ \"Albania\", new Date(2011,7,19), 247.55 ], [ \"Algeria\", new Date(2011,7,19), 244.07 ], [ \"Angola\", new Date(2011,7,19), 175 ], [ \"Argentina\", new Date(2011,7,19), 128.52 ], [ \"Aruba\", new Date(2011,7,19), 137 ], [ \"Australia\", new Date(2011,7,19), 130.48 ], [ \"Austria\", new Date(2011,7,19), 142.78 ], [ \"Bahamas\", new Date(2011,7,19), 445.34 ], [ \"Bahrain\", new Date(2011,7,19), 167.07 ], [ \"Bangladesh\", new Date(2011,7,19), 169.05 ], [ \"Belarus\", new Date(2011,7,19), 234.38 ], [ \"Belgium\", new Date(2011,7,19), 239.64 ], [ \"Bermuda\", new Date(2011,7,19), 267.22 ], [ \"Bolivia\", new Date(2011,7,19), 141.66 ], [ \"Bosnia\", new Date(2011,7,19), 155.56 ], [ \"Botswana\", new Date(2011,7,19), 20.833 ], [ \"Brazil\", new Date(2011,7,19), 189.72 ], [ \"Bulgaria\", new Date(2011,7,19), 144.19 ], [ \"Burkina Faso\", new Date(2011,7,19), 471.5 ], [ \"Cambodia\", new Date(2011,7,19), 326.69 ], [ \"Cameroon\", new Date(2011,7,19), 105.21 ], [ \"Canada\", new Date(2011,7,19), 149.73 ], [ \"Cape Verde\", new Date(2011,7,19), 295.14 ], [ \"Chad\", new Date(2011,7,19), 61.538 ], [ \"Channel Islands\", new Date(2011,7,19), 100 ], [ \"Chile\", new Date(2011,7,19), 208.81 ], [ \"China\", new Date(2011,7,19), 176.31 ], [ \"Colombia\", new Date(2011,7,19), 205.11 ], [ \"Congo\", new Date(2011,7,19), 171.41 ], [ \"Cook Islands\", new Date(2011,7,19), 100 ], [ \"Costa Rica\", new Date(2011,7,19), 181 ], [ \"Cote d'Ivoire\", new Date(2011,7,19), 279.8 ], [ \"Croatia\", new Date(2011,7,19), 225 ], [ \"Cuba\", new Date(2011,7,19), 257.8 ], [ \"Czech Republic\", new Date(2011,7,19), 188.02 ], [ \"Denmark\", new Date(2011,7,19), 192.12 ], [ \"Djibouti\", new Date(2011,7,19), 59.926 ], [ \"DR Congo\", new Date(2011,7,19), 77.083 ], [ \"Ecuador\", new Date(2011,7,19), 111.77 ], [ \"Egypt\", new Date(2011,7,19), 215.23 ], [ \"El Salvador\", new Date(2011,7,19), 375.92 ], [ \"Eritrea\", new Date(2011,7,19), 200 ], [ \"Estonia\", new Date(2011,7,19), 146.97 ], [ \"Ethiopia\", new Date(2011,7,19), 145 ], [ \"Fiji\", new Date(2011,7,19), 115.76 ], [ \"France\", new Date(2011,7,19), 158.71 ], [ \"Georgia\", new Date(2011,7,19), 285.7 ], [ \"Germany\", new Date(2011,7,19), 149.52 ], [ \"Ghana\", new Date(2011,7,19), 71.212 ], [ \"Greece\", new Date(2011,7,19), 160.62 ], [ \"Greenland\", new Date(2011,7,19), 48.611 ], [ \"Guatemala\", new Date(2011,7,19), 207.09 ], [ \"Haiti\", new Date(2011,7,19), 253.88 ], [ \"Honduras\", new Date(2011,7,19), 243.76 ], [ \"Hong Kong\", new Date(2011,7,19), 215.87 ], [ \"Hungary\", new Date(2011,7,19), 371.88 ], [ \"Iceland\", new Date(2011,7,19), 270.35 ], [ \"India\", new Date(2011,7,19), 142.31 ], [ \"Indonesia\", new Date(2011,7,19), 148.31 ], [ \"Iran\", new Date(2011,7,19), 228.59 ], [ \"Iraq\", new Date(2011,7,19), 190.46 ], [ \"Ireland\", new Date(2011,7,19), 79.82 ], [ \"Isle of Man\", new Date(2011,7,19), 169.33 ], [ \"Israel\", new Date(2011,7,19), 217.02 ], [ \"Italy\", new Date(2011,7,19), 182.47 ], [ \"Jamaica\", new Date(2011,7,19), 189.55 ], [ \"Japan\", new Date(2011,7,19), 208.64 ], [ \"Jordan\", new Date(2011,7,19), 133.65 ], [ \"Kenya\", new Date(2011,7,19), 157.08 ], [ \"Kiribati\", new Date(2011,7,19), 362.05 ], [ \"Kyrgyzstan\", new Date(2011,7,19), 183.33 ], [ \"Laos\", new Date(2011,7,19), 275.69 ], [ \"Lebanon\", new Date(2011,7,19), 234.33 ], [ \"Liberia\", new Date(2011,7,19), 136.31 ], [ \"Libya\", new Date(2011,7,19), 219.95 ], [ \"Liechtenstein\", new Date(2011,7,19), 314.29 ], [ \"Lithuania\", new Date(2011,7,19), 254.93 ], [ \"Malawi\", new Date(2011,7,19), 216.23 ], [ \"Malaysia\", new Date(2011,7,19), 235.86 ], [ \"Maldives\", new Date(2011,7,19), 126.19 ], [ \"Mexico\", new Date(2011,7,19), 195.89 ], [ \"Monaco\", new Date(2011,7,19), 60.164 ], [ \"Mongolia\", new Date(2011,7,19), 232.82 ], [ \"Montenegro\", new Date(2011,7,19), 100 ], [ \"Morocco\", new Date(2011,7,19), 60.637 ], [ \"Mozambique\", new Date(2011,7,19), 248.33 ], [ \"Myanmar\", new Date(2011,7,19), 359.41 ], [ \"Namibia\", new Date(2011,7,19), 14.286 ], [ \"Nauru\", new Date(2011,7,19), 125 ], [ \"Nepal\", new Date(2011,7,19), 234.61 ], [ \"Netherlands\", new Date(2011,7,19), 99.185 ], [ \"New Caledonia\", new Date(2011,7,19), 250.89 ], [ \"New Zealand\", new Date(2011,7,19), 110.16 ], [ \"Nicaragua\", new Date(2011,7,19), 420.2 ], [ \"Niger\", new Date(2011,7,19), 297.32 ], [ \"Nigeria\", new Date(2011,7,19), 197.16 ], [ \"North Korea\", new Date(2011,7,19), 215.5 ], [ \"Norway\", new Date(2011,7,19), 237.13 ], [ \"Oman\", new Date(2011,7,19), 203.12 ], [ \"Pakistan\", new Date(2011,7,19), 175.04 ], [ \"Palestine\", new Date(2011,7,19), 227.93 ], [ \"Panama\", new Date(2011,7,19), 263.89 ], [ \"Peru\", new Date(2011,7,19), 192.65 ], [ \"Philippines\", new Date(2011,7,19), 208.45 ], [ \"Poland\", new Date(2011,7,19), 348.84 ], [ \"Portugal\", new Date(2011,7,19), 108.42 ], [ \"Puerto Rico\", new Date(2011,7,19), 372.95 ], [ \"Romania\", new Date(2011,7,19), 127.61 ], [ \"Russia\", new Date(2011,7,19), 202.26 ], [ \"Rwanda\", new Date(2011,7,19), 243.77 ], [ \"Samoa\", new Date(2011,7,19), 116.67 ], [ \"San Marino\", new Date(2011,7,19), 197.23 ], [ \"Saudi Arabia\", new Date(2011,7,19), 195.95 ], [ \"Senegal\", new Date(2011,7,19), 200 ], [ \"Serbia\", new Date(2011,7,19), 177.15 ], [ \"Seychelles\", new Date(2011,7,19), 99.251 ], [ \"Sierra Leone\", new Date(2011,7,19), 300.79 ], [ \"Singapore\", new Date(2011,7,19), 202.43 ], [ \"Slovenia\", new Date(2011,7,19), 154.52 ], [ \"Somalia\", new Date(2011,7,19), 161.72 ], [ \"South Africa\", new Date(2011,7,19), 114.02 ], [ \"South Korea\", new Date(2011,7,19), 161.18 ], [ \"Spain\", new Date(2011,7,19), 125.66 ], [ \"Sri Lanka\", new Date(2011,7,19), 395.04 ], [ \"Sudan\", new Date(2011,7,19), 267 ], [ \"Sweden\", new Date(2011,7,19), 186.29 ], [ \"Switzerland\", new Date(2011,7,19), 152.42 ], [ \"Syria\", new Date(2011,7,19), 196.7 ], [ \"Taiwan\", new Date(2011,7,19), 215.62 ], [ \"Tajikistan\", new Date(2011,7,19), 40.873 ], [ \"Tanzania\", new Date(2011,7,19), 183.52 ], [ \"Thailand\", new Date(2011,7,19), 123.83 ], [ \"Togo\", new Date(2011,7,19), 200 ], [ \"Tonga\", new Date(2011,7,19), 340.93 ], [ \"Trinidad and Tobago\", new Date(2011,7,19), 171.43 ], [ \"Tunisia\", new Date(2011,7,19), 201.97 ], [ \"Turkey\", new Date(2011,7,19), 229.06 ], [ \"Turkmenistan\", new Date(2011,7,19), 255.56 ], [ \"Turks and Caicos Islands\", new Date(2011,7,19), 253.33 ], [ \"UAE\", new Date(2011,7,19), 134.35 ], [ \"Uganda\", new Date(2011,7,19), 106.36 ], [ \"UK\", new Date(2011,7,19), 61.63 ], [ \"Ukraine\", new Date(2011,7,19), 285.42 ], [ \"Uruguay\", new Date(2011,7,19), 315.98 ], [ \"US\", new Date(2011,7,19), 124.91 ], [ \"Uzbekistan\", new Date(2011,7,19), 126.35 ], [ \"Vanuatu\", new Date(2011,7,19), 207.79 ], [ \"Vatican\", new Date(2011,7,19), 335.02 ], [ \"Venezuela\", new Date(2011,7,19), 290.66 ], [ \"Viet Nam\", new Date(2011,7,19), 235.78 ], [ \"Yemen\", new Date(2011,7,19), 198.18 ], [ \"Zimbabwe\", new Date(2011,7,19), 179.39 ], [ \"Afghanistan\", new Date(2011,7,20), 136.97 ], [ \"Algeria\", new Date(2011,7,20), 187.89 ], [ \"Angola\", new Date(2011,7,20), 239.15 ], [ \"Australia\", new Date(2011,7,20), 181.95 ], [ \"Austria\", new Date(2011,7,20), 62.5 ], [ \"Bahamas\", new Date(2011,7,20), 229.09 ], [ \"Belgium\", new Date(2011,7,20), 119.05 ], [ \"Bermuda\", new Date(2011,7,20), 23.409 ], [ \"Bolivia\", new Date(2011,7,20), 103.7 ], [ \"Bosnia\", new Date(2011,7,20), 100 ], [ \"Botswana\", new Date(2011,7,20), 304.17 ], [ \"Brazil\", new Date(2011,7,20), 63.449 ], [ \"Burkina Faso\", new Date(2011,7,20), 397.43 ], [ \"Burundi\", new Date(2011,7,20), 200 ], [ \"Cameroon\", new Date(2011,7,20), 200 ], [ \"Chad\", new Date(2011,7,20), 245.24 ], [ \"Chile\", new Date(2011,7,20), 120.68 ], [ \"China\", new Date(2011,7,20), 149.99 ], [ \"Costa Rica\", new Date(2011,7,20), 33.333 ], [ \"Cote d'Ivoire\", new Date(2011,7,20), 184.23 ], [ \"Cuba\", new Date(2011,7,20), 141.94 ], [ \"Czech Republic\", new Date(2011,7,20), 11.111 ], [ \"Denmark\", new Date(2011,7,20), 225 ], [ \"DR Congo\", new Date(2011,7,20), 212.82 ], [ \"Egypt\", new Date(2011,7,20), 207.3 ], [ \"Eritrea\", new Date(2011,7,20), 213.89 ], [ \"Ethiopia\", new Date(2011,7,20), 167.46 ], [ \"France\", new Date(2011,7,20), 154.52 ], [ \"Gabon\", new Date(2011,7,20), 280 ], [ \"Germany\", new Date(2011,7,20), 102.32 ], [ \"Ghana\", new Date(2011,7,20), 245.97 ], [ \"Guatemala\", new Date(2011,7,20), 102.7 ], [ \"India\", new Date(2011,7,20), 35.973 ], [ \"Iran\", new Date(2011,7,20), 167.4 ], [ \"Iraq\", new Date(2011,7,20), 71.521 ], [ \"Ireland\", new Date(2011,7,20), 33.083 ], [ \"Israel\", new Date(2011,7,20), 134.45 ], [ \"Italy\", new Date(2011,7,20), 224.22 ], [ \"Japan\", new Date(2011,7,20), 157.83 ], [ \"Kenya\", new Date(2011,7,20), 152.95 ], [ \"Lesotho\", new Date(2011,7,20), 291.71 ], [ \"Liberia\", new Date(2011,7,20), 111 ], [ \"Libya\", new Date(2011,7,20), 196.64 ], [ \"Madagascar\", new Date(2011,7,20), 200 ], [ \"Malawi\", new Date(2011,7,20), 278.13 ], [ \"Malaysia\", new Date(2011,7,20), 108.11 ], [ \"Mexico\", new Date(2011,7,20), 137.23 ], [ \"Mozambique\", new Date(2011,7,20), 221.3 ], [ \"Namibia\", new Date(2011,7,20), 200 ], [ \"Netherlands\", new Date(2011,7,20), 64.286 ], [ \"New Zealand\", new Date(2011,7,20), 164.96 ], [ \"Niger\", new Date(2011,7,20), 220.26 ], [ \"Nigeria\", new Date(2011,7,20), 170 ], [ \"North Korea\", new Date(2011,7,20), 231.31 ], [ \"Norway\", new Date(2011,7,20), 131.07 ], [ \"Pakistan\", new Date(2011,7,20), 91.094 ], [ \"Palestine\", new Date(2011,7,20), 258.95 ], [ \"Philippines\", new Date(2011,7,20), 162.13 ], [ \"Poland\", new Date(2011,7,20), 196.18 ], [ \"Russia\", new Date(2011,7,20), 131.12 ], [ \"Rwanda\", new Date(2011,7,20), 155 ], [ \"San Marino\", new Date(2011,7,20), 14.286 ], [ \"Saudi Arabia\", new Date(2011,7,20), 33.694 ], [ \"Senegal\", new Date(2011,7,20), 151.07 ], [ \"Sierra Leone\", new Date(2011,7,20), 300 ], [ \"Singapore\", new Date(2011,7,20), 100 ], [ \"Somalia\", new Date(2011,7,20), 170.76 ], [ \"South Africa\", new Date(2011,7,20), 61.8 ], [ \"Spain\", new Date(2011,7,20), 126.04 ], [ \"Sudan\", new Date(2011,7,20), 224.8 ], [ \"Swaziland\", new Date(2011,7,20), 179.55 ], [ \"Sweden\", new Date(2011,7,20), 217.86 ], [ \"Switzerland\", new Date(2011,7,20), 12.5 ], [ \"Syria\", new Date(2011,7,20), 141.19 ], [ \"Tajikistan\", new Date(2011,7,20), 213.79 ], [ \"Tanzania\", new Date(2011,7,20), 127.46 ], [ \"Togo\", new Date(2011,7,20), 200 ], [ \"Tunisia\", new Date(2011,7,20), 232.18 ], [ \"Turkey\", new Date(2011,7,20), 101.89 ], [ \"UAE\", new Date(2011,7,20), 15.074 ], [ \"Uganda\", new Date(2011,7,20), 212.14 ], [ \"UK\", new Date(2011,7,20), 102.47 ], [ \"US\", new Date(2011,7,20), 91.5 ], [ \"Vanuatu\", new Date(2011,7,20), 112.29 ], [ \"Vatican\", new Date(2011,7,20), 108.78 ], [ \"Western Sahara\", new Date(2011,7,20), 200 ], [ \"Zimbabwe\", new Date(2011,7,20), 146.25 ], [ \"Afghanistan\", new Date(2011,7,23), 42.478 ], [ \"Australia\", new Date(2011,7,23), 92.593 ], [ \"Canada\", new Date(2011,7,23), 177.78 ], [ \"China\", new Date(2011,7,23), 59.397 ], [ \"France\", new Date(2011,7,23), 80.557 ], [ \"Germany\", new Date(2011,7,23), 125.08 ], [ \"Hong Kong\", new Date(2011,7,23), 25 ], [ \"Hungary\", new Date(2011,7,23), 374.82 ], [ \"India\", new Date(2011,7,23), 78.668 ], [ \"Indonesia\", new Date(2011,7,23), 124.25 ], [ \"Iran\", new Date(2011,7,23), 127.44 ], [ \"Iraq\", new Date(2011,7,23), 18.895 ], [ \"Israel\", new Date(2011,7,23), 75.398 ], [ \"Japan\", new Date(2011,7,23), 175.98 ], [ \"Kenya\", new Date(2011,7,23), 100 ], [ \"Libya\", new Date(2011,7,23), 117.22 ], [ \"Mexico\", new Date(2011,7,23), 18.75 ], [ \"Netherlands\", new Date(2011,7,23), 92.145 ], [ \"Nigeria\", new Date(2011,7,23), 110.53 ], [ \"North Korea\", new Date(2011,7,23), 264.79 ], [ \"Norway\", new Date(2011,7,23), 167 ], [ \"Pakistan\", new Date(2011,7,23), 166.15 ], [ \"Palestine\", new Date(2011,7,23), 138.46 ], [ \"Poland\", new Date(2011,7,23), 201.74 ], [ \"Russia\", new Date(2011,7,23), 158.58 ], [ \"Saudi Arabia\", new Date(2011,7,23), 71.666 ], [ \"Somalia\", new Date(2011,7,23), 104.76 ], [ \"Sweden\", new Date(2011,7,23), 437.5 ], [ \"Switzerland\", new Date(2011,7,23), 106.67 ], [ \"Syria\", new Date(2011,7,23), 140.02 ], [ \"UAE\", new Date(2011,7,23), 23.529 ], [ \"UK\", new Date(2011,7,23), 48.851 ], [ \"US\", new Date(2011,7,23), 126.82 ], [ \"Vatican\", new Date(2011,7,23), 208.33 ], [ \"Afghanistan\", new Date(2011,7,25), 154.32 ], [ \"Angola\", new Date(2011,7,25), 341.67 ], [ \"Australia\", new Date(2011,7,25), 36.111 ], [ \"Austria\", new Date(2011,7,25), 200 ], [ \"Bulgaria\", new Date(2011,7,25), 150 ], [ \"Cape Verde\", new Date(2011,7,25), 190.48 ], [ \"Chile\", new Date(2011,7,25), 193 ], [ \"China\", new Date(2011,7,25), 136.26 ], [ \"Congo\", new Date(2011,7,25), 202.1 ], [ \"Cote d'Ivoire\", new Date(2011,7,25), 200 ], [ \"Denmark\", new Date(2011,7,25), 95.833 ], [ \"Djibouti\", new Date(2011,7,25), 200 ], [ \"Egypt\", new Date(2011,7,25), 248.52 ], [ \"France\", new Date(2011,7,25), 179.06 ], [ \"Germany\", new Date(2011,7,25), 153.91 ], [ \"Hong Kong\", new Date(2011,7,25), 446.43 ], [ \"Hungary\", new Date(2011,7,25), 475 ], [ \"India\", new Date(2011,7,25), 108.97 ], [ \"Iran\", new Date(2011,7,25), 133.33 ], [ \"Iraq\", new Date(2011,7,25), 102.08 ], [ \"Israel\", new Date(2011,7,25), 154.42 ], [ \"Italy\", new Date(2011,7,25), 230.73 ], [ \"Japan\", new Date(2011,7,25), 238.75 ], [ \"Kenya\", new Date(2011,7,25), 122.79 ], [ \"Liberia\", new Date(2011,7,25), 180 ], [ \"Libya\", new Date(2011,7,25), 191.93 ], [ \"Malawi\", new Date(2011,7,25), 252.11 ], [ \"Niger\", new Date(2011,7,25), 309.71 ], [ \"Nigeria\", new Date(2011,7,25), 130.52 ], [ \"Norway\", new Date(2011,7,25), 97.778 ], [ \"Pakistan\", new Date(2011,7,25), 115.28 ], [ \"Palestine\", new Date(2011,7,25), 280.01 ], [ \"Russia\", new Date(2011,7,25), 111.83 ], [ \"Rwanda\", new Date(2011,7,25), 110 ], [ \"Senegal\", new Date(2011,7,25), 100 ], [ \"Sierra Leone\", new Date(2011,7,25), 150.74 ], [ \"Somalia\", new Date(2011,7,25), 119.55 ], [ \"South Africa\", new Date(2011,7,25), 145.44 ], [ \"Spain\", new Date(2011,7,25), 343.08 ], [ \"Sudan\", new Date(2011,7,25), 195.73 ], [ \"Swaziland\", new Date(2011,7,25), 130 ], [ \"Sweden\", new Date(2011,7,25), 169.17 ], [ \"Syria\", new Date(2011,7,25), 179.18 ], [ \"Tanzania\", new Date(2011,7,25), 114.16 ], [ \"Tunisia\", new Date(2011,7,25), 159.52 ], [ \"Turkey\", new Date(2011,7,25), 208.62 ], [ \"UAE\", new Date(2011,7,25), 145.83 ], [ \"Uganda\", new Date(2011,7,25), 120.99 ], [ \"UK\", new Date(2011,7,25), 93.576 ], [ \"US\", new Date(2011,7,25), 147.51 ], [ \"Vatican\", new Date(2011,7,25), 438.1 ], [ \"Yemen\", new Date(2011,7,25), 180.72 ], [ \"Zambia\", new Date(2011,7,25), 152.32 ], [ \"Zimbabwe\", new Date(2011,7,25), 194.88 ], [ \"Afghanistan\", new Date(2011,7,26), 163.6 ], [ \"Algeria\", new Date(2011,7,26), 169.67 ], [ \"Argentina\", new Date(2011,7,26), 161.02 ], [ \"Aruba\", new Date(2011,7,26), 216.98 ], [ \"Australia\", new Date(2011,7,26), 154.05 ], [ \"Austria\", new Date(2011,7,26), 99.999 ], [ \"Bahamas\", new Date(2011,7,26), 538.96 ], [ \"Bahrain\", new Date(2011,7,26), 227.49 ], [ \"Bolivia\", new Date(2011,7,26), 200 ], [ \"Bosnia\", new Date(2011,7,26), 900 ], [ \"Cameroon\", new Date(2011,7,26), 200 ], [ \"Canada\", new Date(2011,7,26), 183.02 ], [ \"Chile\", new Date(2011,7,26), 248.59 ], [ \"China\", new Date(2011,7,26), 143.53 ], [ \"Colombia\", new Date(2011,7,26), 300 ], [ \"Egypt\", new Date(2011,7,26), 148.5 ], [ \"Ethiopia\", new Date(2011,7,26), 23.846 ], [ \"France\", new Date(2011,7,26), 185.85 ], [ \"Germany\", new Date(2011,7,26), 118.03 ], [ \"Greece\", new Date(2011,7,26), 115.93 ], [ \"Guatemala\", new Date(2011,7,26), 193.57 ], [ \"Haiti\", new Date(2011,7,26), 339.86 ], [ \"India\", new Date(2011,7,26), 151.96 ], [ \"Indonesia\", new Date(2011,7,26), 166.67 ], [ \"Iran\", new Date(2011,7,26), 177.57 ], [ \"Iraq\", new Date(2011,7,26), 211.64 ], [ \"Ireland\", new Date(2011,7,26), 118.35 ], [ \"Israel\", new Date(2011,7,26), 247.79 ], [ \"Italy\", new Date(2011,7,26), 336.89 ], [ \"Jamaica\", new Date(2011,7,26), 100 ], [ \"Japan\", new Date(2011,7,26), 178.35 ], [ \"Kenya\", new Date(2011,7,26), 164.87 ], [ \"Lebanon\", new Date(2011,7,26), 16.667 ], [ \"Libya\", new Date(2011,7,26), 145.67 ], [ \"Lithuania\", new Date(2011,7,26), 250.74 ], [ \"Malaysia\", new Date(2011,7,26), 132.42 ], [ \"Mexico\", new Date(2011,7,26), 141.7 ], [ \"Myanmar\", new Date(2011,7,26), 100 ], [ \"Nepal\", new Date(2011,7,26), 315.56 ], [ \"Nigeria\", new Date(2011,7,26), 169.25 ], [ \"North Korea\", new Date(2011,7,26), 327.14 ], [ \"Norway\", new Date(2011,7,26), 145.66 ], [ \"Pakistan\", new Date(2011,7,26), 146 ], [ \"Palestine\", new Date(2011,7,26), 168.42 ], [ \"Peru\", new Date(2011,7,26), 139.02 ], [ \"Philippines\", new Date(2011,7,26), 220 ], [ \"Puerto Rico\", new Date(2011,7,26), 402.84 ], [ \"Russia\", new Date(2011,7,26), 320.23 ], [ \"Singapore\", new Date(2011,7,26), 450 ], [ \"Somalia\", new Date(2011,7,26), 118.58 ], [ \"Spain\", new Date(2011,7,26), 190.91 ], [ \"Sudan\", new Date(2011,7,26), 187.92 ], [ \"Sweden\", new Date(2011,7,26), 214.73 ], [ \"Syria\", new Date(2011,7,26), 160.73 ], [ \"Tanzania\", new Date(2011,7,26), 176.92 ], [ \"Thailand\", new Date(2011,7,26), 164.17 ], [ \"Tunisia\", new Date(2011,7,26), 229.17 ], [ \"Turkey\", new Date(2011,7,26), 282.35 ], [ \"UAE\", new Date(2011,7,26), 10.345 ], [ \"Uganda\", new Date(2011,7,26), 200 ], [ \"UK\", new Date(2011,7,26), 74.562 ], [ \"US\", new Date(2011,7,26), 127.26 ], [ \"Vatican\", new Date(2011,7,26), 319.76 ], [ \"Venezuela\", new Date(2011,7,26), 325.64 ], [ \"Yemen\", new Date(2011,7,26), 171.1 ], [ \"Afghanistan\", new Date(2011,7,30), 265.03 ], [ \"Albania\", new Date(2011,7,30), 387.41 ], [ \"Algeria\", new Date(2011,7,30), 320.36 ], [ \"Argentina\", new Date(2011,7,30), 251.43 ], [ \"Aruba\", new Date(2011,7,30), 410.35 ], [ \"Australia\", new Date(2011,7,30), 153.31 ], [ \"Austria\", new Date(2011,7,30), 291.38 ], [ \"Bahrain\", new Date(2011,7,30), 370.69 ], [ \"Bangladesh\", new Date(2011,7,30), 99.815 ], [ \"Belarus\", new Date(2011,7,30), 329 ], [ \"Belgium\", new Date(2011,7,30), 249.83 ], [ \"Bermuda\", new Date(2011,7,30), 18.237 ], [ \"Bhutan\", new Date(2011,7,30), 200 ], [ \"Bolivia\", new Date(2011,7,30), 314.75 ], [ \"Bosnia\", new Date(2011,7,30), 948.61 ], [ \"Botswana\", new Date(2011,7,30), 411.59 ], [ \"Brazil\", new Date(2011,7,30), 372.94 ], [ \"Brunei\", new Date(2011,7,30), 226.51 ], [ \"Bulgaria\", new Date(2011,7,30), 384.62 ], [ \"Burkina Faso\", new Date(2011,7,30), 562.5 ], [ \"Cambodia\", new Date(2011,7,30), 503.22 ], [ \"Cameroon\", new Date(2011,7,30), 318.42 ], [ \"Canada\", new Date(2011,7,30), 185.43 ], [ \"Chad\", new Date(2011,7,30), 23.792 ], [ \"Chile\", new Date(2011,7,30), 284.05 ], [ \"China\", new Date(2011,7,30), 196.16 ], [ \"Colombia\", new Date(2011,7,30), 341.8 ], [ \"Congo\", new Date(2011,7,30), 436.9 ], [ \"Costa Rica\", new Date(2011,7,30), 25.556 ], [ \"Cote d'Ivoire\", new Date(2011,7,30), 380.23 ], [ \"Croatia\", new Date(2011,7,30), 182.44 ], [ \"Cuba\", new Date(2011,7,30), 289.6 ], [ \"Czech Republic\", new Date(2011,7,30), 315.95 ], [ \"Denmark\", new Date(2011,7,30), 211.07 ], [ \"East Timor\", new Date(2011,7,30), 260.51 ], [ \"Ecuador\", new Date(2011,7,30), 218.75 ], [ \"Egypt\", new Date(2011,7,30), 251.82 ], [ \"El Salvador\", new Date(2011,7,30), 33.929 ], [ \"Eritrea\", new Date(2011,7,30), 265.39 ], [ \"Estonia\", new Date(2011,7,30), 346.13 ], [ \"Ethiopia\", new Date(2011,7,30), 389.41 ], [ \"Fiji\", new Date(2011,7,30), 32.745 ], [ \"Finland\", new Date(2011,7,30), 166.67 ], [ \"France\", new Date(2011,7,30), 192.55 ], [ \"Gabon\", new Date(2011,7,30), 100 ], [ \"Georgia\", new Date(2011,7,30), 194.17 ], [ \"Germany\", new Date(2011,7,30), 274.1 ], [ \"Greece\", new Date(2011,7,30), 159.35 ], [ \"Greenland\", new Date(2011,7,30), 22.222 ], [ \"Guatemala\", new Date(2011,7,30), 208.1 ], [ \"Guyana\", new Date(2011,7,30), 403.51 ], [ \"Haiti\", new Date(2011,7,30), 349.77 ], [ \"Honduras\", new Date(2011,7,30), 391.74 ], [ \"Hong Kong\", new Date(2011,7,30), 263.94 ], [ \"Hungary\", new Date(2011,7,30), 333.75 ], [ \"Iceland\", new Date(2011,7,30), 318.16 ], [ \"India\", new Date(2011,7,30), 151.32 ], [ \"Indonesia\", new Date(2011,7,30), 162.08 ], [ \"Iran\", new Date(2011,7,30), 282.58 ], [ \"Iraq\", new Date(2011,7,30), 183.18 ], [ \"Ireland\", new Date(2011,7,30), 77.623 ], [ \"Israel\", new Date(2011,7,30), 276.38 ], [ \"Italy\", new Date(2011,7,30), 212.72 ], [ \"Jamaica\", new Date(2011,7,30), 100.71 ], [ \"Japan\", new Date(2011,7,30), 170.43 ], [ \"Jordan\", new Date(2011,7,30), 244.86 ], [ \"Kenya\", new Date(2011,7,30), 205.91 ], [ \"Kiribati\", new Date(2011,7,30), 186.53 ], [ \"Laos\", new Date(2011,7,30), 109.09 ], [ \"Latvia\", new Date(2011,7,30), 250 ], [ \"Lebanon\", new Date(2011,7,30), 166.76 ], [ \"Liberia\", new Date(2011,7,30), 344.01 ], [ \"Libya\", new Date(2011,7,30), 266.13 ], [ \"Lithuania\", new Date(2011,7,30), 81.481 ], [ \"Macedonia\", new Date(2011,7,30), 366.67 ], [ \"Malawi\", new Date(2011,7,30), 396.31 ], [ \"Malaysia\", new Date(2011,7,30), 336.55 ], [ \"Mexico\", new Date(2011,7,30), 285.1 ], [ \"Monaco\", new Date(2011,7,30), 100 ], [ \"Mongolia\", new Date(2011,7,30), 166.67 ], [ \"Myanmar\", new Date(2011,7,30), 248.73 ], [ \"Nepal\", new Date(2011,7,30), 257.07 ], [ \"Netherlands\", new Date(2011,7,30), 135.48 ], [ \"New Zealand\", new Date(2011,7,30), 141.39 ], [ \"Niger\", new Date(2011,7,30), 370.07 ], [ \"Nigeria\", new Date(2011,7,30), 325.65 ], [ \"North Korea\", new Date(2011,7,30), 279.59 ], [ \"Norway\", new Date(2011,7,30), 301.72 ], [ \"Pakistan\", new Date(2011,7,30), 194.46 ], [ \"Palestine\", new Date(2011,7,30), 234.96 ], [ \"Panama\", new Date(2011,7,30), 374.57 ], [ \"Peru\", new Date(2011,7,30), 513.66 ], [ \"Philippines\", new Date(2011,7,30), 210.94 ], [ \"Poland\", new Date(2011,7,30), 535.91 ], [ \"Portugal\", new Date(2011,7,30), 293.13 ], [ \"Puerto Rico\", new Date(2011,7,30), 318.3 ], [ \"Qatar\", new Date(2011,7,30), 243.86 ], [ \"Romania\", new Date(2011,7,30), 311.19 ], [ \"Russia\", new Date(2011,7,30), 198.24 ], [ \"Rwanda\", new Date(2011,7,30), 476.95 ], [ \"San Marino\", new Date(2011,7,30), 28.572 ], [ \"Saudi Arabia\", new Date(2011,7,30), 156.7 ], [ \"Senegal\", new Date(2011,7,30), 100 ], [ \"Serbia\", new Date(2011,7,30), 266.08 ], [ \"Sierra Leone\", new Date(2011,7,30), 691.03 ], [ \"Singapore\", new Date(2011,7,30), 105 ], [ \"Slovenia\", new Date(2011,7,30), 300 ], [ \"Solomon Islands\", new Date(2011,7,30), 588.1 ], [ \"Somalia\", new Date(2011,7,30), 194.38 ], [ \"South Africa\", new Date(2011,7,30), 156.88 ], [ \"South Korea\", new Date(2011,7,30), 189.35 ], [ \"Spain\", new Date(2011,7,30), 310.52 ], [ \"Sri Lanka\", new Date(2011,7,30), 411.94 ], [ \"Sudan\", new Date(2011,7,30), 339.73 ], [ \"Swaziland\", new Date(2011,7,30), 328.52 ], [ \"Sweden\", new Date(2011,7,30), 310.59 ], [ \"Switzerland\", new Date(2011,7,30), 203.92 ], [ \"Syria\", new Date(2011,7,30), 250.61 ], [ \"Taiwan\", new Date(2011,7,30), 187.01 ], [ \"Tajikistan\", new Date(2011,7,30), 219.49 ], [ \"Tanzania\", new Date(2011,7,30), 250.94 ], [ \"Thailand\", new Date(2011,7,30), 107.81 ], [ \"Tonga\", new Date(2011,7,30), 202.22 ], [ \"Trinidad and Tobago\", new Date(2011,7,30), 475.77 ], [ \"Tunisia\", new Date(2011,7,30), 491.69 ], [ \"Turkey\", new Date(2011,7,30), 252.99 ], [ \"UAE\", new Date(2011,7,30), 14.368 ], [ \"Uganda\", new Date(2011,7,30), 152.08 ], [ \"UK\", new Date(2011,7,30), 82.977 ], [ \"Ukraine\", new Date(2011,7,30), 250.77 ], [ \"Uruguay\", new Date(2011,7,30), 675.74 ], [ \"US\", new Date(2011,7,30), 112.06 ], [ \"Uzbekistan\", new Date(2011,7,30), 91.111 ], [ \"Vanuatu\", new Date(2011,7,30), 230.46 ], [ \"Vatican\", new Date(2011,7,30), 312.22 ], [ \"Venezuela\", new Date(2011,7,30), 379.61 ], [ \"Viet Nam\", new Date(2011,7,30), 203.53 ], [ \"Yemen\", new Date(2011,7,30), 234.18 ], [ \"Zambia\", new Date(2011,7,30), 15.79 ], [ \"Zimbabwe\", new Date(2011,7,30), 312.56 ], [ \"Argentina\", new Date(2011,7,31), 223.64 ], [ \"Brazil\", new Date(2011,7,31), 306.92 ], [ \"Chile\", new Date(2011,7,31), 169.62 ], [ \"Costa Rica\", new Date(2011,7,31), 50.526 ], [ \"Guatemala\", new Date(2011,7,31), 76.923 ], [ \"Haiti\", new Date(2011,7,31), 304.17 ], [ \"Palestine\", new Date(2011,7,31), 155.65 ], [ \"Peru\", new Date(2011,7,31), 277.63 ] ]; data.addColumn('string','Country'); data.addColumn('date','Date'); data.addColumn('number','Views'); data.addRows(datajson); return(data); } // jsDrawChart function drawChartMotionChartID1937e74() { var data = gvisDataMotionChartID1937e74() var chart = new google.visualization.MotionChart( document.getElementById('MotionChartID1937e74') ); var options ={}; options[\"width\"] = 1000; options[\"height\"] = 600; chart.draw(data,options); } // jsDisplayChart function displayChartMotionChartID1937e74() { google.load(\"visualization\", \"1\", { packages:[\"motionchart\"] }); google.setOnLoadCallback(drawChartMotionChartID1937e74); } // jsChart displayChartMotionChartID1937e74() //--   Digg News Cycle The googleVis chart can also help us understand the cycle of online news. Take the Digg news for example:\n // jsData function gvisDataAnnotatedTimeLineID556e641 () { var data = new google.visualization.DataTable(); var datajson = [ [ new Date(2009,6,2), 13, 28, 17, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, null, 1, null, 1, null, null, 1, null, null, 1, null, 1, 1, null, null, null, 2, 1, null, null, 1, 1, null, 1, 1, null, 1, null, null, null, 1, null, null, 1, 1, null, 1, null, 1, null, null, null, null, 1, null, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, 1, 1, null, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, 1, null, 1, 1, null, null, null, null, null, null, null ], [ new Date(2009,6,3), 13, 7, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, 1, 1, 1, 1, null, 1, null, 1, null, null, 1, 1, null, 1, null, null, 2, null, null, null, 1, 1, null, 1, 1, 1, null, 1, 1, null, null, null, null, null, null, null, 1, 1, 1, null, null, null, 1, null, null, 1, null, null, null, 1, 1, null, 1, null, null, null, 1, null, null, null, 1, null, null, null, null, 1, null, null, null, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, 1, null, null, null, null, null, null ], [ new Date(2009,6,4), 1, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, null, null, null, 1, 1, null, 1, 1, null, null, 1, null, null, 1, null, null, null, null, null, 1, null, null, null, 1, null, null, 1, 1, null, null, 1, 1, 1, null, null, null, null, null, null, 1, null, 1, null, null, null, 1, null, null, null, null, null, null, 1, 2, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, 1, null, 1, null, 2, null, null, null, null, 1, null, null, 1, 1, null, 1, 1, 1, 1, null, null, 1, 1, null, 1, 1, null, null, null, null, null, null, null ], [ new Date(2009,6,5), null, 2, 2, 1, null, null, null, null, 1, 1, 1, null, null, null, null, 1, null, 1, null, null, null, 1, null, null, null, 1, null, null, null, null, null, null, null, 1, null, null, null, null, 1, null, null, 1, null, null, null, 1, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, 1, null, null, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, 1, 1, null, null, null, null, null, null, null, null, null, null, null, null ], [ new Date(2009,6,1), null, null, null, 11, 154, 5, 4, 9, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, null, 7, 1, 1, 1, 4, 1, null, 1, 1, 1, 1, null, null, 2, null, 1, null, 1, 1, 1, 2, 1, 2, null, 1, 1, 1, 1, 1, null, null, null, null, 1, 2, 1, 1, null, null, 1, 1, null, null, null, null, null, 1, 1, null, 1, 1, null, null, null, null, null, 1, 1, null, null, null, 1, 1, null, null, 1, null, 1, null, null, null, 1, null, null, null, null, 1, null, 1, 1, null, null, null, null, null, null, null, null, null, 1, null, null, null, 1, null, null ], [ new Date(2009,5,30), null, null, null, null, 18, 73, 10, 22, 50, 41, 4, 56, 5, 1, 5, 2, 1, 1, 2, 1, 1, 4, 1, 1, 1, 2, 1, null, 1, 2, 1, 1, 1, 1, 2, null, 1, 1, 2, 1, 1, 1, 1, 1, null, 1, 1, 1, null, 1, 1, null, 1, null, 1, 1, 1, null, null, 1, 1, null, null, null, 1, 2, null, 1, 1, null, 1, null, null, null, null, 1, null, null, 2, null, null, null, 1, 2, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, 1, 1, null, null, 1, null, 1, 1, null, 1, null, null, null, 1, null, 1, null, null ], [ new Date(2009,5,29), null, null, null, null, null, 20, 8, 17, 42, 2, 12, 4, 17, 39, 1, 5, 1, 4, 5, 1, 2, 9, 1, 3, 1, 7, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, null, 1, null, null, 1, 1, 1, 1, 1, 1, null, 1, null, 1, null, null, null, 1, 1, null, 1, 1, null, null, null, null, null, null, 1, null, null, 1, null, null, null, null, 1, 1, null, 1, null, 1, null, null, null, 1, null, null, null, null, 1, null, 1, 1, null, 1, null, null, 1, null, null, 2, null, null, 1, null, 1, 1, null, null ], [ new Date(2009,5,28), null, null, null, null, null, null, null, null, null, null, null, null, null, 11, 2, 12, 32, 45, 21, 1, 6, 14, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 2, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 3, 1, 1, 1, null, 1, null, null, null, 1, 1, 1, 1, null, 1, 1, null, null, 1, 1, 1, 1, null, 1, null, 1, null, 1, 1, 1, 1, null, null, 1, null, null, null, 1, 1, 1, null, 1, null, 1, 1, null, null, null, null, null, null, null, null, 1, null, null, null, 1, null, null, null, 1, 1, 1, null, null, null, null, null, null, 1, null ], [ new Date(2009,5,27), null, null, null, null, null, null, null, null, null, null, null, null, null, null, 3, 10, 1, 17, 3, 62, 4, 58, 1, 2, 1, 3, 1, 1, 2, 1, null, 1, 1, 1, 3, null, 4, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, null, null, null, null, null, null, 1, 1, 1, null, null, 1, 1, null, null, 1, 1, 1, null, 1, 1, null, null, null, null, null, null, 1, 1, null, 1, null, 1, null, null, 1, 1, null, 1, null, 2, null, null, null, null, null, 1, null, null, 1, null, null, null, null, 1, null, null, 1, null, 1, 1, null, null, null, null, 1, 1, null, null ], [ new Date(2009,5,26), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 12, 3, 14, 8, 25, 92, 2, 5, 23, 2, 1, 1, 2, 5, 1, 4, 1, 4, 1, 2, 1, 1, 1, 1, 1, 4, 2, null, 1, 1, 1, 1, null, null, null, 1, null, 4, 1, 1, 1, null, 1, 1, 1, null, 1, null, 1, null, 1, 1, null, 1, 1, null, null, null, 1, null, null, 1, null, null, 1, null, 1, 2, null, 1, null, 1, null, null, null, 1, null, null, null, null, 1, null, 1, 1, null, null, null, null, null, null, 1, 1, null, null, null, null, null, null, null, 1 ], [ new Date(2009,5,25), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 3, 13, 1, 539, 3, 7, 52, 20, 4, 15, 3, 1, 5, 1, 1, 1, 1, 2, 1, 1, 5, 6, 1, 1, 1, 1, 1, null, null, null, null, null, 1, 2, 1, 1, 1, 1, 1, null, null, null, 1, 1, null, 1, 2, null, 1, null, 1, 1, 1, 1, null, null, 1, null, null, null, null, 1, 1, 1, 1, null, 1, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, 1, 1, null, 1, 1, null, null, null, 1, null, null, null ], [ new Date(2009,5,24), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 19, 6, 21, 1, 12, 14, 5, 57, 21, 18, 3, 8, 19, 4, 3, 1, 1, 3, 8, 1, 1, 2, 1, 1, 1, 1, null, 1, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, null, null, null, null, 1, null, 1, 1, null, 1, null, null, null, 1, 2, 1, 1, 1, null, 2, null, null, null, 1, null, null, null, null, 1, null, null, null, null, null, null, null, 1, 1, 1, 2, null, null, null, 1, 1, 1, null, 1 ], [ new Date(2009,5,23), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 13, 17, 13, 3, 37, 179, 13, 133, 16, 14, 1, 9, 5, 1, 6, 3, 1, 1, 1, 1, null, 1, 1, 1, 1, 3, null, null, 1, 2, null, 1, 1, null, 1, 1, 1, 1, null, 1, null, 1, null, null, 1, null, null, null, null, null, null, null, 1, 2, null, 1, null, 3, null, null, null, 1, 1, null, null, 1, 1, null, null, 1, null, null, null, null, null, null, 1, 1, 1, null, null, null, 1, null, null, null ], [ new Date(2009,5,22), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 6, 28, 25, 25, 23, 14, 16, 72, 169, 206, 7, 47, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, null, 1, null, 1, null, 1, 1, null, null, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, null, 1, 2, null, 2, null, 2, 1, 1, null, 1, null, null, 1, null, 1, null, null, 1, null, 1, null, 1, 1, null, null, 1, null, 1, null, 1, 1, null, 1, null ], [ new Date(2009,5,21), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 16, 11, 4, 1, 11, 2, 7, 81, 2, 1, 1, null, 1, 1, 1, 1, 2, null, 1, 1, 1, 1, null, 1, 6, 2, 1, 1, 2, 1, 1, null, null, null, null, null, 1, 1, 2, null, 1, null, 1, 1, 1, null, 1, null, 1, null, 1, null, null, null, null, null, null, 2, null, 1, 1, null, null, null, null, 1, null, null, 1, null, null, null, null, null, null, null, null ], [ new Date(2009,5,20), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 15, 15, 7, 1, 1, 2, 1, 1, 1, 1, 2, null, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 2, null, 1, null, 1, 1, 1, 1, null, null, 1, null, null, null, null, 2, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, 1, 1, null, null, null, null, 1, null, 1, 1, null, null, null, null, 1, null, null, null ], [ new Date(2009,5,18), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 2, 18, 9, 9, 2, 30, 12, 2, 6, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, null, null, 1, null, null, null, 1, 2, 1, 1, 1, null, 1, null, null, 1, 1, 1, null, null, null, 2, null, 1, 1, null, null, null, null, 1, null, 1, 1, null, 1, null, null, 2, 1, null, 1 ], [ new Date(2009,5,19), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 4, 30, 3, 5, 7, 1, 3, 1, 3, null, 3, 2, 1, null, 1, null, 1, 1, 1, 1, 1, null, 2, 1, 1, 1, 1, 2, null, null, 1, null, null, null, null, 1, 1, 1, 1, null, 3, null, null, null, null, null, 1, null, null, 1, null, 1, null, null, 1, null, 1, 1, null, null, null, null, 1, null, null, 1, null, 1, null ], [ new Date(2009,5,17), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 11, 25, 16, 19, 79, 28, 178, 3, 2, 12, 4, 1, 2, 1, 4, 1, 1, 1, 2, 1, 2, 1, null, null, null, 1, 1, 1, 1, null, null, null, 1, 2, 4, null, 2, 1, 4, null, null, null, null, null, 1, null, null, 1, null, null, 1, null, null, null, null, null, null, null, 1, 1, null, null, null, 2, 1, null, null ], [ new Date(2009,5,16), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 27, 35, 27, 30, 6, 233, 3, 16, 6, 2, 4, 2, 2, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, null, null, 1, 1, 2, 1, null, 1, 1, 4, 1, null, 1, null, 1, 1, 1, 1, 1, 1, 2, 1, null, 1, null, null, 1, null, 1, 1, null, 1, 1, null, null, 1, null, null ], [ new Date(2009,5,15), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 23, 1, 15, 12, 23, 6, 24, 93, 20, 17, 5, 55, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 3, 3, 1, 1, null, 6, 1, 1, null, 1, null, 1, null, 1, 2, 1, 1, 2, 1, 1, null, null, null, 1, null, 1, null, null, null, 1, 1, null, null, 1 ], [ new Date(2009,5,14), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 14, 1, 16, 5, 35, 5, 6, 29, 4, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 4, 1, 1, 2, null, 4, 1, null, null, 1, null, null, null, null, 1, null, 1, 1, 1, 1, null, null, 1, 1, 1, 1, null, null, null, null, 1, 1, null, null ], [ new Date(2009,5,13), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 2, 20, 9, 20, 25, 57, 11, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 5, 2, 1, 1, 1, 2, 1, 1, null, 1, 1, 1, null, null, 2, 1, 1, 1, null, 1, null, null, null, null, null, 1, null, 1, null, null, null, 1, null, null ], [ new Date(2009,5,12), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 14, 6, 6, 4, 41, 14, 5, 3, 5, 1, 1, 1, 8, 4, 1, 1, 1, 4, 1, null, 1, 1, 1, null, 1, null, 2, 1, 1, 2, null, 1, null, null, 1, null, 1, 1, 1, 1, null, 1, null, 1, null, 1 ], [ new Date(2009,5,11), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 14, 4, 14, 9, 7, 2, 1, 21, 6, 9, 64, 92, 2, 2, 1, 3, 1, 1, null, 1, 1, 1, null, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 2, 1, null ], [ new Date(2009,5,10), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 7, 28, 2, 2, 5, 13, 9, 24, 30, 5, 79, 6, 71, 1, 1, null, 1, 1, 1, null, 1, 2, 1, 1, 1, null, 1, null, null, 1, 1, 1, 2, 1, 1, null, 1, 1, 1, null, null ], [ new Date(2009,5,9), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 11, 41, 14, 6, 10, 9, 2, 1, 4, 1, 2, 2, 1, 2, 1, 2, 7, 2, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1 ], [ new Date(2009,5,8), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 6, 11, 8, 108, 32, 22, 4, 2, 2, 3, 3, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, null, 1, 1, 1, 1, 1 ], [ new Date(2009,5,6), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 7, 7, 14, 6, 7, 12, 6, 2, 5, 93, 7, 2, 2, 1, 1, 3, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1 ], [ new Date(2009,5,7), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 4, 3, 10, 18, 13, 1, 2, 2, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1 ], [ new Date(2009,5,5), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 29, 2, 21, 2, 224, 36, 5, 291, 10, 15, 4, 20, 3, 12, 3, 42, 13, 1, 1, 1, 2, 1, 1, 1 ], [ new Date(2009,5,4), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 39, 33, 25, 18, 9, 3, 1, 1, 5, 2, 29, 9, 1, 7, 2, 3, 4, 1, 1, 1 ], [ new Date(2009,5,3), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5, 4, 26, 19, 2, 11, 11, 13, 8, 17, 4, 5 ], [ new Date(2009,5,2), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 9, 16, 2, 1, 9, 7, 4 ], [ new Date(2009,5,1), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 5, 11 ] ]; data.addColumn('date','time'); data.addColumn('number','8'); data.addColumn('number','12'); data.addColumn('number','15'); data.addColumn('number','57'); data.addColumn('number','187'); data.addColumn('number','325'); data.addColumn('number','327'); data.addColumn('number','330'); data.addColumn('number','335'); data.addColumn('number','406'); data.addColumn('number','417'); data.addColumn('number','443'); data.addColumn('number','446'); data.addColumn('number','492'); data.addColumn('number','557'); data.addColumn('number','559'); data.addColumn('number','568'); data.addColumn('number','605'); data.addColumn('number','621'); data.addColumn('number','649'); data.addColumn('number','677'); data.addColumn('number','696'); data.addColumn('number','716'); data.addColumn('number','794'); data.addColumn('number','822'); data.addColumn('number','846'); data.addColumn('number','850'); data.addColumn('number','932'); data.addColumn('number','963'); data.addColumn('number','971'); data.addColumn('number','993'); data.addColumn('number','1030'); data.addColumn('number','1038'); data.addColumn('number','1118'); data.addColumn('number','1148'); data.addColumn('number','1167'); data.addColumn('number','1179'); data.addColumn('number','1190'); data.addColumn('number','1198'); data.addColumn('number','1203'); data.addColumn('number','1266'); data.addColumn('number','1286'); data.addColumn('number','1306'); data.addColumn('number','1321'); data.addColumn('number','1340'); data.addColumn('number','1342'); data.addColumn('number','1372'); data.addColumn('number','1390'); data.addColumn('number','1558'); data.addColumn('number','1637'); data.addColumn('number','1688'); data.addColumn('number','1689'); data.addColumn('number','1750'); data.addColumn('number','1781'); data.addColumn('number','1822'); data.addColumn('number','1900'); data.addColumn('number','1937'); data.addColumn('number','1953'); data.addColumn('number','1990'); data.addColumn('number','2005'); data.addColumn('number','2021'); data.addColumn('number','2029'); data.addColumn('number','2070'); data.addColumn('number','2140'); data.addColumn('number','2166'); data.addColumn('number','2170'); data.addColumn('number','2184'); data.addColumn('number','2187'); data.addColumn('number','2192'); data.addColumn('number','2234'); data.addColumn('number','2242'); data.addColumn('number','2282'); data.addColumn('number','2321'); data.addColumn('number','2370'); data.addColumn('number','2371'); data.addColumn('number','2380'); data.addColumn('number','2465'); data.addColumn('number','2501'); data.addColumn('number','2541'); data.addColumn('number','2560'); data.addColumn('number','2564'); data.addColumn('number','2566'); data.addColumn('number','2568'); data.addColumn('number','2576'); data.addColumn('number','2593'); data.addColumn('number','2656'); data.addColumn('number','2700'); data.addColumn('number','2726'); data.addColumn('number','2796'); data.addColumn('number','2807'); data.addColumn('number','2889'); data.addColumn('number','2927'); data.addColumn('number','2953'); data.addColumn('number','2972'); data.addColumn('number','3012'); data.addColumn('number','3033'); data.addColumn('number','3042'); data.addColumn('number','3082'); data.addColumn('number','3090'); data.addColumn('number','3134'); data.addColumn('number','3136'); data.addColumn('number','3148'); data.addColumn('number','3159'); data.addColumn('number','3160'); data.addColumn('number','3162'); data.addColumn('number','3194'); data.addColumn('number','3227'); data.addColumn('number','3243'); data.addColumn('number','3251'); data.addColumn('number','3297'); data.addColumn('number','3352'); data.addColumn('number','3353'); data.addColumn('number','3424'); data.addColumn('number','3460'); data.addColumn('number','3461'); data.addColumn('number','3490'); data.addColumn('number','3507'); data.addRows(datajson); return(data); } // jsDrawChart function drawChartAnnotatedTimeLineID556e641() { var data = gvisDataAnnotatedTimeLineID556e641() var chart = new google.visualization.AnnotatedTimeLine( document.getElementById('AnnotatedTimeLineID556e641') ); var options ={}; options[\"width\"] = 1000; options[\"height\"] = 600; options[\"displayAnnotations\"] = true; options[\"legendPosition\"] = \"newRow\"; chart.draw(data,options); } // jsDisplayChart function displayChartAnnotatedTimeLineID556e641() { google.load(\"visualization\", \"1\", { packages:[\"annotatedtimeline\"] }); google.setOnLoadCallback(drawChartAnnotatedTimeLineID556e641); } // jsChart displayChartAnnotatedTimeLineID556e641() //--   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a2a0aae5231598e9aa43e8676e4acf57","permalink":"https://chengjunwang.com/post/en/2011-12-11-visualize-with-googlevis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/en/2011-12-11-visualize-with-googlevis/","section":"post","summary":"GoogleVis could be used to visualize the dynamic change of social pattern. Here I will test some examples.\nFirst, let us see the examples in googleVis:\nlibrary(googleVis) data(package=\u0026quot;googleVis\u0026quot;) # Data sets in package ‘googleVis’: # Andrew Hurricane Andrew: googleVis example data set # CityPopularity CityPopularity: googleVis example data set # Exports Exports: googleVis example data set # Fruits Fruits: googleVis example data set # OpenClose OpenClose: googleVis example data set # Population Population: googleVis example data set # Regions Regions: googleVis example data set # Stock Stock: googleVis example data set  Second, we try the example of hurricane of andrew:","tags":null,"title":"Visualizing dynamic changes with googleVis","type":"post"},{"authors":null,"categories":null,"content":"“袁世凯在中国近代的历时转型期中，也算是一个悲剧人物。”——唐德刚 一 挟六镇军威 养敌以自重 袁世凯是一个以军功起家的人物，以小站练兵的方式建立了忠于自己的军队——北洋六镇，又被称之为北洋系，是民国后各系军阀之祖。在袁世凯的班底中，其文班底“嵩山四友”：徐世昌，李经羲，张謇，赵尔巽；武班底包括“北洋三杰”龙虎狗三将军：王士珍，段祺瑞，冯国璋。\n但袁世凯的仕途并没有我们所想的那般顺畅，1908年四十九岁的袁世凯被摄政王载沣开缺回籍。之后他以中国古代官僚所特有的政治智慧自诩“洹上钓叟”，于养寿园中悠游林泉。历时三年，方才应召回京，东山再起，是年10月10日武昌起义，受令讨伐武汉之起义军。狡猾的袁世凯称疾不就，养敌自重。 二 中山成黑马 国体师美国 革命军可基本上分为武汉方面（简称汉方）和上海方面（简称沪方）。汉方拥护黎元洪为革命军大元帅，沪方则抢先选举黄兴为大元帅。后双方到达南京重新选举，以黎，黄分任正负大元帅。 鉴于袁世凯的军威，清廷和革命军都在事实上不得不接受让袁世凯担任皇帝或者总统的现实。但是深谙中国五千年来的政治智慧的袁世凯却既不愿逼宫取位，他盘算着让溥仪退位禅让，自己则必须三辞而后受之；又不能鲁莽得接受国民党等革命军的议会选举，事缓则圆，袁世凯也不想仓促中激起清廷的对抗。 恰在袁世凯举旗观望和黎黄争位之时，孙中山兼程回国，“参议员诸公既然不能举孙为大元帅，就只有举他为临时大总统，以待袁驱除鞑虏后再来让贤了”，这样中山先生就只好以其建国学理和崇高威望戏剧性地成了中华民国第一任临时大总统了，当然选孙文为大总统的另一个原因是传言他获得海外华人百万捐款（实际上却是不名一钱）。 值得一书的是在大局未定之时沪汉双方都同意采纳美国的政治制度：议会制和总统制。这可以被认为中国的共和制度之始，实在是意义非凡。 ##三 不流血政变 袁世凯当权 南方已定，孙文电告袁世凯，暂代临时大总统，虚位以待袁。 此时的袁世凯也不得不加快逼宫的进程，裕隆太后为袁世凯所骗，先是拿出私帑以救武汉之急，后有听信革命军如何有钱，如何厉害，只有退位了。裕隆念念不忘袁世凯许诺的每年400万两的皇室优待费，同意让溥仪退位。是为1912年2月12日之宣统下诏退位，遂成中国之不流血的宫廷政变。 之后，做了45天大总统的孙文辞职，中华民国临时参议院在南京全票选举袁世凯为中华民国第二位临时大总统，并派人迎接袁世凯建都南京。狡猾的袁世凯制造了京津兵变，假称北方未定，不肯迁都南京，革命派只好顺从其意。 为了安抚孙大炮，袁世凯让他出任中国铁路总公司总理的优缺肥差。原来，理想主义的中山先生有一个20万里铁路计划，这不能不说是个万分宏伟的想法，因为中国在1998年方才规划到2002年实现铁路突破7万里。袁世凯明知孙中山之计划不切实际，不可能实现，却并不挑明。待得后来孙文浪费百十万两白银未修成一寸铁路，真可谓“君子可欺以其方”。黄兴则没有这么好远，被任命为南京留守，做安抚那些要被解散的革命军的吃力不讨好的事情，最后被裁撤了之。 但1912年3月11日，孙文任总统期间却公布了由《临时政府组织大纲》改订的《中华民国临时约法》，其核心是将政体由美国总统制改为法国式的内阁制，总统的权利受到内阁限制。由内阁总理直接向国会负责，总统成为虚位元首，这当然是为袁世凯而设计的。 但袁世凯却是一个离不开权利的人，不久唐绍仪内阁即告倒台。年轻的宋教仁从唐内阁中下岗之后就开始了收编小党，将同盟会该组成国民党的活动，后者在1913年在国会中大获全胜，而宋教仁在之前就对外宣称要组织清一色的国民党内阁，这些当然不免让袁世凯大叫其苦。 袁世凯于其时不怕重理论的孙大炮，却怕有组织才能并且锋芒毕露的宋教仁。收买不成，就只好假赵秉均之手杀之而后快了，是为震惊民国的“宋教仁案”。 唐德刚评论说：”在民国史上政变不循法律途径而用枪杆。袁之杀宋是一错，国民党之以暴易暴，兴兵讨袁，则是再错。”“接着三错，四错随之而来，就变成武力至上，军阀混战了。” 教仁即殁，黄兴等主和派主张以法律解决，孙中山等主战派则主张以武力讨伐之。但国民党其实无兵无地又无钱，而袁世凯却恰好获得六国银行团的贷款2500万金镑，未经一月革命党之二月革命即告破产，袁世凯却托中山之福剪除异己，削除藩镇，一举控制了广东江西和安徽这几那个云南，广西。南京的张勋，山西的阎锡山，奉天张作霖，云南唐继尧莫不胆寒，连黎菩萨元洪也被请到北京软禁起来，当然几乎同时被软禁起来的还有梁启超弟子，云南王蔡锷将军。 权倾朝野的袁大头终于登上正式大总统宝座，1914年公布的《中华民国约法》和同年12月29日《修正大总统选举法》袁遂成终身大总统并且可以传位于妻，子。但是贪心不足的袁世凯却在犹豫不定中想要走得更远。 ##四 称帝忧患间 墙倒众人推 民国创立后的第一次农民起义——白朗起义于1913年秋爆发了，次年8月被平定。但相较于内忧，外患才是最严重的：美国划定所谓的麦克马洪线侵占西藏；日本和俄国瓜分东北三省；俄国策划外蒙古独立；日本更是雪上加霜地侵占胶州湾取代了德国在山东的特权，袁世凯拖不过去到底签了丧权辱国的二十一条。凡此种种，袁世凯虽勉力维持，终不堪重负，贻人口舌。 在风雨飘摇之中的袁世凯却最终不合时宜地在摇摆不定地萌发了做皇帝的想法，由其控制的筹安会“六君子”，参政院和全国代表大会拥立袁世凯复辟。袁终于在１９１５年１２月１３日成为中华帝国的洪宪大皇帝。 袁世凯称帝自然为革命派所不容，但其内部的文武班底也反对。狗将军冯国璋和虎将军段祺瑞都恐与之交恶的袁世凯的大儿子袁克定继承大统之后对他们痛下杀手，遂成北洋系之窝里反。更加重袁世凯的担心的是日本也发表了对袁世凯称帝的反对。 外为舆论不容，内为自家人反对，袁世凯在风雨飘摇中走到了人生的终点。１９１６年９月６日，袁世凯病逝，符合袁世凯对冯国璋所说的袁家男人寿不过六十的话。正应了老子之言：物壮则老，谓之不道，不道早已。 是年，段祺瑞取而代之，民国遂入军阀混乱之迷局。惜哉。 ##五　帝制向后转　共和向前看 对于历史深层的国体政体之选择，唐德刚先生说，走过了两千年的封建和帝制的历史，中国已经驶入转型时期的历史三峡，“顺流而下，滩高浪险，掉头逆水，必然翻船，而袁世凯及其党不知也，悲夫。” 是啊，共和制也不是万能的，但共和制虽有诸多不合国情之处却毕竟是向前看的，恰若唐德刚先生所言，共和制是权力递减的制度安排，在一个转型的历史阶段，运用共和制有可能会带来暂时的权力的极度地扩张，恰如蒋介石的权力在某些方面比之古代君王有过之而无不及，但是到了其子蒋经国先生的时候，总统的权力就已经有效地减小了。看来，唐德刚先生是一个赞成政治上的休克疗法的学者。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"eefe734b35b45ccfa352a9f07e71acef","permalink":"https://chengjunwang.com/zh/archive/2008-09-25-yuan-shikai.zh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/archive/2008-09-25-yuan-shikai.zh/","section":"zh","summary":"","tags":null,"title":"写在《袁氏当国》之后","type":"zh"},{"authors":null,"categories":null,"content":"黠之大者\n序言 这个短篇小说是我对本科生活的纪念。那时候的我蜗居在一个山村里。紧张得上着课，看各种不着边际的书。渴望未来，却看不到边界；憧憬爱情，却不善于表达。\n王二是我们在大学这座围城的缩影。本科的学习，我们仍无法窥见科学的全景，对各种工具也缺乏了解，更多的时候只是抱着人文取暖。大四的时候，看王小波的《黄金时代》，叙事的精巧，精神的贲张，让我为之击节。王二便是借了其中的主人公的名字，但缺少了其中的锋芒，多了更多的世俗和顽固。\n围城里有快乐吗？这是一个开放的问题。我想是有的，因为大学时一个改变的场所，身处其境，每时每刻都埋藏着思想和行为改变的种子。虽然身在其中却往往不得其所。这正是大学的魅力，让你身在囹圄，却得以茁壮成长。\n目录  chapter1 王二 chapter2 杨亦凌 chapter3 一条狗 chapter4 小六 chapter5 女大学生 chapter6 教学楼 chapter7 图书馆 chapter8 考研时期的爱情 chapter9 一切都如此重要 chapter10 毛片 chapter11 女人如衣服 chapter12 影吧 chapter13 毛片续 chapter13 鬼的存在 chapter15 失乐园 chapter16 失恋 chapter17 空档期 chapter18 烟 chapter19 自杀论 chapter20 功利主义 chapter21 挟持 chapter22 许三多和斯密 chapter25 纠缠不清 chapter26 旁观者 chapter27 不会经历的奇遇  chapter1:王二 “我们根本就生活在一个悲剧的时代，因此我们不愿惊惶自忧。大灾难已经来临，我们处于废墟之中，我们开始建立一些新的小小的栖息地，怀抱一些新的微小的希望。这是一种颇为艰难的工作。现在没有一条通向未来的康庄大道，但是我们却迂回前进，或攀援障碍而过。不管天翻地覆，我们都得生活。” ——《查泰莱夫人的情人》\n王二何许人也，已经无人考证，因为考证出了也不能写个论文、发个帖子什么的光耀门楣。重要的是王二生在了80年代，这注定了他在一个社会转型的黑铁时代兀自唏嘘。\n虽然王二不是一个经常多愁善感的人，做人也很低调，但是还是有好事者考证出了王二的出处：他是一个学生物的，L大学图书馆里的生物化学课本上都有王二的笔迹。后来我去找过，没发现。\n生在八十年代的王二干事情很认真，他是农民的儿子，是个穿着谈吐透着土气。王二04年高考了，之前他从来没有关心过别人，包括他的父母。王二想的很简单，考个好学校，找个好女人。王二要为他的简单付出代价。\n成绩下来，王二高兴地填了L大学。于是我今天才会写这个短篇。我想幸亏王二选了L大学。不然，我的书就有得换主角了，我很早就打算写本小说，换了很多主角了，从江隆基到李发伸，但是我终于发现我面对他们时丝毫没有激情。我不会写作了。但自从遇到王二，我知道我该写谁了。傻逼王二全身透着冲突，不然后来他不会自杀了。\n我想肯定是王二得罪了这个好事者。不过王二一向龌龊，这样似乎也在所难免。\n我第一次见王二是四年前，那时候的王二身高已经达到1.69m,比我低了一头。王二见到我时说：“丫的你留了多少级，长这么高。”我就只好给王二解释说，身高和营养有很大关系，要多喝牛奶，多锻炼。后来王二就常跟我们去锻炼，打篮球。但是四年过去了，我可以肯定的是：他一厘米也没再长高，还是比我低一头，我也没长高。大学四年了，我们似乎被凝固了，什么也没变。\nchapter2:杨亦凌 就是在球场上王二第一次遇到了杨亦凌。杨亦凌是新疆人，高高的鼻梁表明她有维族人的血统，杨亦凌的父亲是汉族人，母亲是维族。当兵的杨父在新疆看上了美丽的杨母就再也没回老家。杨亦凌跟其他女孩不同，她喜欢打篮球。那天杨亦凌正在跟几个维族帅哥一起打球。\n金黄色的头发使杨亦凌看起来很像是个老外。正因为如此土鳖王二大大咧咧的对我们说：丫的，看对面有个老外也打篮球。\n杨亦凌听了很生气，她冲着王二喊：come on, young man. Let me teach you how to play basketball.\n王二不服气，撺掇我们两群人打比赛。结果身高不足的王二被杨亦凌盖了几个大帽。\n杨亦凌的错误在于休息的时候对王二说，小子，不服再来。\n王二说，哼，不信打不过女人。\n我注意到那时杨亦凌的眼神闪过一丝杀意。\n球场失败的王二决定从哪跌倒就从哪里爬起来，他决定去追杨亦凌。这直接导致了王二后来成为彗星观察爱好者协会的会长。\n王二第一次吻杨亦凌是在十一去青海湖的火车上，杨亦凌后来说，那是第二次。我想知道第一次是什么时候就去问王二。那天王二正在刷牙，时间已经是大三上了，也就是06年深秋，王二吐着白沫说，没有第一次，因为他有很多次试图去吻杨亦凌都没成功。我忘了交代了，杨亦凌身高175cm，所以王二要想得手不仅要有天时还要有地利。\n杨亦凌那时候是个骗子，更确切地说是一个社团——彗星观察爱好者协会的社长。年纪轻轻就成了头，想必你也猜出了杨亦凌其实是王二的师姐了。那时王二大一，杨亦凌大三。但这就给了王二得逞的机会，虽然社团可以靠着骗取无知大学生的信任并收取会费生存，但是彗星本来就不多，想观察到就更难，何况已经有了一个天文爱好者协会。所以，临危受命并急于骗人的杨亦凌决定接受王二的入会申请。\nchapter3一条狗 我的大学生活越发无聊，在失恋之后我决定养狗。我发现，养狗的人都有点小资，够小资的人都在大三、大四。但我决定打破这个僵局。那年我大一。但我没想到我还打破了另外一个僵局。 事实上王二大一上的爱情生活并不顺利。他和高中的女友分了，虽然我知道王二乐得如此，但是我还是看到了王二的伪善的眼泪。\n我说：王二，丫装个什么劲啊，故意冷落别人让她先提出，好像自己很无辜啊。\n于是乎我看到了王二眼里闪过了杨亦凌眼中曾出现过的杀机。\n王二：丫的一边去，爷正伤感呢。闲了就写你的小说去。哪门子的网络写手，还整个什么兰陵小\n小生，你小个p,个子比李恒滨还大，年龄比王皓还老。\n人情冷暖啊，我决定养条狗，并且专门挑了一条凶狠的狗。我给他取了个名字叫路易十四，不过我更愿意简称它为小四。特此声明，那时候我还没看过蜡笔小新。否则，我会给它取名叫小白，因为后来我发现它很色。经我调教之后，它开始在宿舍里为祸一方。\n事实上，王二也很痛苦，不过他发泄痛苦的方法太没创意，他也养了只狗，不过无论个头还是性情都不能跟我的小四相提并论，真是狗如其主人啊。\n小四长的很快，行为也越来越出格，由以前的叼别人的牙刷发展到叼别人的脸盆。那天，小四就是因为叼走了王二的脸盆被王二从六楼追到一楼。\n我不知道杨亦凌是不是也在追另外一条狗，总之，她和王二撞到一块。\n那时，王二追累了，叉着腰简直就是个夜叉。路易十四也跑累了，停在王二脚边王二踢不着的地梳理皮毛。可能是因为它的夜生活太丰富，昨天晚上它同样因为叼走了对面宿舍小六的拖鞋被追的满宿舍楼跑。杨亦凌走近王二，像一个官僚看到了下级，其实就是一个官僚看到了下级，她也叉着腰，像个母夜叉，事实证明后来她就成了夜叉的对象——母夜叉。\n杨亦凌说:王二，你的狗真可爱，它咬人吗？\n一面夸路易十四可爱，一面担心被咬，可见她的夸奖并不真实。并不傻逼的读者，相信你们都能看得出来杨亦凌脑子并不少根筋，只是面对王二，她没有危机感，不想动脑子。\n王二想表现自己，拍着胸脯说：绝对不咬。\n于是，杨亦凌在得到肯定的回复之后想表现下自己的爱心。她弯腰要抱起小四，于是乎手上便留下了一圈并不浅的齿痕。血像三月的春花，从那些先花植物的枯干上涌现，异常绚丽。\n杨亦凌恶狠狠的看了王二一眼。\n王二心中一冷，说：这不是我的狗\u0026hellip;\u0026hellip;\n再给个镜头，我想我能猜出小四的想法，一个母夜叉和一个追了自己很久的夜叉对话后伸出双手靠近自己，这种行为怎么可能是善意的呢。咬，才是合乎理性的行为。但如果老是咬住不放，不管是咬的快感降低——因为边际效用递减，还是咬的行为成本增加——可能被夜叉和母夜叉抓住群殴，于是乎小四松口逃跑。由此可见，小四作为一个和农民、女人一样的弱势群体一样是最为理性的，完全符合我分析它的行为的理性狗的假设。\nchapter4 小六 这个世界如果还有真的话，那是因为存在着太多的假。小六就爱较真。王二就相反，也因此最更为可恶。例如，小六会因为脸盆被路易十四叼走追了它一夜。因为他发现小四的恶行后说：大爷今天逮不着你就不睡了。\n看着在楼道中踱步的小六，王二说：至于吗，跟个狗过不去。\n小六说：爷愿意。又不是你的狗？\n我看得出王二听了牙根发痒，他想打小六一顿，但王二还是有点顾忌的——那时候的小六壮得像头牛，又有一腔纯真的热情。\n两年后才实现这个夙愿。那天，王二、小六和楼管一起打牌、喝酒。那天，小六喝多了，回来发酒疯，把个酒瓶子摔碎在地上，王二说：小六，你丫的，要摔摔你们宿舍里去，别再爷宿舍里撒野。\n小六酒劲上来，怂人胆壮：王二，怎么着，我还打你那。\n王二立稳了，一个拳就把他打倒在地。\n小六从地上爬起来，一脚就踹过去，正中王二小腹，把王二踢到了走廊。王二喝的也不少，四仰八叉的躺在地上，嘴里还念念有词，“哪个孙子踢的？”\n小六闻声一脚又踢向王二，王二头一偏，小六踢中墙壁，站立不稳，再次摔倒。\n众人将他俩拉开。大学里的打架大抵如此，总不能尽兴。\n大一下，疯狂的玩了一学期的王二、我决定背水一战、绝地反击。王二是笨人，又迂（我们那管固执叫迂），他们决定看书。我是虽然不是个顽主，但是明白看一夜书到底不顶用，不如抄袭。大学考试不像高考那么严格，大家坐的近，我的视力好，一不小心就把前后左右的答案看了个遍。\n考高数的那天，我如愿以偿的抄地不亦乐乎。出来后当我给王二讲起高斯定理什么的时候听得他棒槌一愣一愣的。\n王二有点发木，他心里想着会不会挂科，“操行，大学刚开始就栽个跟头。”\n我想王二是真的受打击了吧。这帮人继承了优秀高中生的优良品质，把挂科看成了悬梁自尽，就像是女人被qj了一样，但挂过之后就是另一番境界了，如小六，自从挂了生化之后就再也不怕挂科了。\n当我擦亮眼镜准备考试（经常对着mp3看电子书弄的我视力下降并且有点斗鸡眼），王二提前两周复习生物统计时，小六仍然浑然不知，在大家都奔赴考场之际，他仍然在玩网游。\n当然小六也觉醒过，因为长时间打网游，小六开始营养不良，身体变得极差——这也是两年后我和王二敢打他的原因。\n那天，小六就觉醒了，早上起床后，冲进我们宿舍说，“兄弟们，我改了。”\n我们才知道他已经把电脑装好，打算再也不玩了，小六说：“兄弟我身体太差，你们帮我把电脑放上铺的墙上的箱子里。”\n我和王二见小六终于觉醒了，大为感动，就帮了他一把。\n下午回来却发现他又再玩，不知道他那孱弱的身体是怎样把沉重的tcl显示器搬下来的。 小六的另一次觉醒是在大病之后，因为营养不良，小六的身体不干了。那时候，小六他妈从遥远的东北赶来了，帮着小六把电脑卖了，在确信儿子不会再玩网游之后，六他妈才踏上火车。小六也的确出息了，改成看小说了，整天歪在床上。躺了几天之后，开始大病。小六开始借钱看病。\n王二犯了心太软的毛病，这个毛病他以前追杨亦凌的时候犯过，就是上次杨亦凌被路易十四咬了之后，王二陪着杨亦凌上兰州打狂犬疫苗。回来后，我们就发现杨亦凌看王二的眼神不对了，透着股含情脉脉。看得小六想吐，小六说：女人真装逼。\n如果说王二因为太有爱心勾搭上母夜叉是得偿所愿的话，这次王二滥用同情就损失了200元大币。小六拿到钱之后依然绝然的冲向了医院外的网吧。所以，后来杨亦凌每见小六总要瞪他几眼。\n王二眼中的小六，遍布校园。他们存在意义或许是让王二明白什么样的大学生活不是他想要的。\nchapter5女大学生 在英格兰，黄金在铸币后很久还不曾取得法币资格。\n———亚当-斯密\n如果说王二在加入彗星观察爱好者协会后，还没有取得作为杨亦凌男朋友的法定资格，那么，杨亦凌被狗咬过之后，王二显然是取得了这个资格。对此，杨亦凌的兴奋也许远没有王二那样厉害。因为，一个漂亮女人想在大学混好的一个重要的要件是做一个大众情人。这样，那些宅男们就只能停留在意淫并且不会疲倦的阶段。当然了，这个要求太难，除非这个女人拥有吴仪似的智慧。\n很显然杨亦凌没有这种智慧，所以她打算与王二先出双入对，至于王二卑劣的双宿双飞的想法杨亦凌则明确反对。这里再次彰显了我兰陵小小生的智慧，很多女人唯一的资本就是自己的美貌，而且在表面上开放实则高度保守的中国当代大学生眼里，女人的美貌又有贞操这一大敌，一但丧失贞操，美貌的边际效用就会出现暴跌而不是简单的递减。 对这个问题，王二则走得更远，这是我敬畏王二的地方之一。王二认为，女大学生即使是仅仅交个男朋友，也会使其吸引力大为降低。\n王二是以美国数学家小约翰-纳什的博弈理论开始的，如果想和舞会上漂亮的姑娘共舞一曲，所有参加舞会的男孩子最明智的策略是邀请那些不那么漂亮的姑娘跳舞。\n因为，如果大家都去邀请最漂亮的姑娘跳舞，那么只会有一个胜出者，而且剩下的姑娘由于你没有把她作为第一选择会感觉到恼怒，这么做的结果是很可能绝大部分男孩子连一个舞伴都请不到。而如果人人都不选择最漂亮的那位姑娘跳第一只舞，那么她就会被晾在那里。出于寂寞，可能会很容易接受你第二轮的邀请。而且，无论如何，在第一轮里你已经找到了个姑娘起舞。杨亦凌可能受够了第一轮不被邀请并因此只能做大众情人的痛苦。 我很怀疑这就是漂亮的杨亦凌被王二追到手的原因——她太漂亮，她身边的男生都是纳什的信徒，王二是个非理性的赌博者。\n这似乎已经成为一个社团的铁律了，所以有很多充满智慧的男生或者女生会选择作一个大众情人，因为现在是一个讲究个性的更为直白的表达自己的内心感受的时代，大家不可避免的会选择自己所心仪的男生或者女生，这样很明显会有很多的竞争者，因为虽然标榜着个性，但是大家对于美丽的认可却遵循着几千年来来的审美标准．很显然，大家成功的概率都极大的缩小了，这恐怕也是初恋往往失败的一个重要原因：我们骨子里的浪漫主义情结和现实巨大的竞争之间的矛盾之间的矛盾。\n于是大家在这个阶段为了规避被动或者失恋的痛苦而选择默言，似乎每个人都已经参透了这些人生的奥义（其实骨子里是因为深深明白主动求爱就会陷入被动之中），于是乎很多人选择做一个大众情人，因为他没有勇气接受或者主动追求，当然这种做法是符合经济学的原理的，这样做的机会成本太高了，理性人，即使是有限理性人也不会傻到这种程度，于是乎就出现了一种不追求，不拒绝，不负责的人生态度。\n但我们不能否认，用经济学来理解爱情不可避免的存在巨大地误差，这在更大程度上不是因为非理性的存在，而是失恋的痛苦在初恋时往往是饮鸩止渴的快乐了，大家在短期痛并快乐着，虔诚地皈依这种悲观。王二也曾体会过这种悲观，直到后来遇到小舟。\n但是时间当然会改变这一切，因为人生不仅仅只有爱情。\nchapter6教学楼 事实上我仍然想不通杨亦凌和王二的感情究竟是怎么回事，因为他俩勾搭到一块是05年春天，那时候王二大一，杨亦凌大三。而那时候的杨亦凌已经在准备考研了。如果我没有忘记暗示读者的话，那么你就应该才得出来杨亦凌是一个充满了远大理想的女性。而这正是王二的不幸。\n但那时的王二是体会不到这些的，为了追杨亦凌王二经常伪装成一个爱好学习者，每天在杨亦凌上自习的座位上晃来晃去。\n王二是更喜欢在教学楼上自习的人，因为教学楼里经常会有很多情侣，所以很多抵抗力差的人是不会在教学楼上自习的。另外，教学楼里的座位是连在一块的，通常是中间的一长排座位仅仅做两人，一边一个，中间空出好大空间，一般人看了是不可能有勇气夹在两个人中间坐的。\n但王二何许人也，爱招摇过市的他从来就有一个厚脸皮。王二的通常做法是这样的：很晚采去，那时候座位都被占完了。推开一个坐的满满的实则空了很多座位的教室，肆无忌惮、明目张胆的走进去。当满教室的眼睛都集中在他身上时，王二获得一种至高无上的满足。这个时候她通常会挑选几个对象肆无忌惮地看过去。由此我们可以看出王二身上所特有的演员的特质。如果王二是一个穿着新装的皇帝的话，王二其实经常这样想，他是不在乎自己身上是否真的披着几匹布的。\n在上管理学时都会讲到马斯洛，他提到了几种人类的基本需要，包括生理的需要、安全的需要、情感的需要、尊重的需要和自我实现的需要。王二在这种巡视中所获得的是什么呢？难道他能够从中获得一种得到注意的巅峰体验吗？或许物质生活堪称贫乏的王二依靠精神的意淫获得满足。\n在这种目光的对峙中总会有首先移开目光的一方，王二通常会坚持下来。但有一次，他没有。那一次，他遇到了小舟。\n坐在后排的小舟右手支颐，左手转着一只自动铅笔，看着王二走进，走过来。王二棋逢对手，但这次还是被小舟看毛了，走过小舟时，王二脚步略为加快，没提防教室后面的一级台阶，被绊了一下，王二忍不住转身却发现小舟以一贯的眼神瞅着他，王二的喜剧细胞一下子活跃起来，他看着小舟的线性代数的课本说：我身上有矩阵吗？\n小舟眼神移到王二的脚上，下巴配合着眼神做出一个示意的动作来。\n王二没反应过来：什么？\n小舟说：你的袜子。\n王二才注意到自己穿了两个不同的袜子，一个耐克，一个阿迪达斯。\n这是王二第一次见何小舟，我很庆幸我还记得这个名字。\nchapter7图书馆 一个美丽的女生应该是什么样子的？你所记忆中美丽的女生是怎样出现的。我们一直在思考什么样的女生最优秀，而不是什么样的女生最适合我们。这是我们最大的错误。王二不巧犯了这个错误。 王二本身当然是一个积极求进步的男人，但是王二的进步主要表现在宿舍里，例如王二喜欢在被窝里看《论美国的民主》，在教学楼、图书馆他是绝对不看的。\n因为何小舟，她的出现使王二再不敢肆无忌惮的闯入教学楼上自习。王二现在如惊弓之鸟，看到教学楼的女生就像看到了千千万万个何小舟们。当然更要的原因是因为杨亦凌，考研的杨亦凌像是一个两栖动物，白天栖息在图书馆里的自习室，深夜才回归宿舍。追随杨亦凌的脚步，王二也加入了图书馆占座的行列。\n郎咸平认为大学教育是一个培育精英的场所，以市场化的逻辑进行教育改革的本身就违背了教育的本意。中国大学的扩招与扩张稀释了有限的教育资源。当然，像王二这种有着自我批判意识的庸人应该感谢这种教育的扩张，因为如果没有扩招，或许王二高中毕业根本考不上大学。但是，市场总是会走向均衡的，扩招本身也稀释了大学毕业生本身的含金量。王二算与中国的教育制度打了个平手。倒霉的是那些精英，他们千辛万苦上了大学却发现身边的同学多是一些像王二一样的庸人。但这本身又存在悖论，这就是教育本质的问题，教育到底能否能够提高人的能力。很多人认为大学教育并不能提高人的能力，实际上我们毕业之后所面对的招聘者的核心衡量指标之一是大学的品牌，但我们应该明白考上不同的大学所体现的是高中教育的价值。王二要在大学实现一次质变，他想表明自己能够体现出大学教育的价值，但是在夏官营大学，王二找不到与仰慕的老师交流的机会，就只好与仰慕的书籍交流。\n所以王二对L大学图书馆的感情是很深的。之前图书馆委屈得窝在一个普通的两层的楼上。其气势便让人感到十分猥琐。所幸，不久新图书馆就建成了。虽然王二觉得翠英山如坟，山下的图书馆如墓碑，但是王二在墓碑里活动时候却无比的兴奋，这也成为了王二后来坚持留在夏官营校区的原因。后来很多人问王二，王二不好意思回答，但答案是他离不开书，确切的说他离不开那么多书。\n但是，杨亦凌在图书馆不是看那写有营养的经典，她不像王二一样喜欢呆在书库，她呆在一楼的自习室里。为了追杨亦凌王二之后委屈求爱情也呆在一楼，但是我知道王二是多么想上层楼、再上层楼到三楼看书。于是，王二就只能抱着柱子意淫一下。\nchapter8考研时期的爱情 转过身去，一切都变得遥远。写作的心境一下子乱了，离歌响起，我们很快会被赶出校园。与L大学四年的契约即将完结。一群人在群里悲吟，喝了这杯还有三杯。但我看着王二，仍然会清晰地想起两年前的往事。\n王二坐在考研者中间总有些不协调，或许在一群在考研者中间看《社会契约论》太奢侈了。王二困惑的是为什么这么多人选择考研，陪伴杨亦凌的日子里王二细致地观察了图书馆自习室，地下一层的南侧和东侧是连个巨大的自习室，也是所有考研人争夺的重点。暑假里第一次去排队占座的王二就被吓倒了，早晨六点刚过，图书馆门前就已经密密地站满了人，一直排到南北方向的道路边。而开门的瞬间，人潮如决堤的洪水泻入。在急促的奔跑中中会有人跌倒。丢掉鞋子什么的。因为从正门进要下楼梯才能到一楼的自习室，从楼梯上跌下去可不是闹着玩的，于是图书馆开始早上开放南门。开门的时间是六点五十左右。但通常六点十分王二就得甜蜜梦中惊坐起，背起包向图书馆跑去，因为宿舍楼管总是不愿意早起开门，王二们还要经常跟楼管进行间歇的斗争。\n走出宿舍的王二通常是要一路奔跑到图书馆南门的。\n在从八月到十一月里的六点十五到六点半，王二通常处于奔跑的状态，而他身边的景物却开始变化，芳草枯萎，风霜委地。有一天，王二感觉到第一场雪落下了。伤春悲秋的王二没有来得及多想就继续奔跑起来，因为晚了就没有位置了，杨亦凌就可能要发脾气了。 因为杨亦凌的原因王二提前经历了考研，但如果回想起来，我宁愿将王二和杨亦凌的爱情称之为考研时期的爱情。\n女人毕竟是女人，话说回来，男人到底是男人。如果你个女人在失落无助之时找不到一个肩膀依靠或许是一件很可怜的事情。这种观点到底是辩证的观点。女权主义的错误是把洗脚水和孩子一起泼掉，坚强过后才发现一身孑然。被主义引领着失去了世俗的智慧。杨亦凌是具有世俗智慧的女人，虽然我一直怀疑她对王二的感情。\n但那个时候的王二却经常与杨亦凌出双如对了，有时候两个人一起牵着手安静地走，有时候打闹着闪躲。杨亦凌拥有女人一切可爱之处。\n也正是这个时候王二开始晚上很晚回来。有时候王二会跟我和小六炫耀，才说到杨亦凌柔若无骨的小手时小六终于在吞了口唾沫后说：“不会吧，母夜叉个头比你都高，抱起一堆书疾走如脱兔，一只手可以握住篮球，手少说也有笊篱那么大。”\n时不时我和小六都要提醒王二：“王二，你已经接连三天晚归了，这样下去，楼管是不会放过你的。”\n我更愿意提醒王二：别没良心，上次买的qq恋省着点用。\n王二则厚颜无耻地说：怕什么，有毓婷。\n终于有一天，不对是有一夜，王二开始夜不归宿。气得小六说：丫的王二，真扎实干啊。 后来，王二说杨亦凌那天很失落，那天她放弃内保了。虽然是主动放弃，但是看着别人高高兴兴地内保，母夜叉的心灵还是很受伤。她像每一个有着远大理想的人一样开始自我感伤。\n那一夜，母夜叉和王二沿着南区的柏油路走出了校园。\nchapter9一切都如此重要 王二大二上买了令他后来为止后悔不已的电脑，05年班上买电脑的同学还不多。王二自称自己是一个“早”教徒，对张爱玲的“出名要趁早”的话王二笃信不移。\n对于买电脑的原因，王二很少对人讲。很多sb大学生可能一辈子都想不清楚自己为什么买电脑。消费社会里的人们把很多东西当作身份的标志。用消费品和他们相区分。王二还没无耻到用他的破电脑来和我们划明界限。\n困扰王二的问题是除了书他还能与谁交流？当和杨亦凌的谈话成为一种习惯性的行为之后，王二蓦然发现无论他热情地和杨亦凌说什么，杨亦凌的反应都是相反的漠然。\n直到有一天杨亦凌开始认真地问王二：你想过你以后做什么吗？\n王二无比谄媚地答：你做什么，我就做什么。\n于是，杨亦凌开始闪动长长的睫毛认真的注视着王二说：未来我们仍可能在一起吗？ 王二那时候就开始想杨亦凌是不是看复习考研时马哲看过头了，马哲里的一个重要的原理是“运动”，一切事物都在不断地变化发展。\n“明天的你还会在我身边吗？”杨亦凌问。\n王二搂住杨亦凌说：别傻了，我不会离开你，只要你不离开我。\n但从此之后王二对于爱情的坚守一下产生了一种莫名的不坚定。我们可能离开爱情生活吗？对于王二来说，以前他所唯一离不开的是书。王二曾不无得意的说：丫的，给老子书读，把老子扔到敦煌看佛经都没关系。现在的爱情呢？把王二和杨亦凌扔在荒原中，王二能安然地活着吗？\n当杨亦凌问王二:如果荒原上没有书，只有你我呢？\n王二眼神痛苦地变得晦暗，低下头没有回答。这证明王二对这个世界的所知仍然太少。 当杨亦凌在思考未来的时候，王二还停留在现在，这说明了王二和杨亦凌的思想还有很大的差距。这个世界上有太多的东西牵绕着王二，王二有太多的东西不忍舍弃。就是在对世间事物的价值产生怀疑的时候——不是怀疑事物的价值小，而是每个事物在王二心中都占有太大的价值，土鳖王二开始将目光转向电脑。花了两千块钱王二从一个大四的手里捧回了后来摆在王二书桌上的电脑。\n开始时，王二对电脑一无所知，他在买电脑前甚至妄想买了后写个程序什么的。事实证明后来的王二并没有成为什么黑客，倒是中了不少灰鸽子；并没有编出一行程序，虽然买了本c语言；并没有欣赏多少经典电影、音乐，倒是看了不少毛片；没有写出什么震铄古今的文章来，倒是在论坛里灌了不少水。\nchapter10毛片 我不知道王二是怎么思考他的电脑的，他叫它儿子。每天王二都会调教他的儿子。通常早上起床的时候王二会说：胖子，把老子的儿子叫醒。 于是，胖子就异常殷勤的把王二的电脑打开。\n对了还没有交代过我们的宿舍成员，虽然这并不太重要，但是为了不让大家觉得王二生活在空中楼阁里，我还是要透露点内幕：王二宿舍四人，我和王二大家都认识了，还有一个是胖子，湖北的，典型的奉行攘外必先安内哲学的湖北佬，我很喜欢丫。陈北，河南人，英文名是baby chen,如果他要有一个英文名的话.\n王二的这些行为都在可容忍的范围之内，最不能容忍的是王二通过他的儿子看毛片。这是王二的可鄙之处。我想如果未来王二有了儿子，如果以后他还会有老婆的话，那么王二肯定会教唆他的儿子帮他买黄片。\n对于看毛片王二这小子是有前科的。那时候，王二还没收养他的儿子。还没有儿子的王二经常拉着我去教学楼的机房上网。那时候上网需要一张贴有你的照片的纸。想要上网就需要去提前排队，被拦在门口的工作人员画押之后方可进入。并且机房通常是没有耳机之类的，为此上网的时候还必须戴上耳机。\n那天进门的时候，王二一心记挂着毛片，急不可耐的脚步绕过要给画押的值日生就往里走。值日生小女生一把抓住王二说：急什么，是你啊，拿来。\n王二像被从梦呓中叫醒，看了小女生一眼说：是你？\n小女生往下看了一眼，说：是啊，今天袜子没穿错。\n如果读者没有忘记的话，这个小女生正是何小舟。\n王二那天就窝在一个靠边的角落里看黄片，他让我坐在旁边。瞪着发光的眼睛等待着网络快车缓慢的下载进度。通过桌面的振动我能感觉到龌龊的王二正在处于一种兴奋的煎熬之中。王二看毛片的时候，同样显露着他的龌龊本性，通常王二看黄片时会将real player播放器拉小，把鼠标放在最小化的标志上，这可以看出王二的不专业。后来，王二进步了，他会将手指放在windows和D键上。但那时候的王二还嫩。当一个身影走近时我用脚碰了碰王二，没反应，快走近了，我只好用手拉了他一把，王二转头，看见何小舟走来，慌乱中王二的卑劣的右手食指无奈的按下去，却将屏幕最大化了。\n小舟看了一眼放在桌子上的王二的被划过押的上机证说:王二，你点错地方了。 王二张大了嘴没说话。\n我猜他想说：姑娘，丫的又是你。\nchapter11女人如衣服 王二和我今天马上就要毕业了，照学士服照片的时候，王二提前走了。王二在迷惑，在送走同学之后，留下的是什么，当大家都在抢着照相的时候，王二确发现自己所能抓住的仅此而已。为此，王二很悲观。由此，我们可以看到，四年之后，王二依然有一颗伤感的灵魂。\n衣服，并不简单的就是衣服。大二下的王二已经感受到这一点。那时候王二还迷惑于杨亦凌的美貌与智慧。每天陪着杨亦凌上自习的空档，王二已经感受到了的痛苦。\n有一天王二对杨亦凌说：咱弄套情侣装吧。我刚瞧过，商业一条街新开了一家。\n杨亦凌说：傻不傻啊，小孩子的游戏。\n也许，在杨亦凌的眼里王二一直很小孩。就像后来王二所感受到的一样。\n有时候王二很疲惫，也会看自习室外的美眉，杨亦凌就会靠近王二的耳朵说：好看么？ 王二会说：那不叫好看，那叫敢露。\n说话的时候，王二会故意认真的看着母夜叉。杨亦凌第二天就会换件衣服。对于这种游戏，王二和杨亦凌乐此不疲，直到有一天，王二发现杨亦凌疲惫了。\n对于榆中，四年后留给王二的是什么？除了图书馆和教学楼，王二想是对榆中女孩子的衣服的记忆了。像很多人说起榆中一样，王二后来也习惯于把榆中称之为“乡下”。而榆中女孩子的特点就是穿衣服特土。\n一年半后，王二从榆中校区搬到医学校区，望着满眼的女孩子，王二说，城市真好。\n榆中究竟怎么啦？当王二后来想起榆中的时候更多的是什么？大一时的王二有时会思考女孩子穿什么衣服才漂亮。\n春天的时候，王二说：“春天到了，女生都像花一样开了。”王二说“花”这个倒霉字眼的时候带着拖腔，每每独自品味良久。\n夏天的时候，王二说：“丫的，这么粗的大腿也拿出来凉。”\n秋天的时候王二说：“身高没我高呢，穿个靴子，快到膝盖了，怎么就没点自知之明呢？”\n冬天的时候王二说：“完了，以前不知道什么叫胖。”\n我和胖子很厌恶王二的虚伪，有的看，看就是了，还得瑟个什么劲。大四的王二还恋恋不舍地回了趟榆中，面对着人烟寥寥的空旷校园，王二沉静得连一点奋斗的欲望都没了。就像原来王二假装学佛时在宿舍播放《准提咒》的时候，王二的一个师弟所说的一样。人呢——对王二来说，确切的问题应该是女生呢？除了教学楼和图书馆自习室外，王二再也找不到了。人都闷在宿舍里，夏官营大学像一个囚笼，这里的囚徒连出来望风的欲望都没有。\n现在的王二说，在榆中，我除了谈恋爱和读书，什么都没干。\nchapter12 影吧 如果读者还记得，有一天失落的杨亦凌和王二沿着南区的柏油路走出了学校大门，那天杨亦凌的心里满是惆怅，王二的心里除了同情还有不轨。走出校园的杨亦凌和王二同时发现，他们做出了一个错误的选择，因为校园外一片荒芜，除了买衣服的地就是吃饭的地，当然还有上网的地和租房子的地。\n初次深夜双双外出的两个夜叉到底是没有勇气去租房，上网也不对劲，到底是母夜叉更机警。她说：王二，咱们去影吧。\n于是，王二就去了那个让他一辈子都不会忘怀的地方。\n付了15块钱后王二和杨亦凌进入了一个被薄薄的木板隔成的狭小空间。除了床和被子外，就仅仅放得下一台彩电和DVD了。王二搜索了半天才在一堆黄色影碟里找了部《色即是空2》，杨亦凌瞪了王二一眼，王二又费力的摸索了半天，居然找到一个《悲情城市》的碟片。台湾本地人对外省人的反抗是激烈的，不管是詹宏志和侯孝贤的这部影片，还有其他很多，例如《牯岭街少年杀人事件》。当夹杂着外省人、日本人、本省人的家族纷繁复杂的成员让王二不胜其扰，听着磨耳朵的闽南话，王二开始走神。\n随着隔壁音响开始变强，喘息的声音开始在空气中渗透。王二听得出神。\n杨亦凌说：王二，什么声音？\n王二没有回答，隔壁的声音开始变强，杨亦凌一下子明白了。\n之后王二和杨亦凌在十分的尴尬中继续看《悲情城市》，王二一下子理解了本我和超我的激烈斗争。我想那时的王二也许还没意识到这是因为他的本我过于丑陋，超我则还对人所具有的神的本性恋恋不舍。\n就在宽美和哑巴文清静静吃饭的时候，宽美夹菜放到文清碗里。静静地盯着屏幕的杨亦凌说：王二，梁朝伟每年都给刘嘉玲送花。\n如果是现在的王二他一定会说：关我什么鸟事。\n但那时的王二还比较较真，他说：为什么女生都喜欢送花呢？\n杨亦凌瞪了他一眼，但王二显然没有停下来的冲动，他望着杨亦凌说：花是植物的生殖器。人与花的不同是一个是隐秘而晦涩的，一个是开放且光鲜的。送花就是把植物的生殖器阉割下来然后送给喜欢的人。你为什么喜欢我把植物的生殖器送给你？\n据说，杨亦凌愤怒地说：王二，去死。\n我能想象杨亦凌面对王二这些弗洛伊德主义者的泛性主义的无奈。可怜的王二沉醉于思想，却搞不清楚母夜叉要王二送花这个简单的问题。\nchapter13毛片续 王二这个人总体上是悲观的，但他更重要的特征是理性的。原来的王二对理性的坚守到了无可附加的地步。没有经过思考的事情王二就不予理睬，这主要表现在王二的反应很慢。这是王二的一个悲剧。例如，上课的时候王二头顶的投影仪啪一声爆了，下面的王二毫无反应，倒是英语老师迅速地把王二拉了起来。英语老师说：王二，要死了，也不动下。 事后王二说：我看到了，但我还没想清楚。\n你很欣赏王二吗？然而这是和实践理性相违背的，很多事情是在我们实践之后才能有所感悟的。形如阿罗所说：learning by doing.干中学。但是王二却妄想靠着纯粹理性格物致知。对于这一点，我一向对王二充满了鄙夷。\n后来王二终于体悟到了这一点，大二下的一天夜里，王二被电了。傻逼王二拉线上网，原因大家都可以想象的来。卫生间里的王二把插头插好，拉着插座往宿舍走，却没发觉线的绝缘外皮开裂了，王二一下就被电的精神百倍。后来，王二说，那一刻他就意思到自己被电了。于是王二生出了一种恐惧，之后王二被电的不由自主地跳了起来。王二说他跳起的一瞬间突然感觉到很爽——废话，离开地面了啊。之后王二就像僵尸一样跳着往前走，并终于摆脱了黏在他手上的电线。\n我问：王二，你是思考清楚了才跳的吗？\n王二说：靠，丫的，大爷就要挂了，还思考个p?\n可见上帝是根据不同人的特点进行启蒙的。王二这样的就欠练。\nchapter13鬼的存在 大二下的我们经常夜里拉线上网，王二的看片品味也开始提升。原来的王二十分迷恋MAZE,北大的一群人搞的一个资料下载软件。有时候我们还真得佩服北大，北大的自由民主和兼容并包让王二在大二才进行了近乎全面却不太健康的性教育。围坐在王二的破显示器前，我们一个个故作镇静地说，“王二，开始吧。”\n最初大家只是静静地看，然后都似乎满怀心事的睡了。看的多了之后我们就开始讨论，整个宿舍存在着一种近乎完美的争鸣的气氛。\n胖子说：这样下去不行，非看出毛病来不行。\n王二说：我看到现在，才看出来自己的毛病。为什么咱们没有性教育课？\n我说：丫的，得了吧，你现在不也自学成才了嘛。\n后来王二品味提高开始看动画片，之后王二就开始评论别人，“丫的，看什么呢？日本AV，真没劲。”“呦，胖子，进步了，看动画了，什么鬼作，你有点出息成吗，那是老男人看的，你还很年轻，意淫个什么劲？”\n后来，《色戒》出来后，愣是没看懂，之后王二就开始猴急的寻找《色戒被删减部分》，黄天不负有心人，终于被王二找到了，还是高清晰版，看过之后的王二终于明白了。 王二说：丫的，必须禁，我党特务被敌特诱惑，情色高于政治，这怎么能行？汤唯就是一个没有理想的女人，禁，坚决要禁。\n厌倦了黄片之后的王二开始寻找新的视觉盛宴，在杨亦凌的帮助下王二找到了，因为杨亦凌喜欢看恐怖片，王二就开始努力想她靠拢。刚开始王二认为自己经过大风大浪，根本不怕什么恐怖片，于是就拉着杨亦凌的手去看《午夜凶铃》，出来的时候杨亦凌开始痛骂王二，因为王二把母夜叉的据说是“柔弱无骨”的手掐出了两个红印。\n王二回来就开始看《沉默的羔羊》，看到了剥去人面皮时候，王二使劲的咽了口唾沫。后来王二又看了《解剖学教室》，看了三遍把剧情看懂之后，王二一夜都没有睡着。那段时间的王二备受折磨，看人的眼神都变了，评价人的方式也变了，比如王二说：胖子，你丫的太纯洁了吧，连恐怖片都不看，你是不是害怕发现自己是多重人格啊。\n后来的王二实在坚持不住了，他决定看鬼片。这再次彰显了王二的与众不同。\n我说：王二，你丫连恐怖片都看不了，还看什么鬼片。\n王二说：你懂什么，鬼都是具有健全理性的，不像人，连自己是多重人格都不知道，寻找杀人犯，到最后发现是自己。除此之外，我对鬼有一种发自内心的亲近。唯物主义最大的问题就是让人的灵魂一下子没有了家园，如果我死后可以变成鬼多好啊，那样我就可以自由的去干很多事情，我可以自由的出国，看韩剧，不交门票看比赛\u0026hellip;\u0026hellip;如果真的有鬼那么我就找回了人类的精神家园，颠覆了唯物主义哲学的桎梏，在死后还可以进行我的不间断的思考。多么幸福啊。\n末了，王二仍恋恋不舍地说：“要是有鬼就好了。”\nchapter15失乐园 当王二回顾自己与杨亦凌的感情经历的时候，王二习惯于说自己从没有开始，这表现了王二的自欺欺人。王二的原话是：我没有得到任何东西，没有得到，就没有失去。\n这充分表明了王二的脆弱的逻辑和软弱的受害者心理，就像王二家被小偷偷了，王二还说我没有从小偷那得到任何的从西，没有得到，就没有失去。\n但小六和胖子等人居然信了。他们对王二表示同情。虽然我想说我对此很遗憾，但是我内心的想法是：太好了，早tmd该break了。王二怎么说也是个优秀青年，没必要吊死在杨亦凌手里。\n但是王二却不得不面对的一个现实是杨亦凌消失了，从王二的身边消失了，再也不会出现。这很残酷，但我不是琼瑶阿姨，我要再次声明夜叉夫妇掰了。也希望读者早点接受这一点。\n冬天过去了，春天就来了。杨亦凌走过了她的鬼魅般的考研生活，06年春天，杨亦凌去北京复试了，之后就回来进行了她的毕业旅行和形式主义的毕业。也就是在这个时候，王二开始走出了王二的视野。\n那天早晨杨亦凌和王二站在图书馆四楼的书库里，阳光很亮，透过大的落地窗照在杨亦凌脸上，宛若仙子，如果存在仙子的话。\n这让王二内心生出一种幸福感，但一会后这一切在瞬间瓦解,宛若一个玻璃的世界被王二不小心打破了。后来，王二这样想。\n杨亦凌说：王二，咱们分手吧。\n王二以为她开玩笑，因为也有一个无知的网友在校内上说‘女人习惯于提出分手，那是因为她们迷恋于被挽留’，王二伸出手戏谑道：好。\n杨亦凌以奇怪的眼神望着王二的眼睛和异常突兀的手。\n王二说：我和你在一起那么久了,怎么说也给点青春损失费吧！\n杨亦凌说：王二，去死。我说真的，我们家里也觉着我们在一起不合适。\n“为什么？”王二说。\n杨亦凌说：我已经有了新的男朋友。\n“谁？”王二说，“我杀了他。”\n杨亦凌冷笑道：“王二，你流氓，你要爱我就该祝福我。”\n王二：他才流氓，勾引别人女人，让我看见我就杀了他。\n杨亦凌：王二，我们不合适。\n王二沉默很久，杨亦凌注视着他的眼睛。王二说：好吧，我祝福你们。\n悬在王二眼中的泪莫名地流出来，王二转身往外走，没提防撞到一个人。被撞倒的女生站起来对着王二吼：王二，又是你，\u0026hellip;..\n“一边去。”王二看了一眼被撞倒的何小舟，回头对站立不动的杨亦凌说：我祝福你们一生一世，直到你们分手。\nchapter16失恋 王二是在被甩了之后才开始失恋的。所谓失恋不过是失去了可以爱的对象。如果一个人拒绝了你，你却还深爱着她，那么这就不是失恋。因为你还有爱慕的对象，只是你通过消除信息不对称的行为弄清楚了一件残酷的事情——那就是你爱的人并不爱你。王二则没有这么幸运，这是王二的卑劣所造成的，杨亦凌的移情别恋让王二一下子明白了杨亦凌的不可爱之处。如果说王二虽然龌龊但仍然不失赤子之心的话，杨亦凌就是一个完全世俗化的女人。\n但不管怎么说，作为一个符号，“甩”的能指当一个人离开另一个人的时候，其所指却是甩人者对于被甩者的作为恋爱对象价值的否定。这通常并不是一句简单的“我们不合适”所能掩盖的，它所传达的是甩人者在被甩者身上找不到她所必须的价值——容貌、才华、金钱、前程、性格、气质。\n而这些价值又可以分为短期价值和长期价值。有的人看重短期价值，如花容月貌、金钱、权势。有的人会看重长期价值，如前程、才华、性格、气质。\n王二身上究竟是少了哪种母夜叉所必须的价值？王二后来一直在想，自负的王二认为自己不缺乏容貌，虽然不是很帅；不缺乏才华，虽然略显平庸；不缺乏前程，虽然仍很遥远；不缺乏男人豪爽豁达的气质，虽然有很多时候略显龌龊。王二有着所有的长期价值。但是王二却缺乏杨亦凌所不能容忍其欠缺的短期价值，金钱和权势。杨亦凌会看重王二所欠缺的金钱和权势吗？对此，王二不敢肯定。他不愿意如此彻底的否定杨亦凌，虽然我常认为应该不怀好意的如此测度。\n王二转而求助于另外一个因素：因为寂寞所以恋爱。\n寂寞和孤独是一种难以避免的生活状态，作为社会人的我们都在选择逃避寂寞和孤独的路径，王二曾经选择了书本，庆幸的是王二直到现在都没有放弃这个选择。所以，王二对于爱情的宽容度就更高——我是指王二不会过多的苛责爱情，王二并不指望从爱情当中获得精神的解脱，王二没有给爱情太多的负担，虽然他坚持的是执子之手，与子偕老，终生相守，相濡以沫；在这一点上杨亦凌和王二存在根本的不同。\n规避寂寞同样是一种短期的价值，虽然杨亦凌认为规避寂寞是一种长期选择。这恐怕是杨亦凌接受王二并甩掉王二的根本原因。\n不管怎么说，王二突然没有喜欢的对象了。\nchapter17空档期 人的心理真的很奇怪，我们可以对得到的事物熟视无睹，却不能容忍一个原本属于自己的事物离开自己，这或许就是根源于人的占有欲望的劣根性。不幸的是王二也有这种劣根性。\n王二开始进入一种悲伤欲绝的状态。王二决心不再关注外部世界，他开始不在意自己的言行举止，迈着八字步低着头在校园里做无意识行走。\n上课的时候，老师让王二回答问题：王二，你来分析一下如何得到腺嘌呤的结晶体。\n王二说：嗯哪，对，好。\n我劝王二：王二，为了个女人没必要。\n王二回答：嗯哪，对。\n王二开始进入一种极度温顺的生活状态，大二下了，王二替我们整个宿舍签到。\n点名的时候给我们宿舍答到。答到第三次时，老师说：同学们都很失落啊。\n后来我逐渐明白王二进入了一种自我保护，就像李连杰版的《太极张三丰》一样。可怜的男人。\n但之后王二的行为就堪称犯贱，具体表现是他开始上自习。王二的自习过程通常是这样的：占个位置，趴在桌上大睡，眯眼假寐，开始看书，走廊散步，抽烟，回来再看书，走人。\n后来，王二说那是因为他处于空档期。\nchapter18 烟 写到这个时候我又开始看《苏丝黄的故事》，感到很沮丧。我不知道苏丝黄是怎么想的，如果她还有一个专栏的主题的话，那么我现在就处于思考这个短篇主题的时候。王二的在L大学的故事如果能够有一个主旨的话，那应该是对大学的反思。\n大二的王二也在思考自己的人生了，那天王二开始抽烟，王二不喜欢说吸烟。他觉得男人就应该有豪放不羁的气质。\n那时候王二所能接触到的兰州最便宜的香烟是海洋，三块钱的。王二笨拙地撕开软包的烟盒时，感到异常的亲切。烟放在嘴里的时候，王二突然有了一种耶稣被钉上十字架的感觉。\n后来，王二跟何小舟谈起烟的时候，王二说：抽烟的时刻，我有一种殉道的感觉。\n我无法理解王二的行为，对此，我只能说王二过于纯洁。可怜的王二坚持认为吸烟对于自己和他人都有很大的危害，虽然他不反对我们这些人在宿舍吸烟，但是后来王二也加入了在宿舍吸烟的行列。这个时候的王二更加沉默，我和小六都是习惯性抽烟者，对我们来说吸烟就像是呼吸一样自然。当我们摸遍身上的口袋都找不到烟时，我们习惯于蹭王二的烟。王二就会很小气的说：你们简直是暴殄天物，浪费香烟。\n在我和小六的启蒙下，王二开始玩弄抽烟的技巧，把一团污浊之气吸入嘴唇和齿间，王二把烟吹出，一股浓烈的烟柱就从王二的口中喷涌而出。这个时候他通常要说话，他看了一眼何小舟说：要不要来一支？\n何小舟说：我没失恋。\n王二说：草履虫不会失恋，我在宿舍培养的草履虫死了，就在昨天。\n何小舟悻悻道：王二，去死。\n王二抬头看了何小舟一眼就头也不回的站起来走回教室。王二习惯于在自习的间隙走到A区和B区之间的地方坐在巨大的落地窗前抽烟。\n王二喜欢等待下课，当很多人如潮水般涌出教学楼的时候，王二就会异常的孤单。王二喜欢这种感觉。恰如一个网友所说，王二的被甩的经过所展现的王二的被否定过程。但王二认为问题比这更严重，他认为自己爱杨亦凌。这一点让我和胖子、小六抓狂。\n让王二无法理解的是几乎每次都能遇到何小舟。以致后来王二开始怀疑何小舟在故意监视他，至于原因肯定是想看王二被戏弄的样子。卑劣的王二根据自己十九年的生命经验推断：何小舟是个虐待狂。除此，王二无法理解何小舟的动机。谈到监视王二所能想到的除了高中时班主任把眼睛贴在在教室后门的洞上观察的情景，王二讨厌被人观察，这充分说明了王二没有成为教师或者名人的希望，那时的王二经常想去在那个洞上涂上一层厚厚的清凉油。虽然后来这个计划一直因为王二的胆怯而被搁置。上了大学的王二开始有时间接触奥威尔，读了《1984》之后，王二开始理解为什么人在全方位的被监视之下会浑身不自在。因为监视者通常都是极权主义者，而王二厌恶被压迫，所以王二决定揭穿何小舟的阴谋。\nchapter19 自杀论 王二开始变得沉默，因为杨亦凌离开的日子快到了。有一天王二对我们说他要去自杀，对此我和胖子都嗤之以鼻，后来也证明我们的鄙夷是正确的。\n那天的王二可以拿了本海子诗集，对于海子王二以一种天然的皈依感，虽然靠近铁路，王二并没有选择卧轨。据说，曾经的L大学可以在黄河边建校，但是后来领导们考虑到大学里会有很多像王二这样的傻逼会因为失恋而自杀，否决了一个绝妙的idea。我们后来就难以理解把本科生新校区建在暴露的铁路边，难道不害怕那些激进的年轻人狂妄而浪漫地卧轨吗？\n但王二总算没有选择卧轨，他留恋西北的大山，王二幼稚地想死在这座荒凉的的山下。出乎大多数人都预料，王二决定去跳山。\n那天是周末，有闲阶级的典型代表王二在备受煎熬之后放弃了在尘世中挣扎的念头，王二在夕阳中向山上走去，他没有吃饭，这样腐烂的时候会好闻些，王二很细心地想。走过一幢幢女生楼的时候，王二莫名生出一种留恋，走过杨亦凌窗下的时候，王二心中的悲凉堵塞理智。之后，王二就悲壮地走向了白虎山，一座后来被改名萃英山的地方，一个王二选择的结束自我生命的对手。\n迈着缓慢的步子，王二感到有些头晕目眩，事实证明吃饭的确是人生中很重要的问题。可怜的王二却拒绝了。\n走上山顶的时候，王二真实地感觉到自己对这个世界的留恋，他沿着山顶平坦的曲线走动，却找不到任何改变的理由。前方有一群人，他们在烧烤。“垃圾。”王二骂道，他不能容忍这个世界对于一个即将离开者的漠视。王二走近他们，他想恶狠狠地瞪他们，事实上王二做到了这一点。在离开的时候，王二突然像海子一样，想尽情地和这个世界的骄傲的物质的无知的人们大打一架，王二捋起了袖子。\n一个女生显然是看见了王二，她丢掉烤肉向王二走来，“王二，是你。”\n王二很生气，他瞪大了眼睛看眼前的这个女人：“何小舟，是你，一直看我出丑很爽吧。” 何小舟能感觉到他的愤怒，但是她坚持说：“是啊。”\n王二转过身去，看着山下，风吹来，王二有庄子御风的感觉，一颗泪开始挤压王二的眼部神经，“活着的人，祝福你们。”\n何小舟很诧异，但王二已经转身跳下。\nchapter20 功利主义 功利主义的早期代表人物边沁认为：有助于产生快乐的行为和事物是善的，反之就是恶的。如果一个行为带来的快乐超过痛苦，那么它就是善。如果一个行为只带来快乐而没有痛苦，那么它就是至善。\n我必须承认，王二的跳山自杀的行为所带来的痛苦远少于快乐，那么以边沁的观点，王二跳山是善举。\n王二从山脚下爬起来，意识到自己没摔死。他脸被小灌木刮破了一道，衣服被撕破了几个地方，王二的头和腿在滚下来的时候撞在输水管道上，刚站起的王二头脑混乱意识模糊，一个趔趄又摔倒在地。\n除了感觉头痛之外，一股撕心裂肺的痛从脚跟传来，“该死，脚崴了。”经常打篮球的王二对此并不陌生。\n阳光的影子已经找不到了，六月的傍晚的风让王二感到很舒畅，回味着从山上滚下的情景，王二心中没有一丝害怕，他感到处于自杀想法中的自己太愚蠢，因为他还没听过从山上一路滚下来自杀成功的。王二苦涩地笑了笑，他感觉不到为愚蠢的自杀未遂感到内疚的必要。\n喘着粗气的王二躺在地上休息，他看了一眼白色衬衫下颤抖的身体，生出一种忽略世界的存在的冲动，王二后来说一个处于狂热和孤独的年轻人的愚蠢的想法是不能当成自杀的充要条件的，既然没有死去的理由，就应当好好生活。\n“我已经为爱情死过一次了。”王二想，“活着就要有所追求，除了爱情和死亡，我可以追求任何有价值的东西，哪怕是追求虚无。”\n但王二没法继续忽略这个世界并延续自己傻逼的想法，因为何小舟跑下山来了。那一刻的何小舟头脑变得虚空，一直以来她没法忽略王二的存在，虽然何小舟一直看着王二的近乎所有在公开场合所展露的傻逼行为，但她对王二的记忆却始终停留在大一开学的时候，与酷爱T恤的我们不同，那时的王二一袭白衬衫，手里握着一瓶纯净水静静地立在体育馆前的队列中，那是要上军训中的军事理论课。从何小舟的视角看过去，或许我们就能看到最为文质彬彬的王二，尤其是他那并不高挑但足够漂亮的鼻翼。之后的何小舟就看到了这个文静男孩近乎夸张地喝水，当她疑惑之际，王二已经离开队列，将手中的空瓶子递给了走过来的拣垃圾的大娘。老人看到了王二的举动，感激地点头。\n从此之后的何小舟就一直没有放弃走近看王二冲动，于是乎我们所有之前的猜测在此处得到近乎圆满的解答。王二这种烂人能有如此造化，必然不是王二优秀，而是看这个男人的何小舟太过特别。充分说明如果王二是属于足够执着的人都话，何小舟就是执着的超人；如果说王二是偏执的话，那何小舟就是偏执狂。\n躺在地上那个王二沉醉于幻想并耽于思想得到救赎的快乐，他显然没有注意到一个人正在注视着他，我必须强调这是一个偏执狂对于偏执者的注视。\n何小舟说：别动，我扶你起来。\n她上前去扶，王二用近乎愤怒的眼神看着她，他推开了她的手，自己站起来，但他才迈出一步就摔倒了。\n几个和她一起跑下的同学看着他俩叫：“盒饭，回去烧烤。”\n何小舟扶住身体前倾的王二，不理会同学的目光和王二的表情，何小舟贴着王二的耳朵说：“咱们走吧。”\nchapter21 挟持 你相信爱情吗？王二在滚下山后，领悟自己应该有新的追求，但他显然没有把爱情放在追求的目标中。\n当何小舟搀着他走下山的时候，王二感觉很不舒服。不过他并没有多想，王二或许只是认为何小舟良心发现而已，这样王二第一次对何小舟放松了警惕，也注定了王二第二次情感曲线出现了一个并不平滑的转折。看来傻逼王二太天真了，他怎么就愣是没看出何小舟眼神中所隐藏的蓄谋已久和永不言弃？\n走过山下的教学楼的时候，王二突然很不好意思，他要挣脱何小舟的手时才发现那丫头片子想熊瞎子抱住在水中逮住的鱼一样愣不撒手。\n在王二尝试几次未遂之后，何小舟突然转过身看着王二说：“别动，老实点。”\n不想继续意淫，但故事的发展是这样的，盒饭和王二去了校医院，王二经检查无碍，又被盒饭挟持着送回宿舍。\n出校医院门口的时候，一个熟悉的身影闪过，是母夜叉杨亦凌。王二迟疑一下就被盒饭拉着走了，这个丫头片子能量真大。\n但杨亦凌显然看到了王二，从外面买水果回来的杨亦凌几步赶上来对王二说：“她是谁？” 王二还没来得及开口，盒饭就说：“我是王二的女朋友。”\n杨亦凌恶狠狠地看了王二一眼，王二赶忙说：“你别误会，我摔倒了，恰巧她看到，她见义勇为呢。”\n苍白的独白换来的是两个女人的白眼，盒饭不等王二说完，就拉着王二走了。\n王二那一刻一定觉着自己方出狼穴又入虎口。\nchapter22 许三多和斯密 “许三多，你不是傻，你是太较真。”这是片中人物对许三多的评价。当许三多被分到红三连五班这个被称之为光荣在于平淡、艰巨在于漫长的荒野之中。本来一个强人却天生一副熊样的许三多，替所有的人整理内务，因为伍排长说过在内务方面要互相帮助。\n许三多显然不是一个我们传统上所说的好兵，队列不好，不够机警，所以他才被分到一个最差的班看守助训练场，五班被扰的鸡犬不宁，因为所有的人都甘于堕落，而许三多却一步一个脚印，从整理内务入手，玩空枪，在一个团结高于军容军纪的班里，许三多是个另类。但许三多的精神在于坚韧。或许，许三多最初不是优秀的，但他始终坚持下去，却成为最优秀的士兵，在这方面，许三多体现了不放弃的精神。许三多在雨中接受了第一个命令：修一条路。他冒着雨就去了，从此许三多就开始修路。\n许三多最让人惊讶的是他认为修路是有意义的。木讷的许三多是如何推论出这个结论的我很疑惑。从斯密的角度看许三多就是一个土鳖傻逼，斯密认为社会分工带来专业化和效率的提高，并能提高整个社会的生产效率。因此，如果让一个土工部队来修就会很快修完。 许三多所展现的是一个近乎哲学化的问题，或许根本不合乎经济的基本原则，但与庄子中所说的不追求技巧不同，许三多所坚守是人的价值，人必须有追求，哪怕追求虚无。许三多一起看守荒原的战友也有追求，如班长研究过桥牌，李梦想写小说。但唯有许三多才矢志不渝的坚持。\n后来毕业的时候王二才完整的看了《士兵突击》，王二突然很庆幸自己像在荒原上一样坚守了下来，更庆幸自己改变了自己的人生轨迹。\n欲死不得的王二回到宿舍，他开始思考人生，迫于生计的人们经常忽略的不是外部的世界，而是内心的想法。学了那么多年理科的王二有一种冲动，他想回到人文之中去，因为他怀念初中时第一次读庄子的感觉。与老子和孔子不同，庄子对于个人内心的皈依与追求达到了一个无以复加的高度。\n“我也应该如此汪洋恣肆地活着。”傻逼王二想，他再也不想对着实验室里的器皿和动植物奸尸了，天生具有幼稚的浪漫主义气息的王二厌恶标本，与之相反，王二更喜欢富有活力的自然、思考、历史文化。\nchapter24 理念的阳光 王二在欲死不成的第二天早晨的强烈的阳光中醒来，头有些痛。\n那闪耀的太阳曾经是八十年代的海子倾尽全力赞美的对象，权利意志的扩张让我们崇尚英雄，包括海子，都在贲张的气氛中挣扎，温润的外表下掩盖的火山在沉寂中酝酿爆发，在偏僻的政法大学外的小酒馆里海子与人大打出手，眼镜破了，但是海子确认为自己获得新生。耗尽生命赞美的太阳到底没有让海子看到现实的光明，他选择了卧轨。 然而却是同一个人却写下了“面朝大海，春暖花开”这样超然物外并充满了乐观的诗句。八十年代的诗人是一个矛盾的主体。后来，王二才明白这乃是存在主义遭遇虚无在中国的镜像。\n王二想到杨亦凌，曾经的美丽变的异常遥远，宛如一个虚假的影像，而王二却一直认为自己所面对的是一个散发着刺眼光芒的理念。\n“柏拉图的伟大之处在于对于理念论的发展。”曾经对柏拉图不屑一顾的王二想,“理念宛若太阳，它才是真实的存在。”\n在哲学导论的课上听到老师讲到天国的理念投射到人间，世间万物不过是对理念的不完美的模仿这句话的时候，王二也曾经报之以轻蔑的笑容。但此刻王二的笑意早已变形。对于现实中的杨亦凌才是完美的存在认识王二从来没有改变，但是曾经的美丽此刻却已经烟消云散。王二再也感觉不到杨亦凌的存在，心中甚至没有了痛的感觉，与杨亦凌分手后在自习室里突然袭来的深不可测的痛苦此刻宛若浮云，似乎永远地离开了。\n感情在时间里被消耗一空，王二想这显然是是不完美的，那么现实的杨亦凌就不是完美的存在，她只是对于完美理念的不完美的模仿。\n此刻的王二重新审视周围的世界顿感无味，如果连自己曾经如此深爱的女人也是虚假的不完美的模仿的话，这个世界还有什么是真实的完美的存在呢？过去的存在因为仅仅是不完美的模仿所以随着时间消逝了，有的仅仅留下躯壳，有的连躯壳也没有留下。那么还有什么真正的不被任何破坏的保存下来了呢？\n此刻王二一下子意识到一切个体，不管是人抑或是动物对外界的认识是千差万别的，而这正是作为不完美的影像在反映完美的理念时的局限性。所以，大象可以感受到次声波，蝙蝠可以感受到超声波，而人类却只能在更为狭窄的波段中感觉声音。同样，有的生物可以看到红外线，有的生物可以看到紫外线，而人却只能在更为狭窄的范围感受光的存在。同样人的味觉嗅觉触觉也都是对于外物的在一个狭窄的范围中的感觉。人类并不能在一个完整的范围中感受外物的存在，所以人的五感在更大程度上是虚假的。\n王二有一段时间沉浸在找不到真实的存在的痛苦中，直到这一天的早晨王二真实的感受到了刺眼的阳光。\n“理念，没错是理念。”王二想，“宛若太阳的理念。”\n一切历史都会随着时间推演，只有理念不灭，譬如人类所创造的散发光芒的文化可以完美地存留下来。\n“我要去追寻理念。”傻逼王二对着太阳说，“追求人文理念。”\nchapter 25 纠缠不清 我一直以为那是傻逼王二人生的转折点，大二下的时候王二说受够在实验室里作那些早就知道结果的实验，有机实验课上他同时打破了酸管和碱管，破了我们损坏实验仪器的记录，我要转到文科去。\n对于王二的想法我是嗤之以鼻的，虽然我们这些被高中生物课本上那句“21世纪最有前途的学科”所骗的人早就意识到自己是被骗了，学生物这专业就业不好，也不是每个人都有足够的天赋对它感兴趣并且喜欢做研究，但并不是所有的人有勇气离开这个专业，我们都习惯于现在的或许并不舒适但总算安稳的日子，我们害怕面临改变的时候的更为繁琐的细节。\n但是王二却恰恰在这里显示辅导员老师了他的纯真的激情，这是西方浪漫主义在中国的滥觞。王二开始草拟各种申请，去院办磨辅导员，到本部磨院长。当然结果是没门，因为王二想到转专业的时候已经是大二下了。于是乎官僚主义以一个冠冕堂皇的理由击败了浪漫主义。\n但王二的运气总算不坏，L大学还有第三条道路，也就是“2+2”，也就是说在大二下，如果对既有专业不满意，可以通过选拔，重新选择一个专业，但是06年的“2+2”已经濒临消亡，只有新闻院和生科开设了“2+2”专业，前者是网络新闻专业，后者是生物技术专业，因为王二本身是学生物的，当然不会选生科，那么就只剩下了网络新闻了。王二实际上仍然没的选择。\nchapter 26 旁观者 一个７５岁的老太婆自然不会损及这个年轻人的名誉，但要是一个陌生的老太太在他车内死去的话，他要如何向世界解释？　－－－德鲁克.《旁观者》\n王二没有想到过了06年的暑假，自己就离开原来的院了。虽然这正是他所想要的。但是，离开总不让人踏实。我不知道他这是否是他处于浪漫主义的虚伪的自恋情结——因为自恋，所以美化自己曾经坚守的事物。\n我说：丫的，王二，你就这样走了。\n王二说：我不想离开大家。\n事实是不久王二就离开了我们这个安乐窝，剩下的日子，我只有和我的小四一起度过，虽然还有胖子还有陈北，王二的这种冷酷让我倍感大学的漫长，我也该检点自己了。 但我恐怕王二在网络新闻班的生活也远没有他所预期的那么好，事实果然如此，因为他发现盒饭－－何小舟也在那里。她在跟几个女同学在前面窃窃私语。他知道自己是应该上前打个招呼的，但是这个时候的王二却不想做表演者，也不想做直接的聆听者，他希望做一个旁观者，从一个完全不同于他人的视角看问题。或许，他会有完全不同的发现，当然不一定是范式的改变，也许只是给别人留下一个性格腼腆的形象。但可怜的王二连这个也没有能够如愿。\n小小的鼻子，小小的嘴巴，明亮的眼眸，扎个马尾辫，较之杨亦凌的张扬，何小舟显然更为可爱。但王二是不会注意到这些的，他的视线在稍微迟疑之后就定格在何小舟身边的一个女生的身上，一个穿着一袭白裙的高个女生，她侧着身子，高高的鼻翼，坚毅的眼神，那一刻王二简直想要跳起来。\n“杨亦凌。”王二在心中大声的喊到。当然，已经日渐稳重的王二并没有叫出声。\n他定睛又看了一眼，才分辨出来她也许不是杨亦凌，因为她扎着耳环，长长的耳环分外招人，这个是杨亦凌所没有的；这个时候杨亦凌也应该在北京，而不是这里。\n当然了，王二并没有排除杨亦凌回心转意并且扎个耳孔戴上耳环来看自己的可能。所以傻逼王二走上前去，对着那帮女生招手。\n“早啊，我叫王二，也是网络班的。”\n何小舟转过身，“早，你的脸还真适合贴胶布。”\n王二摸着跳山给自己的额头留下的创可贴说：“为什么？”\n“因为你面目可憎。”何小舟说，但她已经注意到王二的略显游历的眼神了。以王二的两眼的视角做直线，沿着直线延伸的方向，何小舟一下明白了王二那罪恶的眼神在看什么。\n或许没有任何一个人注视另外一个人会像王二一样专注，他的眼神像麦芽糖粘住牙齿一样粘在了耳环女的脸上。忘了交代了，王二的审美比较其特，或许我们可以称之为看面相：他只关注女生的肩以上部分，他一般不会关注身高，因为需要他仰视的女生很少有比他矮的；他不必担心年龄，因为这些在脸孔的皱纹上显露无遗。\n“噢，忘记给你介绍了，这个是我的朋友，叫李琳。”\n“你\u0026hellip;\u0026hellip;是李琳？”\n“你好，我叫李琳，法学一班的，我是小舟的老乡，刚才正好看到盒饭也这。就过来聊会中秋老乡聚会的事。”李琳很镇定，她肯定经常遇到像王二这种处处对她留情的人。\n得到肯定回答的王二一下子没了精神，他想原来不是杨亦凌。\n“哦，很高兴认识你。”说着王二就走开了。\n李琳或者什么名字也好，此刻都没有了意义，她们全变成了理念的不完美的模仿。 chapter 27 不会经历的奇遇 萨特在《恶心》里叙述了一个孤独的灵魂奇遇，他没有能够幸免，不断的遭遇恶心，他把自己埋藏在世俗里，他为自学者的单纯叹息，为前女友的决绝叹息，为历史中的存在者叹息，但他却无法改变这一切，面对过去的场景，他感到恶心；面对他人，他感到恶心。他最终决定离开小城，去写书，一本关于不会发生的经历的书，他要描写一种美丽，让他人看到它感到羞愧。\n如果说存在必须找到一个对立面才能存在的话，那么空虚就不可或缺了。一个人只有在孤独的时候，才会认真地体悟存在。\n王二没有想到在自己19岁的人生会经历充满如此多的波折，在一年多的时间里他经历了恋爱、失恋、自杀。现在对人生的思考也是王二所意想不到的，大学总还是有很多精彩的地方的，但王二此次却不能从那些社团活动、班级活动、体育活动中得到任何乐趣。 在暑假里，王二读完了凯恩斯的《通论》，这本书王二是一页一页地翻过去，经历了杨亦凌之后，王二有很多问题想不清楚。\n但我更愿意认为他不愿意去想清楚。杨亦凌没有他所想的那么好，或许这就是答案。对于这个问题，我曾当面对王二说过，没理由为了一个把心系在天上的女人牺牲天下苍生。你跟着那个女人只会变成一个胸无大志的渣滓。\n王二反驳到：把对方看成恶的，很多问题都会迎刃而解。\n但在《通论》凯恩斯却开始从个体的人存在的时间来考察人的经济行为，毕竟个体的人也只是有限的存在，很多东西我们并不能找到一个有效的方式使其超越时间传承下去。而未来又有着太多的不确定性。天有不测风云，生命可能在意外中陨殁，金钱可能一夜之间失去，房子可能被付之一炬。反倒不如“有花堪折直须折，莫待无花空折枝。”黑格尔、迪尔凯姆、马克思都十分关注分工造成的极大风险，认为那样会撕裂社会的道德基础。罗尔斯的无知之幕也依赖于人生的不确定性。回避了不确定性，一切制度都是有效率的。很多人会选择活在当下，这样就可以解释很多看似不理性的行为。凯恩斯所开创的宏观经济学正是建立在这样的一个前提下，在此基础上，他引入了各种偏好，例如流动性偏好，为什么偏好流动性，为什么愿意持有货币呢?凯恩斯将人们的货币需求是出自于以下三种动机：交易动机、预防动机和投机动机。除了流动偏好外，还有时间偏好，当人们的收入增加时，即期消费也会增加。当然增加的幅度小于收入增加的幅度。\n杨亦凌的有限性在于她同样也生活在凯恩斯的场景之下，她没有能够超越它，她小心地回避不确定性。\n王二或许也感觉到了一种不得不去面对的绝望：生活已经如此残酷。\n面对这种生活，王二只感觉到悲凉，连恶心的决绝都没有，但他同样不想被它所束缚。历史，是我们很难去描述的，每当我们挖开故纸堆去翻阅揣测遥远的古人的时候，我们都堕入了文本的束缚和我们自身认知的束缚。过去的存在让我们无法鼓起足够的勇气去回顾，因为每次真诚地回顾所带来的都是被篡改的历史。\n与王二不同的是，杨亦凌除了拒斥过去之外，她同样拒斥未来。她只生活在当下。 但傻逼王二却决不允许自己从理想主义的迷梦中醒来，他拒斥过去，他热爱当下，但他对于未来之生活却有着更高的向往。\n我想，王二或许也想像萨特一样，对有德性的生活向往不已。不同的是萨特笔下的男主人公要写一个不会发生的有德性的生活的故事，而王二却要实现自己所热爱的崇高的生活。\n结尾 这是一个尾巴，难道围城就是这个样子吗？快乐如此短暂，仿佛才刚刚开始，却已经画上了圆点。再回头看的时候，已经是几年甚至几十年以后了。王二跳脱了短暂的爱情，在理念的阳光里寻找自我。或许，这才是不会发生的奇遇。\n幸运的是，对于爱情的向往是一个不死的魂灵，围城里的气氛若大雨将至时的紧张，耐人寻味却异常短暂。几年之后，王二开始快乐地跟何小舟生活在一起。现在的王二如那个恋爱的犀牛。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"808cc13f83fd1be206b34a1d3dc82cd7","permalink":"https://chengjunwang.com/zh/archive/2008-05-01-happy-city.zh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/archive/2008-05-01-happy-city.zh/","section":"zh","summary":"","tags":null,"title":"围城里的快乐","type":"zh"}]