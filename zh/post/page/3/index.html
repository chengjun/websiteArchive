<!DOCTYPE html>
<html lang="zh-cn">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.30.2" />
  <meta name="author" content="Cheng-Jun Wang">
  <meta name="description" content="Associate Professor">

  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  


  

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://chengjunwang.com/zh/post/index.xml" type="application/rss+xml" title="Cheng-Jun Wang">
  <link rel="feed" href="https://chengjunwang.com/zh/post/index.xml" type="application/rss+xml" title="Cheng-Jun Wang">
  

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://chengjunwang.com/zh/post/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ChengJunWang">
  <meta property="twitter:creator" content="@ChengJunWang">
  
  <meta property="og:site_name" content="Cheng-Jun Wang">
  <meta property="og:url" content="https://chengjunwang.com/zh/post/">
  <meta property="og:title" content="Posts | Cheng-Jun Wang">
  <meta property="og:description" content="Associate Professor">
  <meta property="og:locale" content="zh-cn">
  
  <meta property="og:updated_time" content="2014-03-10T00:00:00&#43;08:00">
  

  

  <title>Posts | Cheng-Jun Wang</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">切换导航</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/zh/">Cheng-Jun Wang</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/zh/#about">
            
            <span>关于</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/zh/#posts">
            
            <span>新闻</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/zh/#teaching">
            
            <span>教学</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/zh/#projects">
            
            <span>项目</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/zh/#contact">
            
            <span>联系</span>
          </a>
        </li>

        
        

        
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-haspopup="true">
            <i class="fa fa-globe" aria-hidden="true"></i>
            <span>中文 (简体)</span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="nav-item">
              <a href="/post/">
                <span>English</span>
              </a>
            </li>
            
          </ul>
        </li>
        
      </ul>

    </div>
  </div>
</nav>





<div class="universal-wrapper">

  <h1>Posts</h1>

  

  
  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/migrate-from-jekyll/" itemprop="url">Migrate from Jekyll to Hugo</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2014-03-10 00:00:00 &#43;0800 CST" itemprop="datePublished">
      Mar 10, 2014
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    2 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    <p>Learn how to migrate an existing website from Jekyll to Hugo.</p>
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/migrate-from-jekyll/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2014-02-28-simulate-network-diffusion-with-r/" itemprop="url">使用R模拟网络扩散</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2014-02-28 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Feb 28, 2014
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    3 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    与普通的扩散研究不同，网络扩散开始考虑网络结构对于扩散过程的影响。
这里介绍一个使用R模拟网络扩散的例子。基本的算法非常简单：
 生成一个网络:g(V, E)。 随机选择一个或几个节点作为种子（seeds）。 每个感染者以概率p（可视作该节点的传染能力,通常表示为$$\beta$$）影响与其相连的节点。  其实这是一个最简单的SI模型在网络中的实现。S表示可感染（susceptible）, I表示被感染（infected）。SI模型描述了个体的状态从S到I之间的转变。因为形式简单，SI模型是可以求出其解析解的。考虑一个封闭的群体，没有出生、死亡和迁移。并假设个体是均匀混合的（homogeneous mixing),也就是要求个体的地理分布均匀，且被感染的概率也相同(T. G. Lewis, 2011)。那么β表示传染率（transmission rate)。SI模型可以表达为：
$$\frac{dS}{dt}=-\beta SI$$
$$\frac{dI}{dt}=\beta SI$$
且满足 I + S = 1，那么以上方程$$\frac{dI}{dt}=\beta SI$$可以表达为：
$$\frac{dI}{dt}=\beta I(1-I)$$
解这个微分方程，我们可以得到累计增长曲线的表达式。有趣的是，这是一个logistic增长，具有明显的S型曲线（S-shaped curve）特征。该模型在初期跨越临界点之后增长较快，后期则变得缓慢。 因而可以用来描述和拟合创新扩散过程（diffusion of innovations）。
当然，对疾病传播而言，SI模型是非常初级的（naive），主要因为受感染的个体以一定的概率恢复健康，或者继续进入可以被感染状态(S，据此扩展为SIS模型)或者转为免疫状态（R,据此扩展为SIR模型）。 免疫表示为R，用$$\gamma$$代表免疫概率（removal or recovery rate)。对于信息扩散而言，这种考虑暂时是不需要的。
第一步，生成网络。
require(igraph) # generate a social graph size = 50 # 规则网 g = graph.tree(size, children = 2); plot(g) g = graph.star(size); plot(g) g = graph.full(size); plot(g) g = graph.ring(size); plot(g) g = connect.
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2014-02-28-simulate-network-diffusion-with-r/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-27-topic-modeling-of-song-peom/" itemprop="url">东风夜放花千树：对宋词进行主题分析初探</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2013-09-27 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Sep 27, 2013
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    邱怡轩在统计之都中展示了对宋词进行的分析（参见http://cos.name/tag/%E5%AE%8B%E8%AF%8D/），因为当时缺乏中文分词的工具，他独辟蹊径，假设宋词中任意两个相邻的汉字构成一个词语，进而找到了宋词当中的高频词。本文则尝试使用他所提供的宋词语料（http://cos.name/wp-content/uploads/2011/03/SongPoem.tar.gz），分析一下使用R进行中文分词、构建词云、高频词语聚类以及主题模型分析。
首先要载入使用的R包并读入数据。
library(Rwordseg) require(rJava) library(tm) library(slam) library(topicmodels) library(wordcloud) library(igraph) setwd(&quot;D:/github/text mining/song&quot;) # 更改为你的工作路径，并存放数据在此。 txt=read.csv(&quot;SongPoem.csv&quot;,colClasses=&quot;character&quot;)  {:lang=&ldquo;ruby&rdquo;}
然后进行对数据的操作。当然，第一步是进行中文分词，主要使用Rwordseg这个R包，其分词效果不错。分词的过程可以自动去掉标点符号。
poem_words &lt;- lapply(1:length(txt$Sentence), function(i) segmentCN(txt$Sentence[i], nature = TRUE))  {:lang=&ldquo;ruby&rdquo;}
然后，我们将数据通过tm这个R包转化为文本-词矩阵（DocumentTermMatrix）。 wordcorpus &lt;- Corpus(VectorSource(poem_words), encoding = &ldquo;UTF-8&rdquo;) # 组成语料库格式
Sys.setlocale(locale=&quot;Chinese&quot;) dtm1 &lt;- DocumentTermMatrix(wordcorpus, control = list( wordLengths=c(1, Inf), # to allow long words bounds = list(global = c(5,Inf)), # each term appears in at least 5 docs removeNumbers = TRUE, # removePunctuation = list(preserve_intra_word_dashes = FALSE), weighting = weightTf, encoding = &quot;UTF-8&quot;) ) colnames(dtm1) findFreqTerms(dtm1, 1000) # 看一下高频词  {:lang=&ldquo;ruby&rdquo;}
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-27-topic-modeling-of-song-peom/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-08-using-cluster-analysis-to-classify-topics-generated-by-topic-modeling/" itemprop="url">使用聚类分析为主题模型划分主题类型</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2013-09-08 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Sep 8, 2013
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    2 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    使用主题模型（topic models）可以较为高效地划分文本的主题，但一个不得不面对的问题是有时候主题的划分过细，使得解读和归类成为困难。其实，聚类分析作为一个“古老”的分析方法可以较为简洁的解决这个问题。
举一个小例子，我们主要使用tm这个R包来完成文本挖掘的前期任务。在得到DocumentTermMatrix之后，可以通过计算cosine 相似度的方法来计算文本之间的不一致性（dissimilarity）。
# Using cluster analysis to classify topics generated by topic modeling # 2013 Sep 08 # Cheng-Jun Wang library(tm) library(topicmodels) require(proxy) data(acq) data(crude) m &lt;- c(acq, crude) dtm &lt;- DocumentTermMatrix(m) dtm &lt;- removeSparseTerms(dtm, 0.8) inspect(dtm[1:5, 1:5]) # cluster analysis of documents based on DocumentTermMatrix dist_dtm &lt;- dissimilarity(mtd, method = 'cosine') hc &lt;- hclust(dist_dtm, method = 'ave') plot(hc, xlab = '')  {:lang=&ldquo;ruby&rdquo;}
我在做RA的时候，面临的一个问题就是在做主体模型的时候出现的：模型拟合得到的主题数量太多。我们用下面这个例子进行简单的介绍。
# topic modeling topic_num = 50 for (k in c(topic_num)) { # k &lt;- 10 SEED &lt;- 2010 jss_TM &lt;- list( VEM = LDA(dtm, k = k, control = list(seed = SEED)), VEM_fixed = LDA(dtm, k = k, control = list(estimate.
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-08-using-cluster-analysis-to-classify-topics-generated-by-topic-modeling/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-07-part-of-speech-analysis-with-opennlp/" itemprop="url">文本挖掘基础：使用openNLP进行词性标注</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2013-09-07 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Sep 7, 2013
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    2 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    使用R软件进行自然语言处理（文本挖掘）是比较方便的。其中一个比较基础的分析是采用part-of-speech tagging的思路进行词性标注。在本文中，我将简单地介绍使用R软件及其子包openNLP进行词性标注。这里的测试语料依然是英文，采用的算法主要是最大熵的方法。
openNLP的发展开始回归到底层的基本功能，之前搭建起来的比较方便实用的函数被取消了，比如tagPOS命令消失了。所以，需要自己来重新写这个方程。这也不太难，根据R文档对Maxent_POS_Tag_Annotator的介绍中的例子重新组合一下，就可以得到。
动词和名词的使用在文本挖掘中异常重要，单纯的名词语料可以用于进一步的文本挖掘，如我要做的是采用它们继续做主题挖掘（topic modeling）。
第一步，当然是重组这个tagPOS命令。
library(openNLP) library(tm) require(NLP) # Compose the tagPOS function tagPOS &lt;- function(text.var, pos_tag_annotator, ...) { s &lt;- as.String(text.var) ## Set up the POS annotator if missing (for parallel) PTA &lt;- Maxent_POS_Tag_Annotator() ## Need sentence and word token annotations. word_token_annotator &lt;- Maxent_Word_Token_Annotator() a2 &lt;- Annotation(1L, &quot;sentence&quot;, 1L, nchar(s)) a2 &lt;- annotate(s, word_token_annotator, a2) a3 &lt;- annotate(s, PTA, a2) ## Determine the distribution of POS tags for word tokens.
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-07-part-of-speech-analysis-with-opennlp/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-31-topic-modeling-with-r/" itemprop="url">使用R做主题模型：词语筛选和主题数量确定</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2013-08-31 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Aug 31, 2013
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    3 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    1. 筛选单词 在数据清理（pre-processing）之后，需要对数据进行适当筛选。对数据的筛选包括至少两个步骤：
第一步，在DocumentTermMatrix中设定
使用R的topicmodels发现设定在DocumentTermMatrix里的约束条件失效，解决方法在此，其实在topicmodels的包里也粗略提及，只是用习惯了tm包的人觉得二者是无缝对接的。其实还很多差异，比如在tm里相似功能称之为TermDocumentMatrix
dtm &lt;- DocumentTermMatrix(corpus, control = list(stemming = TRUE, stopwords = TRUE, wordLengths=c(4, 15), bounds = list(global = c(5,Inf)), # each term appears in at least 5 docs removeNumbers = TRUE, removePunctuation = list(preserve_intra_word_dashes = FALSE) #,encoding = &quot;UTF-8&quot; ) ) colnames(dtm) ## inspect all the words for errors dim(dtm)  {:lang=&ldquo;ruby&rdquo;}
第二步，通过tf-idf和col_sums选择高频词
这背后的逻辑在于主题模型是要对文本进行分类，频次较少的词的贡献并不大。但会显著的占用计算资源。
term_tfidf &lt;-tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) * log2(nDocs(dtm)/col_sums(dtm &gt; 0)) l1=term_tfidf &gt;= quantile(term_tfidf, 0.
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-31-topic-modeling-with-r/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-29-encoding-in-r-for-text-mining/" itemprop="url">使用R做主题模型：举一个处理Encoding问题的例子</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2013-08-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Aug 29, 2013
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    3 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    引言 遭遇“邪恶的拉丁引号” 我遇到的问题比较复杂，因为原文里混合了latin1和UTF-8两种encoding的字形，最初我统一再读入text数据的时候采用encoding =&ldquo;UTF-8&rdquo;的方法，结果发现了很多奇诡的单引号和双引号错误。在生成的DocumentTermMatrix里出现了很多以引号开始或结束的terms，例如：“grandfather， “deputy with the constitution” 。用Encoding命令看一下它的原形是：
&gt; Encoding(&quot;“&quot;) [1] &quot;latin1&quot;  只所以说是原形，是因为它们可以变形！&rdquo;â€œ&rdquo;， &ldquo;â€™&rdquo;， &ldquo;â€\u009d&rdquo;， &ldquo;â€&rdquo;都是它在不设定Encoding的环境下的形状。但我觉得不足以刻画我对它的厌恶，特别附图一张：
直到最后，我也没彻底搞定这些邪恶的拉丁引号，但我使用了一些tricks解决的我的问题。
1. 读入数据不设定encoding！ 因为邪恶的拉丁引号在UTF-8格式下根本就无法对付，在不设encoding方法的时候，它们现身为â€“, â€™, â€œ等形式，还可以对付。
dat1 = read.csv(&quot;D:/chengjun/Crystal/Schwab_data_cleaningSep.csv&quot;, header = F, sep = &quot;|&quot;, quote = &quot;&quot;, stringsAsFactors=F, fileEncoding = &quot;&quot;) # , encoding =&quot;UTF-8&quot;); dim(dat1) names(dat1) = c('name', 'organization', 'year', 'country', 'website', 'shortIntro', 'focus', 'geo', 'model', 'benefit', 'budget', 'revenue', 'recognization', 'background', 'innovation', 'entrepreneur')  2. 文本数据清理第一步：载入R包，选取变量 library(tm) library(topicmodels) text = dat1$entrepreneur  3.
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-29-encoding-in-r-for-text-mining/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-09-sna-book-chapter/" itemprop="url">探寻社交网络中的关系: 统计网络模型初探</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2013-08-09 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Aug 9, 2013
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    王成军
香港城市大学媒体与传播系
在上一章当中，我们对于网络的基本知识进行了介绍，这些知识构建起了网络科学的基础，同时也孕育着巨大的潜能。社会科学追求理论的建构，但疏于思考理论层次的丰富性。以社会学为例，一度在宏大理论和抽象实证主义之间摇摆（参见米尔斯所著《社会学的想象力》）。大数据时代的到来，再一次使得少数人开始对理论的认识产生动摇，以为只要把握住数据就足够了。这与可计算性社会科学都是相互矛盾的。可计算性社会科学研究社会现实，紧紧抓住数据，但是绝不束缚于数据。
数据（data）、模式（pattern）、法则（law）、机制（mechanism）和隐含的原理(principle)构成了科学研究等级，如图11-1所示。科学理论的等级在这里又被粗略地划分为四个等级：模式、法则、机制和原理。网络科学以关系来度量物理世界和社会现实（social reality）。这些稳定的关系——表现为网络中的链接——构成了网络科学可计算性的基础。沿着网络中的链接出发，网络科学正在尝试突破社会现实混沌的迷宫，从社会现实的数据出发，发掘社会系统内部的模式、法则、机制、原理。
图 11-1. 科学研究的金字塔
网络科学所采用的方法非常多样，除了经典的统计方法之外，很多物理学的方法也被广泛的应用在网络研究当中。具体而言，网络科学有两个方法来源，一个是传统的社会网络分析，一个是近十几年里面迅猛发展起来的复杂网络研究。这两股研究的脉络构成了网络科学的两条主线。网络科学已经走出传统的社会网研究的藩篱。互联网浪潮的袭来推动传统网络研究与互联网科学（web science)的融合。一种以复杂网络（complex network）为代表的新型网络科学开始迅速成长(Barabasi, 2003)。例如，巴拉巴西等人采用动力系统的研究方法分析复杂网络的增长机制(Barabási &amp; Albert, 1999)。但在本章当中，我将主要关注统计网络模型（statistical network models），并通过介绍处理社会化网络数据的例子来深化我们对于网络的认识。
本章的结构安排如下：一、通过介绍网络科学的异军突起来思考可计算性在不同学科的发展，以便于启发我们对于可计算社会科学的认识；二、我们介绍数字化媒体的发展，以及由此带来的大数据浪潮的挑战和机遇；三、我们开始介绍网络链接的属性，拓展对于网络的认识；四、简略介绍QAP检验；五、介绍指数随机图模型；六、结论和讨论。
 网络科学的异军突起：反思可计算性 数字化媒体和大数据 扩展对于网络的认识（二模网络与多模网络和时间序列网络） QAP检验 指数随机图模型（ERGM） 一条开放的道路  ###一、网络科学的异军突起：反思可计算性
事实上，作为一个后起之声，可计算性社会科学（computational social science）已经在各个分支学科和新的交叉性学科中如火如荼！关于计算社会科学的介绍可见Lazer等人(2009)发表在《科学》杂志上的一文。Lazer等人综述了可计算性社会科学的涌现和发展，尤其强调了网络科学研究在其中所扮演的角色和数字媒体所提供的机遇。网络科学和可计算性社会科学的兴起都使得我们开始更加严肃地思考可计算性在科学版图当中的作用。
对于可计算性的追求在自然科学一直是主流。物理学具有着最强的可计算性。物质世界的稳定性给了物理学发展提供了得天独厚的条件。物理学家采用各种稳定的手段测量物理世界的状态：长度、面积、体积、质量、速度、时间、能量。从牛顿力学到相对论，电磁学、再到量子力学，物理学展现了理论和数据的高度统一：我们可以精确地知道桥梁的重量、地球到月球的距离和卫星发射的速度。这种成就在一开始就激励着社会科学的发展。生物学诞生之初，研究者多少博物学家，忙着收集标本，区分生物所属的界、门、纲、目、科、属、种的类别。即使到了达尔文提出物种起源假说，生物学的发展依然备受局限。是什么使得生物学步入可计算化的路径，进而实现新的飞跃？一个可能的答案是“基因”。抓住这个计算性的本源，生物学开始迅速崛起。
社会科学则是另一番图景。试思考为什么经济学是社会科学中发展较好的？答案是货币。用货币度量经济行为使经济学具有了天然的可计算性；其次是心理学，不是量表，而是实验，使得心理学具有了“模糊的”比较能力。而其他传统的社会科学，如传播学，则处于摇摆当中缓慢发展。
值得注意的是三个迅速发展的学科：计算机科学、统计语言学、和我们正在谈论的网络科学。毋庸置疑，计算机科学是二十世纪发展最快的学科之一。其中一个重要的原因就在于计算机科学所对付的对象是离散的0和1。0和1通过二进制的运算构成了现代计算机的基础，也使得计算机科学从诞生之初，其“基因”当中就蕴含了强大的可计算性。在此基础上，计算机科学可以相对容易地与数学相结合研究信息和通信问题，并借助计算性思维（computational thinking）通过算法设计来自动化地解决问题(Wing, 2006)。统计语言学是传统语言学与计算机科学相互融合的结果。通过建立关于语言学的数学模型，并通过计算机来进行运算，统计语言学使得语言学在过去的三十年当中取得长足进步(吴军, 2012)，例如自然语言处理（natural language processing）已经广泛地应用在互联网产业当中和其他学科的研究当中。最近升起的新星则当属网络科学。网络科学对社会关系进行运算，借用统计物理的方法，很快发现复杂网络（例如，大规模的社会网络就是一种复杂网络）具有明显的小世界特征(Watts &amp; Strogatz, 1998)和无标度特征(Barabási &amp; Albert, 1999)。
概括以上内容，我们可以发现：可计算性植根于不同的学科当中。发掘可计算性对于不同的学科具有举足轻重的意义。基于可计算性的研究才有较高的信度和效度，才能得到更确实的（solid）发现，才能和数学工具和物理学工具更好的结合，才能更深刻地探寻社会模式背后的法则、机制、规律。
图 11-2. 学科历史与其可计算性的关系
###二、数字化媒体和大数据 互联网的发展使得人类社会进入了一个新的时代：数字媒体时代（the era of digital media）。这种变化的影响已经被诸多预言者和研究者所分析，也为这个时代的个体所体认与观察。人类的交往模式，商业行为，舆论空间等，都因互联网而改变。但本文由数字化痕迹开始讲起。
数字化媒体（digital media）的崛起正在深刻变革的社会科学的研究视野。因为数字化技术的发展（比如互联网）使得很多的人类行为变得可以观察，因而给我们更真实地认识世界提供了一个崭新的入口——数字化痕迹（digital traces）。比如，你在网络上购物的经历，你在社交媒体上的使用记录。这些数字化痕迹（又称数字化指纹（digital fingerprint），或数字化脚印（digital footprint）），使得研究者可以追逐这种痕迹，分析其行为背后隐藏的社会规律，进而提供了一个巨大的资源。这种资源的出现正在变革着不同学科的研究视角和研究疆域。比如，网络化的大规模数据的数字化痕迹（digital traces）第一次使得传播行为获得了计算性。而记录（document）、收集（collect）、分析（analyze）、可视化（visualize）这些传播行为就成为了计算传播学的主要工作。按照这个设想，社会科学必须走出传统的研究套路，获得在网络上保存、抓取、分析、可视化大规模电子化数据的能力，也需要支持这些工作的工具。毫无疑问，社会科学因此将和计算机科学开始交汇，至少需要程序员投入到这种大规模数据的挖掘工作中来。计算机科学家越来越将更多的注意力放在社交媒体的使用研究方面来。一系列的计算机会议以社交媒体研究作为重心。其它的学科分支也马上意识到互联网带来的机遇和挑战。这里要首先谈人类认知世界的一个重要方法——观察法。
观察法是社会研究和自然研究最古老的方法。在社会研究领域，这种方法因其复杂和难以操控，往往只是适用于研究初期。研究中后期往往使用调查和实验方法，但后面这两种方法的优点是根据研究者的视角进行操控（manipulate），但缺点也在这里。因为访谈或问卷或实验，往往会降低研究的效度。而数字化痕迹使得这种限制减少，使得研究者真正在研究活生生的人类行为，并且研究的规模非常巨大，且往往具有时间序列的信息。数字化痕迹使得非介入的观察（unobtrusive observation）成为可能，因而给研究者带来的巨大的机遇。机遇是数据的获取为检验和发展经典理论提供了土壤。但同时也伴随着挑战。这种挑战则首先主要来自这种数字痕迹的获取、分析和储存上。
当然第一关是数据的获取。资源虽然存在，却并不能为所有的人所使用。因为这里有一个天然的、历史原因造成的技术屏障——计算机技术。数字化痕迹的还有一些其它特点。比如规模巨大，难以分析，当然这涉及到数据的分析问题，不是本文的重点。另外一个方面，这些数字指纹往往是流数据，这意味着如果此刻不获取这些数据，过一段时间这些数据就很难或者没有可能获取了。甚至因为数据规模庞大，一些互联网公司也并不会储存所有的数据。这也为数据获取者提供了一种学习的急迫性。
其中最简单的是研究者的编程技术。传统的社会科学研究者和读者往往忽略计算机技术尤其是编程能力的培养。因而，在学科转型之初，第一步就是这种开始学习崭新的东西。这多多少少让新手感到畏惧。需要指出的是，这种畏惧是不必要的。因为技术的发展趋势是越来越人性化和具有可读性。这给编程语言的学习带来便利。社会科学研究者可以选取简单的编程语言（R、Python、Ruby）开始计算机编程的学习。一个问题是是否可以采用即成的数据抓取软件呢？我的理解是，就目前而言，打包好的数据抓取软件过于死板，且效率低下，并且多数价格不菲、不是开源的软件。因而不是首选。现在很多统计语言往往也可以从事数据抓取的工作，比如R社趣发展了twiiteR的包和Rweibo的包。虽然其接口并不完善，但研究者根据自我需求进行自由的开发。
社交网站为了自身的发展，往往选择向外界开放部分资源，以方便第三方发展基于该社交网站的产品，进而更好吸引使用者使用。比如新浪微博上有着纵多的应用，这些应用的数据接口就是由新浪微博所提供的。当然这种数据提供需要注册和认证，例如，对新浪微博而言可到应用开发页面注册 。因而，数据抓取的第一步，就是建立数据连接的工作，以获取社交网站开放数据流的许可。现在流行的方式是使用OAuth获取连接社会化媒体的API的使用权限。这种机制的好处是直接从网站数据库获取数据，因而数据结构化较好，不需要经过复杂繁琐的处理。且更好保护了使用者的隐私(Russell, 2011)。获取数据使用许可之后，其使用就非常方便灵活了。
在本章当中，我们使用李舰 (Li, 2013)编写的Rweibo来连接新浪微博的API接口，并获取我们所需要的信息。Rweibo是一个新浪微博针对R语言的软件开发工具包（Software Development Kit, SDK）。作为一个R的软件包，Rweibo可以在R软件当中自由安装和调用。
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-09-sna-book-chapter/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-04-qap-test-of-network-analysis/" itemprop="url">QAP检验：计算两个网络的关联</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2013-08-04 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Aug 4, 2013
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    1 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    QAP检验：两个网络之间的关联 通常一组个体具有多种类型的关系，例如友谊关系和经济往来关系。我们通常会对这两种网络关系在多大程度上相互关联感兴趣。当我们知道一组个体之间的两种关系网络，我们就可以计算这个两个关系网络之间的相关程度。在统计学当中，皮尔森相关系数是用来反映两个变量线性相关程度的统计量。与之类似，对于由一组个体所组成的两个网络，也可以计算其相应的相关皮尔逊相关系数。当然，还可以计算其他你感兴趣的统计量，如协相关系数。
我们使用sna这个R软件包来计算网络相关系数（并调用qaptest命令）。通过安装和使用statnet这个R软件包，就会自动加载sna等子软件包。另外，statnet当中还集成了其他的几个相关的R软件包，包括进行动态网络建模的tergm子软件包。
# R程序11-8：计算网络的皮尔逊相关系数 install.packages(&quot;statnet&quot;) library(statnet) # 首先随机生成3个由10个节点构成的有向网络 g=array(dim=c(3,10,10)) g[1,,] = rgraph(10) g[2,,] = rgraph(10,tprob=g[1,,]*0.8) # 设置g1和g2两个网络强相关 g[3,,] = 1; g[3,1,2] = 0 # g3接近于一个派系（clique） # 绘制这3个网络 par(mfrow=c(1,3)) for(i in 1:3) { gplot(g[i,,],usecurv=TRUE, mode = &quot;fruchtermanreingold&quot;, vertex.sides=3:8)} #计算网络的相关矩阵 gcor(g)  在通常使用皮尔逊相关系数的时候，可以用t统计量对总体相关系数为0的原假设进行检验。但在计算网络的相关系数（graph correlations）时，经典的零假设检验方法往往会带来偏差，因而并不适用。通常使用非参数检验的方法，比如QAP(Quadratic Assignment Procedure)检验。
矩阵的随机排列（Random matrix permutations）是QAP检验的关键部分，在子软件包sna中主要通过rmperm来进行。通过矩阵的随机排列，可以对网络中的节点编号（而不是链接！！）进行随机置换（relabelling）或重新“洗牌”（reshuffling），并得到一组（比如1000个）重连后的网络。因为只是置换节点，这种操作只是重新标记节点的编号（relabelling）。
# R程序11-9：矩阵的随机置换方法 j = rgraph(5) # 随机生成一个网络 j #看一下这个网络的矩阵形式 rmperm(j) #随机置换后的网络的矩阵形式  对这一组重构的网络可以计算其网络级别的参数（如两个网络的相关参数，协相关参数），并因此得到一个参数分布。QAP检验的零假设是实际观测到的网络参数（如）来自于这一个参数分布。也就是说，原假设认为这种观测到的相关关系是由随机因素带来的，因而这种网络相关并不显著。拒绝原假设，就从统计的角度证明了观测到的网络相关系数是显著的。
# R程序11-10：QAP检验 q.12 = qaptest(g, gcor, g1 = 1, g2 = 2) q.
    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-04-qap-test-of-network-analysis/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  
    
    

<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2012-12-06-intenet-ecology/" itemprop="url">互联网的法则：网络生态学的起点</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2012-12-16 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Dec 16, 2012
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    1 分钟阅读时间
  </span>
  

  
  

  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    

<p>作者： 黠之大者（网名），王成军，香港城市大学博士（在读）</p>

<p>本文载于《数字媒体阅读报告》</p>

<h2 id="the-laws-of-the-web">The Laws of the Web</h2>

<h3 id="patterns-in-the-ecology-of-information">Patterns in the Ecology of Information</h3>

<p><img src="http://d202m5krfqbpi5.cloudfront.net/books/1347698642l/706406.jpg" alt="" /></p>

<p>Bernardo A. Huberman (Author)</p>

<p>Paperback: 115 pages</p>

<p>Publisher: The MIT Press (April 1, 2001)</p>

<p>Language: English</p>

<p>ISBN-10: 0262582252</p>

<p>伯纳德-胡伯曼是惠普实验室的科学家，同时是斯坦福大学应用物理系的顾问教授（Consulting Professor）。他培养了很多学生，其中比较有名的当属Lada Adamic。他们两个在1999年以来的关于互联网的研究使之成为网络科学研究的重要成员，也奠定了本书基本的架构。他的第一篇论文发表于1970年，可以说是一个常青树。直到现在，依然保持着较高的学术产量。</p>

<p>浏览其发表的论文，会很明显得发现他从物理学转型到互联网的结构和动态的研究，而现在则主要关注注意力经济的研究。从Strong Regularities in World Wide Web Surfing （1998， 《科学》），Evolutionary Dynamics of the World Wide Web  （1999， 《自然》）等文章开始，胡伯曼的研究成为与其它主流研究者（如巴拉巴西）对话的重要人物，尤其是关于互联网的直径问题和互联网的增长机制问题 （读者可参见更好地一篇书评 ）。在其1998年的文章中，胡伯曼就提出了互联网的访问量满足幂律分布，而1999年的文章则表明互联网的结构同样满足幂律分布。这种普世的现象，胡伯曼将之称之为法则（law）。</p>

<p>在讨论网络的演化与结构的过程中，胡伯曼强调关于市场中的个体的计划和策略的相吸信息不足以帮助我们理解一个市场的行为。主要是因为集体行为是互动的结果，单纯的个体信息只抓住了节点，而忽略的动态的互动。因此，追踪一些单个的个体的网页浏览行为也不能预测整体上的网络浏览规律。胡伯曼说，“我们必须放弃这些个体信息，而代之以更为整体的、系统水平的行为特征 ”（p. 23）。他将这种思路称之为整体的思路（the aggregate way），并认为这是一个强大的方法论，可以用来解决的大的分布系统，如股票市场、计算机网络、社会组织。不得不说，这是一种过于简略的思路。胡伯曼在这个问题上似乎对于微观的机制并没有太多兴趣，他执意要绕开从微观行为到宏观结果的涌现，而在系统层面讨论系统问题。恰因如此，他能够顺畅地讨论网络增长和网路规模这种系统水平的问题，而避开令人畏惧的个体行为。</p>

<p>在等待牛顿的道路上，这对于普通研究者而言，不失为一种明智之举。却也显露出胡伯曼的局限。不过，这也是不绝对的，科学的道路，在发现法则之后，必然要走向背后的机制（mechanism）和普世的原理（principle）。物理学方法重视动力学方程的建立，他们以另外一种方式——数学和理论的途径面对微观的问题，但十分清楚这个从微观到宏观的过程不是简单的个体信息能顺利解决的。网络的另一特特征是小世界特性，胡伯曼指出目前的研究，尤其是巴拉巴西等人提出的优先链接机制不能较好的揭示网络的聚类特征，因此网络科学仍在寻找一个能够综合小世界特征和无标度特征的网络生成机制。其它几章讲解互联网阻塞、信息下载和互联网市场的问题，也多真知灼见。整体来看，这是一本非常简明的小书（正文只有95页）。作为较早的对网络科学研究的一个总结，值得读一下。</p>

    
  </div>
  <p class="read-more">
    <a href="https://chengjunwang.com/zh/post/cn/cn_archive/2012-12-06-intenet-ecology/" class="btn btn-primary btn-outline">
      继续阅读
    </a>
  </p>
</div>

  

  
<nav>
  <ul class="pager">
    
    <li><a href="/zh/post/page/2/">&lt;</a></li>
    
    
    <li><a href="/zh/post/page/4/">&gt;</a></li>
    
  </ul>
</nav>



</div>
<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2016 Cheng-Jun Wang &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">引用</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> 复制
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> 下载
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

