<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>https://chengjun.github.io/zh/post/index.xml</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>&amp;copy; 2016 Cheng-Jun Wang</copyright>
    <lastBuildDate>Thu, 28 Dec 2017 14:32:07 +0800</lastBuildDate>
    <atom:link href="/zh/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>2017年“大事记”</title>
      <link>https://chengjun.github.io/zh/post/news2017/</link>
      <pubDate>Thu, 28 Dec 2017 14:32:07 +0800</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/news2017/</guid>
      <description>

&lt;h1 id=&#34;sunbelt2017社会网络分析国际研讨会&#34;&gt;SUNBELT2017社会网络分析国际研讨会&lt;/h1&gt;

&lt;p&gt;2017年6月4日上午，实验中心成员王成军在北京参加了2017年XXXV|| International Network for Social Network Analysis Conference 社会网络分析国际研讨会及第十三届中国社会学会社会网与社会资本研究专业委员会年会，发表论文Leveraging the Flow of Collective Attention for Computational Communication Research，并主持社会网络与计算传播学分论坛第二场。&lt;/p&gt;

&lt;h1 id=&#34;本科生论文答辩&#34;&gt;本科生论文答辩&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;5月27日 14:00&lt;/li&gt;
&lt;li&gt;费彝民楼A407&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;指导学术论文&#34;&gt;指导学术论文&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;专硕

&lt;ul&gt;
&lt;li&gt;周纬 《权威与中心:基于HITS算法的收视率分析》&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;本科生

&lt;ul&gt;
&lt;li&gt;黄浩 134056004 􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰关于搭讪艺术家的行为动机与策略的调查报告&lt;/li&gt;
&lt;li&gt;沈越 &lt;a href=&#34;https://data-journalism.github.io/olympic/index.html&#34; target=&#34;_blank&#34;&gt;《“梦之队”统治奥运会？》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;曾维靓 131050038 《大学生群体对于微博原生广告的态度及其影响因素》
􏴊􏴋􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;云南白族扎染暑期社会实践指导&#34;&gt;云南白族扎染暑期社会实践指导&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Q: 关于实际想探究问题，我们又探究了一下，但感觉都找不到很具体的研究方向，我整理了一下我们大概的想法，麻烦老师你看看有没有哪个想法具有可研究性😶&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;1. 民族旅游发展下的“扎染女”的生存现状与角色变迁&lt;/li&gt;
&lt;li&gt;2.扎染工艺需要做出怎样的改变，才能继续发展?&lt;/li&gt;
&lt;li&gt;3.当地工艺在过去是怎么发展和延续的？&lt;/li&gt;
&lt;li&gt;4.我们可以研究当地人在怎么努力挽救这个工艺么&lt;/li&gt;
&lt;li&gt;5.从扎染看当地经济结构的变迁？&lt;/li&gt;
&lt;li&gt;6.探究云南白族扎染工艺当前生存状况并以白族扎染为例探究对传统手工艺的生产性方式保护.&lt;/li&gt;
&lt;li&gt;7.探究白族扎染的工艺特色，艺术特征，在现代社会的创新运用.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A: 首先概念化，白族扎染是一种国家非物质文化遗产，也是一种传传统手工技艺。这背后对应着什么概念？然后是寻找新的问题。白族扎染作为一种手工技艺，在传承的过程中存在什么新的问题（其它手工艺没有的）？当前产业化的趋势使部分传统扎染技艺走向消亡，原有的民间特色开始退化，污染问题日益突出，市场经营滋生了对经济利益的过度追求，植物染料板兰根供不应求。在此情势下，白族扎染技艺的传承受到困扰。产业化是手工艺凋亡的关键原因，这个解释力很强，白族扎染很难幸免。要确保找到的问题是新的问题，即明确而且有意义。如有可能，要尝试理论化，找找既有的理论如何解释传统工艺的传承。研究问题要将个体（研究者）的困惑与社会结构（问题）联系起来。你们要好好琢磨一下，面对这种手工艺，你们有什么困惑？它又反应了什么social issue？强烈建议你们首先查询相关的论文和图书。&lt;/p&gt;

&lt;h1 id=&#34;华人思想库-省侨办共建智库-华智-项目讨论&#34;&gt;华人思想库-省侨办共建智库（华智）项目讨论&lt;/h1&gt;

&lt;p&gt;《全球治理时代的中国新型智库》&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;陈晓晨 （人大重阳金融研究院专家）&lt;/li&gt;
&lt;li&gt;2017-04-28 9:00 am&lt;/li&gt;
&lt;li&gt;费彝民楼5楼圆桌会议室&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;信得过、用得着、靠得住；建设自己的报送渠道；资金来源稳定，不干涉。&lt;/p&gt;

&lt;h1 id=&#34;计算传播学-用ai穿透你的注意力壁垒&#34;&gt;计算传播学——用AI穿透你的注意力壁垒&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;集智学园简介：&lt;a href=&#34;http://campus.swarma.org/gvid=10140&#34; target=&#34;_blank&#34;&gt;http://campus.swarma.org/gvid=10140&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;时间：2017-04-12 20:00-23:00&lt;/li&gt;
&lt;li&gt;网址：&lt;a href=&#34;http://xue.duobeiyun.com&#34; target=&#34;_blank&#34;&gt;http://xue.duobeiyun.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;硕士预答辩&#34;&gt;硕士预答辩&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;费彝民楼503&lt;/li&gt;
&lt;li&gt;2017-03-30 16:00&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;计算传播讲座&#34;&gt;计算传播讲座&lt;/h1&gt;

&lt;p&gt;2017年3月22日 10：00-12：00， 费彝民楼A418， 王成军向2016级博士生同学介绍计算传播学研究进展，包括计算社会科学的发展状况、代表性研究成果，如何评价其理论创新问题，并对社会科学理论进入丛林的问题进行了讨论。&lt;/p&gt;

&lt;h1 id=&#34;博士之家&#34;&gt;博士之家&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;地点：费彝民楼A418&lt;/li&gt;
&lt;li&gt;时间：3月10日 12：00-14：00&lt;/li&gt;
&lt;li&gt;主讲者：&lt;a href=&#34;http://sociology.nju.edu.cn/teacher/social/quanzhi/350.html&#34; target=&#34;_blank&#34;&gt;吴愈晓&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;主持人：王成军&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;创享沙龙-对话音乐与虚拟现实技术&#34;&gt;创享沙龙：对话音乐与虚拟现实技术&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;地点：南京大学（仙林校区） 大学生活动中心南花园206&lt;/li&gt;
&lt;li&gt;时间：2月27日 18：30-19：30&lt;/li&gt;
&lt;li&gt;主讲者：向雪怀、王成军&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;南大新闻 &lt;a href=&#34;http://news.nju.edu.cn/show_article_4_45010&#34; target=&#34;_blank&#34;&gt;音乐人向雪怀与我校师生对话VR技术与校园音乐
&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>手机用户在真实与虚拟空间中的移动</title>
      <link>https://chengjun.github.io/zh/post/cn/2015-12-02-renormalization/</link>
      <pubDate>Wed, 02 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2015-12-02-renormalization/</guid>
      <description>

&lt;p&gt;思考手机用户在真实和虚拟世界的移动本身有什么价值:比较两种类型的网络结构，一个是分形的，一个是小世界的。二者之间不是完全对立的，而是可以平滑过渡的，因而可以计算从小世界到分形的连续变量的取值，即网络增长的过程中，新节点多大程度上按照小世界规则加入网络，多大程度上按照分形加入网络（Song, 2006）。&lt;/p&gt;

&lt;p&gt;自相似或者说分形是本研究切入的重点，分形的特点是在不同尺度上具有相同的特征，这种自相似的特征往往表现为系统特征与观测尺度之间的对应关系。一般对于分形网络而言，重整化之后的盒子数量log(N)与盒子大小log(L)之间存在无标度关系。我们确实也发现人在移动互联网站构成的网络重整化过程中，盒子数量与盒子大小之间具有这种无标度关系，但是人在现实世界的物理移动构成的网络经过重整化，其盒子数量与盒子大小之间则是指数分布。由此可见二者网络结构是如何不同的，前者接近分形，后者接近小世界。&lt;/p&gt;

&lt;p&gt;衡量小世界和分形的重要方法是度相关。分形意味着较强的异配性，而小世界则是同配性。正向的度相关意味着同配性和小世界，负向意味着分形。对于同配性的网络度相关通过重整化，一般会被抹平。有趣的是我们发现真实移动网络会由正变负。即当盒子比较大的时候，局部地区的同配性消失，表现出异配性。&lt;/p&gt;

&lt;p&gt;Song（2006）将网络增长与重整化看成一个逆过程，网络增长的过程可以看成重整化的尺度由大变小的过程。小世界网络增长的过程中，网络的平均直径L与网络中的节点数量具有对数关系，L ~ Log(N)。重整化需要的步数约等于最终网络的平均直径，例如一个直径是14的网络，大约经过14步重整化会由一个完整的网络坍缩为一个节点。在重整化过程中，所选择的盒子的大小l的取值范围约等于最终网络的平均直径range(L)。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www-levich.engr.ccny.cuny.edu/webpage/hmakse/&#34; target=&#34;_blank&#34;&gt;Hernan Makse&lt;/a&gt;是City College of New York的物理学教授，主要从事复杂网络的研究，他和Song Chaoming就分形网络发表了两篇重要论文(Song 2005&amp;amp;2006)。他非常注重代码和数据的分享。我一直关注的是第一作者Song和鼎鼎大名的Havlin，并没有注意到Hernan， 后来搜索实现fractal_model的python代码的时候才找到他，恍然发现他是两篇论文的通讯作者。&lt;/p&gt;

&lt;p&gt;在这个算法里面，主要有四个参数：世代（generation)、新增子代数量(m)、子代间新增链接的数量(x)、断开父代链接的比例(e)。每一代是一个操作过程：以这一代的每一条边为单位，该边上的两个节点a和b各自新增子代m个，其中m对子代间形成（x-1)个链接，若随机概率大于e，那么断开父代节点a和b之间的链接，同时增加一条m对子代间链接。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;generation, m, x, e = 2, 1, 1, 0
G=nx.Graph()
G.add_edge(0,1) #Two seed nodes(generation 0), then add m offsprings to these seed nodes.
node_index = 2
for n in range(1,generation+1):
    print &#39;STEP:&#39;, n, &#39;\n&#39;
    all_links = G.edges()
    while all_links:
            link = all_links.pop() # [(0, 1)] ----&amp;gt; (0, 1)
            print link
            new_nodes_a = range(node_index,node_index + m)
            print link[0], new_nodes_a
            #random.shuffle(new_nodes_a)
            node_index += m
            new_nodes_b = range(node_index,node_index + m)
            #random.shuffle(new_nodes_b)
            print link[1], new_nodes_b
            node_index += m
            G.add_edges_from([(link[0],node) for node in new_nodes_a])
            G.add_edges_from([(link[1],node) for node in new_nodes_b])
            repulsive_links = zip(new_nodes_a,new_nodes_b) # 相斥的的链接
            print repulsive_links
            add_repulsive_links = [repulsive_links.pop() for i in range(x-1)]
            G.add_edges_from(add_repulsive_links) # add edges between offsprings
            print &#39;add repusive edges&#39;, add_repulsive_links
            if random.random() &amp;gt; e: # 当概率大于e的时候，断开hub间的链接
                print &#39;delete&#39;, link
                G.remove_edge(*link) # 减少一对hub的链接
                add_a_repulsive_link = repulsive_links.pop()
                print &#39;add_a_repulsive_link&#39;, add_a_repulsive_link
                G.add_edge(*add_a_repulsive_link) #相应得，增加一对其子代的链接
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;真实世界的移动网络是小世界的。例如Vito Latora 等（2002）分析了波斯顿地铁网络的结构（小世界）。随机网平均直径低，规则网聚类系数高。小世界网络在平均路径长度方面接近随机网，而在聚类系数方面接近规则网。Latora等认为我们对于小世界的两种衡量方式（平均直径L和聚类系数C）有缺陷（ill-defined），因为仅仅强调了链接是否存在，而忽略了链接的&lt;code&gt;权重&lt;/code&gt;，比如链接的实际长度（the physical length of the link）。他们试图提出一种考虑权重的衡量小世界特征的测量:邻接矩阵 $ a&lt;em&gt;{ij} $ 表示任意两个节点i、j之间是否有链接; $ l&lt;/em&gt;{ij} $  表示任意两个节点i、j之间的权重（比如地铁站之间的空间距离;使用邻接矩阵  $ a&lt;em&gt;{ij} $  可以得到节点间的最短路径矩阵  $ d&lt;/em&gt;{ij} $ 。&lt;/p&gt;

&lt;p&gt;此时，无法算出聚类系数，因为很多地铁站只有两个邻居，算出的平均直径的信息也很少， $ \varepsilon&lt;em&gt;{ij} = \frac{1}{N(N-1)d&lt;/em&gt;{ij}}  $  表示输运效率，可以在globa和local两个层面计算，分别对应平均路径长度L和聚类系数C。当两个节点无链接时，其 $ d&lt;em&gt;{ij} $ 无穷大， $ \varepsilon&lt;/em&gt;{ij} = 0 $ 。避免了计算平均路径长度无穷大的问题。同时可以定义输运成本 $ cost = \frac{\sum&lt;em&gt;{i\neq j} a&lt;/em&gt;{ij}l&lt;em&gt;{ij}}{\sum&lt;/em&gt;{i\neq j}l_{ij} } $ 。如此计算波斯顿地铁的MBTA全局输运效率为0.63，局部输运效率为0.03，成本为0.002。即网络整体输运效率可以达到理想情况的63%，但是局部输运效率很差，不过整个网络的成本很小。如果加上公交网络MBTA+bus，全局效率上升为 0.72，局部效率大幅度上升为0.46，花费的成本仅仅上升为0.004。&lt;/p&gt;

&lt;h3 id=&#34;参考文献&#34;&gt;参考文献&lt;/h3&gt;

&lt;p&gt;Vito Latora（2002）Is the Boston subway a small-world network? Physica A&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>iching：一个用来算卦的python包</title>
      <link>https://chengjun.github.io/zh/post/cn/2015-07-04-iching-python/</link>
      <pubDate>Sat, 04 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2015-07-04-iching-python/</guid>
      <description>&lt;iframe src=&#34;http://nbviewer.ipython.org/github/chengjun/iching/blob/master/iching_intro.ipynb&#34; scrolling=&#34;no&#34; width=&#34;700&#34; height=&#34;6500&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>打包发布python软件包</title>
      <link>https://chengjun.github.io/zh/post/cn/2015-02-22-distribute-python-package/</link>
      <pubDate>Sun, 22 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2015-02-22-distribute-python-package/</guid>
      <description>&lt;p&gt;我们经常写一些程序碎片，却很少有动力把它们整合起来。前段时间写了一个爬取并可视化谷歌学术网的python程序。今天想不如把它整合一下，虽然非常简单（只有一个函数）。主要参考python官网的&lt;a href=&#34;https://packaging.python.org/en/latest/distributing.html#uploading-your-project-to-pypi&#34; target=&#34;_blank&#34;&gt;发布指南&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;##注册
于是首先来到pypi网站注册。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://pypi.python.org/pypi?%3Aaction=submit_form&#34; target=&#34;_blank&#34;&gt;https://pypi.python.org/pypi?%3Aaction=submit_form&lt;/a&gt;
记下用户名chengjun和密码W4&lt;/p&gt;

&lt;p&gt;##填写软件包信息
《指南》推荐直接在线填写 &lt;a href=&#34;https://pypi.python.org/pypi?%3Aaction=submit_form&#34; target=&#34;_blank&#34;&gt;https://pypi.python.org/pypi?%3Aaction=submit_form&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;##打包和发布工具
先要安装两个包：twine和wheel。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install wheel
pip install twine
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##整理项目文件夹
找项目实例（&lt;a href=&#34;https://github.com/pypa/sampleproject）下载下来，修改其中的部分内容即可。详见指南，或者自己摸索即可。&#34; target=&#34;_blank&#34;&gt;https://github.com/pypa/sampleproject）下载下来，修改其中的部分内容即可。详见指南，或者自己摸索即可。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;##打包发布
1.在window环境下，使用cmd，转换工作路径到项目文件夹。
2. 主要参考 &lt;a href=&#34;https://github.com/pypa/twine打包发布：&#34; target=&#34;_blank&#34;&gt;https://github.com/pypa/twine打包发布：&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#Create some distributions in the normal way:
$ python setup.py sdist bdist_wheel

#Upload with twine:
$ twine upload dist/*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我使用上传的时候出错（typeError），于是直接使用打包好的zip文件（在dist子文件夹当中）手工上传到pypi。注意，每次上传到pypi需要修改一次setup.py中的版本号，并重新打包才可上传。如此而已，比我想象当中要速度快得多、简单的多。&lt;/p&gt;

&lt;p&gt;这里是我刚刚打包发布的一个可视化谷歌学术网络的python软件包：&lt;a href=&#34;https://pypi.python.org/pypi/scholarNetwork/&#34; target=&#34;_blank&#34;&gt;https://pypi.python.org/pypi/scholarNetwork/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>表达、检索、练习——写给Python的初学者</title>
      <link>https://chengjun.github.io/zh/post/cn/2015-02-22-fresh-python/</link>
      <pubDate>Sun, 22 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2015-02-22-fresh-python/</guid>
      <description>&lt;p&gt;三年前，我写过一篇小日志，介绍如何从零开始学习R语言。后来我的工作越来越多的使用python，于是摸爬滚打自己探索了挺久的。身边也越来越多的人问起新手如何从零学习python的问题。我想练习、检索、表达这三点依旧是关键，只不过顺序稍有不同。很多人说，学习python，你来推荐一些资料吧。我想了想，资料还不是关键，关键是自身。&lt;/p&gt;

&lt;p&gt;##看书还是上手？
以前我们学语言，比如C语言或者Basic语言，首先讲的都是字符、数字、列表、逻辑符等。几乎所有的编程书都会这么讲，所以很多人会觉得看书没有什么新意。不过我觉得看书还是必须的，重点就是要去掌握这些基本的东西。&lt;/p&gt;

&lt;p&gt;当然了，掌握这些并不能帮助我们完成手上的工作。是的，并不能！总有一些细节的地方你必须去hack现有的代码。于是乎就有了另外一种学习语言的哲学：干中学（learn by doing）。基本的逻辑就是不断摸索，硬着头皮上。这种风格非常强悍，虽然刚开始的时候容易犯非常浅显的毛病，但是却是真正学语言的不二法门。&lt;/p&gt;

&lt;p&gt;##表达
到底看书还是上手呢？我主张先明确自己的问题是什么。做研究的人都知道，我们往往对于自己所面临的问题并不明确。写程序、学语言也是这个样子。首先要明确地表达出来。这是表达的第一重意思。&lt;/p&gt;

&lt;p&gt;##检索
当你问题明确之后，就可以去检索了。去哪里检索？书中、网上，不拘于形式。重要的是解决问题。这个过程中，我们带着问题读书、上网、提问，能够培养我们独立思考的能力。&lt;/p&gt;

&lt;p&gt;互联网的发展，使得很多时候我们并不需要真正去创造什么，只要检索一下，总能找到好的代码，修改以下就能解决自己的问题。我觉得挺好。这符合我们学习语言的初衷。有个说法是十年学会编程，但是使用编程一个月就够了。&lt;/p&gt;

&lt;p&gt;既然可以看书，有什么推荐的吗？我推荐Beginning Python这本书，虽然我是从A Byte of Python开始看的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A Byte of Python &lt;a href=&#34;http://book.douban.com/subject/5948760/&#34; target=&#34;_blank&#34;&gt;http://book.douban.com/subject/5948760/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Beginning Python （Python 基础教程） &lt;a href=&#34;http://book.douban.com/subject/3205338/&#34; target=&#34;_blank&#34;&gt;http://book.douban.com/subject/3205338/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hello World！Computer Programming for Kids and Other Beginners 与孩子一起学编程 &lt;a href=&#34;http://book.douban.com/subject/5338024/&#34; target=&#34;_blank&#34;&gt;http://book.douban.com/subject/5338024/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How to Think Like a Computer Scientist: Learning with Python &lt;a href=&#34;http://book.douban.com/subject/1481058/&#34; target=&#34;_blank&#34;&gt;http://book.douban.com/subject/1481058/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;21 Recipes for Mining Twitter &lt;a href=&#34;http://book.douban.com/subject/5988563/&#34; target=&#34;_blank&#34;&gt;http://book.douban.com/subject/5988563/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Mining the Social Web &lt;a href=&#34;http://book.douban.com/subject/5391582/&#34; target=&#34;_blank&#34;&gt;http://book.douban.com/subject/5391582/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Toby Segaran (2007) Programming Collective Intelligence Building Smart Web 2.0 Applications. O&amp;rsquo;Reilly Media&lt;/li&gt;
&lt;li&gt;Python公开课 中文课程 &lt;a href=&#34;http://www.imooc.com/view/177&#34; target=&#34;_blank&#34;&gt;http://www.imooc.com/view/177&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##练习
有了问题和思路之后，重要的就是练习了。不要怕麻烦，经常动手写东西。这个是不二法门。&lt;/p&gt;

&lt;p&gt;还有一些琐碎的东西，如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;我觉得学python上手很重要，选一个好的IDE很重要，对于windows用户我推荐winpython，使用集成于其中的spyder编程很方便，不需要指定python的路径，安装第三方包也很方便。&lt;/li&gt;
&lt;li&gt;每天都接触点Python,写写博客。&lt;/li&gt;
&lt;li&gt;既然使用Python了，那么google就是你最好的朋友！用英文检索。&lt;/li&gt;
&lt;li&gt;不要错过Github。上传你的代码。便于保存和分享。python的精神是开放，开源。&lt;/li&gt;
&lt;li&gt;很多时候，最大的问题是你不知道自己面临的问题：我的经验是用英文一句话说出你的问题。然后借助搜索引擎。你一般都能找到答案。Python的email list和stackoverflow中有很多想要的答案。&lt;/li&gt;
&lt;li&gt;实在找不到解决方案，不要过多寄希望于身边的朋友，stackoverflow上有更合适的回答你问题的人！去那里提问。&lt;/li&gt;
&lt;li&gt;熟悉一个package。经常阅读package的文档。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>再次尝试shinyApp</title>
      <link>https://chengjun.github.io/zh/post/cn/2015-01-11-shinyapp/</link>
      <pubDate>Sun, 11 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2015-01-11-shinyapp/</guid>
      <description>&lt;p&gt;昨天收到了shinyapp的一封邮件，想起之前自己做的关于网络扩散的东西，就想把它转化为app的形式。最直接的办法还是看tutorial，比如（&lt;a href=&#34;http://shiny.rstudio.com/tutorial）。&#34; target=&#34;_blank&#34;&gt;http://shiny.rstudio.com/tutorial）。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;现学现卖，于是我马上做了一个使用igraph绘制BA网络的小应用：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://chengjun.shinyapps.io/testApp/&#34; target=&#34;_blank&#34;&gt;https://chengjun.shinyapps.io/testApp/&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&#39;https://chengjun.shinyapps.io/testApp/&#39; scrolling=&#34;no&#34; width=&#34;600&#34; height = &#34;800&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;##通过rstudio学习shinyApp制作
其实R的王牌编辑器Rstudio已经和shiny完美的结合，完全可以通过rstudio学习shinyApp制作。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  system.file(&amp;quot;examples&amp;quot;, package=&amp;quot;shiny&amp;quot;)

  runExample(&amp;quot;01_hello&amp;quot;) # a histogram
  runExample(&amp;quot;02_text&amp;quot;) # tables and data frames
  runExample(&amp;quot;03_reactivity&amp;quot;) # a reactive expression
  runExample(&amp;quot;04_mpg&amp;quot;) # global variables
  runExample(&amp;quot;05_sliders&amp;quot;) # slider bars
  runExample(&amp;quot;06_tabsets&amp;quot;) # tabbed panels
  runExample(&amp;quot;07_widgets&amp;quot;) # help text and submit buttons
  runExample(&amp;quot;08_html&amp;quot;) # shiny app built from HTML
  runExample(&amp;quot;09_upload&amp;quot;) # file upload wizard
  runExample(&amp;quot;10_download&amp;quot;) # file download wizard
  runExample(&amp;quot;11_timer&amp;quot;) # an automated timer
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Echarts使用简介</title>
      <link>https://chengjun.github.io/zh/post/cn/2015-01-10-myecharts/</link>
      <pubDate>Sat, 10 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2015-01-10-myecharts/</guid>
      <description>&lt;p&gt;昨天听谈和讲解了echarts的使用，他的讲解非常直接简单，就是直接修改echarts的实例。之后，我发现林峰将echarts的实例的html代码写得非常复杂，但其实单独调用一个js的时候，却非常简单。具体做法如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;准备工作：建立一个js子文件夹，将esl，echarts，pie，bar，map等各种js放入其中。在js文件夹外新建一个空的html文件。&lt;/li&gt;
&lt;li&gt;首先，调用esl.js，它提供了echarts图片的载体。&lt;/li&gt;
&lt;li&gt;其次，使用require方法调用echarts.js和具体使用的类型图的js（比如map.js）。&lt;/li&gt;
&lt;li&gt;再次，输入需要输入的数据。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;最后，封装。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;!DCOTYPE html&amp;gt;
    &amp;lt;html&amp;gt;
        &amp;lt;head&amp;gt;
            &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;
            &amp;lt;title&amp;gt;echarts testing page&amp;lt;/title&amp;gt;
            &amp;lt;script src=&amp;quot;./js/esl.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
            &amp;lt;script src=&amp;quot;./js/echarts.js&amp;quot; type=&amp;quot;text/javascript&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
        &amp;lt;/head&amp;gt;
        &amp;lt;body&amp;gt;
            &amp;lt;div id=&amp;quot;main&amp;quot; style=&amp;quot;height:400px;&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
            &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
                require.config({
                    paths:{
                        &amp;quot;echarts&amp;quot;:&amp;quot;js/echarts&amp;quot;,
                        &amp;quot;echarts/chart/map&amp;quot;:&amp;quot;js/map&amp;quot;
                    }
                });

                //using
                require(
                    [
                        &amp;quot;echarts&amp;quot;,
                        &amp;quot;echarts/chart/map&amp;quot;
                    ],
                    function(ec){
                        var myChart=ec.init(document.getElementById(&amp;quot;main&amp;quot;));  
                        &amp;lt;!--Input your code below--&amp;gt;                    

                        &amp;lt;!--Input your code above--&amp;gt;                    
                //loading data
                        myChart.setOption(option);
                    }
                );
            &amp;lt;/script&amp;gt;
        &amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##弦图
&lt;a href=&#34;http://chengjun.github.io/myecharts/chord.html&#34; target=&#34;_blank&#34;&gt;http://chengjun.github.io/myecharts/chord.html&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&#39;http://chengjun.github.io/myecharts/chord.html&#39; scrolling=&#34;no&#34; width=&#34;600&#34; height = &#34;400&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;##柱状图
&lt;a href=&#34;http://chengjun.github.io/myecharts/bar.html&#34; target=&#34;_blank&#34;&gt;http://chengjun.github.io/myecharts/bar.html&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&#39;http://chengjun.github.io/myecharts/bar.html&#39; scrolling=&#34;no&#34; width=&#34;600&#34; height = &#34;400&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;##饼图
&lt;a href=&#34;http://chengjun.github.io/myecharts/pie1.html&#34; target=&#34;_blank&#34;&gt;http://chengjun.github.io/myecharts/pie1.html&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&#39;http://chengjun.github.io/myecharts/pie1.html&#39; scrolling=&#34;no&#34; width=&#34;600&#34; height = &#34;400&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;##线图
&lt;a href=&#34;http://chengjun.github.io/myecharts/line1.html&#34; target=&#34;_blank&#34;&gt;http://chengjun.github.io/myecharts/line1.html&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&#39;http://chengjun.github.io/myecharts/line1.html&#39; scrolling=&#34;no&#34; width=&#34;600&#34; height = &#34;400&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;##地图
&lt;a href=&#34;http://chengjun.github.io/myecharts/map9.html&#34; target=&#34;_blank&#34;&gt;http://chengjun.github.io/myecharts/map9.html&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&#39;http://chengjun.github.io/myecharts/map9.html&#39; scrolling=&#34;no&#34; width=&#34;600&#34; height = &#34;400&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;##力图&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://chengjun.github.io/myecharts/force2&#34; target=&#34;_blank&#34;&gt;http://chengjun.github.io/myecharts/force2&lt;/a&gt;&lt;/p&gt;

&lt;iframe src=&#39;http://chengjun.github.io/myecharts/force2.html&#39; scrolling=&#34;no&#34; width=&#34;600&#34; height = &#34;400&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;##后记
发现chrome无法加载，再加入了以下代码后就可以使用了。可惜用了整整一个上午才更正这个问题。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        &amp;lt;script src=&amp;quot;./js/echarts.js&amp;quot; type=&amp;quot;text/javascript&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>使用Python快速分割数据的方法</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-08-31-fast-split-data-with-python/</link>
      <pubDate>Sun, 31 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-08-31-fast-split-data-with-python/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://chengjun.qiniudn.com/longcat.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;分割数据最慢的过程其实是打开和关闭一个文件，因此尽量减少这种操作可以飞速的提升分割数据的速度。之前在&lt;a href=&#34;http://stackoverflow.com/questions/519633/lazy-method-for-reading-big-file-in-python?lq=1&#34; target=&#34;_blank&#34;&gt;stackoverflow上看到一种方法&lt;/a&gt;非常高效，放在这里研究一下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; from collections import defaultdict

 path = &#39;D:/chengjun/Sina Weibo/DepthOverTime/&#39;

 #define a function
 def splitData(f):
     #using dict to &#39;classify&#39; rows
     E = defaultdict(lambda:[])
     for line in f:
         lists = line.strip().split(&#39;,&#39;)
         rtmid = lists[0]
         file_save = path + &#39;single_weibo/&#39;+rtmid
         E[file_save].append(line)
     for key in E.keys():
         try:
             with open(key,&#39;a&#39;) as p:
                 for record in E[key]:
                     p.write(record+&amp;quot;\n&amp;quot;)
         except:
             pass
 # start to read in data by chunks
 bigfile = open(path + &#39;diffusion_path_date2552.csv&#39;)
 chunkSize = 100000000
 chunk = bigfile.readlines(chunkSize)
 while chunk:
     splitData(chunk)
     chunk = bigfile.readlines(chunkSize)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面这段代码有两个地方导致非常高效：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;使用dict来将相同的key的行整理到一起， 以便一次将吞进来的某一个key下面的数据全部写入硬盘&lt;/li&gt;
&lt;li&gt;每次使用readlines读入足够多的行，充分发挥内存的作用&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>使用d3network做网络可视化</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-08-27-d3network/</link>
      <pubDate>Wed, 27 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-08-27-d3network/</guid>
      <description>&lt;p&gt;在之前的&lt;a href=&#34;http://chengjun.github.io/cn/2014/07/chinese-university-friendship-network/&#34; target=&#34;_blank&#34;&gt;一个博客&lt;/a&gt;中，我介绍了使用R进行社区划分并可视化的方法。这里使用相同的数据，介绍如何使用d3network实现网络可视化的方法。&lt;/p&gt;

&lt;p&gt;首先，安装d3network&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;devtools::install_github(&amp;quot;d3Network&amp;quot;, &amp;quot;christophergandrud&amp;quot;)
require(d3Network)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后可以使用简单的可视化方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;d3SimpleNetwork(data[,1:2],
                file = &amp;quot;chinese_university100.html&amp;quot;,
                width = 1024,
                height = 763,
                fontsize = 12)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我想要展现社区划分的结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#链接数据
links = data
names(links) = c(&amp;quot;source&amp;quot;, &amp;quot;target&amp;quot;, &amp;quot;value&amp;quot;)

#节点列表
fc = fastgreedy.community(g); sizes(fc)
mfc = membership(fc)
nodes = data.frame(name = names(mfc), group = mfc)

#对应链接数据和节点数据
ids = 0:(nrow(nodes)-1) # notice: start with zero!
links[,1] = ids[match(links[,1], nodes$name )]
links[,2] = ids[match(links[,2], nodes$name )]
links = links[with(links, order(source)), ] # sort by source

#处理边的权重大小
links$value = log(links$value)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后就可以使实现可视化结果啦：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;d3ForceNetwork(Links = links, Nodes = nodes,
               Source = &amp;quot;source&amp;quot;, Target = &amp;quot;target&amp;quot;,
               Value = &amp;quot;value&amp;quot;,
               NodeID = &amp;quot;name&amp;quot;,
               Group = &amp;quot;group&amp;quot;,
               file = &amp;quot;chinese_university_groups100.html&amp;quot;,
               width = 1550, height = 800,iframe = TRUE,
               opacity = 0.9, zoom = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe src=&#39;http://chengjun.github.io/vis/chinese_university_groups100.html&#39; scrolling=&#34;no&#34; width=&#34;800&#34; height = &#34;800&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;但是对于中文要麻烦一些，需要手工修改html里的encoding设置，包括meta部分和script部分两个地方：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;meta charset=&amp;quot;gbk&amp;quot;&amp;gt;
&amp;lt;script charset=&amp;quot;gbk&amp;quot; src=http://d3js.org/d3.v3.min.js&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除此之外，我还尝试了下&lt;a href=&#34;http://chengjun.github.io/vis/chinese_university_groups200more.html&#34; target=&#34;_blank&#34;&gt;两百所学校的情况：点这里。&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NetworkX初步：创建网络、提取属性和绘图</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-08-14-networkx-intro/</link>
      <pubDate>Thu, 14 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-08-14-networkx-intro/</guid>
      <description>&lt;p&gt;NetworkX是使用python分析网络数据的重要武器。它的使用非常简单。&lt;/p&gt;

&lt;p&gt;首先，创建网络对象：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import matplotlib.pyplot as plt
import networkx as nx

G=nx.DiGraph()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后，添加链接：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;G.add_edge(&#39;source&#39;,1,weight=80)
G.add_edge(1,2,weight=50)
G.add_edge(1,3,weight=30)
G.add_edge(3,2,weight=10)
G.add_edge(2,4,weight=20)
G.add_edge(2,5,weight=30)
G.add_edge(4,5,weight=10)
G.add_edge(5,3,weight=5)
G.add_edge(2,&#39;sink&#39;,weight=10)
G.add_edge(4,&#39;sink&#39;,weight=10)
G.add_edge(3,&#39;sink&#39;,weight=25)
G.add_edge(5,&#39;sink&#39;,weight=35)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以很容易提取边的权重:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;edges,colors = zip(*nx.get_edge_attributes(G,&#39;weight&#39;).items())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;计算加权过的出度：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;d = G.out_degree(weight = &#39;weight&#39;) #计算节点的中心度
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;选择一个常用的可视化方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pos=nx.spring_layout(G) #设置网络的布局
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;绘制网络:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nx.draw(G, pos, node_color = &#39;orange&#39;, with_labels = True,
        nodelist = d.keys(), node_size = [v*5 for v in d.values()], 
        edgelist = edges, edge_color = colors, width = 5, edge_cmap=plt.cm.Blues)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://chengjun.qiniudn.com/demo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;计算流距离：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&#39;&#39;&#39;
# get flow distance
&#39;&#39;&#39;
def toSink(G, i):
        try:
            di = G[i][&#39;sink&#39;].values()[0]
        except:
            di = 0 
        return di

def flowDistanceDT(G): #input a balanced nx graph
    R = G.reverse()
    mapping = {&#39;source&#39;:&#39;sink&#39;,&#39;sink&#39;:&#39;source&#39;} 
    H = nx.relabel_nodes(R,mapping)
    #---------initialize flow distance dict------
    L = dict((i,1) for i in G.nodes())  #FlowDistance
    #---------prepare weighted out-degree dict------
    D = {i: toSink(G, i) for i in G.nodes()} #Di
    T = G.out_degree(weight=&#39;weight&#39;)        #Ti
    #---------iterate until converge------------
    ls = np.array(L.values())
    delta = len(L)*0.01 + 1
    while delta &amp;gt; len(L)*0.01:
        for i in L:
            l=1
            for m,n in H.edges(i):
                l+=L[n]*H[m][n].values()[0]/float(T[m])
            L[i]=l
        delta = sum(np.abs(np.array(L.values()) - ls))
        ls = np.array(L.values())
    #---------clean the result-------
    del L[&#39;sink&#39;]
    for i in L:
        L[i]-=1
    L[&#39;sink&#39;] = L.pop(&#39;source&#39;)
    T[&#39;sink&#39;] = T.pop(&#39;source&#39;)
    D[&#39;sink&#39;] = D.pop(&#39;source&#39;)
    return L.values(), D.values(), T.values()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>中国高校间的友谊网络：大学排名、地理位置和演化规律</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-07-21-chinese-university-friendship-network/</link>
      <pubDate>Mon, 21 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-07-21-chinese-university-friendship-network/</guid>
      <description>&lt;p&gt;许小可老师和我决定使用可视化的方法分析一下中国高校之间的友谊关系网络。我们是想通过这个图从一个侧面说明各个大学在社交网络上的影响力和关系：所以节点大小表示每个大学在该网络中的友谊关系数量，连边宽度表示节点之间的连接关系，节点颜色的不同可以表示节点的影响力大小（介度中心性指标）。&lt;/p&gt;

&lt;p&gt;###数据清洗
现有数据有学校信息。我可以通过构建字典的方式来将user_id和学校信息（以最新的学校信息为主）剥离出来。使用这个字典可以计算学校人数的分布并挑选前一百的学校。然后根据user_id来match社交网络数据和学校数据，构建：university1&amp;mdash;university2&amp;mdash;date的数据形式。如果该行数据中的学校都在top100的名单中，则保留，否则不保留，这样可以构建所需要的学校和学校的随时间变化的网络，并采用考虑连边权重的贪婪算法来划分网络社团。&lt;/p&gt;

&lt;p&gt;###数据分析&lt;/p&gt;

&lt;p&gt;数据清洗之后，使用R软件进行数据分析，使用igraph包进行数据的可视化。代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(igraph)
setwd(&amp;quot;F:/xiaonei/&amp;quot;)

################
# all data
################
data = read.table(&amp;quot;./friends_university_top100_by_all.txt&amp;quot;, header = FALSE,
                 sep = &#39;\t&#39;, stringsAsFactors = FALSE)

data = data[which(data[,3] &amp;gt;= mean(data[,3])*1.2), ]
data = data[which(data[,1] != data[,2]),]
g =graph.data.frame(data[,1:2],directed=FALSE )
E(g)$weight = data[,3]
E(g)$color = &amp;quot;lightgrey&amp;quot;
# layout
set.seed(34)   ## to make this reproducable
l=layout.fruchterman.reingold(g)
# size
nodeSize = graph.strength(g)
V(g)$size = (nodeSize - min(nodeSize))/(max(nodeSize) - min(nodeSize))*20
centrality = betweenness(g)
# colors
colors = heat.colors(37)
position = rank(-centrality, ties.method = &amp;quot;first&amp;quot;)
V(g)$color = colors[position]
# width
E(g)$width = (log(E(g)$weight)- 8)*1.5
# label
nodeLabel = V(g)$name
V(g)$label.cex = log(centrality+1)/20 + 0.5
V(g)$label.color = &amp;quot;black&amp;quot;
# community detection
fc = fastgreedy.community(g); sizes(fc)
mfc = membership(fc)
# plot
drawFigure = function(g){
  plot(g, vertex.label= nodeLabel,  
       edge.curved = FALSE, vertex.frame.color=&amp;quot;#FFFFFF&amp;quot;,
       layout=l,mark.groups = by(seq_along(mfc), mfc, invisible) )
}

drawFigure(g)

# save png
png(&amp;quot;./all_color.png&amp;quot;,
    width=10, height=10,
    units=&amp;quot;in&amp;quot;, res=700)
drawFigure(g)
dev.off()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://chengjun.qiniudn.com/all_color.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;数据的可视化表明：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;学校间的友谊关系的建立取决于学校的排名 （排名越靠前的学校的网络中心性较高）&lt;/li&gt;
&lt;li&gt;同一个省的学校之间存在更多的友谊关系 （存在地理上的proximity）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;还可以根据月份来可视化，看一下2006年一月的情况吧：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://chengjun.qiniudn.com/month_color_%201.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;使用R生成24个月的图片，使用&lt;a href=&#34;http://makeagif.com/&#34; target=&#34;_blank&#34;&gt;makeagif&lt;/a&gt;生成GIF动态图片：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://cdn.makeagif.com/media/8-07-2014/iuOvDr.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;显然：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;最早加入这个社交网络的是北京的几所著名高校；&lt;/li&gt;
&lt;li&gt;2006年4月才走出北京；&lt;/li&gt;
&lt;li&gt;随后友谊关系开始在全国扩张；&lt;/li&gt;
&lt;li&gt;扩张的过程围绕着那些著名高校为中心进行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文提供&lt;a href=&#34;http://chengjun.qiniudn.com/friends_university_top100_by_all.txt&#34; target=&#34;_blank&#34;&gt;汇总的数据&lt;/a&gt;下载，供感兴趣的同学玩。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>网络残缺度：共同好友间可否两步到达？</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-05-05-network-dispersion/</link>
      <pubDate>Mon, 05 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-05-05-network-dispersion/</guid>
      <description>

&lt;p&gt;网络是由节点和关系构成的，而对于关系的描述是社会网络的关键。我们已经知道对于节点的网络特性可以从中心度、近度、介度、特征度（eigenvalue centrality）等方式描述。那么对于关系呢？最简单的就是直接关系的强度了。&lt;/p&gt;

&lt;h2 id=&#34;关系强度-tie-strength&#34;&gt;关系强度（&lt;code&gt;tie strength&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;通常对于关系强度的测量是基于两个节点之间链接的权重来衡量的。并不是说关系的强度越高越好，也不是说越多的强关系就越好。例如，格兰诺维特的论文&lt;code&gt;The strength of weak ties&lt;/code&gt;强调了弱关系的重要性。&lt;/p&gt;

&lt;h2 id=&#34;共同好友-common-friends&#34;&gt;共同好友（&lt;code&gt;common friends&lt;/code&gt;）&lt;/h2&gt;

&lt;p&gt;但是以直接的链接强度度量一对关系的强度显然过于简单。它忽略的网络中的三角形（triads）：网络的局部传递性(transtivity)。关系的传递性是社会网络分析的一种重要观点。比如，朋友的朋友成为自己的朋友的可能性很高。这种关系的强度不只限于一模网络中。在传播学中有ABX模型，A和B是两个人，X是一种对象（信息、意见、创新等）。A和B是好朋友，A喜欢X，那么B喜欢X的可能性就提高。也就是爱朋友及朋友喜欢的东西，有点像爱屋及乌。&lt;/p&gt;

&lt;p&gt;怎么抓住网络的传递性？找两个节点(一对关系)的共同好友！找到共同好友就抓住了网络中的三角形。存在的三角形数量就表明了传递性的程度。这种思路其实对于做共引（co-citation)分析的学者来说并不陌生。如果一篇论文同时引用了两篇论文，那么这两篇论文就存在一定的相似性。因此，找共同好友类似于找共引关系。&lt;/p&gt;

&lt;h2 id=&#34;嵌入度-embededness&#34;&gt;嵌入度（&lt;code&gt;embededness&lt;/code&gt;）&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://farm6.staticflickr.com/5323/13926813860_7382ec2f52_o.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;共同好友数量是判断两个人亲密程度的一个重要变量。如果共同好友的数量足够多，表明这两个人彼此深度的融入了对方的社会关系当中。基于这种思路，我们可以计算嵌入型。对于i和j两个人, $$k&lt;em&gt;{i}$$、$$k&lt;/em&gt;{j}$$分别表示i和j的好友数量。$$n_{ij}$$表示其共同好友数量。那么，我们可以如下计算嵌入度：&lt;/p&gt;

&lt;p&gt;$$
Embededness&lt;em&gt;{ij} = \frac{n&lt;/em&gt;{ij}}{(k&lt;em&gt;{i} -1) + (k&lt;/em&gt;{j} -1) - n_{ij}}
$$&lt;/p&gt;

&lt;h2 id=&#34;残缺性-dispersion&#34;&gt;残缺性（&lt;code&gt;dispersion&lt;/code&gt;）&lt;/h2&gt;

&lt;p&gt;残缺度（&lt;code&gt;dispersion&lt;/code&gt;， 或译为分散度）是Lars Backstrom &amp;amp; Jon Kleinberg (2013) 为了识别Facebook中亲密关系而提出的度量。它同样是基于共同好友的，主要测量的是共同好友之间的链接缺失程度。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;‘dispersion’ — the extent to which two people’s mutual friends are not themselves well-connected. &lt;code&gt;Lars Backstrom &amp;amp; Jon Kleinberg (2013)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Lars Backstrom &amp;amp; Jon Kleinberg使用了脸书的数据发现，使用残缺度这个度量方式，可以非常准确识别诸如夫妻、男女朋友、恋爱关系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://farm8.staticflickr.com/7429/14090280746_d962b282c8_o.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如上图中，u和v两个人有a、b、c、d四个共同好友。残缺度主要考察在多大程度上，这些共同好友&lt;strong&gt;不能&lt;/strong&gt;在&lt;code&gt;两步之内到达彼此&lt;/code&gt;。如果两个共同好友之间不存在直接连接，且也不存在（除去u和v之外的）共同好友，那么残缺度就增加1。&lt;/p&gt;

&lt;p&gt;以C_{uv}来表示u和v的共同好友之间的链接，那么在上图中只有a、b之间和c、d之间存在链接。a-c, a-d, b-c, b-d四对节点之间既没有直接链接又没有共同好友（除去了u和v)。所以残缺度是4。&lt;/p&gt;

&lt;p&gt;再举一个例子，如果u和v的共同好友b-c之间存在直接的链接。那么残缺度会是多大？如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://farm3.staticflickr.com/2936/14133498133_ed0857e2a0_o.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;因为只有a-d之间没有办法在两步内到达彼此，所以残缺度是1。&lt;/p&gt;

&lt;p&gt;当然了这种定义残缺度的方法是基于节点间的距离的。例如以$$d_{s, t}$$表示共同好友中任意两个节点s和t之间的距离。在这个初始的定义中，两步内不能到达算是关系残缺。那么我们可以将其扩展为3步内不能到达算残缺，或者n步能不能到达算残缺。不过根据Lars Backstrom &amp;amp; Jon Kleinberg的实验，两步不能到达是一个较好的基准。&lt;/p&gt;

&lt;p&gt;如果浪漫关系的确可以由高残缺度刻画，那么说明兔子不吃窝边草在国外是存在的。太熟了下不去手的现象在国内也是存在的。记得一个笑话说：找男女朋友的时候都说找互补的，实际上找到的都是类似的！白富美总是跟高富帅在一起嘛。这应该是对的，人的收入、相貌、工作都是匹配的（match）,从这个角度上讲的确是相似的。但至少从网路结构的角度来说，男女关系依然是互补的！&lt;/p&gt;

&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;

&lt;p&gt;Lars Backstrom &amp;amp; Jon Kleinberg (2013) Romantic Partnerships and the &lt;code&gt;Dispersion&lt;/code&gt; of Social Ties: A Network Analysis of Relationship Status on Facebook.arXiv&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>空间分析初步：使用D3可视化</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-03-15-d3-map/</link>
      <pubDate>Sat, 15 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-03-15-d3-map/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://bgc-dml.wdfiles.com/local--files/d3/D3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图1 &lt;a href=&#34;http://d3js.org/&#34; target=&#34;_blank&#34;&gt;D3 examples&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;###1. 起源
斯坦福学校可视化团队Jeff Heer教授, 那时候的博士生Mike Bostock,那时候的硕士生 Vadim Ogievetsky在2009年创造了Protovis：一个从数据中生成 SVG 图的工具。2011年, Bostock和的老板Heer、师弟Ogievetsky开发了D3.js (&lt;a href=&#34;http://vis.stanford.edu/files/2011-D3-InfoVis.pdf&#34; target=&#34;_blank&#34;&gt;Bostock, Heer &amp;amp; Ogievetsky 2011&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://b.vimeocdn.com/ts/442/674/442674389_640.jpg&#34; alt=&#34;Mike Bostocks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图2 &lt;a href=&#34;http://vimeo.com/69448223&#34; target=&#34;_blank&#34;&gt;Eyeo 2013 - Mike Bostock&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;此后，Mike Bostocks致力于D3的继续开发和维护， Mike的网站&lt;a href=&#34;http://bost.ocks.org/&#34; target=&#34;_blank&#34;&gt;http://bost.ocks.org/&lt;/a&gt;和github（&lt;a href=&#34;https://github.com/mbostock/d3&#34; target=&#34;_blank&#34;&gt;https://github.com/mbostock/d3&lt;/a&gt;）成为发展D3力量的重要领地。仅仅三年，作为一个社区（community)，D3的发展已经蔚为大观。&lt;/p&gt;

&lt;p&gt;###2. D3是什么？
D3是数据驱动文件（Data-Driven Documents）的缩写。作为一个javascript的库，D3(或D3.js)建构于电子数据（digital data）之上，使用数据创造并控制在网络浏览器里运行的动态交互的图形。&lt;/p&gt;

&lt;p&gt;D3必须要嵌入到html网页中，它依赖矢量图像（Scalable Vector Graphics，SVG）、层叠式样式表（Cascading Style Sheets，CSS3)等html的工具来展示图形。&lt;/p&gt;

&lt;p&gt;JavaScript函数来选择（&lt;strong&gt;select&lt;/strong&gt;）元素，生成矢量图（SVG），赋予其样式（style），加入变化。 这种函数式的操作使得D3可以很容易的将大的数据（large dataset,而不是big data）从原始数据格式（json, csv， geoJSON, topoJOSON）转为矢量图对象，并且速度非常快。&lt;/p&gt;

&lt;p&gt;D3拥有自己的&lt;strong&gt;哲学&lt;/strong&gt;，其中很重要的一条是&lt;a href=&#34;http://bost.ocks.org/mike/join/&#34; target=&#34;_blank&#34;&gt;Thinking with Joins&lt;/a&gt;。比如，读者与D3制作的图形交互的时候，会激发数据请求（如选择某一个时间段的数据），新的数据进来（data enter），D3的元素（如svg）就会相应的更新（elements update）。数据与元素的互动是由D3编写的Javascript函数指导的，交互之后之后互动结束，读者就看到一个新的图形了。一个例子是使用D3制作的《悲惨世界》中人物的共现关系（&lt;a href=&#34;http://bost.ocks.org/mike/miserables/&#34; target=&#34;_blank&#34;&gt;Les Misérables Co-occurrence&lt;/a&gt;）。这样做的好处是使得动态的图形展示变得简单。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://pixelmonkey.org/pub/dataviz-elements/notes/_images/data_join.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;图3 Thinking with Joins&lt;/p&gt;

&lt;h3 id=&#34;3-学习d3&#34;&gt;3. 学习D3&lt;/h3&gt;

&lt;p&gt;学习使用D3可以从这个&lt;a href=&#34;https://github.com/mbostock/d3/wiki/Tutorials&#34; target=&#34;_blank&#34;&gt;Tutorials&lt;/a&gt;开始。&lt;/p&gt;

&lt;h3 id=&#34;4-使用d3绘制网络&#34;&gt;4. 使用D3绘制网络&lt;/h3&gt;

&lt;p&gt;因为网络的可视化相对简单，因而发展也比较成熟。R社区很快开发了R包d3network&lt;/p&gt;

&lt;h3 id=&#34;5-使用d3绘制地图&#34;&gt;5. 使用D3绘制地图&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://bl.ocks.org/tnightingale/4718717&#34; target=&#34;_blank&#34;&gt;Christchurch 2010 Timeline&lt;/a&gt;这个例子正是我想要的。&lt;/p&gt;

&lt;p&gt;一些其它的例子。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bost.ocks.org/mike/map/&#34; target=&#34;_blank&#34;&gt;Let’s Make a Map&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.d3noob.org/2013/03/a-simple-d3js-map-explained.html&#34; target=&#34;_blank&#34;&gt;A simple d3js map explained&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.meetup.com/NYC-Open-Data/events/137244272/&#34; target=&#34;_blank&#34;&gt;D3.js workshop II: make beautiful maps &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;embed src=&#34;http://www.xiami.com/widget/2901500_3570908/singlePlayer.swf&#34; type=&#34;application/x-shockwave-flash&#34; width=&#34;257&#34; height=&#34;33&#34; wmode=&#34;transparent&#34;&gt;&lt;/p&gt;

&lt;p&gt;###参考文献&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Bostock, Michael; Ogievetsky, Vadim; Heer, Jeffrey (October 2011), D3: Data-Driven Documents, IEEE Transactions on Visualization and Computer Graphics, IEEE Press&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>空间分析初步：空间点类型分析</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-03-12-first-step-spatial-analysis-with-r/</link>
      <pubDate>Wed, 12 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-03-12-first-step-spatial-analysis-with-r/</guid>
      <description>

&lt;h3 id=&#34;引言&#34;&gt;引言&lt;/h3&gt;

&lt;p&gt;空间分析（spatial analysis）对于扩散研究非常重要，它揭示了传播在空间维度上的分布。令人略感惊奇的是空间分析的研究者越来越多地使用R软件。其中一个原因是R包罗万象，而空间分析仍在发展且神情未定。在这个时候难以判定哪种方法最优。此时，策略当然是博观约取。R因其囊括众多统计方法而成为连接不同分析套路的首选；另外在R当中使用者可以继续开发新的数据分析包。可谓一举两得。　&lt;/p&gt;

&lt;h3 id=&#34;数据读入&#34;&gt;数据读入&lt;/h3&gt;

&lt;p&gt;我使用的是2013年米兰城12月份推特用户的地理信息数据。该数据来自&lt;a href=&#34;http://www.telecomitalia.com/tit/en/bigdatachallenge/contest/dataset.html&#34; target=&#34;_blank&#34;&gt;Big Data Challenge&lt;/a&gt; of Telecommunication。使用Python写很简单的script从其服务器api接口读取数据:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Download milano tweets data using python
# chengjun wang @ cmc
# 2014 Mar 11

import urllib2
import json

f = open(&#39;D:/chengjun/Milan/Social pulse/Milano_sample.csv&#39;, &#39;w&#39;)
for offset in range(0,269290/100 +1):
    print &amp;quot;working on offset: &amp;quot;, offset
    req_url = &#39;https://api.dandelion.eu/datagem/social-pulse-milano/data/v1/?$limit=100&amp;amp;$offset=&#39;+str(offset)+&#39;&amp;amp;$app_id=d...a&amp;amp;$app_key=2e...7c&#39;
    jstr = urllib2.urlopen(req_url).read() # json string
    &amp;quot;&amp;quot;&amp;quot; these are flickr-specific &amp;quot;&amp;quot;&amp;quot;
    jinfo = json.loads( jstr )
    for i in range(0, len(jinfo[&#39;items&#39;])):
        lan = jinfo[&#39;items&#39;][i][&#39;language&#39;]
        time = jinfo[&#39;items&#39;][i][&#39;created&#39;]
        geo = jinfo[&#39;items&#39;][i][&#39;geometry&#39;][&#39;coordinates&#39;]
        timestamp = jinfo[&#39;items&#39;][i][&#39;timestamp&#39;]
        municipality_name = jinfo[&#39;items&#39;][i][&#39;municipality&#39;][&#39;name&#39;]
        municipality_id = jinfo[&#39;items&#39;][i][&#39;municipality&#39;][&#39;acheneID&#39;]
        entities = jinfo[&#39;items&#39;][i][&#39;entities&#39;]
        user = jinfo[&#39;items&#39;][i][&#39;user&#39;]
        print &amp;gt;&amp;gt;f, &amp;quot;%s;%s;%s;%s;%s;%s;&#39;%s&#39;;%s&amp;quot; % (lan, time, geo, timestamp, municipality_name, municipality_id, entities, user)
f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先，读入点的时空分布数据。　&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# read data
library(maptools)
library(sp)
library(rgdal)

setwd(&amp;quot;D:/chengjun/Milan&amp;quot;)
dat = read.csv(&amp;quot;./Social pulse/Milano_sample.csv&amp;quot;, header = FALSE, stringsAsFactors = FALSE, sep = &amp;quot;;&amp;quot;, quote = &amp;quot;&amp;quot;)
names(dat) = c(&amp;quot;lan&amp;quot;, &amp;quot;time&amp;quot;, &amp;quot;geo&amp;quot;, &amp;quot;timestamp&amp;quot;, &amp;quot;mname&amp;quot;, &amp;quot;mid&amp;quot;, &amp;quot;entities&amp;quot;, &amp;quot;user&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进行简单的清洗：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# clean data
dat = subset(dat, dat$time &amp;gt;= as.POSIXlt(&amp;quot;2013-12-01 00:00:00&amp;quot;)); dim(dat)
dat$time = do.call(rbind, strsplit(dat$time, split = &amp;quot;\\.&amp;quot;))[,1]
dat$time = gsub(&amp;quot;T&amp;quot;, &amp;quot; &amp;quot;, dat$time)
dat$time = as.POSIXlt(dat$time)
dat$geo = gsub(&amp;quot;[&amp;quot;, &amp;quot;&amp;quot;, dat$geo, fixed = T)
dat$geo = gsub(&amp;quot;]&amp;quot;, &amp;quot;&amp;quot;, dat$geo, fixed = T)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从openstreetmap下载米兰城的交通地理信息。使用rgdal这个R包读入数据：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# download shp data from
# http://metro.teczno.com/#milan
ost=readOGR(&amp;quot;./Milano Grid/milano-grid/milan.imposm-shapefiles/milan.osm-mainroads.shp&amp;quot;, layer = &amp;quot;milan.osm-mainroads&amp;quot;) #will load the shapefile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要把地理信息转为经纬度的数据表示形式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;spl = spTransform(ost, CRS(&amp;quot;+proj=longlat&amp;quot;)) # convert to longitude and latitude
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果要画出spl的话，速度有点慢, 因为绘制的点比较多。&lt;/p&gt;

&lt;p&gt;用了其中一个小数据(涵盖一天中的几个小时)，为了展现了每个小时的&lt;a href=&#34;http://chengjun.github.io/big_data_challenge/visualization.html&#34; target=&#34;_blank&#34;&gt;动态变化&lt;/a&gt;，使用CartoDB网站来制作了一个简单的可视化。顺便找了一遍各种javascript的库和其它包（googleVis, Echarts等），发现都不实用，所以还是用R吧。&lt;/p&gt;

&lt;p&gt;设置绘图的函数，来看一下数据的形式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# plot function
make_plot = function(){
  tz = as.POSIXlt(&amp;quot;2013-12-01 00:00:00&amp;quot;)
  end_time = as.POSIXlt(&amp;quot;2013-12-02 00:00:00&amp;quot;)
  while(tz &amp;lt;= end_time){
    print(tz)
    datd = subset(dat, dat$time &amp;gt; tz&amp;amp; dat$time &amp;lt;= tz + 3600)
    plot(spl, col = &amp;quot;pink&amp;quot;)
    title(tz)
    p = do.call(rbind, strsplit(datd$geo, split=&#39;,&#39;))
    p1 = as.numeric(p[,1])
    p2 = as.numeric(p[,2])
    points(p2~p1, pch = 1, col = &amp;quot;red&amp;quot;, cex = 0.1)
    tz = tz + 3600
  }
}

# save figures
png(file = &amp;quot;./linear%2d.png&amp;quot;,
    width=5, height=5,
    units=&amp;quot;in&amp;quot;, res=700)
make_plot()
dev.off()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;读者也可以直接使用animation这个R包来绘图。我在实验室的机器上安装ImageMagick有点问题，干脆存为图片了，再转为gif了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm3.staticflickr.com/2610/13103072964_078e5abcc6_o.gif&#34; alt=&#34;米兰城12月1日每个小时发推特的时空分布&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;图1&lt;/strong&gt; 米兰城一天当中的发推特的时空分布&lt;/p&gt;

&lt;p&gt;把12月31天的数据累积起来，我们可以得到米兰城2013年12月当中的发推特的空间分布。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# the overall geographical distribution
png(&amp;quot;./milano_social_pulse_December.png&amp;quot;,
    width=10, height=10,
    units=&amp;quot;in&amp;quot;, res=700)
plot(spl, col = &amp;quot;purple&amp;quot;)
p = do.call(rbind, strsplit(dat$geo, split=&#39;,&#39;))
p1 = as.numeric(p[,1])
p2 = as.numeric(p[,2])
points(p2~p1, pch = 1, col = &amp;quot;red&amp;quot;, cex = 0.01)
dev.off()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7349/13103304784_11e17eae38.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;图2&lt;/strong&gt; 米兰城2013年12月当中的发推特的空间分布&lt;/p&gt;

&lt;p&gt;这个图还是有点意思的：街道是城市人流的管道（Tube,伦敦好像把地铁直接称为tube）,人的移动等行为（包括社会媒体使用行为）则是穿行其间的流。推特聚集的地方与街道的轮廓高度契合。城市的中心推特的密度大（因为人流的密度大？）。所以可以检验下点的分布是否是随机的。&lt;/p&gt;

&lt;h3 id=&#34;空间点类型分析&#34;&gt;空间点类型分析&lt;/h3&gt;

&lt;p&gt;这里涉及到空间点类型分析（spatial point pattern analysis）。检验下点的分布是否是随机的最简单的方法是进行完全空间随机（complete spatial randomness， CSR）分析。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;G方程方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里说的最近邻居，英文当中却成为nearest event。把一个点的存在称之为事件也挺好玩。我们知道两个节点$$E_i$$和$$E_j$$的距离为:&lt;/p&gt;

&lt;p&gt;$$d(E_i, E_j) = \sqrt{(x_i - x_j)^2 + (y_i-y_j)^2}$$&lt;/p&gt;

&lt;p&gt;平均最近邻居距离可以表示为:&lt;/p&gt;

&lt;p&gt;$$\overline{d}&lt;em&gt;{min} = \frac{\sum&lt;/em&gt;{i}^{n}d_{min}(X_i)}{n}$$&lt;/p&gt;

&lt;p&gt;于是可以定义事件-事件最近邻居距离，即任意一个事件到它的最近事件之间的距离。任意一个事件$$E_i$$的事件-事件最近邻居距离：&lt;/p&gt;

&lt;p&gt;$$d_i = {min}&lt;em&gt;j {d&lt;/em&gt;{ij}, \forall j\neq i }$$&lt;/p&gt;

&lt;p&gt;对于一个距离d, 可定义G(d)为最近邻居距离的累计频数分布：&lt;/p&gt;

&lt;p&gt;$$ G(d) = \frac{# d_{min}E_i&amp;lt;d}{n} $$&lt;/p&gt;

&lt;p&gt;说以G方程方法测量的最近邻居距离小于d的事件的比率。当事件分布存在聚集的情况的时候，G在距离较小的时候就增长特别快；当事件分布均匀时，距离较小的时候G增长缓慢，当距离达到使得多数事件分隔的大小后，G开始快速增长。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;F方程方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;另外一个有用的测度是F方程。F方程测量了从空间中任意一个&lt;strong&gt;点&lt;/strong&gt;到与它最近的&lt;strong&gt;事件&lt;/strong&gt;之间的距离，因而它测量的是&lt;strong&gt;点-事件最近邻居距离&lt;/strong&gt;。据此，F方程也被称之为空虚空间距离。&lt;/p&gt;

&lt;p&gt;计算F方程或点-事件距离的时候要先随机的抽取一些空间中的点, 计算它的最短距离，然后统计其中满足最短距离小于d的比率。&lt;/p&gt;

&lt;p&gt;$$F(d) = \frac{#d_{min}(x_i&amp;lt;d)}{m}$$&lt;/p&gt;

&lt;p&gt;因为F方程是随机抽取空间中的点来统计，因而可以应对较大的数据规模。一个小的事件的聚集会导致G方程快速增长，但其实其它多数空间都是空的，所以F方程增长会较慢。当然了，对于规则分布的点，这种对比的结果则可能相反。&lt;/p&gt;

&lt;p&gt;使用G和F方程可以测量事件分布的实际情况，我们的零假设是事件分布是随机的，符合泊松分布:&lt;/p&gt;

&lt;p&gt;$$f(k, \lambda) = \frac{\lambda^k e^{-\lambda}}{k!}$$&lt;/p&gt;

&lt;p&gt;用$$\lambda$$表示事件的空间分布密度，在一个半径为d的平面$$\pi d^2$$里面理论上存在的事件数量是$$\lambda \pi d^2$$。&lt;/p&gt;

&lt;p&gt;此处推导略去（汗，我不会啊。），那么G和F的理论值按照泊松分布应该是：&lt;/p&gt;

&lt;p&gt;$$G = F = 1-e^{-\lambda \pi d^2}$$&lt;/p&gt;

&lt;p&gt;有了理论值，有了实际值，我们就可以对比二者之间的差距。进而推论空间事件的点分布是否是随机的了。&lt;/p&gt;

&lt;p&gt;这个推断的过程使用spatstat这个R包进行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;require(spatstat)
#the analysis of point patterns
geo = data.frame(dat$p1, dat$p2)
# Convert data to ppp format
geo_ppp = ppp(geo[,1], geo[,2],
               c(min(geo[,1]), max(geo[,1])),
               c(min(geo[,2]), max(geo[,2]))
               ) # slow
# G function method
g = Gest(geo_ppp)
plot(g)

# F function method
f = Fest(geo_ppp)
plot(f)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里可以使用envelope的方法，使用蒙特卡洛的方法，根据一些算法来随机生成n个（比如100个）数据，以保证分析的准确性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;g = envelope(geo_ppp, Gest, nsim = 100)
plot(g)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm4.staticflickr.com/3824/13124103465_64f43f59bc.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;f = envelope(geo_ppp, Fest, nsim = 100)
plot(f)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7362/13124385414_f32593880e.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;显然发推特的空间位置的分布并非随机的，具有较明显的聚集现象，所以G方程一开始就增长很快，而虚空空间函数F方程则增长缓慢。&lt;/p&gt;

&lt;h3 id=&#34;空间点过程分析&#34;&gt;空间点过程分析&lt;/h3&gt;

&lt;p&gt;这毕竟还是有点不够形象，有没有高大上的形象的方法？试试&lt;a href=&#34;http://cran.at.r-project.org/web/packages/spatstat/vignettes/getstart.pdf&#34; target=&#34;_blank&#34;&gt;kernel smoother of point density&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;plot(density.ppp(geo_ppp), main = &amp;quot;&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm3.staticflickr.com/2636/13124643824_4ee4b447d5_c.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意density.ppp返回的不是一个概率密度。它是对点密度的估计。密度是每个单位空间里随机点的期望。密度通常与空间位置有关。使用空间面积对密度函数积分，得到的是落入该区域的点的数量。&lt;/p&gt;

&lt;p&gt;于是乎，规律就更明显了：不仅仅是简单的点聚集，而且是箭靶形式的聚集，像北京环城路一样。越是中心，点就越密集。&lt;/p&gt;

&lt;p&gt;不过不要高兴太早，因为这个结果还是太粗糙。我们明明看到点的聚集情况并非如此完美的圆环。因为使用kernel平滑方法估计点的密度这种方法对于频宽（bandwidth）的大小特别敏感。有必要加以控制。另外，这里涉及到两种kernel的方法：四次多项式平滑和高斯平滑。这里要使用splancs这个R包。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;##############
&amp;quot;quartic and Gaussian kernels&amp;quot;
##############

library(splancs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;抱怨一下，因为以下用到的bw.diggle这个用来为kernel密度来选择经过交叉检验的频宽（Cross Validated Bandwidth Selection for Kernel Density）的命令，我不得不使用部分数据，因为它实在太消耗内存了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# subset a week-long small data
dat1 = subset(dat, dat$day &amp;gt;=as.Date(&amp;quot;2013-12-01&amp;quot;)&amp;amp;dat$day &amp;lt;=as.Date(&amp;quot;2013-12-07&amp;quot;))

geo = data.frame(dat1$p1, dat1$p2)
geo_ppp = ppp(geo[,1], geo[,2],
  c(min(geo[,1]), max(geo[,1])),
  c(min(geo[,2]), max(geo[,2]))
) # slow

## Quartic kernel
mserwq&amp;lt;-mse2d(as.points(coordinates(geo)),
  as.points(list(x=c(0,1,1,0), y=c(0,0,1,1))), 100, range = .001) # flexible range
bwq&amp;lt;-mserwq$h[which.min(mserwq$mse)]
bwq

## Gaussian kernel
mserw&amp;lt;-bw.diggle(as(geo_ppp, &amp;quot;ppp&amp;quot;)) #   Reached total allocation of 32765Mb: see help(memory.size)
bw&amp;lt;-as.numeric(mserw)
bw

&amp;quot;plot the Mean Square Error-Bandwidth&amp;quot;
par(mfrow=c(1, 2))
plot(mserwq$h, mserwq$mse, xlab=&amp;quot;Bandwidth&amp;quot;, ylab=&amp;quot;MSE&amp;quot;, type=&amp;quot;l&amp;quot;, main=&amp;quot;Quartic kernel&amp;quot;)
i&amp;lt;-which.min(mserwq$mse)
points(mserwq$h[i], mserwq$mse[i], col = &amp;quot;red&amp;quot;)
plot(mserw, main=&amp;quot;Gaussian kernel&amp;quot;, xlab=&amp;quot;Bandwidth&amp;quot;, ylab=&amp;quot;MSE&amp;quot;)
points(attr(mserw, &amp;quot;h&amp;quot;)[attr(mserw, &amp;quot;iopt&amp;quot;)], bw, col = &amp;quot;red&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7310/13145953075_2b2ae6a1e1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;看，最优化的频宽选择并不太有用，不过频宽真得很小。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;geos = SpatialPointsDataFrame(geo, geo)
poly = as.points(list(x = c(0, 0, 1, 1), y = c(0, 1, 1, 0)))

sG &amp;lt;- Sobj_SpatialGrid(geos, maxDim=100)$SG
grd &amp;lt;- slot(sG, &amp;quot;grid&amp;quot;)
summary(grd)

# k0 &amp;lt;- spkernel2d(geos, poly, h0=bw, grd)
# k1 &amp;lt;- spkernel2d(geos, poly, h0=.05, grd)
# k2 &amp;lt;- spkernel2d(geos, poly, h0=.1, grd)
# k3 &amp;lt;- spkernel2d(geos, poly, h0=.15, grd)
# df &amp;lt;- data.frame(k0=k0, k1=k1, k2=k2, k3=k3)
# kernels &amp;lt;- SpatialGridDataFrame(grd, data=df)
# summary(kernels)
# 这里都是NA,四次多项式的结果并不好

##################################
cc &amp;lt;- coordinates(sG); head(cc)
xy&amp;lt;-list(x=cc[,1], y=cc[,2])
k0&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw, dimyx=c(100, 100), xy=xy)
k1&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw*200, dimyx=c(100, 100), xy=xy)
k2&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw*500, dimyx=c(100, 100), xy=xy)
k3&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw*600, dimyx=c(100, 100), xy=xy)
k4&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw*800, dimyx=c(100, 100), xy=xy)
k5&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw*1000, dimyx=c(100, 100), xy=xy)
k6&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw*1500, dimyx=c(100, 100), xy=xy)
k7&amp;lt;-density(as(geos, &amp;quot;ppp&amp;quot;), .5*bw*2000, dimyx=c(100, 100), xy=xy)
&amp;quot;plot the MSE-Bandwidth&amp;quot;
png(file = &amp;quot;./gaussian_kernel_density_first_week_in_december2.png&amp;quot;,
width=8, height=16,
units=&amp;quot;in&amp;quot;, res=700)

par(mfrow=c(4, 2), mar=rep(1, 4))
plot(k0)
plot(k1)
plot(k2)
plot(k3)
plot(k4)
plot(k5)
plot(k6)
plot(k7)

dev.off()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7408/13145698615_5559e6ba2c_o.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里列出几个比较小的频宽的核密度图：这与我们的观察比较一致。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# kernels$k7&amp;lt;-as(k7, &amp;quot;SpatialGridDataFrame&amp;quot;)$v
df &amp;lt;- data.frame(k0=k0, k1=k1, k2=k2, k3=k3, k4=k4, k5=k5， k6 = k6, k7 = k7)
kernels &amp;lt;- SpatialGridDataFrame(grd, data=df)
summary(kernels)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参考文献&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Lloyd，D.C.(2007) Local Models for Spatial Analysis. CRC press&lt;/p&gt;

&lt;p&gt;Baddeley, A. (2010) Analysing spatial point patterns in R. Workshop notes. CSIRO online technical publication. URL: www.csiro.au/resources/pf16h.html&lt;/p&gt;

&lt;p&gt;Diggle, P.J. (1985) A kernel method for smoothing point process data. Applied Statistics (Journal of the Royal Statistical Society, Series C) 34 (1985) 138–147.&lt;/p&gt;

&lt;p&gt;Diggle, P.J. (2003) Statistical analysis of spatial point patterns, Second edition. Arnold.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>使用R模拟网络扩散</title>
      <link>https://chengjun.github.io/zh/post/cn/2014-02-28-simulate-network-diffusion-with-r/</link>
      <pubDate>Fri, 28 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjun.github.io/zh/post/cn/2014-02-28-simulate-network-diffusion-with-r/</guid>
      <description>&lt;p&gt;与普通的扩散研究不同，网络扩散开始考虑网络结构对于扩散过程的影响。&lt;/p&gt;

&lt;p&gt;这里介绍一个使用R模拟网络扩散的例子。基本的算法非常简单：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;生成一个网络:g(V, E)。&lt;/li&gt;
&lt;li&gt;随机选择一个或几个节点作为种子（seeds）。&lt;/li&gt;
&lt;li&gt;每个感染者以概率p（可视作该节点的传染能力,通常表示为$$\beta$$）影响与其相连的节点。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其实这是一个最简单的SI模型在网络中的实现。S表示可感染（susceptible）, I表示被感染（infected）。SI模型描述了个体的状态从S到I之间的转变。因为形式简单，SI模型是可以求出其解析解的。考虑一个封闭的群体，没有出生、死亡和迁移。并假设个体是均匀混合的（homogeneous mixing),也就是要求个体的地理分布均匀，且被感染的概率也相同(T. G. Lewis, 2011)。那么β表示传染率（transmission rate)。SI模型可以表达为：&lt;/p&gt;

&lt;p&gt;$$\frac{dS}{dt}=-\beta SI$$&lt;/p&gt;

&lt;p&gt;$$\frac{dI}{dt}=\beta SI$$&lt;/p&gt;

&lt;p&gt;且满足 I + S = 1，那么以上方程$$\frac{dI}{dt}=\beta SI$$可以表达为：&lt;/p&gt;

&lt;p&gt;$$\frac{dI}{dt}=\beta I(1-I)$$&lt;/p&gt;

&lt;p&gt;解这个微分方程，我们可以得到累计增长曲线的表达式。有趣的是，这是一个logistic增长，具有明显的S型曲线（S-shaped curve）特征。该模型在初期跨越临界点之后增长较快，后期则变得缓慢。 因而可以用来描述和拟合创新扩散过程（diffusion of innovations）。&lt;/p&gt;

&lt;p&gt;当然，对疾病传播而言，SI模型是非常初级的（naive），主要因为受感染的个体以一定的概率恢复健康，或者继续进入可以被感染状态(S，据此扩展为SIS模型)或者转为免疫状态（R,据此扩展为SIR模型）。 免疫表示为R，用$$\gamma$$代表免疫概率（removal or recovery rate)。对于信息扩散而言，这种考虑暂时是不需要的。&lt;/p&gt;

&lt;p&gt;第一步，生成网络。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;require(igraph)
# generate a social graph
size = 50

# 规则网
g = graph.tree(size, children = 2); plot(g)
g = graph.star(size); plot(g)
g = graph.full(size); plot(g)
g = graph.ring(size); plot(g)
g = connect.neighborhood(graph.ring(size), 2); plot(g) # 最近邻耦合网络

# 随机网络
g = erdos.renyi.game(size, 0.1)

# 小世界网络
g = rewire.edges(erdos.renyi.game(size, 0.1), prob = 0.8 )
# 无标度网络
g = barabasi.game(size) ; plot(g)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二步，随机选取一个或n个种子。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#  initiate the diffusers
seeds_num = 1
set.seed(2014); diffusers = sample(V(g),seeds_num) ; diffusers
infected =list()
infected[[1]]= diffusers
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第三步，在这个简单的例子中，每个节点的传染能力是0.5，即与其相连的节点以0.5的概率被其感染。在R中的实现是通过抛硬币的方式来实现的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# for example, set percolation probability = 0.5
coins = c(0,1)
n = length(coins)
sample(coins, 1, replace=TRUE, prob=rep(1/n, n))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;显然，这很容易扩展到更一般的情况，比如节点的平均感染能力是0.128，那么可以这么写：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;p = 0.128
coins = c(rep(1, p*1000), rep(0,(1-p)*1000))
n = length(coins)
sample(coins, 1, replace=TRUE, prob=rep(1/n, n))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然最重要的一步是要能按照“时间”更新网络节点被感染的信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# function for updating the diffusers
update_diffusers = function(diffusers){
  nearest_neighbors = neighborhood(g, 1, diffusers)
  nearest_neighbors = data.frame(table(unlist(nearest_neighbors)))
  nearest_neighbors = subset(nearest_neighbors, !(nearest_neighbors[,1]%in%diffusers))
  # toss the coins
  toss = function(freq) {
    tossing = NULL
    for (i in 1:freq ) tossing[i] = sample(coins, 1, replace=TRUE, prob=rep(1/n, times=n))
    tossing = sum(tossing)
    return (tossing)
  }
  keep = unlist(lapply(nearest_neighbors[,2], toss))
  new_infected = as.numeric(as.character(nearest_neighbors[,1][keep &amp;gt;= 1]))
  diffusers = unique(c(diffusers, new_infected))
  return(diffusers)
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;完成了以上三步。准备好了吗，现在开始开启扩散过程！&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## Start the contagion!
i = 1
while(length(infected[[i]]) &amp;lt; size){
  infected[[i+1]] = sort(update_diffusers(infected[[i]]))
  cat(length(infected[[i+1]]), &amp;quot;\n&amp;quot;)
  i = i + 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先看看S曲线吧：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# &amp;quot;growth_curve&amp;quot;
num_cum = unlist(lapply(1:i, function(x) length(infected［x］) ))
p_cum = num_cum/max(num_cum)
time = 1:i

png(file = &amp;quot;./temporal_growth_curve.png&amp;quot;,
    width=5, height=5,
    units=&amp;quot;in&amp;quot;, res=300)
plot(p_cum~time, type = &amp;quot;b&amp;quot;)
dev.off()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7299/12845959103_e19cd9cd99_n.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;为了可视化这个扩散的过程，我们用红色来标记被感染者。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# generate a palette
E(g)$color = &amp;quot;blueviolet&amp;quot;
V(g)$color = &amp;quot;white&amp;quot;
set.seed(2014); layout.old = layout.fruchterman.reingold(g)
V(g)$color[V(g)%in%diffusers] = &amp;quot;red&amp;quot;
plot(g, layout =layout.old)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用谢益辉开发的animation的R包可视化。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(animation)

saveGIF({
  ani.options(interval = 0.5, convert = shQuote(&amp;quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe&amp;quot;))
  # start the plot
  m = 1
  while(m &amp;lt;= length(infected)){
    V(g)$color = &amp;quot;white&amp;quot;
    V(g)$color[V(g)%in%infected[[m]]] = &amp;quot;red&amp;quot;
    plot(g, layout =layout.old)
    m = m + 1}
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm4.staticflickr.com/3806/12826172695_368a6f50a2_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm3.staticflickr.com/2848/12826237753_d8c97b1019_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm4.staticflickr.com/3729/12826584654_c84452f397_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm3.staticflickr.com/2851/12826173505_34649f488d_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7391/12826173255_574e471023_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm4.staticflickr.com/3675/12826584484_7c6f35380c_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://farm8.staticflickr.com/7432/12826173045_ef3548ec04_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如同在Netlogo里一样，我们可以把网络扩散与增长曲线同时展示出来：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;saveGIF({
  ani.options(interval = 0.5, convert = shQuote(&amp;quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe&amp;quot;))
  # start the plot
  m = 1
  while(m &amp;lt;= length(infected)){
    # start the plot
    layout(matrix(c(1, 2, 1, 3), 2,2, byrow = TRUE), widths=c(3,1), heights=c(1, 1))
    V(g)$color = &amp;quot;white&amp;quot;
    V(g)$color[V(g)%in%infected[[m]]] = &amp;quot;red&amp;quot;
    num_cum = unlist(lapply(1:m, function(x) length(infected[[x]]) ))
    p_cum = num_cum/size
    p = diff(c(0, p_cum))
    time = 1:m
    plot(g, layout =layout.old, edge.arrow.size=0.2)
    title(paste(&amp;quot;Scale-free Network \n Day&amp;quot;, m))
    plot(p_cum~time, type = &amp;quot;b&amp;quot;, ylab = &amp;quot;CDF&amp;quot;, xlab = &amp;quot;Time&amp;quot;,
         xlim = c(0,i), ylim =c(0,1))
    plot(p~time, type = &amp;quot;h&amp;quot;, ylab = &amp;quot;PDF&amp;quot;, xlab = &amp;quot;Time&amp;quot;,
         xlim = c(0,i), ylim =c(0,1), frame.plot = FALSE)
    m = m + 1}
}, ani.width = 800, ani.height = 500)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://farm4.staticflickr.com/3672/12848749413_7f9da8b8c7_o.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
