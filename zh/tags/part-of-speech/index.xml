<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Part of Speech on Academic</title>
    <link>https://chengjunwang.com/zh/tags/part-of-speech/</link>
    <description>Recent content in Part of Speech on Academic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>&amp;copy; 2016 Cheng-Jun Wang</copyright>
    <lastBuildDate>Sat, 07 Sep 2013 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://chengjunwang.com/zh/tags/part-of-speech/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>文本挖掘基础：使用openNLP进行词性标注</title>
      <link>https://chengjunwang.com/zh/post/cn/2013-09-07-part-of-speech-analysis-with-opennlp/</link>
      <pubDate>Sat, 07 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/zh/post/cn/2013-09-07-part-of-speech-analysis-with-opennlp/</guid>
      <description>使用R软件进行自然语言处理（文本挖掘）是比较方便的。其中一个比较基础的分析是采用part-of-speech tagging的思路进行词性标注。在本文中，我将简单地介绍使用R软件及其子包openNLP进行词性标注。这里的测试语料依然是英文，采用的算法主要是最大熵的方法。
openNLP的发展开始回归到底层的基本功能，之前搭建起来的比较方便实用的函数被取消了，比如tagPOS命令消失了。所以，需要自己来重新写这个方程。这也不太难，根据R文档对Maxent_POS_Tag_Annotator的介绍中的例子重新组合一下，就可以得到。
动词和名词的使用在文本挖掘中异常重要，单纯的名词语料可以用于进一步的文本挖掘，如我要做的是采用它们继续做主题挖掘（topic modeling）。
第一步，当然是重组这个tagPOS命令。
library(openNLP) library(tm) require(NLP) # Compose the tagPOS function tagPOS &amp;lt;- function(text.var, pos_tag_annotator, ...) { s &amp;lt;- as.String(text.var) ## Set up the POS annotator if missing (for parallel) PTA &amp;lt;- Maxent_POS_Tag_Annotator() ## Need sentence and word token annotations. word_token_annotator &amp;lt;- Maxent_Word_Token_Annotator() a2 &amp;lt;- Annotation(1L, &amp;quot;sentence&amp;quot;, 1L, nchar(s)) a2 &amp;lt;- annotate(s, word_token_annotator, a2) a3 &amp;lt;- annotate(s, PTA, a2) ## Determine the distribution of POS tags for word tokens.</description>
    </item>
    
  </channel>
</rss>