<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Network on Academic</title>
    <link>https://chengjunwang.com/zh/categories/network/</link>
    <description>Recent content in Network on Academic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>&amp;copy; 2016 Cheng-Jun Wang</copyright>
    <lastBuildDate>Thu, 14 Aug 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://chengjunwang.com/zh/categories/network/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>NetworkX初步：创建网络、提取属性和绘图</title>
      <link>https://chengjunwang.com/zh/post/cn/2014-08-14-networkx-intro/</link>
      <pubDate>Thu, 14 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/zh/post/cn/2014-08-14-networkx-intro/</guid>
      <description>NetworkX是使用python分析网络数据的重要武器。它的使用非常简单。
首先，创建网络对象：
import matplotlib.pyplot as plt import networkx as nx G=nx.DiGraph()  然后，添加链接：
G.add_edge(&#39;source&#39;,1,weight=80) G.add_edge(1,2,weight=50) G.add_edge(1,3,weight=30) G.add_edge(3,2,weight=10) G.add_edge(2,4,weight=20) G.add_edge(2,5,weight=30) G.add_edge(4,5,weight=10) G.add_edge(5,3,weight=5) G.add_edge(2,&#39;sink&#39;,weight=10) G.add_edge(4,&#39;sink&#39;,weight=10) G.add_edge(3,&#39;sink&#39;,weight=25) G.add_edge(5,&#39;sink&#39;,weight=35)  可以很容易提取边的权重:
edges,colors = zip(*nx.get_edge_attributes(G,&#39;weight&#39;).items())  计算加权过的出度：
d = G.out_degree(weight = &#39;weight&#39;) #计算节点的中心度  选择一个常用的可视化方法：
pos=nx.spring_layout(G) #设置网络的布局  绘制网络:
nx.draw(G, pos, node_color = &#39;orange&#39;, with_labels = True, nodelist = d.keys(), node_size = [v*5 for v in d.values()], edgelist = edges, edge_color = colors, width = 5, edge_cmap=plt.</description>
    </item>
    
    <item>
      <title>使用R模拟网络扩散</title>
      <link>https://chengjunwang.com/zh/post/cn/2014-02-28-simulate-network-diffusion-with-r/</link>
      <pubDate>Fri, 28 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/zh/post/cn/2014-02-28-simulate-network-diffusion-with-r/</guid>
      <description>与普通的扩散研究不同，网络扩散开始考虑网络结构对于扩散过程的影响。
这里介绍一个使用R模拟网络扩散的例子。基本的算法非常简单：
 生成一个网络:g(V, E)。 随机选择一个或几个节点作为种子（seeds）。 每个感染者以概率p（可视作该节点的传染能力,通常表示为$$\beta$$）影响与其相连的节点。  其实这是一个最简单的SI模型在网络中的实现。S表示可感染（susceptible）, I表示被感染（infected）。SI模型描述了个体的状态从S到I之间的转变。因为形式简单，SI模型是可以求出其解析解的。考虑一个封闭的群体，没有出生、死亡和迁移。并假设个体是均匀混合的（homogeneous mixing),也就是要求个体的地理分布均匀，且被感染的概率也相同(T. G. Lewis, 2011)。那么β表示传染率（transmission rate)。SI模型可以表达为：
$$\frac{dS}{dt}=-\beta SI$$
$$\frac{dI}{dt}=\beta SI$$
且满足 I + S = 1，那么以上方程$$\frac{dI}{dt}=\beta SI$$可以表达为：
$$\frac{dI}{dt}=\beta I(1-I)$$
解这个微分方程，我们可以得到累计增长曲线的表达式。有趣的是，这是一个logistic增长，具有明显的S型曲线（S-shaped curve）特征。该模型在初期跨越临界点之后增长较快，后期则变得缓慢。 因而可以用来描述和拟合创新扩散过程（diffusion of innovations）。
当然，对疾病传播而言，SI模型是非常初级的（naive），主要因为受感染的个体以一定的概率恢复健康，或者继续进入可以被感染状态(S，据此扩展为SIS模型)或者转为免疫状态（R,据此扩展为SIR模型）。 免疫表示为R，用$$\gamma$$代表免疫概率（removal or recovery rate)。对于信息扩散而言，这种考虑暂时是不需要的。
第一步，生成网络。
require(igraph) # generate a social graph size = 50 # 规则网 g = graph.tree(size, children = 2); plot(g) g = graph.star(size); plot(g) g = graph.full(size); plot(g) g = graph.ring(size); plot(g) g = connect.</description>
    </item>
    
    <item>
      <title>探寻社交网络中的关系: 统计网络模型初探</title>
      <link>https://chengjunwang.com/zh/post/cn/2013-08-09-sna-book-chapter/</link>
      <pubDate>Fri, 09 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/zh/post/cn/2013-08-09-sna-book-chapter/</guid>
      <description>王成军
香港城市大学媒体与传播系
在上一章当中，我们对于网络的基本知识进行了介绍，这些知识构建起了网络科学的基础，同时也孕育着巨大的潜能。社会科学追求理论的建构，但疏于思考理论层次的丰富性。以社会学为例，一度在宏大理论和抽象实证主义之间摇摆（参见米尔斯所著《社会学的想象力》）。大数据时代的到来，再一次使得少数人开始对理论的认识产生动摇，以为只要把握住数据就足够了。这与可计算性社会科学都是相互矛盾的。可计算性社会科学研究社会现实，紧紧抓住数据，但是绝不束缚于数据。
数据（data）、模式（pattern）、法则（law）、机制（mechanism）和隐含的原理(principle)构成了科学研究等级，如图11-1所示。科学理论的等级在这里又被粗略地划分为四个等级：模式、法则、机制和原理。网络科学以关系来度量物理世界和社会现实（social reality）。这些稳定的关系——表现为网络中的链接——构成了网络科学可计算性的基础。沿着网络中的链接出发，网络科学正在尝试突破社会现实混沌的迷宫，从社会现实的数据出发，发掘社会系统内部的模式、法则、机制、原理。
图 11-1. 科学研究的金字塔
网络科学所采用的方法非常多样，除了经典的统计方法之外，很多物理学的方法也被广泛的应用在网络研究当中。具体而言，网络科学有两个方法来源，一个是传统的社会网络分析，一个是近十几年里面迅猛发展起来的复杂网络研究。这两股研究的脉络构成了网络科学的两条主线。网络科学已经走出传统的社会网研究的藩篱。互联网浪潮的袭来推动传统网络研究与互联网科学（web science)的融合。一种以复杂网络（complex network）为代表的新型网络科学开始迅速成长(Barabasi, 2003)。例如，巴拉巴西等人采用动力系统的研究方法分析复杂网络的增长机制(Barabási &amp;amp; Albert, 1999)。但在本章当中，我将主要关注统计网络模型（statistical network models），并通过介绍处理社会化网络数据的例子来深化我们对于网络的认识。
本章的结构安排如下：一、通过介绍网络科学的异军突起来思考可计算性在不同学科的发展，以便于启发我们对于可计算社会科学的认识；二、我们介绍数字化媒体的发展，以及由此带来的大数据浪潮的挑战和机遇；三、我们开始介绍网络链接的属性，拓展对于网络的认识；四、简略介绍QAP检验；五、介绍指数随机图模型；六、结论和讨论。
 网络科学的异军突起：反思可计算性 数字化媒体和大数据 扩展对于网络的认识（二模网络与多模网络和时间序列网络） QAP检验 指数随机图模型（ERGM） 一条开放的道路  ###一、网络科学的异军突起：反思可计算性
事实上，作为一个后起之声，可计算性社会科学（computational social science）已经在各个分支学科和新的交叉性学科中如火如荼！关于计算社会科学的介绍可见Lazer等人(2009)发表在《科学》杂志上的一文。Lazer等人综述了可计算性社会科学的涌现和发展，尤其强调了网络科学研究在其中所扮演的角色和数字媒体所提供的机遇。网络科学和可计算性社会科学的兴起都使得我们开始更加严肃地思考可计算性在科学版图当中的作用。
对于可计算性的追求在自然科学一直是主流。物理学具有着最强的可计算性。物质世界的稳定性给了物理学发展提供了得天独厚的条件。物理学家采用各种稳定的手段测量物理世界的状态：长度、面积、体积、质量、速度、时间、能量。从牛顿力学到相对论，电磁学、再到量子力学，物理学展现了理论和数据的高度统一：我们可以精确地知道桥梁的重量、地球到月球的距离和卫星发射的速度。这种成就在一开始就激励着社会科学的发展。生物学诞生之初，研究者多少博物学家，忙着收集标本，区分生物所属的界、门、纲、目、科、属、种的类别。即使到了达尔文提出物种起源假说，生物学的发展依然备受局限。是什么使得生物学步入可计算化的路径，进而实现新的飞跃？一个可能的答案是“基因”。抓住这个计算性的本源，生物学开始迅速崛起。
社会科学则是另一番图景。试思考为什么经济学是社会科学中发展较好的？答案是货币。用货币度量经济行为使经济学具有了天然的可计算性；其次是心理学，不是量表，而是实验，使得心理学具有了“模糊的”比较能力。而其他传统的社会科学，如传播学，则处于摇摆当中缓慢发展。
值得注意的是三个迅速发展的学科：计算机科学、统计语言学、和我们正在谈论的网络科学。毋庸置疑，计算机科学是二十世纪发展最快的学科之一。其中一个重要的原因就在于计算机科学所对付的对象是离散的0和1。0和1通过二进制的运算构成了现代计算机的基础，也使得计算机科学从诞生之初，其“基因”当中就蕴含了强大的可计算性。在此基础上，计算机科学可以相对容易地与数学相结合研究信息和通信问题，并借助计算性思维（computational thinking）通过算法设计来自动化地解决问题(Wing, 2006)。统计语言学是传统语言学与计算机科学相互融合的结果。通过建立关于语言学的数学模型，并通过计算机来进行运算，统计语言学使得语言学在过去的三十年当中取得长足进步(吴军, 2012)，例如自然语言处理（natural language processing）已经广泛地应用在互联网产业当中和其他学科的研究当中。最近升起的新星则当属网络科学。网络科学对社会关系进行运算，借用统计物理的方法，很快发现复杂网络（例如，大规模的社会网络就是一种复杂网络）具有明显的小世界特征(Watts &amp;amp; Strogatz, 1998)和无标度特征(Barabási &amp;amp; Albert, 1999)。
概括以上内容，我们可以发现：可计算性植根于不同的学科当中。发掘可计算性对于不同的学科具有举足轻重的意义。基于可计算性的研究才有较高的信度和效度，才能得到更确实的（solid）发现，才能和数学工具和物理学工具更好的结合，才能更深刻地探寻社会模式背后的法则、机制、规律。
图 11-2. 学科历史与其可计算性的关系
###二、数字化媒体和大数据 互联网的发展使得人类社会进入了一个新的时代：数字媒体时代（the era of digital media）。这种变化的影响已经被诸多预言者和研究者所分析，也为这个时代的个体所体认与观察。人类的交往模式，商业行为，舆论空间等，都因互联网而改变。但本文由数字化痕迹开始讲起。
数字化媒体（digital media）的崛起正在深刻变革的社会科学的研究视野。因为数字化技术的发展（比如互联网）使得很多的人类行为变得可以观察，因而给我们更真实地认识世界提供了一个崭新的入口——数字化痕迹（digital traces）。比如，你在网络上购物的经历，你在社交媒体上的使用记录。这些数字化痕迹（又称数字化指纹（digital fingerprint），或数字化脚印（digital footprint）），使得研究者可以追逐这种痕迹，分析其行为背后隐藏的社会规律，进而提供了一个巨大的资源。这种资源的出现正在变革着不同学科的研究视角和研究疆域。比如，网络化的大规模数据的数字化痕迹（digital traces）第一次使得传播行为获得了计算性。而记录（document）、收集（collect）、分析（analyze）、可视化（visualize）这些传播行为就成为了计算传播学的主要工作。按照这个设想，社会科学必须走出传统的研究套路，获得在网络上保存、抓取、分析、可视化大规模电子化数据的能力，也需要支持这些工作的工具。毫无疑问，社会科学因此将和计算机科学开始交汇，至少需要程序员投入到这种大规模数据的挖掘工作中来。计算机科学家越来越将更多的注意力放在社交媒体的使用研究方面来。一系列的计算机会议以社交媒体研究作为重心。其它的学科分支也马上意识到互联网带来的机遇和挑战。这里要首先谈人类认知世界的一个重要方法——观察法。
观察法是社会研究和自然研究最古老的方法。在社会研究领域，这种方法因其复杂和难以操控，往往只是适用于研究初期。研究中后期往往使用调查和实验方法，但后面这两种方法的优点是根据研究者的视角进行操控（manipulate），但缺点也在这里。因为访谈或问卷或实验，往往会降低研究的效度。而数字化痕迹使得这种限制减少，使得研究者真正在研究活生生的人类行为，并且研究的规模非常巨大，且往往具有时间序列的信息。数字化痕迹使得非介入的观察（unobtrusive observation）成为可能，因而给研究者带来的巨大的机遇。机遇是数据的获取为检验和发展经典理论提供了土壤。但同时也伴随着挑战。这种挑战则首先主要来自这种数字痕迹的获取、分析和储存上。
当然第一关是数据的获取。资源虽然存在，却并不能为所有的人所使用。因为这里有一个天然的、历史原因造成的技术屏障——计算机技术。数字化痕迹的还有一些其它特点。比如规模巨大，难以分析，当然这涉及到数据的分析问题，不是本文的重点。另外一个方面，这些数字指纹往往是流数据，这意味着如果此刻不获取这些数据，过一段时间这些数据就很难或者没有可能获取了。甚至因为数据规模庞大，一些互联网公司也并不会储存所有的数据。这也为数据获取者提供了一种学习的急迫性。
其中最简单的是研究者的编程技术。传统的社会科学研究者和读者往往忽略计算机技术尤其是编程能力的培养。因而，在学科转型之初，第一步就是这种开始学习崭新的东西。这多多少少让新手感到畏惧。需要指出的是，这种畏惧是不必要的。因为技术的发展趋势是越来越人性化和具有可读性。这给编程语言的学习带来便利。社会科学研究者可以选取简单的编程语言（R、Python、Ruby）开始计算机编程的学习。一个问题是是否可以采用即成的数据抓取软件呢？我的理解是，就目前而言，打包好的数据抓取软件过于死板，且效率低下，并且多数价格不菲、不是开源的软件。因而不是首选。现在很多统计语言往往也可以从事数据抓取的工作，比如R社趣发展了twiiteR的包和Rweibo的包。虽然其接口并不完善，但研究者根据自我需求进行自由的开发。
社交网站为了自身的发展，往往选择向外界开放部分资源，以方便第三方发展基于该社交网站的产品，进而更好吸引使用者使用。比如新浪微博上有着纵多的应用，这些应用的数据接口就是由新浪微博所提供的。当然这种数据提供需要注册和认证，例如，对新浪微博而言可到应用开发页面注册 。因而，数据抓取的第一步，就是建立数据连接的工作，以获取社交网站开放数据流的许可。现在流行的方式是使用OAuth获取连接社会化媒体的API的使用权限。这种机制的好处是直接从网站数据库获取数据，因而数据结构化较好，不需要经过复杂繁琐的处理。且更好保护了使用者的隐私(Russell, 2011)。获取数据使用许可之后，其使用就非常方便灵活了。
在本章当中，我们使用李舰 (Li, 2013)编写的Rweibo来连接新浪微博的API接口，并获取我们所需要的信息。Rweibo是一个新浪微博针对R语言的软件开发工具包（Software Development Kit, SDK）。作为一个R的软件包，Rweibo可以在R软件当中自由安装和调用。</description>
    </item>
    
    <item>
      <title>QAP检验：计算两个网络的关联</title>
      <link>https://chengjunwang.com/zh/post/cn/2013-08-04-qap-test-of-network-analysis/</link>
      <pubDate>Sun, 04 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://chengjunwang.com/zh/post/cn/2013-08-04-qap-test-of-network-analysis/</guid>
      <description>QAP检验：两个网络之间的关联 通常一组个体具有多种类型的关系，例如友谊关系和经济往来关系。我们通常会对这两种网络关系在多大程度上相互关联感兴趣。当我们知道一组个体之间的两种关系网络，我们就可以计算这个两个关系网络之间的相关程度。在统计学当中，皮尔森相关系数是用来反映两个变量线性相关程度的统计量。与之类似，对于由一组个体所组成的两个网络，也可以计算其相应的相关皮尔逊相关系数。当然，还可以计算其他你感兴趣的统计量，如协相关系数。
我们使用sna这个R软件包来计算网络相关系数（并调用qaptest命令）。通过安装和使用statnet这个R软件包，就会自动加载sna等子软件包。另外，statnet当中还集成了其他的几个相关的R软件包，包括进行动态网络建模的tergm子软件包。
# R程序11-8：计算网络的皮尔逊相关系数 install.packages(&amp;quot;statnet&amp;quot;) library(statnet) # 首先随机生成3个由10个节点构成的有向网络 g=array(dim=c(3,10,10)) g[1,,] = rgraph(10) g[2,,] = rgraph(10,tprob=g[1,,]*0.8) # 设置g1和g2两个网络强相关 g[3,,] = 1; g[3,1,2] = 0 # g3接近于一个派系（clique） # 绘制这3个网络 par(mfrow=c(1,3)) for(i in 1:3) { gplot(g[i,,],usecurv=TRUE, mode = &amp;quot;fruchtermanreingold&amp;quot;, vertex.sides=3:8)} #计算网络的相关矩阵 gcor(g)  在通常使用皮尔逊相关系数的时候，可以用t统计量对总体相关系数为0的原假设进行检验。但在计算网络的相关系数（graph correlations）时，经典的零假设检验方法往往会带来偏差，因而并不适用。通常使用非参数检验的方法，比如QAP(Quadratic Assignment Procedure)检验。
矩阵的随机排列（Random matrix permutations）是QAP检验的关键部分，在子软件包sna中主要通过rmperm来进行。通过矩阵的随机排列，可以对网络中的节点编号（而不是链接！！）进行随机置换（relabelling）或重新“洗牌”（reshuffling），并得到一组（比如1000个）重连后的网络。因为只是置换节点，这种操作只是重新标记节点的编号（relabelling）。
# R程序11-9：矩阵的随机置换方法 j = rgraph(5) # 随机生成一个网络 j #看一下这个网络的矩阵形式 rmperm(j) #随机置换后的网络的矩阵形式  对这一组重构的网络可以计算其网络级别的参数（如两个网络的相关参数，协相关参数），并因此得到一个参数分布。QAP检验的零假设是实际观测到的网络参数（如）来自于这一个参数分布。也就是说，原假设认为这种观测到的相关关系是由随机因素带来的，因而这种网络相关并不显著。拒绝原假设，就从统计的角度证明了观测到的网络相关系数是显著的。
# R程序11-10：QAP检验 q.12 = qaptest(g, gcor, g1 = 1, g2 = 2) q.</description>
    </item>
    
  </channel>
</rss>