[{"authors":["admin"],"categories":null,"content":"王成军，传播学博士。现为南京大学新闻传播学院副教授，计算传播学实验中心主任，兼任香港城市大学互联网挖掘实验室研究员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》(2015)、合著《计算传播学导论》(2018)。他的研究成果发表于SSCI和SCI索引的期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology。2014年，王成军发起创建了计算传播网。更多信息见英文页面或他的简历。\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"zh","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://chengjunwang.com/zh/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/authors/admin/","section":"authors","summary":"王成军，传播学博士。现为南京大学新闻传播学院副教授，计算传播学实验中心主任，兼任香港城市大学互联网挖掘实验室研究员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》(2015)、合著《计算传播学导论》(2018)。他的研究成果发表于SSCI和SCI索引的期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology。2014年，王成军发起创建了计算传播网。更多信息见英文页面或他的简历。","tags":null,"title":"王成军","type":"authors"},{"authors":null,"categories":null,"content":" 王成军 王成军，传播学博士。现为南京大学新闻传播学院副教授，计算传播学实验中心主任，兼任香港城市大学互联网挖掘实验室研究员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》(2015)。他的研究成果发表于SSCI和SCI索引的期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology。2014年，王成军发起创建了计算传播网。更多信息见英文页面或他的简历。\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"c49faaf776ad96559909345880ea07f4","permalink":"https://chengjunwang.com/zh/zh/post/about/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/zh/post/about/","section":"zh","summary":"王成军 王成军，传播学博士。现为南京大学新闻传播学院副教授，计算传播学实验中心主任，兼任香港城市大学互联网挖掘实验室研究员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》(2015)。他的研究成果发表于SSCI和SCI索引的期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology。2014年，王成军发起创建了计算传播网。更多信息见英文页面或他的简历。","tags":null,"title":"","type":"zh"},{"authors":null,"categories":null,"content":" 王成军 王成军，传播学博士。现为南京大学新闻传播学院副教授，计算传播学实验中心主任，兼任香港城市大学互联网挖掘实验室研究员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》(2015)。他的研究成果发表于SSCI和SCI索引的期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology。2014年，王成军发起创建了计算传播网。更多信息见英文页面或他的简历。\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"ebd4356f24e4ae00deeac1d95b2289e6","permalink":"https://chengjunwang.com/zh/post/about/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/post/about/","section":"post","summary":"王成军 王成军，传播学博士。现为南京大学新闻传播学院副教授，计算传播学实验中心主任，兼任香港城市大学互联网挖掘实验室研究员。参与翻译《社会网络分析：方法与实践》(2013)、合著《社交网络上的计算传播学》(2015)。他的研究成果发表于SSCI和SCI索引的期刊，例如Scientific Reports、PloS ONE、Physica A、Cyberpsychology。2014年，王成军发起创建了计算传播网。更多信息见英文页面或他的简历。","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"75ee6a49d0a291250da0133bfaaaab33","permalink":"https://chengjunwang.com/zh/post/posts/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/post/posts/","section":"post","summary":"","tags":null,"title":"Recent Posts","type":"post"},{"authors":null,"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"a3081b1982a524f4c248e17175656369","permalink":"https://chengjunwang.com/zh/zh/post/posts/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/zh/post/posts/","section":"zh","summary":"","tags":null,"title":"Recent Posts","type":"zh"},{"authors":null,"categories":null,"content":" 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015-2018, 20万元，主持 中国博士后科学基金面上项目（第57批), 找回失落的参考群体:对“沉默的螺旋”进行多主体建模，2015-2018, 5万元，主持 国家自然科学基金（常规面上项目），61673070，互联网上的集体注意力流研究，2017-2020,￥655200, 参与  ","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"80126f3ca65f57c02696067f99846f6e","permalink":"https://chengjunwang.com/zh/post/projects/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/post/projects/","section":"post","summary":" 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015-2018, 20万元，主持 中国博士后科学基金面上项目（第57批), 找回失落的参考群体:对“沉默的螺旋”进行多主体建模，2015-2018, 5万元，主持 国家自然科学基金（常规面上项目），61673070，互联网上的集体注意力流研究，2017-2020,￥655200, 参与  ","tags":null,"title":"研究项目","type":"post"},{"authors":null,"categories":null,"content":" 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015-2018, 20万元，主持 中国博士后科学基金面上项目（第57批), 找回失落的参考群体:对“沉默的螺旋”进行多主体建模，2015-2018, 5万元，主持 国家自然科学基金（常规面上项目），61673070，互联网上的集体注意力流研究，2017-2020,￥655200, 参与  ","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"6f9c96d88133139941803832e42d1a9e","permalink":"https://chengjunwang.com/zh/zh/post/projects/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/zh/post/projects/","section":"zh","summary":" 国家社会科学基金青年项目, 15CXW017, 媒体融合背景下舆论形成与扩散的网络门槛研究，2015-2018, 20万元，主持 中国博士后科学基金面上项目（第57批), 找回失落的参考群体:对“沉默的螺旋”进行多主体建模，2015-2018, 5万元，主持 国家自然科学基金（常规面上项目），61673070，互联网上的集体注意力流研究，2017-2020,￥655200, 参与  ","tags":null,"title":"研究项目","type":"zh"},{"authors":null,"categories":null,"content":"  复旦大学《计算新闻传播学》课程  python代码、PPT见GitHub 。课程内容包括：计算传播学导论、大数据简介、数据科学的编程工具、数据抓取、数据清洗、统计分析、机器学习、文本挖掘、推荐系统、网络科学多个部分。  \n 南京大学研究生课程 《大数据挖掘与分析》\n 2018 春季 周\u0008二 第5-6节  南京大学本科生课程 《计算传播》\n 2018 春季 2017 春季  南京大学本科生课程 《数据新闻》\n 2017 秋季 周一 第3-4节 逸B-210 1-18周 2016 秋季 2015 秋季  南京大学人文艺术传播类《媒介案例研究》\n 《计算传播》案例部分 每周二7、8节（4-18周）逸B-104   学生  研究生(在读)：秦强、陈志聪 已毕业研究生：周纬(2017) 本科生（指导毕业论文）：  2017：沈越、曾维靓   ","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"08ef546a8a8ad210e4b71cacf21c8232","permalink":"https://chengjunwang.com/zh/zh/post/teaching/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/zh/post/teaching/","section":"zh","summary":"  复旦大学《计算新闻传播学》课程  python代码、PPT见GitHub 。课程内容包括：计算传播学导论、大数据简介、数据科学的编程工具、数据抓取、数据清洗、统计分析、机器学习、文本挖掘、推荐系统、网络科学多个部分。  \n 南京大学研究生课程 《大数据挖掘与分析》\n 2018 春季 周\u0008二 第5-6节  南京大学本科生课程 《计算传播》\n 2018 春季 2017 春季  南京大学本科生课程 《数据新闻》\n 2017 秋季 周一 第3-4节 逸B-210 1-18周 2016 秋季 2015 秋季  南京大学人文艺术传播类《媒介案例研究》\n 《计算传播》案例部分 每周二7、8节（4-18周）逸B-104   学生  研究生(在读)：秦强、陈志聪 已毕业研究生：周纬(2017) 本科生（指导毕业论文）：  2017：沈越、曾维靓   ","tags":null,"title":"教学","type":"zh"},{"authors":null,"categories":null,"content":"  复旦大学《计算新闻传播学》课程  python代码、PPT见GitHub 。课程内容包括：计算传播学导论、大数据简介、数据科学的编程工具、数据抓取、数据清洗、统计分析、机器学习、文本挖掘、推荐系统、网络科学多个部分。  \n 南京大学研究生课程 《大数据挖掘与分析》\n 2018 春季 周\u0008二 第5-6节  南京大学本科生课程 《计算传播》\n 2018 春季 2017 春季  南京大学本科生课程 《数据新闻》\n 2017 秋季 周一 第3-4节 逸B-210 1-18周 2016 秋季 2015 秋季  南京大学人文艺术传播类《媒介案例研究》\n 《计算传播》案例部分 每周二7、8节（4-18周）逸B-104   学生  研究生(在读)：秦强、陈志聪 已毕业研究生：周纬(2017) 本科生（指导毕业论文）：  2017：沈越、曾维靓   ","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"0882314c340265c6cd04ca3e23a06fba","permalink":"https://chengjunwang.com/zh/post/teaching/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/post/teaching/","section":"post","summary":"  复旦大学《计算新闻传播学》课程  python代码、PPT见GitHub 。课程内容包括：计算传播学导论、大数据简介、数据科学的编程工具、数据抓取、数据清洗、统计分析、机器学习、文本挖掘、推荐系统、网络科学多个部分。  \n 南京大学研究生课程 《大数据挖掘与分析》\n 2018 春季 周\u0008二 第5-6节  南京大学本科生课程 《计算传播》\n 2018 春季 2017 春季  南京大学本科生课程 《数据新闻》\n 2017 秋季 周一 第3-4节 逸B-210 1-18周 2016 秋季 2015 秋季  南京大学人文艺术传播类《媒介案例研究》\n 《计算传播》案例部分 每周二7、8节（4-18周）逸B-104   学生  研究生(在读)：秦强、陈志聪 已毕业研究生：周纬(2017) 本科生（指导毕业论文）：  2017：沈越、曾维靓   ","tags":null,"title":"教学","type":"post"},{"authors":null,"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"011093809ca57c2b33fe7b2fb4a90304","permalink":"https://chengjunwang.com/zh/post/contact/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/post/contact/","section":"post","summary":"","tags":null,"title":"联系","type":"post"},{"authors":null,"categories":null,"content":"","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461110400,"objectID":"1fabe0ee769015455aa6a0744a085ef5","permalink":"https://chengjunwang.com/zh/zh/post/contact/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/zh/zh/post/contact/","section":"zh","summary":"","tags":null,"title":"联系","type":"zh"},{"authors":null,"categories":null,"content":" Quotations  Before God we are all equally wise and equally foolish. Do not worry about your difficulties in Mathematics. I can assure you mine are still greater. \u0026ndash; Albert Einstein 🚀\nWe know that people often desire something but do not really want it. Don’t be afraid to really want what you desire. \u0026ndash; Slavoj Žižek speaks at Occupy Wall Street 🚀\n ","date":1507996800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1507996800,"objectID":"72beaff7b924ca92701cc59751754ea2","permalink":"https://chengjunwang.com/zh/zh/post/hero/","publishdate":"2017-10-15T00:00:00+08:00","relpermalink":"/zh/zh/post/hero/","section":"zh","summary":" Quotations  Before God we are all equally wise and equally foolish. Do not worry about your difficulties in Mathematics. I can assure you mine are still greater. \u0026ndash; Albert Einstein 🚀\nWe know that people often desire something but do not really want it. Don’t be afraid to really want what you desire. \u0026ndash; Slavoj Žižek speaks at Occupy Wall Street 🚀\n ","tags":null,"title":"","type":"zh"},{"authors":null,"categories":null,"content":" Quotations  Before God we are all equally wise and equally foolish. Do not worry about your difficulties in Mathematics. I can assure you mine are still greater. \u0026ndash; Albert Einstein 🚀\nWe know that people often desire something but do not really want it. Don’t be afraid to really want what you desire. \u0026ndash; Slavoj Žižek speaks at Occupy Wall Street 🚀\n ","date":1507996800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1507996800,"objectID":"14dfc94c1e3906abac606238d0f35603","permalink":"https://chengjunwang.com/zh/post/hero/","publishdate":"2017-10-15T00:00:00+08:00","relpermalink":"/zh/post/hero/","section":"post","summary":" Quotations  Before God we are all equally wise and equally foolish. Do not worry about your difficulties in Mathematics. I can assure you mine are still greater. \u0026ndash; Albert Einstein 🚀\nWe know that people often desire something but do not really want it. Don’t be afraid to really want what you desire. \u0026ndash; Slavoj Žižek speaks at Occupy Wall Street 🚀\n ","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":" 2019年来了，农历新年过去了，今天是情人节。米粒马上四岁，米果也快要满两岁了。再过两年，\u0008牛年一到，我也要36岁了。岁月太可怕了，总以为自己还有很多时间，却似乎一转眼就要40岁了。\n今天一早，我搭晓青公司的车去驾校，晓青去合肥出差。\n鲜花折纸 很漂亮的月季花折纸,简单易学,看了就会的手工DIY花朵\n我和米粒搜索了半天，这个方法最为简单。\n 但是\u0008，因为没有粉红色的纸，我们首先用水墨的颜料将白色便签纸染成粉红。 要严格按照上图的步骤来，前三步最关键。否则，容易把花朵🌺剪成两半！ 然后，按照图纸一番折腾，终于得到如下图的一朵粉红色的小花。  \u0008学开车 另外，晓青强行给我在手机app上预约了三天的驾驶科目三的课程。今天谷峰驾校第一天开课，我一早8点就找到了教练。结果，驾校开会从8：30到10点多。然后，就开始练习。\n科目三考试内容\nDay 1 2月14日\n 首先，上车  从车前方走过  练习打方向盘\n 向左打到底1.5圈   然后，练习启动和停车四步骤。\n 比如，启动的顺序是：  \u0008一踩脚刹 二挂前进挡D1 三打转向灯 四松手刹 （*注意：颠倒三、四步车会前溜，因为手刹挡不住动力系统*） 最后\u0008，松脚刹，踩油门前进。  停车与之相反：  一拉手刹 二停转向灯 三挂停车挡 四松脚刹   直行\n 目视前方30米处 在不影响驾驶的情况下，\u0008观察左、\u0008右后视镜 根据路的弯度，非常轻微转动方向盘  变线\n \u0008首先，打转向灯 其次，后视镜观察\u0008，确保可以转向 如果可以转向，三秒后轻打方向盘（非常小角度）转向 转向后，扶正方向盘  右转\n \u0008确保车子在右转向\u0008道 \u0008看到倒数第二个减速标志，轻踩刹车 看到倒数最后一个减速标志，刹车停住 左顾右盼：左右转头，观察人行横道 观察红绿灯，允许转向时才可以转 根据转向角度，打方向盘，随时调整 只有当\u0008车子方向正了之后，才完全回正方向盘  （左）掉头\n 减速 车头偏向中间\u0008花坛 当肩膀与路中间花坛平行时，继续前进3-4米 向左打死方向盘 脚放刹车 左顾右盼 \u0008\u0008掉头后，只有当\u0008车子方向正了之后，才完全回正方向盘   轻点刹车\n 手刹\n   手刹的专业称呼是辅助制动器，采用钢丝拉线连接到后制动蹄上，以对车子进行制动。手刹对于小型汽车来说，有的是在变速箱后，与传动轴连接的地方有一个制动盘，类似盘式制动器的（当然也有鼓式的），然后通过钢索，将拉力传动到那，从而实现驻车制动。拉动手刹后，它利用一个液压辅缸，推动车下边的液压总缸运动，然后带动气阀，（之所以这么设计，是为了驾驶室不听到那些空气的声音），然后气阀动作之后，制动传动轴。\n ","date":1550016000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1550016000,"objectID":"afeb8df51200275a08033259ab403092","permalink":"https://chengjunwang.com/zh/post/cn/2019-02-14-lovers-day/","publishdate":"2019-02-13T00:00:00Z","relpermalink":"/zh/post/cn/2019-02-14-lovers-day/","section":"post","summary":"2019年来了，农历新年过去了。米粒马上四岁，米果也快要满两岁了。再过两年，\u0008牛年一到，我也要36岁了。岁月太可怕了，总以为自己还有很多时间，却似乎一转眼就要40岁了。今天是情人节，晓青出差，我去驾校。\n","tags":["news"],"title":"学折纸、学开车","type":"post"},{"authors":null,"categories":null,"content":"第三届中国系统科学大会拟于2019年5月18-19日在湖南长沙举行。大会由上海系统科学研究院主办,国防科技大学承办,中国科学院数学与系统科学研究院系统科学研究所、北京师范大学系统科学学院、北京交通大学交通系统科学与工程研究院、中国船舶工业系统工程研究院、中国系统工程学会、中国自动化学会控制理论专业委员会等单位协办。旨在为系统科学及其相关领域的国内外专家学者提供一个学术交流平台，促进相关学科的交流、发展和融合，促进新方向、新领域的产生。会议将采取大会报告、专题研讨、会前专题讲座、分组报告等形式进行交流。 http://iss.amss.cas.cn/cssc2019/zwtz/\n 2019系统科学大会邀请组组织者，请提交一个不超过500字的邀请组申请书，并附拟邀请报告人的姓名、单位、联系信息等。每个邀请组须由8-10位报告人组成。详情参见：http://cms.amss.ac.cn。\n 人类和疾病的传播行为之所以难以理解主要的原因在于其中卷入了海量的异质性的个体及其相互之间的互动，而复杂系统和网络科学为理解人类\u0008\u0008信息扩散和疾病传播提供了丰富的理论视角。人类的存在无往不在各种复杂系统当中，包括但不限于社会系统、经济系统、通信系统、交通系统、生态系统等。基于数字媒体等方式可以从复杂系统当中收集的海量数据，而大数据技术和人工智能的发展则为理解各种传播现象提供了丰富的计算方法。面对纷繁复杂的重要问题，收集大规模数据，采用计算机科学的算法挖掘和分析背后的模式，采用数据科学、系统科学的视角构建模型则为我们理解模式背后的机制提供了更多的可能性。\n狭义的计算传播是指数据驱动的、借助于可算方法所进行的传播过程，而分析计算传播现象的研究领域就是计算传播学。计算传播学主要关注人类传播行为可计算的基础问题，以传播网络分析、传播文本挖掘、数据科学等作为主要的分析工具，大规模地收集并分析人类和疾病传播行为背后的模式或法则，并分析模式背后的生成机制以及基本原理。为了更好地理解疾病扩散、假新闻的传播等计算传播问题，我们提议在系统科学年会中组织计算传播分论坛，邀请相关领域的研究者对（包括但不限于）以下研究领域进行探讨：\n 复杂系统当中的传播现象的计算基础是什么？其本身是否可以计算？是否可预测？ 计算传播如何推动大问题、大理论、大数据的融合？如何帮助我们理解复杂的人类群体行为？ 计算方法在计算传播研究中的应用。 计算传播的实践或者商业价值  ","date":1544054400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544054400,"objectID":"5a430702fec2627116585bd2d586fcbf","permalink":"https://chengjunwang.com/zh/post/cn/2018-12-07-ccr-panel/","publishdate":"2018-12-06T00:00:00Z","relpermalink":"/zh/post/cn/2018-12-07-ccr-panel/","section":"post","summary":"人类和疾病的传播行为之所以难以理解主要的原因在于其中卷入了海量的异质性的个体及其相互之间的互动，而复杂系统和网络科学为理解人类\u0008\u0008信息扩散和疾病传播提供了丰富的理论视角。\n","tags":["news"],"title":"2019系统科学大会的计算传播学Panel","type":"post"},{"authors":null,"categories":null,"content":" 计算传播2017非毕业班的同学们：我8月8日登陆教务处系统录入成绩，发现系统暂时关闭了成绩录入；联系教务处（025-89682303）回复说因为系统原因，我需要开学后才能给你们录入成绩。\nhttps://github.com/computational-class/cc2017/issues/4\nSUNBELT2017社会网络分析国际研讨会 2017年6月4日上午，实验中心成员王成军在北京参加了2017年XXXV|| International Network for Social Network Analysis Conference 社会网络分析国际研讨会及第十三届中国社会学会社会网与社会资本研究专业委员会年会，发表论文Leveraging the Flow of Collective Attention for\u000bComputational Communication Research，并主持社会网络与计算传播学分论坛第二场。\n本科生论文答辩  5月27日 14:00 费彝民楼A407  指导学术论文  专硕  周纬 《权威与中心:基于HITS算法的收视率分析》  本科生  黄浩 134056004 􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰关于搭讪艺术家的行为动机与策略的调查报告 沈越 《“梦之队”统治奥运会？》 曾维靓 131050038 《大学生群体对于微博原生广告的态度及其影响因素》 􏴊􏴋􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓   云南白族扎染暑期社会实践指导  Q: 关于实际想探究问题，我们又探究了一下，但感觉都找不到很具体的研究方向，我整理了一下我们大概的想法，麻烦老师你看看有没有哪个想法具有可研究性😶\n  1. 民族旅游发展下的“扎染女”的生存现状与角色变迁 2.扎染工艺需要做出怎样的改变，才能继续发展? 3.当地工艺在过去是怎么发展和延续的？ 4.我们可以研究当地人在怎么努力挽救这个工艺么\u0014 5.从扎染看当地经济结构的变迁？ 6.探究云南白族扎染工艺当前生存状况并以白族扎染为例探究对传统手工艺的生产性方式保护. 7.探究白族扎染的工艺特色，艺术特征，在现代社会的创新运用.  A: 首先概念化，白族扎染是一种国家非物质文化遗产，也是一种传传统手工技艺。这背后对应着什么概念？然后是寻找新的问题。白族扎染作为一种手工技艺，在传承的过程中存在什么新的问题（其它手工艺没有的）？当前产业化的趋势使部分传统扎染技艺走向消亡，原有的民间特色开始退化，污染问题日益突出，市场经营滋生了对经济利益的过度追求，植物染料板兰根供不应求。在此情势下，白族扎染技艺的传承受到困扰。产业化是手工艺凋亡的关键原因，这个解释力很强，白族扎染很难幸免。要确保找到的问题是新的问题，即明确而且有意义。如有可能，要尝试理论化，找找既有的理论如何解释传统工艺的传承。研究问题要将个体（研究者）的困惑与社会结构（问题）联系起来。你们要好好琢磨一下，面对这种手工艺，你们有什么困惑？它又反应了什么social issue？强烈建议你们首先查询相关的论文和图书。\n华人思想库-省侨办共建智库（华智）项目讨论 《全球治理时代的中国新型智库》\n 陈晓晨 （人大重阳金融研究院专家） 2017-04-28 9:00 am 费彝民楼5楼圆桌会议室  信得过、用得着、靠得住；建设自己的报送渠道；资金来源稳定，不干涉。\n计算传播学——用AI穿透你的注意力壁垒  集智学园简介：http://campus.swarma.org/gvid=10140 时间：2017-04-12 20:00-23:00 网址：http://xue.duobeiyun.com  硕士预答辩  费彝民楼503 2017-03-30 16:00  计算传播讲座 2017年3月22日 10：00-12：00， 费彝民楼A418， 王成军向2016级博士生同学介绍计算传播学研究进展，包括计算社会科学的发展状况、代表性研究成果，如何评价其理论创新问题，并对社会科学理论进入丛林的问题进行了讨论。\n博士之家  地点：费彝民楼A418 时间：3月10日 12：00-14：00 主讲者：吴愈晓 主持人：王成军  创享沙龙：对话音乐与虚拟现实技术  地点：南京大学（仙林校区） 大学生活动中心南花园206 时间：2月27日 18：30-19：30 主讲者：向雪怀、王成军  南大新闻 音乐人向雪怀与我校师生对话VR技术与校园音乐 \n","date":1514442727,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1514442727,"objectID":"5a9be373f3940ebf4415f3098242f3e3","permalink":"https://chengjunwang.com/zh/post/news2017/","publishdate":"2017-12-28T14:32:07+08:00","relpermalink":"/zh/post/news2017/","section":"post","summary":"\n","tags":["news"],"title":"2017年“大事记”","type":"post"},{"authors":null,"categories":null,"content":" 计算传播2017非毕业班的同学们：我8月8日登陆教务处系统录入成绩，发现系统暂时关闭了成绩录入；联系教务处（025-89682303）回复说因为系统原因，我需要开学后才能给你们录入成绩。\nhttps://github.com/computational-class/cc2017/issues/4\nSUNBELT2017社会网络分析国际研讨会 2017年6月4日上午，实验中心成员王成军在北京参加了2017年XXXV|| International Network for Social Network Analysis Conference 社会网络分析国际研讨会及第十三届中国社会学会社会网与社会资本研究专业委员会年会，发表论文Leveraging the Flow of Collective Attention for\u000bComputational Communication Research，并主持社会网络与计算传播学分论坛第二场。\n本科生论文答辩  5月27日 14:00 费彝民楼A407  指导学术论文  专硕  周纬 《权威与中心:基于HITS算法的收视率分析》  本科生  黄浩 134056004 􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰关于搭讪艺术家的行为动机与策略的调查报告 沈越 《“梦之队”统治奥运会？》 曾维靓 131050038 《大学生群体对于微博原生广告的态度及其影响因素》 􏴊􏴋􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓􏳔􏳕􏲄􏲯􏲰􏴃􏳤􏱼􏱽􏱾􏱿􏲀􏲄􏲁􏱴􏲅􏲆􏳓   云南白族扎染暑期社会实践指导  Q: 关于实际想探究问题，我们又探究了一下，但感觉都找不到很具体的研究方向，我整理了一下我们大概的想法，麻烦老师你看看有没有哪个想法具有可研究性😶\n  1. 民族旅游发展下的“扎染女”的生存现状与角色变迁 2.扎染工艺需要做出怎样的改变，才能继续发展? 3.当地工艺在过去是怎么发展和延续的？ 4.我们可以研究当地人在怎么努力挽救这个工艺么\u0014 5.从扎染看当地经济结构的变迁？ 6.探究云南白族扎染工艺当前生存状况并以白族扎染为例探究对传统手工艺的生产性方式保护. 7.探究白族扎染的工艺特色，艺术特征，在现代社会的创新运用.  A: 首先概念化，白族扎染是一种国家非物质文化遗产，也是一种传传统手工技艺。这背后对应着什么概念？然后是寻找新的问题。白族扎染作为一种手工技艺，在传承的过程中存在什么新的问题（其它手工艺没有的）？当前产业化的趋势使部分传统扎染技艺走向消亡，原有的民间特色开始退化，污染问题日益突出，市场经营滋生了对经济利益的过度追求，植物染料板兰根供不应求。在此情势下，白族扎染技艺的传承受到困扰。产业化是手工艺凋亡的关键原因，这个解释力很强，白族扎染很难幸免。要确保找到的问题是新的问题，即明确而且有意义。如有可能，要尝试理论化，找找既有的理论如何解释传统工艺的传承。研究问题要将个体（研究者）的困惑与社会结构（问题）联系起来。你们要好好琢磨一下，面对这种手工艺，你们有什么困惑？它又反应了什么social issue？强烈建议你们首先查询相关的论文和图书。\n华人思想库-省侨办共建智库（华智）项目讨论 《全球治理时代的中国新型智库》\n 陈晓晨 （人大重阳金融研究院专家） 2017-04-28 9:00 am 费彝民楼5楼圆桌会议室  信得过、用得着、靠得住；建设自己的报送渠道；资金来源稳定，不干涉。\n计算传播学——用AI穿透你的注意力壁垒  集智学园简介：http://campus.swarma.org/gvid=10140 时间：2017-04-12 20:00-23:00 网址：http://xue.duobeiyun.com  硕士预答辩  费彝民楼503 2017-03-30 16:00  计算传播讲座 2017年3月22日 10：00-12：00， 费彝民楼A418， 王成军向2016级博士生同学介绍计算传播学研究进展，包括计算社会科学的发展状况、代表性研究成果，如何评价其理论创新问题，并对社会科学理论进入丛林的问题进行了讨论。\n博士之家  地点：费彝民楼A418 时间：3月10日 12：00-14：00 主讲者：吴愈晓 主持人：王成军  创享沙龙：对话音乐与虚拟现实技术  地点：南京大学（仙林校区） 大学生活动中心南花园206 时间：2月27日 18：30-19：30 主讲者：向雪怀、王成军  南大新闻 音乐人向雪怀与我校师生对话VR技术与校园音乐 \n","date":1514442727,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1514442727,"objectID":"1c79ac53c1ad44c54630addebc3aa9e8","permalink":"https://chengjunwang.com/zh/zh/post/news2017/","publishdate":"2017-12-28T14:32:07+08:00","relpermalink":"/zh/zh/post/news2017/","section":"zh","summary":"\n","tags":["news"],"title":"2017年“大事记”","type":"zh"},{"authors":null,"categories":null,"content":" 文献综述：采用引文分析等方法系统整理舆论扩散研究领域的论文和成果。尤其是针对舆论扩散的讨论模型进行了系统的总结，从参与者、议题、行动三个维度刻画了舆论扩散的过程。 数据获取：基本完成数据收集方案，获取1千万新浪微博用户的数据信息，建立新浪微博舆论扩散数据库；收集了占领华尔街这一主题的推特数据库；收集了Digg新闻扩散数据库。 数据分析：对这个数据进行数据清洗、分析，按照门槛模型、扩散深度等概念的要求，从多个维度对舆论扩散数据进行测量。一、尝试采用网路科学分析方法，文本挖掘的方法挖掘微博信息扩散的网络门槛与扩散规模之间的关系，发现扩散深度对于网络门槛影响的调节作用。二、对于占领华尔街的推特数据，从时间序列分析方法对数据进行分析和挖掘，有针对性地提取了舆论的讨论模型的三要素：参与者、议题、行动，建立了结构化贝叶斯模型，分析了三者对于舆论演化的整体影响；三、针对Digg数据，从注意力流动网络的角度刻画了新闻舆论扩散的过程； 整理了现阶段的研究成果，发表了一系列相关的论文，其中包括五篇英文论文和三篇中文论文，以及多篇会议论文。 经费使用：主要用于会议、差旅和少数办公用品，共花费18735元。  ","date":1511568000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1511568000,"objectID":"9e9fa385ee3d082b252d5091adc8ed18","permalink":"https://chengjunwang.com/zh/post/cn/2017-11-25-cn-project/","publishdate":"2017-11-25T00:00:00Z","relpermalink":"/zh/post/cn/2017-11-25-cn-project/","section":"post","summary":"　基本完成数据收集方案，获取1千万新浪微博用户的数据信息，建立新浪微博舆论扩散数据库；收集了占领华尔街这一主题的推特数据库；收集了Digg新闻扩散数据库。\n","tags":["news"],"title":"2017年社科项目进展","type":"post"},{"authors":null,"categories":null,"content":" turkserver\nhttp://turkserver.readthedocs.io/\nTutorials：quick start http://turkserver.readthedocs.io/en/latest/quick-start.html\nTurkServer/tutorial https://github.com/TurkServer/tutorial\n install meteor sign up AWS Account, get the id and secret.  浏览器歧视: - 一个可以打开 http://localhost:3000/experiment - 另一个打开 http://localhost:3000/turkserver\nOops, looks like there\u0026rsquo;s no route on the client or the server for url: \u0026laquo;http://localhost:3000/mturk/externalSubmit.\u0026quot;\nmlab https://mlab.com/\nazure https://portal.azure.cn/\n chengjunwang@chengjunwang.partner.onmschina.cn Datalab2017  error chengjuns-MacBook-Pro:server chengjun$ MONGO_URL=mongodb://localhost:27017/test PORT=3000 ROOT_URL=http://localhost:3000 npm start\n meteor-dev-bundle@0.0.0 start /Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server node ../../main\n /Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/node_modules/fibers/future.js:313 throw(ex); ^\nError: failed to connect to [localhost:27017] at Object.Future.wait (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/node_modules/fibers/future.js:449:15) at new MongoConnection (packages/mongo/mongo_driver.js:213:27) at new MongoInternals.RemoteCollectionDriver (packages/mongo/remote_collection_driver.js:4:16) at Object. (packages/mongo/remote_collection_driver.js:38:10) at Object.defaultRemoteCollectionDriver (packages/underscore/underscore.js:750:1) at new Mongo.Collection (packages/mongo/collection.js:103:40) at AccountsServer.AccountsCommon (packages/accounts-base/accounts_common.js:23:18) at new AccountsServer (packages/accounts-base/accounts_server.js:18:5) at meteorInstall.node_modules.meteor.accounts-base.server_main.js (packages/accounts-base/server_main.js:9:12) at fileEvaluate (packages/modules-runtime/.npm/package/node_modules/install/install.js:153:1) - - - - - at . (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm/node_modules/meteor/npm-mongo/node_modules/mongodb/lib/mongodb/connection/server.js:556:25) at emitThree (events.js:116:13) at emit (events.js:194:7) at . (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm/node_modules/meteor/npm-mongo/node_modules/mongodb/lib/mongodb/connection/connection_pool.js:156:15) at emitTwo (events.js:106:13) at emit (events.js:191:7) at Socket. (/Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm/node_modules/meteor/npm-mongo/node_modules/mongodb/lib/mongodb/connection/connection.js:534:10) at emitOne (events.js:96:13) at Socket.emit (events.js:188:7) at emitErrorNT (net.js:1272:8)\nnpm ERR! Darwin 17.2.0 npm ERR! argv \u0026laquo;/usr/local/bin/node\u0026raquo; \u0026laquo;/usr/local/bin/npm\u0026raquo; \u0026laquo;start\u0026raquo; npm ERR! node v6.2.2 npm ERR! npm v3.9.5 npm ERR! code ELIFECYCLE npm ERR! meteor-dev-bundle@0.0.0 start: node ../../main npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the meteor-dev-bundle@0.0.0 start script \u0026lsquo;node ../../main\u0026rsquo;. npm ERR! Make sure you have the latest version of node.js and npm installed. npm ERR! If you do, this is most likely a problem with the meteor-dev-bundle package, npm ERR! not with npm itself. npm ERR! Tell the author that this fails on your system: npm ERR! node ../../main npm ERR! You can get information on how to open an issue for this project with: npm ERR! npm bugs meteor-dev-bundle npm ERR! Or if that isn\u0026rsquo;t available, you can get their info via: npm ERR! npm owner ls meteor-dev-bundle npm ERR! There is likely additional logging output above.\nnpm ERR! Please include the following file with any support request: npm ERR! /Users/chengjun/GitHub/tutorial/.demeteorized/bundle/programs/server/npm-debug.log chengjuns-MacBook\n","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1509235200,"objectID":"11a4387b93993d5becdc74c8a5609b14","permalink":"https://chengjunwang.com/zh/post/cn/2017-12-14-turkserver/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/post/cn/2017-12-14-turkserver/","section":"post","summary":"TurkServer is a framework based on the JavaScript app platform Meteor that makes it easy to build interactive web-based user experiments for deployment on Amazon Mechanical Turk.\n","tags":["news"],"title":"2017年黑客马拉松之turkserver","type":"post"},{"authors":null,"categories":null,"content":"  中文名称：计算传播学 拼音：jisuan chuanbo\n 外文名称：Computational Communication Research  基本概念条（长）\n1. 定义和定性叙述 计算传播学是计算社会科学一个重要分支，它主要关注人类传播行为可计算的基础问题，以传播网络分析、传播文本挖掘、数据科学等作为主要的分析工具，大规模地收集并分析人类传播行为背后的模式或法则，并分析模式背后的生成机制以及基本原理，可以被广泛地应用到新闻学研究、 数据新闻和计算广告等场景。狭义的计算传播是指数据驱动的、借助于可算方法所进行的传播过程，而分析计算传播现象的研究领域就是计算传播学。\n2. 名称来源、又名 计算传播学（英文：computational communication research）起源于计算社会科学（英文：computational social science）。2009年，Lazer等一批社会科学家、计算机科学家和物理学家在《科学》杂志上发表题为 “网络中的生活:计算社会科学时代的到来”的论文，宣告计算社会科学的诞生，提出发展计算 社会科学的主要逻辑在于我们就生活在网络之中，例如发邮件、打电话、在线支付。这些网络化的行为以数字化痕迹的方式被记录下来。计算社会科学是一个正在涌现的研究领域，强调采用计算方法研究社会科学，在利用人类社会不断增强的数据收集和分析能力方面。21世纪是计算社会科学的时代。计算社会科学具备前所未有的广度、深度和规模，为研究者提供了一个理解复杂社会系统的崭新机会。毫无疑问，采用可算方法、基于大规模的互联网上的人类传播行为数据为代表的传播学研究属于计算社会科学这一研究传统。\n3. 概念形成过程 计算传播学的概念起源于是计算社会科学的发展。计算社会科学以分析社会系统的复杂性作为主要研究范式。社会系统作为一个复杂系统，本身包含了多重本体以及他们之间众多的联系，既有从微观到宏观的联系，也有从宏观到微观的影 响，这造就了社会现象所特有的复杂性。计算社会科学研究主要关注复杂社会系统中的社会现象、社会行为、社会 组织的涌现，例如居住隔离、合作、互惠、社会规范、市场、国家。计算社会科学中的“涌现” 往往表现为一种群体智慧，它是通过海量的异质性个体之间的互动而在群体层面出现的结果。作为一种崭新的研究范式，计算社会科学从数据基础和计算方法两个层面丰富了人们对于 社会现象的认识。\n互联网上的人类传播行为是驱动计算社会科学发展的一个主要动力。与自然科学相比，社会现象卷入了海量的异质性个体的互动行为，因而异常复杂并且难以预测。通常社会科学研究的数据往往是用户报告的、静态的、小规模数据。互联网行为数据和大规模的互联网实验却提供了另外一种可能性。邓肯•瓦茨认为互联网传播数据将会变革我们对于群体人类行为的理解，并产生了一种新的社会科学，邓肯•瓦茨称之为“二十一世纪的科学”，也就是后来广为人知的“计算社会科学”。\nShah等人曾提出目前社交数据多为传播文本数据，并且与图形数据和视频数据相比，传播文本数据相对容易分析，因而计算社会科学将 传播文本数据作为关注焦点之一，并认为这意味着计算传播学(computational communication science)的兴起。Cohen等人2011年就提出采用计算机科学技术发展新闻学的主张。发展计算传播学研究已经成为计算社会科学在新闻传播领域主要工作。2014年祝建华等人回顾和讨论了计算社会科学在新闻传播领域的应用，按照经典的5W模型，系统介绍了计算社会科学在传播者、渠道、受众、内容、效果 五个领域的主要应用案例;(祝建华等，2014:p.3-13)。2014年，计算传播学作为一个正式的研究领域被提出，王成军从计算社会科学的视角论述了计算传播学的理论框架，强调了寻找人类传播行为“可计算的基因”作为计算传播学发展的基础，以传播网络分析和传播文本挖掘作为主要的研究方法。2015年第一本计算传播学相关的图书《社交网络上的计算传播学》出版，这本书系统总结了采用计算传播学的视角进行社交网络研究的方法、理论和进展。2015年，南京大学成立了计算传播学实验中心，2016年第一届计算传播学论坛召开。计算传播学研究社群的涌现及其建制化发展有助于建立身份认同、促进科研合作、增强 学科间对话、运用群体智慧解决现实和理论问题。\n4. 基本内容 一、计算传播学的定义首先强调的的人类传播行为可计算的基础。人类的传播行为、传播过程和传播技术构建了一种社会复杂系统。海量的数据和不断提升的计算能力为回答人类传播学的可计算性问题提供了重要条件。以新闻扩散研究为例， 1945年Miller 在《美国社会学评论》发表题为“一个大众传播研究笔记:我们的社区怎样知道罗斯福总统的 死讯”一文。这一研究传统经历了由盛到衰，直到社交媒体发展起来又重新复兴的过程。新闻扩散研究主要关注人们通过何种渠道获知新闻，尤其是社交和(大众)媒体在其中所扮演的角色。其中，以 Greenberg的研究最为精彩，他发现社交作用与新闻扩散规模之间存在“J”形曲线关系，即对于一些小的新闻事件，社交影响与扩散规模呈反比(可能主要靠媒体传播);对于重大的新闻，社交作用则可以促进新闻扩散。然而受到传统研究方式的限制， 研究者只能采用调查问卷的方式请受访者回忆并填写相应情况，所研究的议题也往往是总统遇 刺等突发新闻事件(往往需要被动地组织研究)，因而无论所选取的新闻事件的数量还是受访者的数量均有限，这在很大程度上限制了这一研究传统。而计算社会科学的方法和工具则可以 帮助新闻扩散研究突破选题和样本的限制。王成军利用新浪微博上的大规模信息扩散数据，采用网络门槛来度量社交影响。网络门槛起源于格兰诺维特所提出的门槛理论。门槛理论假设个体是否参加某种行为的决定主要取决于他或她的朋友参与的比例。该研究验证了“J”形曲线理论;并且发现信息扩散的深度可以调节社交作用的影响，那些扩散深度低的信息往往是局部社区的信息(无法穿透社区的束缚)，社交作用(以网络门槛度量)将限制它的扩散，例如传播一个普通人生日信息的人往往 是他或她最亲密的朋友，社交作用很强，但扩散规模很小。\n二、计算传播学强调了对海量数据的收集、分析和挖掘。驱动计算传播的数据主要来自人类使用数字媒体时记录下来的数字痕迹或数字指纹。例如，当我们通过有线电视观看电视节目的时候、通过手机打电话的时候、通过互联网使用社交网站的时候，我们的行为都会被数字媒体详细地记录下来。这些海量的人类传播行为数据和媒体使用记录的数据构成了采用计算方法研究人类传播行为的基础。\n三、计算传播学强调对于基于数据的清洗、分析、挖掘等计算的过程。恰如伽利略通过自己改进的天文望远镜研究天文学，计算传播学主张利用强大的计算工具研究社会问题，例如自动化信息提取、网络分析、地理空间分析、复杂性模型、社会模拟模型等。在传统的内容分析中，需要编码员人工识别文本中的信息，采用文本挖掘的方法，可以自动地提取社会事件的属性，如事件、地点、参与者、文本的主题、文本的情感等。\n四、计算传播学强调了将大问题、大理论和大数据相结合。驱动计算传播学发展的主要力量来源于人类传播行为当中的重大问题，发展计算传播研究有助于解决新闻产业变革过程中发现的理论问题和实际困惑。就理论视角而言，计算传播学更加倾向于从复杂性的角度看待传播行为和传播过程。这种复杂性的思维方式需要研究者具备对复杂系统分析的能力和方法。值得注意的是，2017年瓦茨再次发表多篇反思计算社会科学的文章，提倡计算社会科学应该更加强调以寻找 解决方案为导向(solution-oriented)，因为社会科学存在太多的相互之间不一致的理论，而这些理论往往不能很容易地验证。寻找解决方案为导向对于新闻产业非常有价值，以新闻推荐系统为例(比如今日头 条)，如何实现更为精准的新闻推荐亟需寻找更加有价值的视角、方法和理论，可以预见经过新闻传播产业检验的理论也将具有更强的解释力和预测力。\n五、计算传播学强调了计算社会科学在理论建构方面所追求的抽象阶梯，即一个好的研究必须是重大的社会问题驱动的，并且能够找到好的数据作为支撑(第一个阶梯);要能够从数据当中挖掘出行为的模式 (第二个阶梯);最好可以阐明模式背后对应的机制(第三个阶梯);并尝试理解背后的基本原理(第四个阶梯，往往难以企及)。从数据、模式、机制、原理这样一个不断提高的抽象的阶梯，可以衡量不同的研究所处的状态和水平，为衡量计算传播学的研究提供了一个基本的标准。\n5. 意义和影响 计算传播的应用有很多，例如数据新闻、计算广告、媒体推荐系统等。计算传播学在过去的几年里，产生了深远的影响。数据新闻风靡全球，重要的国际媒体纷纷采用数据新闻，基于开放数据、数据挖掘与可视化的方式为公众提供信息和经过数据分析所发现的知识；不管是门户网站、搜索引擎、社交媒体，纷纷将计算广告作为数据变现的重要渠道，以计算方法对广告进行拍卖，实现媒体、用户、广告主三方利益的匹配；媒体推荐系统成为个性化的信息获取途径，不管是传统的社交新闻网站，还是今日头条等后起之秀，纷纷采用协同过滤的方式为用户提供信息。\n6. 参考文献 Watts, D.J., \u0026laquo;A twenty-first century science,\u0026raquo; Nature 445 (127) (2007):p.489.\nLazer, D., et al., \u0026laquo;Life in the network: The coming age of computational social science,\u0026raquo; Science 323 (5915)(2009):pp.721-723.\nGreenberg, B.S., \u0026laquo;Person-to-Person Communication in the Diffusion of News Events,\u0026raquo; Journalism Quarterly 41 (4)(1964):pp.489-494.\nWatts, D.J., \u0026laquo;Should social science be more solution-oriented?\u0026raquo; Nature Human Behaviour 1 (2017):p.0015.\n王成军.计算传播学:作为计算社会科学的传播学[J].中国网络传播研究，2014，第193-206页.\n王成军.计算传播学的起源、概念和应用[J].编辑学刊，2016(3)，第59-64页.\n祝建华、彭泰权、梁海、王成军、秦洁、陈鹤鑫.计算社会科学在新闻传播研究中的应用[J].科研信息化技术与应用，2014(2)，第3-13页.\n王成军 (2017).计算社会科学视野下的新闻学研究：挑战与机遇[J]. 新闻大学, 4:26-32\n7. 推荐书目 许小可、胡海波、张伦、王成军 （2015）社交网络上的计算传播学. 北京：中国科学出版社.\n 撰稿：王成军 审稿：巢乃鹏  ","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1509235200,"objectID":"4d157aeba455148e2c2d5453991a8118","permalink":"https://chengjunwang.com/zh/post/cn/2017-10-29-ccr/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/post/cn/2017-10-29-ccr/","section":"post","summary":"计算传播学是计算社会科学一个重要分支，它主要关注人类传播行为可计算的基础问题，以传播网络分析、传播文本挖掘、数据科学等作为主要的分析工具，大规模地收集并分析人类传播行为背后的模式或法则，并分析模式背后的生成机制以及基本原理，可以被广泛地应用到新闻学研究、 数据新闻和计算广告等场景。狭义的计算传播是指数据驱动的、借助于可算方法所进行的传播过程，而分析计算传播现象的研究领域就是计算传播学。\n","tags":["news"],"title":"中国大百科：计算传播学","type":"post"},{"authors":null,"categories":null,"content":"2010年9月，我作为博士生进入到香港城市大学互联网挖掘实验室以来，切身感受到了传播学研究者在互联网时代的身份焦虑。1998年邓肯-瓦茨关于小世界网络的模型和1999年阿尔伯特-巴拉巴西关于幂律和无标度网络的研究复兴了网络科学。一石激起千层浪，在学术领域产生了深远的影响。对于万维网上的人类行为的研究也形成了一个子领域，被称之为万维网科学(Web Science);伴随着社交媒体等数字媒体的发展，对于社会学而言，社会网络分析开始受到前所未有的重视，对于传播学而言，社交网络上的信息流动网络研究也引起广泛的兴趣；与此同时，机器学习和数据科学取得了突飞猛进的发展，进一步加速了计算化的浪潮；在新闻传播产业当中，数据驱动的新闻生产、计算广告和媒体推荐系统开始成为席卷世界的潮流。面对海量的互联网数据、持续困扰人类的重大社会问题、崭新的理论视角、诱人的物理学模型，在世界大战中发展起来的新闻传播学研究会走向什么地方？这构成了困扰我们的时代问题。\n面对这些挑战，或许很多人可以做一群鸵鸟，只盯住让自己感觉舒适的领域，当危险来的时候干脆把头埋进沙子里，但是年轻人没有逃避的理由。年轻研究者必须敢于冒险，才能走出不一样的路来。计算传播学正是回应这一时代叩问的一种尝试，它也给了传播学这个领域一个革命的火种。\n“计算传播学”这个词的提出源于香港城市大学互联网挖掘实验室成员之间在2012年初的一次组会讨论。每周，祝建华老师都会组织实验室成员进行内部讨论，讨论的主要内容除了每个人的研究进展之外，还包括文献分享、经验见闻等内容。在我的印象里，在这次讨论当中，我们再一次讨论了2009年大卫-拉泽等人发表在科学杂志上的一篇文章《计算社会科学》。在这篇文章当中，来自社会科学、计算机科学、网络科学等领域的资深研究者们宣告了计算社会科学的诞生，它以大规模数据收集和数据分析作为主要的工具，采用网络科学作为主要的研究视角，力图揭示个体和群体行为的模式。2012年1月29日，我在新浪博客上写了一篇短文《计算传播学:宣言与版图》，强调了将寻找人类传播行为的可计算基因作为计算传播学的发展使命。这篇小文章首先在一个名为《数字媒体阅读报告》的小圈子里流传。 在2月14日，我在与澳大利亚国立大学的指导老师Robert Ackland的邮件通信中，我提出了我想要做计算传播方面的研究的想法。2012年2月21日-23日，林武来实验室交流，分享了关于Python编程基础、数据抓取、hadoop使用等方面的知识。应该是2月21日或者2月22日，在实验室组会上，当我们再次讨论到在计算社会科学时代，我们自己期待传播学将走向什么地方这一时代问题的时候，我再次提出了计算传播（computational communication）的思路。当天晚上，吴令飞、汪臻真、我三个人在又一城散步的时候，令飞很郑重地说应该重视计算传播学的发展，在他的提议之下，2012年2月22日计算传播学谷歌邮件组建立。2月29日吴令飞在计算传播学谷歌邮件组发了第一封邮件，分享了抓取Alexa点击流网络的Python代码；2012年3月26日，计算传播学豆瓣小站正式建立。2012年底，吴令飞在多贝上发布了一系列计算传播学课程，后来更名为计算社会科学系列课程，之后他完成新书《Data Mining in Social Science》，发布在GitBook上，可免费在线阅读或者下载PDF。\n2017年春季，在酝酿第二届计算传播学论坛暨工作坊的过程中，许小可老师、张伦老师、胡海波老师和我开始计划写一本《计算传播学导论》书。按照祝建华老师的建议，我们曾对参加了2016年第一届计算传播学论坛的研究者公开征集计算传播学工作坊的题目。经过汇总整理之后的题目包括：计算机模拟/多主体建模、社交媒体数据爬取、传播文本挖掘和主题模型分析、使用深度学习进行传播学研究、社交媒体数据的时间序列分析和空间分析、传播学研究和数据新闻的可视化方法、传播网络分析（社区识别、复杂网络与信息流动）、机器学习、意见形成、Python编程，以及如何教授新闻传播学专业的学生网络分析/数据新闻/编程。我们的想法是每年遴选两个主题组织计算传播学工作坊，系统地整理和组织工作坊教学材料，基于此形成《计算传播学导论》一书的基本材料。2017年2月22-23日，第一届计算传播学工作坊在南京大学成功举办。为期一天半，分为两个子题并行进行，分别为“信息传播的网络分析”(Network Approaches to Information Diffusion)和“文本数据处理方法”(Processing Text Data)。前者定位为高级程度，聚焦于计算传播学研究中的一个核心而又困难的题目，以探讨研究设计、理论模型、数据要求、方法选择等问题为主、操作问题为辅，适合已掌握基本方法并有一定研究经验者。后者定位为入门程度，介绍用于文本数据处理的各个步骤上的方法、工具、算法等，含有众多动手操作。这次工作坊“信息传播的网络分析”部分由张子柯和王成军主讲《网络信息传播基础》、许小可讲《网络信息传播实证研究》、胡海波和阮中远讲解《网络信息传播模型》，“文本数据处理方法”部分又张伦主讲《文本分析的基本步骤与方法》、王成军介绍《主题模型》、汪臻真主讲《情感分析》。\n","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1509235200,"objectID":"2abe641993a10ec9006e6a1ea3d3cf4c","permalink":"https://chengjunwang.com/zh/post/cn/2017-12-05-backwords/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/post/cn/2017-12-05-backwords/","section":"post","summary":"计算传播学是传播学研究者对于传播学研究方向的一次新的探索。\n","tags":["news"],"title":"后记","type":"post"},{"authors":null,"categories":null,"content":"党的十九大报告再次对打赢脱贫攻坚战作出部署，明确指出重点攻克深度贫困地区脱贫任务，确保到2020年我国现行标准下农村人口实现脱贫，贫困县全部摘帽，解决区域性整体贫困，做到脱真贫、真脱贫。\n全国6000多万贫困人口稳定脱贫，贫困发生率从10.2%下降到4%以下。精准扶贫，不仅要精准施策，而且要精准到户。\n眼下，脱贫攻坚战的主战场正在转移到深度贫困地区。今年6月份，习近平总书记在山西考察时，深刻论述了深度贫困问题。扶贫攻坚从精准扶贫到瞄准深度贫困，既是认识的深化\n","date":1509235200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1509235200,"objectID":"519db704f9163b0654a7a2a5a7df13bc","permalink":"https://chengjunwang.com/zh/post/cn/2017-11-20-poverty/","publishdate":"2017-10-29T00:00:00Z","relpermalink":"/zh/post/cn/2017-11-20-poverty/","section":"post","summary":"　　让贫困人口和贫困地区同全国一道进入全面小康社会，是党向全国人民作出的庄严承诺。党的十九大报告再次对打赢脱贫攻坚战作出部署，明确指出重点攻克深度贫困地区脱贫任务，确保到2020年我国现行标准下农村人口实现脱贫，贫困县全部摘帽，解决区域性整体贫困，做到脱真贫、真脱贫。\n","tags":["news"],"title":"扶贫数据","type":"post"},{"authors":null,"categories":null,"content":" JCR Journal Data Filtered By: Selected JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: \u0026lsquo;COMMUNICATION\u0026rsquo; Selected Category Scheme: WoS\nSCI和SCIE SCI和SCIE（SCI Expanded）分别是科学引文索引及科学引文索引扩展版（即网络版），主要是收录自然科学、工程技术领域最具影响力的重要期刊，包括2000多种外围刊。\nTable    Rank Full Journal Title Total Cites Journal Impact Factor Eigenfactor Score     1 NEW MEDIA \u0026amp; SOCIETY 3,592 4.180 0.009310   2 Journal of Computer-Mediated Communication 4,011 4.113 0.005010   3 JOURNAL OF COMMUNICATION 5,579 3.914 0.008400   4 MEDIA PSYCHOLOGY 1,264 3.125 0.001440   5 COMMUNICATION RESEARCH 3,459 3.021 0.004410   6 JOURNAL OF ADVERTISING 3,425 2.896 0.001740   7 COMMUNICATION THEORY 1,834 2.773 0.002080   8 Information Communication \u0026amp; Society 2,005 2.692 0.006010   9 PUBLIC UNDERSTANDING OF SCIENCE 2,007 2.552 0.003150   10 POLITICAL COMMUNICATION 1,645 2.467 0.002930   11 International Journal of Advertising 1,308 2.451 0.001150   12 Comunicar 641 2.212 0.000650   13 IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION 515 2.184 0.000470   14 TECHNICAL COMMUNICATION 615 2.100 0.000340   15 JOURNAL OF ADVERTISING RESEARCH 2,514 2.034 0.000920   16 Journalism Studies 1,335 1.927 0.002760   17 RESEARCH ON LANGUAGE AND SOCIAL INTERACTION 1,016 1.896 0.003010   18 SCIENCE COMMUNICATION 968 1.852 0.001640   19 COMMUNICATION MONOGRAPHS 2,134 1.738 0.001150   20 Journal of Public Relations Research 961 1.720 0.001000   21 JOURNAL OF HEALTH COMMUNICATION 3,233 1.614 0.007080   22 HUMAN COMMUNICATION RESEARCH 2,836 1.549 0.001950   23 TELECOMMUNICATIONS POLICY 1,509 1.526 0.002270   24 International Journal of Press-Politics 546 1.523 0.002120   25 International Journal of Communication 1,277 1.498 0.005030   26 HEALTH COMMUNICATION 2,207 1.487 0.004080   27 Journalism 1,204 1.484 0.003890   28 JOURNAL OF SOCIAL AND PERSONAL RELATIONSHIPS 2,675 1.425 0.003050   29 Environmental Communication-A Journal of Nature and Culture 371 1.414 0.000820   30 EUROPEAN JOURNAL OF COMMUNICATION 885 1.408 0.001570   31 PUBLIC OPINION QUARTERLY 4,893 1.386 0.005970   32 Television \u0026amp; New Media 417 1.365 0.001080   33 JOURNAL OF BROADCASTING \u0026amp; ELECTRONIC MEDIA 1,874 1.311 0.002040   33 PUBLIC RELATIONS REVIEW 2,704 1.311 0.003070   35 Mass Communication and Society 984 1.308 0.001660   36 JOURNALISM \u0026amp; MASS COMMUNICATION QUARTERLY 1,574 1.301 0.001620   37 JOURNAL OF LANGUAGE AND SOCIAL PSYCHOLOGY 1,011 1.272 0.000910   38 INTERNATIONAL JOURNAL OF PUBLIC OPINION RESEARCH 851 1.254 0.001770   39 WRITTEN COMMUNICATION 669 1.200 0.000850   40 MEDIA CULTURE \u0026amp; SOCIETY 1,533 1.128 0.003180   41 Games and Culture 436 1.109 0.000410   42 Management Communication Quarterly 995 1.091 0.001130   43 Discourse \u0026amp; Communication 326 1.085 0.000850   44 JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION 243 1.062 0.000260   45 Journal of Media Psychology-Theories Methods and Applications 292 1.057 0.000680   46 Ecquid Novi-African Journalism Studies 153 1.056 0.000450   47 DISCOURSE \u0026amp; SOCIETY 1,354 1.029 0.001420   48 Discourse Context \u0026amp; Media 89 1.000 0.000590   49 Interaction Studies 370 0.958 0.000660   50 Convergence-The International Journal of Research into New Media Technologies 455 0.950 0.000870   51 Communications-European Journal of Communication Research 340 0.933 0.000460   52 Critical Discourse Studies 308 0.882 0.001090   53 CRITICAL STUDIES IN MEDIA COMMUNICATION 448 0.881 0.000560   54 DISCOURSE STUDIES 1,046 0.833 0.001650   55 LANGUAGE \u0026amp; COMMUNICATION 848 0.793 0.001080   56 INTERNATIONAL JOURNAL OF CONFLICT MANAGEMENT 652 0.786 0.000290   57 Communication and Critical-Cultural Studies 249 0.767 0.000670   58 PERSONAL RELATIONSHIPS 1,856 0.739 0.002100   59 Argumentation 324 0.689 0.000310   59 Visual Communication 353 0.689 0.000760   61 Translator 236 0.686 0.000280   62 Asian Journal of Communication 347 0.638 0.000570   63 International Communication Gazette 486 0.622 0.001030   64 Chinese Journal of Communication 129 0.562 0.000430   65 Social Semiotics 344 0.484 0.000720   66 Continuum-Journal of Media \u0026amp; Cultural Studies 496 0.468 0.000910   67 QUARTERLY JOURNAL OF SPEECH 737 0.460 0.000270   68 Communication Culture \u0026amp; Critique 209 0.448 0.000710   68 Text \u0026amp; Talk 297 0.448 0.000830   70 Journal of Mass Media Ethics 243 0.419 0.000370   71 JAVNOST-THE PUBLIC 191 0.413 0.000330   72 Media International Australia 264 0.346 0.000680   73 Rhetoric Society Quarterly 204 0.333 0.000300   74 NARRATIVE INQUIRY 379 0.317 0.000430   75 JOURNAL OF APPLIED COMMUNICATION RESEARCH 692 0.308 0.000720   76 JOURNAL OF MEDIA ECONOMICS 187 0.217 0.000170   77 African Journalism Studies 12 0.171 0.000020   77 Tijdschrift voor Communicatiewetenschap 42 0.171 0.000070   79 Journal of African Media Studies 66 0.154 0.000180    ","date":1504656000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1504656000,"objectID":"4aca9952d14ad79492f915fdf3588320","permalink":"https://chengjunwang.com/zh/post/cn/2017-09-06-jcr/","publishdate":"2017-09-06T00:00:00Z","relpermalink":"/zh/post/cn/2017-09-06-jcr/","section":"post","summary":"Journal Data Filtered By:  Selected JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: 'COMMUNICATION' Selected Category Scheme: WoS\t\n","tags":["news"],"title":"JCR2017 for COMMUNICATION","type":"post"},{"authors":null,"categories":null,"content":" 今年的研读营主要由吴令飞和尤亦庄负责。吴令飞主张研读营应该解决只有研读营才能做的事情。最初大家想分组搞一些研究项目，但考虑到大家因为项目的压力，每一个人都想得是一个可以deliver的东西。虫洞和weak tie有什么关联？boltzmann machine与社会计算？ising model与图灵机：一个社会系统在做计算。就人员组成而言，主要分成了社会科学组合物理学组两大阵营。\n社科与物理两大阵营是否可以理解对方的工作？ 社科和物理两大阵营作为两个组，每个组提议五对文献，任意一对论文有一篇好的，一篇是相对差的。于是两组分别出了一套题目，仅仅给出标题和摘要。\n 社会科学组出的题目\n 物理组出的题目  过程如下：首先，每个人选出自己认为正确的选项；然后，汇总并公示组内结果，每个人发表意见；最后，小组决议，投票决定。最终的结果如下图所示，社科组错了一个，物理组错了三个。\n这个结果略微让人吃惊，因为一般人认为物理组比较难，社科的人难以理解。结果却是对于那些发表出来的文章而言，物理组更搞不清楚社科的难度（“水”）有多深。当然，第二种解读就是，社会科学太软、太水，需要太多的口耳相传的训练，仅仅习得表面的功夫就只能做表面文章。\n玻尔兹曼机  A graphical representation of an example Boltzmann machine. Each undirected edge represents dependency. In this example there are 3 hidden units and 4 visible units. This is not a restricted Boltzmann machine.\n They are named after the Boltzmann distribution in statistical mechanics, which is used in their sampling function. It was invented by Geoffrey Hinton and Terry Sejnowski in 1985.\n unsupervised machine learning  unsupervised learning需要记住所有的东西 supervised learning是建立mapping  ising model  graph as the background geometric structure node  there is a binary spin on each node $\\sigma_v = 1 \\; or -1$  edge  hamiltonian (energy)    $$E = -\\left(\\sum{i\u0026lt;j} w{ij} \\, s_i \\, s_j + \\sum_i \\theta_i \\, s_i \\right)$$\nWhere: * $w_{ij}$ is the connection strength between unit $j$ and unit $i$. * $s_i$ is the state, $s_i \\in {0,1}$, of unit $i$. * $\\theta_i$ is the bias of unit $i$ in the global energy function. ($-\\theta_i$ is the activation threshold for the unit.)\nOften the weights are represented as a symmetric matrix $W$, with zeros along the diagonal.\nNewmann q modularity hamiltonian on the network\nsbm stochastic block model\n deepwalk http://www.perozzi.net/publications/14_kdd_deepwalk.pdf node2vector http://snap.stanford.edu/node2vec/  闭上眼猜测，睁开眼观察，比较二者的差别。\n袁行远介绍雾霾预报 肖达介绍RNN原理 word2vec https://www.tensorflow.org/tutorials/word2vec\n为什么深度学习有效? The humans working behind the ai curtain\n董磊介绍城市研究 制造业的衰落\n贫穷\n回到北京 结束了四天古北水镇的研读营，来到清华参加集智年会。\n浮光掠影 参加了夜游长城的活动。\n","date":1500359527,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1500359527,"objectID":"4bc98837832dbb38ef29597231ccf13f","permalink":"https://chengjunwang.com/zh/post/swarma-summer-camp/","publishdate":"2017-07-18T14:32:07+08:00","relpermalink":"/zh/post/swarma-summer-camp/","section":"post","summary":"\n","tags":["news"],"title":"集智俱乐部暑期研读营","type":"post"},{"authors":null,"categories":null,"content":" 今年的研读营主要由吴令飞和尤亦庄负责。吴令飞主张研读营应该解决只有研读营才能做的事情。最初大家想分组搞一些研究项目，但考虑到大家因为项目的压力，每一个人都想得是一个可以deliver的东西。虫洞和weak tie有什么关联？boltzmann machine与社会计算？ising model与图灵机：一个社会系统在做计算。就人员组成而言，主要分成了社会科学组合物理学组两大阵营。\n社科与物理两大阵营是否可以理解对方的工作？ 社科和物理两大阵营作为两个组，每个组提议五对文献，任意一对论文有一篇好的，一篇是相对差的。于是两组分别出了一套题目，仅仅给出标题和摘要。\n 社会科学组出的题目\n 物理组出的题目  过程如下：首先，每个人选出自己认为正确的选项；然后，汇总并公示组内结果，每个人发表意见；最后，小组决议，投票决定。最终的结果如下图所示，社科组错了一个，物理组错了三个。\n这个结果略微让人吃惊，因为一般人认为物理组比较难，社科的人难以理解。结果却是对于那些发表出来的文章而言，物理组更搞不清楚社科的难度（“水”）有多深。当然，第二种解读就是，社会科学太软、太水，需要太多的口耳相传的训练，仅仅习得表面的功夫就只能做表面文章。\n玻尔兹曼机  A graphical representation of an example Boltzmann machine. Each undirected edge represents dependency. In this example there are 3 hidden units and 4 visible units. This is not a restricted Boltzmann machine.\n They are named after the Boltzmann distribution in statistical mechanics, which is used in their sampling function. It was invented by Geoffrey Hinton and Terry Sejnowski in 1985.\n unsupervised machine learning  unsupervised learning需要记住所有的东西 supervised learning是建立mapping  ising model  graph as the background geometric structure node  there is a binary spin on each node $\\sigma_v = 1 \\; or -1$  edge  hamiltonian (energy)    $$E = -\\left(\\sum{i\u0026lt;j} w{ij} \\, s_i \\, s_j + \\sum_i \\theta_i \\, s_i \\right)$$\nWhere: * $w_{ij}$ is the connection strength between unit $j$ and unit $i$. * $s_i$ is the state, $s_i \\in {0,1}$, of unit $i$. * $\\theta_i$ is the bias of unit $i$ in the global energy function. ($-\\theta_i$ is the activation threshold for the unit.)\nOften the weights are represented as a symmetric matrix $W$, with zeros along the diagonal.\nNewmann q modularity hamiltonian on the network\nsbm stochastic block model\n deepwalk http://www.perozzi.net/publications/14_kdd_deepwalk.pdf node2vector http://snap.stanford.edu/node2vec/  闭上眼猜测，睁开眼观察，比较二者的差别。\n袁行远介绍雾霾预报 肖达介绍RNN原理 word2vec https://www.tensorflow.org/tutorials/word2vec\n为什么深度学习有效? The humans working behind the ai curtain\n董磊介绍城市研究 制造业的衰落\n贫穷\n回到北京 结束了四天古北水镇的研读营，来到清华参加集智年会。\n浮光掠影 参加了夜游长城的活动。\n","date":1500359527,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1500359527,"objectID":"6f9532b95f2ecc88364c3e3c290c6e18","permalink":"https://chengjunwang.com/zh/zh/post/swarma-summer-camp/","publishdate":"2017-07-18T14:32:07+08:00","relpermalink":"/zh/zh/post/swarma-summer-camp/","section":"zh","summary":"\n","tags":["news"],"title":"集智俱乐部暑期研读营","type":"zh"},{"authors":null,"categories":null,"content":" Data Tech2017大赛由中国移动浙江公司与浙江大数据交易中心联合主办，大赛以“数据众智美好未来”为主题，解锁运营商数据，整合气象、交通、空间等数据， 以“开放、互联”的精神激发全社会创新能量，共创美好未来。\n数据改变了人类的生活方式，从衣、食、住、行到生产生活都离不开数据的支撑。数据，让一切有迹可循，让一切有源可溯。为了挖掘数据价值、实践数据赋能，推动大众创业、万众创新，由浙江省经济和信息化委员会指导，中国移动浙江公司和浙江大数据交易中心主办的Data Tech 2017浙江大数据建模与创新应用大赛即将拉开序幕。\n本次Data Tech 2017浙江大数据建模与创新应用大赛以”数据众智美好未来”为主题，分为“模型挑战赛”和“众智创新赛”，并面向全社会开放，高等院校、科研单位、互联网企业、创客团队等人员均可报名参赛。数据集由中国移动浙江公司和浙江大数据交易中心会员单位授权提供，所有数据均以经过脱敏处理，切实保障数据安全。参赛者们利用数据分析方法，挖掘数据价值，探索数据应用，寻找真实业务问题和社会问题的解决方案。\n同时为了推动参赛者创业与就业，大赛组委会联合中国通信信息研究院、数据中心联盟等行业权威研究机构和重点联盟，浙江大学计算机学院、浙江大学管理学院、浙江省计算机学会等学术机构，发动创新工场、百分点等知名企业参与，为参赛选手提供资深的技术支持和创业辅导。此外，本次大赛还将汇集Preangle十维资本、星路资本、银杏谷资本等多家投资机构，为参赛者优秀成果的展示与孵化提供更多的机会，打造技术、产业、资本相融合的良性发展环境。\n大赛启动日期2017年7月15日，初赛截止日期2017年9月2日。报名及查看详细信息请登录大赛官网，网址：http://datatech.zjdex.com。\n初赛阶段提供7000个用户的完整行为数据。决赛阶段提供20万用户的完整行为数据。\n模型挑战赛初赛数据 获取方式：\n选题一 用户旅游出行意向和类型预测 选题一（数据包大小97.5M）下载链接： http://caiyun.feixin.10086.cn/sh/tHlKp3-XYvfebUgC\n选题二用户购买意向预测 选题二（数据包大小1.56M）下载链接： http://caiyun.feixin.10086.cn/sh/YlpDClB0h6vIqeRr\n选题三通信信用风险评估 选题三（数据包大小24K）下载链接： http://caiyun.feixin.10086.cn/sh/xllHu0ExJAZhdmuc\n公共数据集（大小210.7M），下载链接： http://caiyun.feixin.10086.cn/sh/UMtCD38q-V2FoIHn\n模型挑战赛决赛数据获取方式\n模型挑战赛决赛参赛队伍将会通过邮件收到浙江大数据开放平台提供的用户名及密码，可进入中国移动浙江公司大数据开放平台使用海量真实数据。\n众智创新赛数据 获取方式：\n移动_基础信息数据包（大小193.7K），下载链接： http://caiyun.feixin.10086.cn/sh/2R9GuE4S1BhmyUIR\n移动_通话信息数据包（大小972.9K），下载链接： http://caiyun.feixin.10086.cn/sh/OvRMzW7hoe8cHZM1\n移动_轨迹信息数据包（大小4.2M），下载链接： http://caiyun.feixin.10086.cn/sh/fAZG6k9UU-hdj0eZ\n移动_上网信息数据包（大小886.4M），下载链接： http://caiyun.feixin.10086.cn/sh/aKdAJmlM3Ga1Rv2J\n四维_地理空间数据包（大小55.2M），下载链接： http://caiyun.feixin.10086.cn/sh/BlVCEFUO-RT-Phfy\n四维_交通数据包（大小145.5M），下载链接： http://caiyun.feixin.10086.cn/sh/rQFBaFwZhx7atZOO\n四维_气象数据包part1（大小911.9M），下载链接： http://caiyun.feixin.10086.cn/sh/d65GTWEvzAuMF8BF\n四维_气象数据包part2（大小1.3G），下载链接： http://caiyun.feixin.10086.cn/sh/2zFL6Hj_3OowNiCq\n其他数据获取方式：\n参赛选手在参赛过程中，如有获取聚合数据平台的数据需求，可以邮件形式（需包含及个人姓名、团队名称、数据需求清单）将需求发送至zhaoyu@zjdex.com，参赛选手的数据需求经审核通过后，会有专门的工作人员与参赛选手联系，为参赛选手提供聚合数据平台数据使用账号。\n","date":1500186727,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1500186727,"objectID":"98cf630dd077d2d7f84cbb5979132faf","permalink":"https://chengjunwang.com/zh/post/zjmobile/","publishdate":"2017-07-16T14:32:07+08:00","relpermalink":"/zh/post/zjmobile/","section":"post","summary":"\n","tags":["news"],"title":"Data Tech2017大赛","type":"post"},{"authors":null,"categories":null,"content":" Data Tech2017大赛由中国移动浙江公司与浙江大数据交易中心联合主办，大赛以“数据众智美好未来”为主题，解锁运营商数据，整合气象、交通、空间等数据， 以“开放、互联”的精神激发全社会创新能量，共创美好未来。\n数据改变了人类的生活方式，从衣、食、住、行到生产生活都离不开数据的支撑。数据，让一切有迹可循，让一切有源可溯。为了挖掘数据价值、实践数据赋能，推动大众创业、万众创新，由浙江省经济和信息化委员会指导，中国移动浙江公司和浙江大数据交易中心主办的Data Tech 2017浙江大数据建模与创新应用大赛即将拉开序幕。\n本次Data Tech 2017浙江大数据建模与创新应用大赛以”数据众智美好未来”为主题，分为“模型挑战赛”和“众智创新赛”，并面向全社会开放，高等院校、科研单位、互联网企业、创客团队等人员均可报名参赛。数据集由中国移动浙江公司和浙江大数据交易中心会员单位授权提供，所有数据均以经过脱敏处理，切实保障数据安全。参赛者们利用数据分析方法，挖掘数据价值，探索数据应用，寻找真实业务问题和社会问题的解决方案。\n同时为了推动参赛者创业与就业，大赛组委会联合中国通信信息研究院、数据中心联盟等行业权威研究机构和重点联盟，浙江大学计算机学院、浙江大学管理学院、浙江省计算机学会等学术机构，发动创新工场、百分点等知名企业参与，为参赛选手提供资深的技术支持和创业辅导。此外，本次大赛还将汇集Preangle十维资本、星路资本、银杏谷资本等多家投资机构，为参赛者优秀成果的展示与孵化提供更多的机会，打造技术、产业、资本相融合的良性发展环境。\n大赛启动日期2017年7月15日，初赛截止日期2017年9月2日。报名及查看详细信息请登录大赛官网，网址：http://datatech.zjdex.com。\n初赛阶段提供7000个用户的完整行为数据。决赛阶段提供20万用户的完整行为数据。\n模型挑战赛初赛数据 获取方式：\n选题一 用户旅游出行意向和类型预测 选题一（数据包大小97.5M）下载链接： http://caiyun.feixin.10086.cn/sh/tHlKp3-XYvfebUgC\n选题二用户购买意向预测 选题二（数据包大小1.56M）下载链接： http://caiyun.feixin.10086.cn/sh/YlpDClB0h6vIqeRr\n选题三通信信用风险评估 选题三（数据包大小24K）下载链接： http://caiyun.feixin.10086.cn/sh/xllHu0ExJAZhdmuc\n公共数据集（大小210.7M），下载链接： http://caiyun.feixin.10086.cn/sh/UMtCD38q-V2FoIHn\n模型挑战赛决赛数据获取方式\n模型挑战赛决赛参赛队伍将会通过邮件收到浙江大数据开放平台提供的用户名及密码，可进入中国移动浙江公司大数据开放平台使用海量真实数据。\n众智创新赛数据 获取方式：\n移动_基础信息数据包（大小193.7K），下载链接： http://caiyun.feixin.10086.cn/sh/2R9GuE4S1BhmyUIR\n移动_通话信息数据包（大小972.9K），下载链接： http://caiyun.feixin.10086.cn/sh/OvRMzW7hoe8cHZM1\n移动_轨迹信息数据包（大小4.2M），下载链接： http://caiyun.feixin.10086.cn/sh/fAZG6k9UU-hdj0eZ\n移动_上网信息数据包（大小886.4M），下载链接： http://caiyun.feixin.10086.cn/sh/aKdAJmlM3Ga1Rv2J\n四维_地理空间数据包（大小55.2M），下载链接： http://caiyun.feixin.10086.cn/sh/BlVCEFUO-RT-Phfy\n四维_交通数据包（大小145.5M），下载链接： http://caiyun.feixin.10086.cn/sh/rQFBaFwZhx7atZOO\n四维_气象数据包part1（大小911.9M），下载链接： http://caiyun.feixin.10086.cn/sh/d65GTWEvzAuMF8BF\n四维_气象数据包part2（大小1.3G），下载链接： http://caiyun.feixin.10086.cn/sh/2zFL6Hj_3OowNiCq\n其他数据获取方式：\n参赛选手在参赛过程中，如有获取聚合数据平台的数据需求，可以邮件形式（需包含及个人姓名、团队名称、数据需求清单）将需求发送至zhaoyu@zjdex.com，参赛选手的数据需求经审核通过后，会有专门的工作人员与参赛选手联系，为参赛选手提供聚合数据平台数据使用账号。\n","date":1500186727,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1500186727,"objectID":"31e5a078844fc0fbc60946ed6d1e4fb5","permalink":"https://chengjunwang.com/zh/zh/post/zjmobile/","publishdate":"2017-07-16T14:32:07+08:00","relpermalink":"/zh/zh/post/zjmobile/","section":"zh","summary":"\n","tags":["news"],"title":"Data Tech2017大赛","type":"zh"},{"authors":null,"categories":null,"content":"2017年7月1日—2日南京大学数字人文大会在仙林校区国际会议中心召开。此次大会主题为“数字人文：大数据时代学术前沿与探索”。“数字人文”是目前国际最具潜力的新兴学科和前沿研究领域，具有创新性强、多学科交叉、研究者年轻化的特点。近十多年来，越来越多独立的“数字人文中心（系）”在北美和欧洲开设，比如美国的斯坦福大学、弗吉尼亚大学、加州大学，英国的国王学院，加拿大的阿尔伯特大学等等。这些机构不仅拥有专职研究人员和技术工程师，同时还开展了很多跨学科项目，涉及历史、考古、艺术史、文学、建筑等多个学术领域，并开始招收、培养硕士和博士研究生。\n视频回放，链接， 密码5954\n中国学界自2010年前后开始关注“数字人文”领域，武汉大学2011年成立了中国内地高校中的第一个数字人文中心。台湾大学及台湾中央研究院自2009年起每年举办“数位人文/数位典藏”的国际研讨会，北京大学与清华大学在2016年1月共同组织了主题大会，上海大学在2015年12月，南开大学在2016年11月都召开了相关的国际研讨会，受到了学界的广泛关注和学者们的积极参与，影响巨大。\n“数字人文：大数据时代学术前沿与探索”学术研讨会正是在此学界浪潮下应运而生，旨在聚集国内外学者探讨数字人文的前沿思想与主要议题，从而使得国内学者、学生了解数字人文国际前沿动态和主要焦点，并促进学者们的相互交流，提升数字人文在国内学术界的认知度，促进数字人文跨学科发展。\n会议议题主要包括，但不限于以下课题：\n· 图像分析与艺术、数字博物馆 （召集人：陈静、殷曼楟） · 文本挖掘与文学研究 （召集人：但汉松） · 数字史学的方法与案例 （召集人：王涛） · 数据分析及社交网络 （召集人：陈静、王成军） · 历史地理信息系统（HGIS）（召集人：陈刚） · 数字人文与空间 （召集人：鲁安东） · 数字人文前沿问题 （召集人：邓柯）\n 会议召开时间为2017年7月1日—2日，6月30日报到。 会议地点：南京大学仙林校区（具体地点待定）。 会务联系方式：digitalhumanities@163.com.  南京大学“数字人文：大数据时代学术前沿与探索”会务组 2017年4月6日\n","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1498867200,"objectID":"3a18382731c94b060ef1771905130f4b","permalink":"https://chengjunwang.com/zh/post/cn/2017-07-01-digital-humanities/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/zh/post/cn/2017-07-01-digital-humanities/","section":"post","summary":"2017年7月1日—2日南京大学数字人文大会在仙林校区国际会议中心召开。此次大会主题为“数字人文：大数据时代学术前沿与探索”。“数字人文”是目前国际最具潜力的新兴学科和前沿研究领域，具有创新性强、多学科交叉、研究者年轻化的特点。\n","tags":["news"],"title":"王成军参与组织数字人文大会","type":"post"},{"authors":null,"categories":null,"content":" Data for Climate Change Big data has big potential for applications to climate change adaptation. PNAS 2016 http://www.dataforclimateaction.org/home/data/\n Anonymized records of cell-phone use could in principle enable the large-scale tracing of people’s movements in the wake of a climate change-related disaster. Image courtesy of Shutterstock/Athi Aachawaradt.\n  GlobeScan pew 马里兰大学世界公共舆论 WPO http://worldpublicopinion.net PIPA 世界银行 盖洛普 BBC NSEE 欧盟民意委员会 美国气候地图  人口迁移、极端气候、青藏高原、西北地区\n中国气候指数 中国气候指数系列分为年度和月度指数,包括雨涝、干旱、台风、高温、低温冰冻五类指数,以及在此基础上合成的中国气候风险指数。以中国气候风险指数为例,风险等级从低至高分为0到10。1981年至2016年,中国气候风险指数平均值为4.19。对比1999年前后的平均值就可明显看出,风险指数从3.69上升为4.69,气候风险呈逐步增加趋势。 http://news.sciencenet.cn/htmlnews/2017/3/370039.shtm\n环保部 - 工作简报内容分析\n国内调查数据  CGSS 中国国家调查数据库CNSDA 环保部 中国气候传播项目中心 零点 汇丰银行。  内隐联想测试 IAT  概念词和属性词， e.g. 花\u0026amp;好的，蜘蛛\u0026amp;不好的，不一类的时候反应时间长 The candidate IAT, 有两个候选人，一个候选人支持气候变化保护，另一个没有强调，判断这两个人与一些好的品质之间的配对，看反应时间长度。  对气候变化的信念、心理问题、政策支持、迫切性、好坏\n气候变化建构出来的社会事实，态度和行为存在鸿沟，心理学可以发挥优势进行行为干预；社科领域的研究还比较少，15%，多数社会科学；中外差异明显，国内关注度低，环境问题排不到前十，主要关注雾霾和环境污染；在手段在技术层面。知识、教育、收入、价值观、党派，但心理因素可以干预。人类中心主义vs自然关联性，正念（mindful）干预，一类以冥想为主，另一类以认知和信息加工。经过干预之后，看待自然更加敏感了，更加相信和支持气候变化。\n","date":1498717927,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1498717927,"objectID":"84913922c39ee65d6f37220d03f01b54","permalink":"https://chengjunwang.com/zh/zh/post/climate-change/","publishdate":"2017-06-29T14:32:07+08:00","relpermalink":"/zh/zh/post/climate-change/","section":"zh","summary":"\n","tags":["news"],"title":"气候变迁研究：数据、调查、视角","type":"zh"},{"authors":null,"categories":null,"content":" Data for Climate Change Big data has big potential for applications to climate change adaptation. PNAS 2016 http://www.dataforclimateaction.org/home/data/\n Anonymized records of cell-phone use could in principle enable the large-scale tracing of people’s movements in the wake of a climate change-related disaster. Image courtesy of Shutterstock/Athi Aachawaradt.\n  GlobeScan pew 马里兰大学世界公共舆论 WPO http://worldpublicopinion.net PIPA 世界银行 盖洛普 BBC NSEE 欧盟民意委员会 美国气候地图  人口迁移、极端气候、青藏高原、西北地区\n中国气候指数 中国气候指数系列分为年度和月度指数,包括雨涝、干旱、台风、高温、低温冰冻五类指数,以及在此基础上合成的中国气候风险指数。以中国气候风险指数为例,风险等级从低至高分为0到10。1981年至2016年,中国气候风险指数平均值为4.19。对比1999年前后的平均值就可明显看出,风险指数从3.69上升为4.69,气候风险呈逐步增加趋势。 http://news.sciencenet.cn/htmlnews/2017/3/370039.shtm\n环保部 - 工作简报内容分析\n国内调查数据  CGSS 中国国家调查数据库CNSDA 环保部 中国气候传播项目中心 零点 汇丰银行。  内隐联想测试 IAT  概念词和属性词， e.g. 花\u0026amp;好的，蜘蛛\u0026amp;不好的，不一类的时候反应时间长 The candidate IAT, 有两个候选人，一个候选人支持气候变化保护，另一个没有强调，判断这两个人与一些好的品质之间的配对，看反应时间长度。  对气候变化的信念、心理问题、政策支持、迫切性、好坏\n气候变化建构出来的社会事实，态度和行为存在鸿沟，心理学可以发挥优势进行行为干预；社科领域的研究还比较少，15%，多数社会科学；中外差异明显，国内关注度低，环境问题排不到前十，主要关注雾霾和环境污染；在手段在技术层面。知识、教育、收入、价值观、党派，但心理因素可以干预。人类中心主义vs自然关联性，正念（mindful）干预，一类以冥想为主，另一类以认知和信息加工。经过干预之后，看待自然更加敏感了，更加相信和支持气候变化。\n","date":1498717927,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1498717927,"objectID":"d1623de5cfa320d1ae31e84c64a01891","permalink":"https://chengjunwang.com/zh/post/climate-change/","publishdate":"2017-06-29T14:32:07+08:00","relpermalink":"/zh/post/climate-change/","section":"post","summary":"\n","tags":["news"],"title":"气候变迁研究：数据、调查、视角","type":"post"},{"authors":null,"categories":null,"content":" 实验法 实验研究方法是由伽利略所发明的一种研究方法，成为了自然科学和社会科学研究最为重要的工具。自然科学取得了辉煌的研究成果，以物理学为例，主要的实证研究成果都来自于实验研究方法。社会科学的发展仅仅经历了不到三百年，最初主要模仿物理学的发展路径，例如，孔德最初将社会学命名为社会物理学，他认为人类社会是自然界的一个部分，人为的社会秩序通常可以看作自然秩序的延伸。然而，社会科学研究的研究对象\u0026ndash;人类具有意识、通过社会互动相互关联，构成了一种复杂系统，其复杂度远远超过自然科学，被邓肯-瓦茨称之为“二十一世纪的科学”。社会科学的实验往往局限于实验室内部，只能针对有限的人群（多为高校学生）开展实验研究，其外部效度有限，难以帮助研究者理解真实的社会和人类行为。\n问题 伴随着数据科学、网络科学的发展，采用计算方法为主的计算社会科学蓬勃发展。计算社会科学采用互联网大数据、网络科学等计算方法研究重要的社会科学问题。然而，既有的数据虽然规模巨大，但往往在很多维度上缺失，不能很好的回答因果关系、缺少控制，依然存在局限。如何针对大量的个体及其互动进行实验研究构成了互联网公司的产品经理、高校研究者共同的问题。\n问题：如何针对大量的个体及其互动进行实验研究？\n思路 基于众包的人类计算搭建“行为实验室”为解决这一问题提出了崭新的思路。通过互联网平台招募实验参与者，通过智能的程序匹配实验者、实验对象，允许实验对象在虚拟的网络环境内进行互动共同完成一个实验任务，允许实验者进行灵活的实验控制，可以较低的价格吸引更多的实验设计者和参与者。采用这一思路最成功的案例来自于亚马逊的Mechanic Turk（机械驱动的土耳其人）平台。\n 机械驱动的土耳其人（Mechanical Turk）原指18世纪一个打扮成土耳其人的机器人，曾巡回欧洲各国打败不少西洋棋高手，甚至跟名人如拿破仑或富兰克林都下过棋，后来被揭露为其实是里头藏着人的骗局。亚马逊借用这个典故，隐喻所提供的服务是一种外表提供机械性功能可是背后却是有人类智能支持。\n 来源：turkserver1\n互联网产品经理和高校研究者可以基于Mechanical Turk平台搭建虚拟实验室开展大规模的人类行为实验。虚拟实验室以这个互联网作为实验室，与传统的实验室相比，具有很多优点：\n 可以获取大规模的数据和互动关系 持续时间可以较长、对于地理位置的约束更小 可以让实验参与者开展更为现实而非抽象的简单的任务 可以实现更为精准的记录。  微软研究员科学家邓肯-瓦茨及其合作者一直致力于发展线上虚拟实验室（virtual lab），例如他们之前曾搭建music lab网站研究音乐的流行度。最近，他们借助于Mechanical Turk平台搭建了turkserver，研究发表了两篇论文，分别研究了囚徒困境 和灾难救助过程中的团队合作及其绩效 。\nMechanic Turk与turkserver相互配合的思路为实现大量的个体及其互动进行实验研究铺平了道路。但是目前在中国的互联网产业中，还缺乏提供类似Mechanic Turk的服务，而turkserver目前也缺少进一步的开发，这是提出本研究项目的主要目标。\n目标：搭建一个简单的turkserver的扩展版，搭建一个社会行为研究在线实验平台。\n参考文献  turkserver http://turkserver.readthedocs.io/en/latest/examples/tutorial.html, 基于amazon的mechanic turk建设virtual lab ^   ","date":1498262400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1498262400,"objectID":"abc5e89b1356a5b764f113fd909d9c32","permalink":"https://chengjunwang.com/zh/post/cn/2017-6-24-turk/","publishdate":"2017-06-24T00:00:00Z","relpermalink":"/zh/post/cn/2017-6-24-turk/","section":"post","summary":"通过互联网平台招募实验参与者，通过智能的程序匹配实验者、实验对象，允许实验对象在虚拟的网络环境内进行互动共同完成一个实验任务，允许实验者进行灵活的实验控制，可以较低的价格吸引更多的实验设计者和参与者。采用这一思路最成功的案例来自于亚马逊的[Mechanic Turk](https://www.mturk.com/mturk/welcome)（机械驱动的土耳其人）平台。\n","tags":["news"],"title":"社会行为研究在线实验平台","type":"post"},{"authors":null,"categories":null,"content":"思考手机用户在真实和虚拟世界的移动本身有什么价值:比较两种类型的网络结构，一个是分形的，一个是小世界的。二者之间不是完全对立的，而是可以平滑过渡的，因而可以计算从小世界到分形的连续变量的取值，即网络增长的过程中，新节点多大程度上按照小世界规则加入网络，多大程度上按照分形加入网络（Song, 2006）。\n自相似或者说分形是本研究切入的重点，分形的特点是在不同尺度上具有相同的特征，这种自相似的特征往往表现为系统特征与观测尺度之间的对应关系。一般对于分形网络而言，重整化之后的盒子数量log(N)与盒子大小log(L)之间存在无标度关系。我们确实也发现人在移动互联网站构成的网络重整化过程中，盒子数量与盒子大小之间具有这种无标度关系，但是人在现实世界的物理移动构成的网络经过重整化，其盒子数量与盒子大小之间则是指数分布。由此可见二者网络结构是如何不同的，前者接近分形，后者接近小世界。\n衡量小世界和分形的重要方法是度相关。分形意味着较强的异配性，而小世界则是同配性。正向的度相关意味着同配性和小世界，负向意味着分形。对于同配性的网络度相关通过重整化，一般会被抹平。有趣的是我们发现真实移动网络会由正变负。即当盒子比较大的时候，局部地区的同配性消失，表现出异配性。\nSong（2006）将网络增长与重整化看成一个逆过程，网络增长的过程可以看成重整化的尺度由大变小的过程。小世界网络增长的过程中，网络的平均直径L与网络中的节点数量具有对数关系，L ~ Log(N)。重整化需要的步数约等于最终网络的平均直径，例如一个直径是14的网络，大约经过14步重整化会由一个完整的网络坍缩为一个节点。在重整化过程中，所选择的盒子的大小l的取值范围约等于最终网络的平均直径range(L)。\nHernan Makse是City College of New York的物理学教授，主要从事复杂网络的研究，他和Song Chaoming就分形网络发表了两篇重要论文(Song 2005\u0026amp;2006)。他非常注重代码和数据的分享。我一直关注的是第一作者Song和鼎鼎大名的Havlin，并没有注意到Hernan， 后来搜索实现fractal_model的python代码的时候才找到他，恍然发现他是两篇论文的通讯作者。\n在这个算法里面，主要有四个参数：世代（generation)、新增子代数量(m)、子代间新增链接的数量(x)、断开父代链接的比例(e)。每一代是一个操作过程：以这一代的每一条边为单位，该边上的两个节点a和b各自新增子代m个，其中m对子代间形成（x-1)个链接，若随机概率大于e，那么断开父代节点a和b之间的链接，同时增加一条m对子代间链接。\ngeneration, m, x, e = 2, 1, 1, 0 G=nx.Graph() G.add_edge(0,1) #Two seed nodes(generation 0), then add m offsprings to these seed nodes. node_index = 2 for n in range(1,generation+1): print 'STEP:', n, '\\n' all_links = G.edges() while all_links: link = all_links.pop() # [(0, 1)] ----\u0026gt; (0, 1) print link new_nodes_a = range(node_index,node_index + m) print link[0], new_nodes_a #random.shuffle(new_nodes_a) node_index += m new_nodes_b = range(node_index,node_index + m) #random.shuffle(new_nodes_b) print link[1], new_nodes_b node_index += m G.add_edges_from([(link[0],node) for node in new_nodes_a]) G.add_edges_from([(link[1],node) for node in new_nodes_b]) repulsive_links = zip(new_nodes_a,new_nodes_b) # 相斥的的链接 print repulsive_links add_repulsive_links = [repulsive_links.pop() for i in range(x-1)] G.add_edges_from(add_repulsive_links) # add edges between offsprings print 'add repusive edges', add_repulsive_links if random.random() \u0026gt; e: # 当概率大于e的时候，断开hub间的链接 print 'delete', link G.remove_edge(*link) # 减少一对hub的链接 add_a_repulsive_link = repulsive_links.pop() print 'add_a_repulsive_link', add_a_repulsive_link G.add_edge(*add_a_repulsive_link) #相应得，增加一对其子代的链接  真实世界的移动网络是小世界的。例如Vito Latora 等（2002）分析了波斯顿地铁网络的结构（小世界）。随机网平均直径低，规则网聚类系数高。小世界网络在平均路径长度方面接近随机网，而在聚类系数方面接近规则网。Latora等认为我们对于小世界的两种衡量方式（平均直径L和聚类系数C）有缺陷（ill-defined），因为仅仅强调了链接是否存在，而忽略了链接的权重，比如链接的实际长度（the physical length of the link）。他们试图提出一种考虑权重的衡量小世界特征的测量:邻接矩阵 $ a{ij} $ 表示任意两个节点i、j之间是否有链接; $ l{ij} $ 表示任意两个节点i、j之间的权重（比如地铁站之间的空间距离;使用邻接矩阵 $ a{ij} $ 可以得到节点间的最短路径矩阵 $ d{ij} $ 。\n此时，无法算出聚类系数，因为很多地铁站只有两个邻居，算出的平均直径的信息也很少， $ \\varepsilon{ij} = \\frac{1}{N(N-1)d{ij}} $ 表示输运效率，可以在globa和local两个层面计算，分别对应平均路径长度L和聚类系数C。当两个节点无链接时，其 $ d{ij} $ 无穷大， $ \\varepsilon{ij} = 0 $ 。避免了计算平均路径长度无穷大的问题。同时可以定义输运成本 $ cost = \\frac{\\sum{i\\neq j} a{ij}l{ij}}{\\sum{i\\neq j}l_{ij} } $ 。如此计算波斯顿地铁的MBTA全局输运效率为0.63，局部输运效率为0.03，成本为0.002。即网络整体输运效率可以达到理想情况的63%，但是局部输运效率很差，不过整个网络的成本很小。如果加上公交网络MBTA+bus，全局效率上升为 0.72，局部效率大幅度上升为0.46，花费的成本仅仅上升为0.004。\n参考文献 Vito Latora（2002）Is the Boston subway a small-world network? Physica A\n","date":1449014400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1449014400,"objectID":"e1d5b27fe8f83d3491a60559c0e6a94a","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2015-12-02-renormalization/","publishdate":"2015-12-02T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2015-12-02-renormalization/","section":"post","summary":"思考手机用户在真实和虚拟世界的移动本身有什么价值:比较两种类型的网络结构，一个是分形的，一个是小世界的。二者之间不是完全对立的，而是可以平滑过渡的，因而可以计算从小世界到分形的连续变量的取值，即网络增长的过程中，新节点多大程度上按照小世界规则加入网络，多大程度上按照分形加入网络（Song, 2006）。\n","tags":null,"title":"手机用户在真实与虚拟空间中的移动","type":"post"},{"authors":null,"categories":null,"content":"","date":1435968000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1435968000,"objectID":"3adcdfa9e69e98c56c10ce33177d9e1a","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2015-07-04-iching-python/","publishdate":"2015-07-04T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2015-07-04-iching-python/","section":"post","summary":"","tags":null,"title":"iching：一个用来算卦的python包","type":"post"},{"authors":null,"categories":null,"content":"我们经常写一些程序碎片，却很少有动力把它们整合起来。前段时间写了一个爬取并可视化谷歌学术网的python程序。今天想不如把它整合一下，虽然非常简单（只有一个函数）。主要参考python官网的发布指南。\n##注册 于是首先来到pypi网站注册。\nhttps://pypi.python.org/pypi?%3Aaction=submit_form 记下用户名chengjun和密码W4\n##填写软件包信息 《指南》推荐直接在线填写 https://pypi.python.org/pypi?%3Aaction=submit_form\n##打包和发布工具 先要安装两个包：twine和wheel。\npip install wheel pip install twine  ##整理项目文件夹 找项目实例（https://github.com/pypa/sampleproject）下载下来，修改其中的部分内容即可。详见指南，或者自己摸索即可。\n##打包发布 1.在window环境下，使用cmd，转换工作路径到项目文件夹。 2. 主要参考 https://github.com/pypa/twine打包发布：\n#Create some distributions in the normal way: $ python setup.py sdist bdist_wheel #Upload with twine: $ twine upload dist/*  我使用上传的时候出错（typeError），于是直接使用打包好的zip文件（在dist子文件夹当中）手工上传到pypi。注意，每次上传到pypi需要修改一次setup.py中的版本号，并重新打包才可上传。如此而已，比我想象当中要速度快得多、简单的多。\n这里是我刚刚打包发布的一个可视化谷歌学术网络的python软件包：https://pypi.python.org/pypi/scholarNetwork/\n","date":1424563200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1424563200,"objectID":"c10f0e6b7af0b292065a0880c4cc213c","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2015-02-22-distribute-python-package/","publishdate":"2015-02-22T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2015-02-22-distribute-python-package/","section":"post","summary":"","tags":null,"title":"打包发布python软件包","type":"post"},{"authors":null,"categories":null,"content":"三年前，我写过一篇小日志，介绍如何从零开始学习R语言。后来我的工作越来越多的使用python，于是摸爬滚打自己探索了挺久的。身边也越来越多的人问起新手如何从零学习python的问题。我想练习、检索、表达这三点依旧是关键，只不过顺序稍有不同。很多人说，学习python，你来推荐一些资料吧。我想了想，资料还不是关键，关键是自身。\n看书还是上手？ 以前我们学语言，比如C语言或者Basic语言，首先讲的都是字符、数字、列表、逻辑符等。几乎所有的编程书都会这么讲，所以很多人会觉得看书没有什么新意。不过我觉得看书还是必须的，重点就是要去掌握这些基本的东西。\n当然了，掌握这些并不能帮助我们完成手上的工作。是的，并不能！总有一些细节的地方你必须去hack现有的代码。于是乎就有了另外一种学习语言的哲学：干中学（learn by doing）。基本的逻辑就是不断摸索，硬着头皮上。这种风格非常强悍，虽然刚开始的时候容易犯非常浅显的毛病，但是却是真正学语言的不二法门。\n表达 到底看书还是上手呢？我主张先明确自己的问题是什么。做研究的人都知道，我们往往对于自己所面临的问题并不明确。写程序、学语言也是这个样子。首先要明确地表达出来。这是表达的第一重意思。\n检索 当你问题明确之后，就可以去检索了。去哪里检索？书中、网上，不拘于形式。重要的是解决问题。这个过程中，我们带着问题读书、上网、提问，能够培养我们独立思考的能力。\n互联网的发展，使得很多时候我们并不需要真正去创造什么，只要检索一下，总能找到好的代码，修改以下就能解决自己的问题。我觉得挺好。这符合我们学习语言的初衷。有个说法是十年学会编程，但是使用编程一个月就够了。\n既然可以看书，有什么推荐的吗？我推荐Beginning Python这本书，虽然我是从A Byte of Python开始看的。\n A Byte of Python http://book.douban.com/subject/5948760/ Beginning Python （Python 基础教程） http://book.douban.com/subject/3205338/ Hello World！Computer Programming for Kids and Other Beginners 与孩子一起学编程 http://book.douban.com/subject/5338024/ How to Think Like a Computer Scientist: Learning with Python http://book.douban.com/subject/1481058/ 21 Recipes for Mining Twitter http://book.douban.com/subject/5988563/ Mining the Social Web http://book.douban.com/subject/5391582/ Toby Segaran (2007) Programming Collective Intelligence Building Smart Web 2.0 Applications. O\u0026rsquo;Reilly Media Python公开课 中文课程 http://www.imooc.com/view/177  练习 有了问题和思路之后，重要的就是练习了。不要怕麻烦，经常动手写东西。这个是不二法门。\n还有一些琐碎的东西，如下：\n 我觉得学python上手很重要，选一个好的IDE很重要，对于windows用户我推荐winpython，使用集成于其中的spyder编程很方便，不需要指定python的路径，安装第三方包也很方便。 每天都接触点Python,写写博客。 既然使用Python了，那么google就是你最好的朋友！用英文检索。 不要错过Github。上传你的代码。便于保存和分享。python的精神是开放，开源。 很多时候，最大的问题是你不知道自己面临的问题：我的经验是用英文一句话说出你的问题。然后借助搜索引擎。你一般都能找到答案。Python的email list和stackoverflow中有很多想要的答案。 实在找不到解决方案，不要过多寄希望于身边的朋友，stackoverflow上有更合适的回答你问题的人！去那里提问。 熟悉一个package。经常阅读package的文档。 ","date":1424563200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1424563200,"objectID":"93725347656a2fce495fd1fac58d13bb","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2015-02-22-fresh-python/","publishdate":"2015-02-22T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2015-02-22-fresh-python/","section":"post","summary":"","tags":null,"title":"表达、检索、练习——写给Python的初学者","type":"post"},{"authors":null,"categories":null,"content":"昨天收到了shinyapp的一封邮件，想起之前自己做的关于网络扩散的东西，就想把它转化为app的形式。最直接的办法还是看tutorial，比如（http://shiny.rstudio.com/tutorial）。\n现学现卖，于是我马上做了一个使用igraph绘制BA网络的小应用：\nhttps://chengjun.shinyapps.io/testApp/\n ##通过rstudio学习shinyApp制作 其实R的王牌编辑器Rstudio已经和shiny完美的结合，完全可以通过rstudio学习shinyApp制作。\n system.file(\u0026quot;examples\u0026quot;, package=\u0026quot;shiny\u0026quot;) runExample(\u0026quot;01_hello\u0026quot;) # a histogram runExample(\u0026quot;02_text\u0026quot;) # tables and data frames runExample(\u0026quot;03_reactivity\u0026quot;) # a reactive expression runExample(\u0026quot;04_mpg\u0026quot;) # global variables runExample(\u0026quot;05_sliders\u0026quot;) # slider bars runExample(\u0026quot;06_tabsets\u0026quot;) # tabbed panels runExample(\u0026quot;07_widgets\u0026quot;) # help text and submit buttons runExample(\u0026quot;08_html\u0026quot;) # shiny app built from HTML runExample(\u0026quot;09_upload\u0026quot;) # file upload wizard runExample(\u0026quot;10_download\u0026quot;) # file download wizard runExample(\u0026quot;11_timer\u0026quot;) # an automated timer ","date":1420934400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1420934400,"objectID":"7ba7837f507cc1ac5c99e9a380255c57","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2015-01-11-shinyapp/","publishdate":"2015-01-11T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2015-01-11-shinyapp/","section":"post","summary":"","tags":null,"title":"再次尝试shinyApp","type":"post"},{"authors":null,"categories":null,"content":"昨天听谈和讲解了echarts的使用，他的讲解非常直接简单，就是直接修改echarts的实例。之后，我发现林峰将echarts的实例的html代码写得非常复杂，但其实单独调用一个js的时候，却非常简单。具体做法如下：\n 准备工作：建立一个js子文件夹，将esl，echarts，pie，bar，map等各种js放入其中。在js文件夹外新建一个空的html文件。 首先，调用esl.js，它提供了echarts图片的载体。 其次，使用require方法调用echarts.js和具体使用的类型图的js（比如map.js）。 再次，输入需要输入的数据。 最后，封装。\n \u0026lt;!DCOTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;echarts testing page\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026quot;./js/esl.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;./js/echarts.js\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026quot;main\u0026quot; style=\u0026quot;height:400px;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt; require.config({ paths:{ \u0026quot;echarts\u0026quot;:\u0026quot;js/echarts\u0026quot;, \u0026quot;echarts/chart/map\u0026quot;:\u0026quot;js/map\u0026quot; } }); //using require( [ \u0026quot;echarts\u0026quot;, \u0026quot;echarts/chart/map\u0026quot; ], function(ec){ var myChart=ec.init(document.getElementById(\u0026quot;main\u0026quot;)); \u0026lt;!--Input your code below--\u0026gt; \u0026lt;!--Input your code above--\u0026gt; //loading data myChart.setOption(option); } ); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   ##弦图 http://chengjun.github.io/myecharts/chord.html\n ##柱状图 http://chengjun.github.io/myecharts/bar.html\n ##饼图 http://chengjun.github.io/myecharts/pie1.html\n ##线图 http://chengjun.github.io/myecharts/line1.html\n ##地图 http://chengjun.github.io/myecharts/map9.html\n ##力图\nhttp://chengjun.github.io/myecharts/force2\n ##后记 发现chrome无法加载，再加入了以下代码后就可以使用了。可惜用了整整一个上午才更正这个问题。\n \u0026lt;script src=\u0026quot;./js/echarts.js\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; ","date":1420848000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1420848000,"objectID":"2ccadb4f399c1ea14e4e1d4ebd886c1d","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2015-01-10-myecharts/","publishdate":"2015-01-10T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2015-01-10-myecharts/","section":"post","summary":"","tags":null,"title":"Echarts使用简介","type":"post"},{"authors":null,"categories":null,"content":"分割数据最慢的过程其实是打开和关闭一个文件，因此尽量减少这种操作可以飞速的提升分割数据的速度。之前在stackoverflow上看到一种方法非常高效，放在这里研究一下。\n from collections import defaultdict path = 'D:/chengjun/Sina Weibo/DepthOverTime/' #define a function def splitData(f): #using dict to 'classify' rows E = defaultdict(lambda:[]) for line in f: lists = line.strip().split(',') rtmid = lists[0] file_save = path + 'single_weibo/'+rtmid E[file_save].append(line) for key in E.keys(): try: with open(key,'a') as p: for record in E[key]: p.write(record+\u0026quot;\\n\u0026quot;) except: pass # start to read in data by chunks bigfile = open(path + 'diffusion_path_date2552.csv') chunkSize = 100000000 chunk = bigfile.readlines(chunkSize) while chunk: splitData(chunk) chunk = bigfile.readlines(chunkSize)  上面这段代码有两个地方导致非常高效：\n 使用dict来将相同的key的行整理到一起， 以便一次将吞进来的某一个key下面的数据全部写入硬盘 每次使用readlines读入足够多的行，充分发挥内存的作用 ","date":1409443200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1409443200,"objectID":"61cf724013bd7307eb4dcd161ffe5ce4","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-08-31-fast-split-data-with-python/","publishdate":"2014-08-31T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-08-31-fast-split-data-with-python/","section":"post","summary":"","tags":null,"title":"使用Python快速分割数据的方法","type":"post"},{"authors":null,"categories":null,"content":"在之前的一个博客中，我介绍了使用R进行社区划分并可视化的方法。这里使用相同的数据，介绍如何使用d3network实现网络可视化的方法。\n首先，安装d3network\ndevtools::install_github(\u0026quot;d3Network\u0026quot;, \u0026quot;christophergandrud\u0026quot;) require(d3Network)  之后可以使用简单的可视化方法：\nd3SimpleNetwork(data[,1:2], file = \u0026quot;chinese_university100.html\u0026quot;, width = 1024, height = 763, fontsize = 12)  我想要展现社区划分的结果：\n#链接数据 links = data names(links) = c(\u0026quot;source\u0026quot;, \u0026quot;target\u0026quot;, \u0026quot;value\u0026quot;) #节点列表 fc = fastgreedy.community(g); sizes(fc) mfc = membership(fc) nodes = data.frame(name = names(mfc), group = mfc) #对应链接数据和节点数据 ids = 0:(nrow(nodes)-1) # notice: start with zero! links[,1] = ids[match(links[,1], nodes$name )] links[,2] = ids[match(links[,2], nodes$name )] links = links[with(links, order(source)), ] # sort by source #处理边的权重大小 links$value = log(links$value)  之后就可以使实现可视化结果啦：\nd3ForceNetwork(Links = links, Nodes = nodes, Source = \u0026quot;source\u0026quot;, Target = \u0026quot;target\u0026quot;, Value = \u0026quot;value\u0026quot;, NodeID = \u0026quot;name\u0026quot;, Group = \u0026quot;group\u0026quot;, file = \u0026quot;chinese_university_groups100.html\u0026quot;, width = 1550, height = 800,iframe = TRUE, opacity = 0.9, zoom = TRUE)   但是对于中文要麻烦一些，需要手工修改html里的encoding设置，包括meta部分和script部分两个地方：\n\u0026lt;meta charset=\u0026quot;gbk\u0026quot;\u0026gt; \u0026lt;script charset=\u0026quot;gbk\u0026quot; src=http://d3js.org/d3.v3.min.js\u0026gt;\u0026lt;/script\u0026gt;  除此之外，我还尝试了下两百所学校的情况：点这里。\n","date":1409097600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1409097600,"objectID":"918ffcbb96258daccfb9ad65d547e7c5","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-08-27-d3network/","publishdate":"2014-08-27T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-08-27-d3network/","section":"post","summary":"","tags":null,"title":"使用d3network做网络可视化","type":"post"},{"authors":null,"categories":null,"content":"NetworkX是使用python分析网络数据的重要武器。它的使用非常简单。\n首先，创建网络对象：\nimport matplotlib.pyplot as plt import networkx as nx G=nx.DiGraph()  然后，添加链接：\nG.add_edge('source',1,weight=80) G.add_edge(1,2,weight=50) G.add_edge(1,3,weight=30) G.add_edge(3,2,weight=10) G.add_edge(2,4,weight=20) G.add_edge(2,5,weight=30) G.add_edge(4,5,weight=10) G.add_edge(5,3,weight=5) G.add_edge(2,'sink',weight=10) G.add_edge(4,'sink',weight=10) G.add_edge(3,'sink',weight=25) G.add_edge(5,'sink',weight=35)  可以很容易提取边的权重:\nedges,colors = zip(*nx.get_edge_attributes(G,'weight').items())  计算加权过的出度：\nd = G.out_degree(weight = 'weight') #计算节点的中心度  选择一个常用的可视化方法：\npos=nx.spring_layout(G) #设置网络的布局  绘制网络:\nnx.draw(G, pos, node_color = 'orange', with_labels = True, nodelist = d.keys(), node_size = [v*5 for v in d.values()], edgelist = edges, edge_color = colors, width = 5, edge_cmap=plt.cm.Blues)  计算流距离：\n''' # get flow distance ''' def toSink(G, i): try: di = G[i]['sink'].values()[0] except: di = 0 return di def flowDistanceDT(G): #input a balanced nx graph R = G.reverse() mapping = {'source':'sink','sink':'source'} H = nx.relabel_nodes(R,mapping) #---------initialize flow distance dict------ L = dict((i,1) for i in G.nodes()) #FlowDistance #---------prepare weighted out-degree dict------ D = {i: toSink(G, i) for i in G.nodes()} #Di T = G.out_degree(weight='weight') #Ti #---------iterate until converge------------ ls = np.array(L.values()) delta = len(L)*0.01 + 1 while delta \u0026gt; len(L)*0.01: for i in L: l=1 for m,n in H.edges(i): l+=L[n]*H[m][n].values()[0]/float(T[m]) L[i]=l delta = sum(np.abs(np.array(L.values()) - ls)) ls = np.array(L.values()) #---------clean the result------- del L['sink'] for i in L: L[i]-=1 L['sink'] = L.pop('source') T['sink'] = T.pop('source') D['sink'] = D.pop('source') return L.values(), D.values(), T.values() ","date":1407974400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1407974400,"objectID":"6c1675624e2df9cc3f9a68d2b424742d","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-08-14-networkx-intro/","publishdate":"2014-08-14T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-08-14-networkx-intro/","section":"post","summary":"","tags":null,"title":"NetworkX初步：创建网络、提取属性和绘图","type":"post"},{"authors":null,"categories":null,"content":"许小可老师和我决定使用可视化的方法分析一下中国高校之间的友谊关系网络。我们是想通过这个图从一个侧面说明各个大学在社交网络上的影响力和关系：所以节点大小表示每个大学在该网络中的友谊关系数量，连边宽度表示节点之间的连接关系，节点颜色的不同可以表示节点的影响力大小（介度中心性指标）。\n###数据清洗 现有数据有学校信息。我可以通过构建字典的方式来将user_id和学校信息（以最新的学校信息为主）剥离出来。使用这个字典可以计算学校人数的分布并挑选前一百的学校。然后根据user_id来match社交网络数据和学校数据，构建：university1\u0026mdash;university2\u0026mdash;date的数据形式。如果该行数据中的学校都在top100的名单中，则保留，否则不保留，这样可以构建所需要的学校和学校的随时间变化的网络，并采用考虑连边权重的贪婪算法来划分网络社团。\n###数据分析\n数据清洗之后，使用R软件进行数据分析，使用igraph包进行数据的可视化。代码如下：\nlibrary(igraph) setwd(\u0026quot;F:/xiaonei/\u0026quot;) ################ # all data ################ data = read.table(\u0026quot;./friends_university_top100_by_all.txt\u0026quot;, header = FALSE, sep = '\\t', stringsAsFactors = FALSE) data = data[which(data[,3] \u0026gt;= mean(data[,3])*1.2), ] data = data[which(data[,1] != data[,2]),] g =graph.data.frame(data[,1:2],directed=FALSE ) E(g)$weight = data[,3] E(g)$color = \u0026quot;lightgrey\u0026quot; # layout set.seed(34) ## to make this reproducable l=layout.fruchterman.reingold(g) # size nodeSize = graph.strength(g) V(g)$size = (nodeSize - min(nodeSize))/(max(nodeSize) - min(nodeSize))*20 centrality = betweenness(g) # colors colors = heat.colors(37) position = rank(-centrality, ties.method = \u0026quot;first\u0026quot;) V(g)$color = colors[position] # width E(g)$width = (log(E(g)$weight)- 8)*1.5 # label nodeLabel = V(g)$name V(g)$label.cex = log(centrality+1)/20 + 0.5 V(g)$label.color = \u0026quot;black\u0026quot; # community detection fc = fastgreedy.community(g); sizes(fc) mfc = membership(fc) # plot drawFigure = function(g){ plot(g, vertex.label= nodeLabel, edge.curved = FALSE, vertex.frame.color=\u0026quot;#FFFFFF\u0026quot;, layout=l,mark.groups = by(seq_along(mfc), mfc, invisible) ) } drawFigure(g) # save png png(\u0026quot;./all_color.png\u0026quot;, width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) drawFigure(g) dev.off()  数据的可视化表明：\n 学校间的友谊关系的建立取决于学校的排名 （排名越靠前的学校的网络中心性较高） 同一个省的学校之间存在更多的友谊关系 （存在地理上的proximity）  还可以根据月份来可视化，看一下2006年一月的情况吧：\n使用R生成24个月的图片，使用makeagif生成GIF动态图片：\n显然：\n 最早加入这个社交网络的是北京的几所著名高校； 2006年4月才走出北京； 随后友谊关系开始在全国扩张； 扩张的过程围绕着那些著名高校为中心进行。  本文提供汇总的数据下载，供感兴趣的同学玩。\n","date":1405900800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1405900800,"objectID":"9f5e6eedfbbe451246918a0fbe4b3aa0","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-07-21-chinese-university-friendship-network/","publishdate":"2014-07-21T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-07-21-chinese-university-friendship-network/","section":"post","summary":"","tags":null,"title":"中国高校间的友谊网络：大学排名、地理位置和演化规律","type":"post"},{"authors":null,"categories":null,"content":"网络是由节点和关系构成的，而对于关系的描述是社会网络的关键。我们已经知道对于节点的网络特性可以从中心度、近度、介度、特征度（eigenvalue centrality）等方式描述。那么对于关系呢？最简单的就是直接关系的强度了。\n关系强度（tie strength) 通常对于关系强度的测量是基于两个节点之间链接的权重来衡量的。并不是说关系的强度越高越好，也不是说越多的强关系就越好。例如，格兰诺维特的论文The strength of weak ties强调了弱关系的重要性。\n共同好友（common friends） 但是以直接的链接强度度量一对关系的强度显然过于简单。它忽略的网络中的三角形（triads）：网络的局部传递性(transtivity)。关系的传递性是社会网络分析的一种重要观点。比如，朋友的朋友成为自己的朋友的可能性很高。这种关系的强度不只限于一模网络中。在传播学中有ABX模型，A和B是两个人，X是一种对象（信息、意见、创新等）。A和B是好朋友，A喜欢X，那么B喜欢X的可能性就提高。也就是爱朋友及朋友喜欢的东西，有点像爱屋及乌。\n怎么抓住网络的传递性？找两个节点(一对关系)的共同好友！找到共同好友就抓住了网络中的三角形。存在的三角形数量就表明了传递性的程度。这种思路其实对于做共引（co-citation)分析的学者来说并不陌生。如果一篇论文同时引用了两篇论文，那么这两篇论文就存在一定的相似性。因此，找共同好友类似于找共引关系。\n嵌入度（embededness） 共同好友数量是判断两个人亲密程度的一个重要变量。如果共同好友的数量足够多，表明这两个人彼此深度的融入了对方的社会关系当中。基于这种思路，我们可以计算嵌入型。对于i和j两个人, $$k{i}$$、$$k{j}$$分别表示i和j的好友数量。$$n_{ij}$$表示其共同好友数量。那么，我们可以如下计算嵌入度：\n$$ Embededness{ij} = \\frac{n{ij}}{(k{i} -1) + (k{j} -1) - n_{ij}} $$\n残缺性（dispersion） 残缺度（dispersion， 或译为分散度）是Lars Backstrom \u0026amp; Jon Kleinberg (2013) 为了识别Facebook中亲密关系而提出的度量。它同样是基于共同好友的，主要测量的是共同好友之间的链接缺失程度。\n ‘dispersion’ — the extent to which two people’s mutual friends are not themselves well-connected. Lars Backstrom \u0026amp; Jon Kleinberg (2013)\n Lars Backstrom \u0026amp; Jon Kleinberg使用了脸书的数据发现，使用残缺度这个度量方式，可以非常准确识别诸如夫妻、男女朋友、恋爱关系。\n如上图中，u和v两个人有a、b、c、d四个共同好友。残缺度主要考察在多大程度上，这些共同好友不能在两步之内到达彼此。如果两个共同好友之间不存在直接连接，且也不存在（除去u和v之外的）共同好友，那么残缺度就增加1。\n以C_{uv}来表示u和v的共同好友之间的链接，那么在上图中只有a、b之间和c、d之间存在链接。a-c, a-d, b-c, b-d四对节点之间既没有直接链接又没有共同好友（除去了u和v)。所以残缺度是4。\n再举一个例子，如果u和v的共同好友b-c之间存在直接的链接。那么残缺度会是多大？如下图：\n因为只有a-d之间没有办法在两步内到达彼此，所以残缺度是1。\n当然了这种定义残缺度的方法是基于节点间的距离的。例如以$$d_{s, t}$$表示共同好友中任意两个节点s和t之间的距离。在这个初始的定义中，两步内不能到达算是关系残缺。那么我们可以将其扩展为3步内不能到达算残缺，或者n步能不能到达算残缺。不过根据Lars Backstrom \u0026amp; Jon Kleinberg的实验，两步不能到达是一个较好的基准。\n如果浪漫关系的确可以由高残缺度刻画，那么说明兔子不吃窝边草在国外是存在的。太熟了下不去手的现象在国内也是存在的。记得一个笑话说：找男女朋友的时候都说找互补的，实际上找到的都是类似的！白富美总是跟高富帅在一起嘛。这应该是对的，人的收入、相貌、工作都是匹配的（match）,从这个角度上讲的确是相似的。但至少从网路结构的角度来说，男女关系依然是互补的！\n参考文献 Lars Backstrom \u0026amp; Jon Kleinberg (2013) Romantic Partnerships and the Dispersion of Social Ties: A Network Analysis of Relationship Status on Facebook.arXiv\n","date":1399248000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1399248000,"objectID":"2ec444428aefd9383a82cced413c1e11","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-05-05-network-dispersion/","publishdate":"2014-05-05T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-05-05-network-dispersion/","section":"post","summary":"","tags":null,"title":"网络残缺度：共同好友间可否两步到达？","type":"post"},{"authors":null,"categories":null,"content":"图1 D3 examples\n###1. 起源 斯坦福学校可视化团队Jeff Heer教授, 那时候的博士生Mike Bostock,那时候的硕士生 Vadim Ogievetsky在2009年创造了Protovis：一个从数据中生成 SVG 图的工具。2011年, Bostock和的老板Heer、师弟Ogievetsky开发了D3.js (Bostock, Heer \u0026amp; Ogievetsky 2011).\n图2 Eyeo 2013 - Mike Bostock\n此后，Mike Bostocks致力于D3的继续开发和维护， Mike的网站http://bost.ocks.org/和github（https://github.com/mbostock/d3）成为发展D3力量的重要领地。仅仅三年，作为一个社区（community)，D3的发展已经蔚为大观。\n###2. D3是什么？ D3是数据驱动文件（Data-Driven Documents）的缩写。作为一个javascript的库，D3(或D3.js)建构于电子数据（digital data）之上，使用数据创造并控制在网络浏览器里运行的动态交互的图形。\nD3必须要嵌入到html网页中，它依赖矢量图像（Scalable Vector Graphics，SVG）、层叠式样式表（Cascading Style Sheets，CSS3)等html的工具来展示图形。\nJavaScript函数来选择（select）元素，生成矢量图（SVG），赋予其样式（style），加入变化。 这种函数式的操作使得D3可以很容易的将大的数据（large dataset,而不是big data）从原始数据格式（json, csv， geoJSON, topoJOSON）转为矢量图对象，并且速度非常快。\nD3拥有自己的哲学，其中很重要的一条是Thinking with Joins。比如，读者与D3制作的图形交互的时候，会激发数据请求（如选择某一个时间段的数据），新的数据进来（data enter），D3的元素（如svg）就会相应的更新（elements update）。数据与元素的互动是由D3编写的Javascript函数指导的，交互之后之后互动结束，读者就看到一个新的图形了。一个例子是使用D3制作的《悲惨世界》中人物的共现关系（Les Misérables Co-occurrence）。这样做的好处是使得动态的图形展示变得简单。\n图3 Thinking with Joins\n3. 学习D3 学习使用D3可以从这个Tutorials开始。\n4. 使用D3绘制网络 因为网络的可视化相对简单，因而发展也比较成熟。R社区很快开发了R包d3network\n5. 使用D3绘制地图 Christchurch 2010 Timeline这个例子正是我想要的。\n一些其它的例子。\nLet’s Make a Map\nA simple d3js map explained\nD3.js workshop II: make beautiful maps \n###参考文献\n Bostock, Michael; Ogievetsky, Vadim; Heer, Jeffrey (October 2011), D3: Data-Driven Documents, IEEE Transactions on Visualization and Computer Graphics, IEEE Press\n","date":1394841600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1394841600,"objectID":"72eef262cc21a8a5f1a41d62c9dc46fb","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-03-15-d3-map/","publishdate":"2014-03-15T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-03-15-d3-map/","section":"post","summary":"","tags":null,"title":"空间分析初步：使用D3可视化","type":"post"},{"authors":null,"categories":null,"content":"引言 空间分析（spatial analysis）对于扩散研究非常重要，它揭示了传播在空间维度上的分布。令人略感惊奇的是空间分析的研究者越来越多地使用R软件。其中一个原因是R包罗万象，而空间分析仍在发展且神情未定。在这个时候难以判定哪种方法最优。此时，策略当然是博观约取。R因其囊括众多统计方法而成为连接不同分析套路的首选；另外在R当中使用者可以继续开发新的数据分析包。可谓一举两得。　数据读入 我使用的是2013年米兰城12月份推特用户的地理信息数据。该数据来自Big Data Challenge of Telecommunication。使用Python写很简单的script从其服务器api接口读取数据:\n# Download milano tweets data using python # chengjun wang @ cmc # 2014 Mar 11 import urllib2 import json f = open('D:/chengjun/Milan/Social pulse/Milano_sample.csv', 'w') for offset in range(0,269290/100 +1): print \u0026quot;working on offset: \u0026quot;, offset req_url = 'https://api.dandelion.eu/datagem/social-pulse-milano/data/v1/?$limit=100\u0026amp;$offset='+str(offset)+'\u0026amp;$app_id=d...a\u0026amp;$app_key=2e...7c' jstr = urllib2.urlopen(req_url).read() # json string \u0026quot;\u0026quot;\u0026quot; these are flickr-specific \u0026quot;\u0026quot;\u0026quot; jinfo = json.loads( jstr ) for i in range(0, len(jinfo['items'])): lan = jinfo['items'][i]['language'] time = jinfo['items'][i]['created'] geo = jinfo['items'][i]['geometry']['coordinates'] timestamp = jinfo['items'][i]['timestamp'] municipality_name = jinfo['items'][i]['municipality']['name'] municipality_id = jinfo['items'][i]['municipality']['acheneID'] entities = jinfo['items'][i]['entities'] user = jinfo['items'][i]['user'] print \u0026gt;\u0026gt;f, \u0026quot;%s;%s;%s;%s;%s;%s;'%s';%s\u0026quot; % (lan, time, geo, timestamp, municipality_name, municipality_id, entities, user) f.close()  首先，读入点的时空分布数据。　# read data library(maptools) library(sp) library(rgdal) setwd(\u0026quot;D:/chengjun/Milan\u0026quot;) dat = read.csv(\u0026quot;./Social pulse/Milano_sample.csv\u0026quot;, header = FALSE, stringsAsFactors = FALSE, sep = \u0026quot;;\u0026quot;, quote = \u0026quot;\u0026quot;) names(dat) = c(\u0026quot;lan\u0026quot;, \u0026quot;time\u0026quot;, \u0026quot;geo\u0026quot;, \u0026quot;timestamp\u0026quot;, \u0026quot;mname\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;entities\u0026quot;, \u0026quot;user\u0026quot;)  进行简单的清洗：\n# clean data dat = subset(dat, dat$time \u0026gt;= as.POSIXlt(\u0026quot;2013-12-01 00:00:00\u0026quot;)); dim(dat) dat$time = do.call(rbind, strsplit(dat$time, split = \u0026quot;\\\\.\u0026quot;))[,1] dat$time = gsub(\u0026quot;T\u0026quot;, \u0026quot; \u0026quot;, dat$time) dat$time = as.POSIXlt(dat$time) dat$geo = gsub(\u0026quot;[\u0026quot;, \u0026quot;\u0026quot;, dat$geo, fixed = T) dat$geo = gsub(\u0026quot;]\u0026quot;, \u0026quot;\u0026quot;, dat$geo, fixed = T)  从openstreetmap下载米兰城的交通地理信息。使用rgdal这个R包读入数据：\n# download shp data from # http://metro.teczno.com/#milan ost=readOGR(\u0026quot;./Milano Grid/milano-grid/milan.imposm-shapefiles/milan.osm-mainroads.shp\u0026quot;, layer = \u0026quot;milan.osm-mainroads\u0026quot;) #will load the shapefile  要把地理信息转为经纬度的数据表示形式：\nspl = spTransform(ost, CRS(\u0026quot;+proj=longlat\u0026quot;)) # convert to longitude and latitude  如果要画出spl的话，速度有点慢, 因为绘制的点比较多。\n用了其中一个小数据(涵盖一天中的几个小时)，为了展现了每个小时的动态变化，使用CartoDB网站来制作了一个简单的可视化。顺便找了一遍各种javascript的库和其它包（googleVis, Echarts等），发现都不实用，所以还是用R吧。\n设置绘图的函数，来看一下数据的形式：\n# plot function make_plot = function(){ tz = as.POSIXlt(\u0026quot;2013-12-01 00:00:00\u0026quot;) end_time = as.POSIXlt(\u0026quot;2013-12-02 00:00:00\u0026quot;) while(tz \u0026lt;= end_time){ print(tz) datd = subset(dat, dat$time \u0026gt; tz\u0026amp; dat$time \u0026lt;= tz + 3600) plot(spl, col = \u0026quot;pink\u0026quot;) title(tz) p = do.call(rbind, strsplit(datd$geo, split=',')) p1 = as.numeric(p[,1]) p2 = as.numeric(p[,2]) points(p2~p1, pch = 1, col = \u0026quot;red\u0026quot;, cex = 0.1) tz = tz + 3600 } } # save figures png(file = \u0026quot;./linear%2d.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) make_plot() dev.off()  读者也可以直接使用animation这个R包来绘图。我在实验室的机器上安装ImageMagick有点问题，干脆存为图片了，再转为gif了。\n图1 米兰城一天当中的发推特的时空分布\n把12月31天的数据累积起来，我们可以得到米兰城2013年12月当中的发推特的空间分布。\n# the overall geographical distribution png(\u0026quot;./milano_social_pulse_December.png\u0026quot;, width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) plot(spl, col = \u0026quot;purple\u0026quot;) p = do.call(rbind, strsplit(dat$geo, split=',')) p1 = as.numeric(p[,1]) p2 = as.numeric(p[,2]) points(p2~p1, pch = 1, col = \u0026quot;red\u0026quot;, cex = 0.01) dev.off()  图2 米兰城2013年12月当中的发推特的空间分布\n这个图还是有点意思的：街道是城市人流的管道（Tube,伦敦好像把地铁直接称为tube）,人的移动等行为（包括社会媒体使用行为）则是穿行其间的流。推特聚集的地方与街道的轮廓高度契合。城市的中心推特的密度大（因为人流的密度大？）。所以可以检验下点的分布是否是随机的。\n空间点类型分析 这里涉及到空间点类型分析（spatial point pattern analysis）。检验下点的分布是否是随机的最简单的方法是进行完全空间随机（complete spatial randomness， CSR）分析。\nG方程方法\n这里说的最近邻居，英文当中却成为nearest event。把一个点的存在称之为事件也挺好玩。我们知道两个节点$$E_i$$和$$E_j$$的距离为:\n$$d(E_i, E_j) = \\sqrt{(x_i - x_j)^2 + (y_i-y_j)^2}$$\n平均最近邻居距离可以表示为:\n$$\\overline{d}{min} = \\frac{\\sum{i}^{n}d_{min}(X_i)}{n}$$\n于是可以定义事件-事件最近邻居距离，即任意一个事件到它的最近事件之间的距离。任意一个事件$$E_i$$的事件-事件最近邻居距离：\n$$d_i = {min}j {d{ij}, \\forall j\\neq i }$$\n对于一个距离d, 可定义G(d)为最近邻居距离的累计频数分布：\n$$ G(d) = \\frac{# d_{min}E_i\u0026lt;d}{n} $$\n说以G方程方法测量的最近邻居距离小于d的事件的比率。当事件分布存在聚集的情况的时候，G在距离较小的时候就增长特别快；当事件分布均匀时，距离较小的时候G增长缓慢，当距离达到使得多数事件分隔的大小后，G开始快速增长。\nF方程方法\n另外一个有用的测度是F方程。F方程测量了从空间中任意一个点到与它最近的事件之间的距离，因而它测量的是点-事件最近邻居距离。据此，F方程也被称之为空虚空间距离。\n计算F方程或点-事件距离的时候要先随机的抽取一些空间中的点, 计算它的最短距离，然后统计其中满足最短距离小于d的比率。\n$$F(d) = \\frac{#d_{min}(x_i\u0026lt;d)}{m}$$\n因为F方程是随机抽取空间中的点来统计，因而可以应对较大的数据规模。一个小的事件的聚集会导致G方程快速增长，但其实其它多数空间都是空的，所以F方程增长会较慢。当然了，对于规则分布的点，这种对比的结果则可能相反。\n使用G和F方程可以测量事件分布的实际情况，我们的零假设是事件分布是随机的，符合泊松分布:\n$$f(k, \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$\n用$$\\lambda$$表示事件的空间分布密度，在一个半径为d的平面$$\\pi d^2$$里面理论上存在的事件数量是$$\\lambda \\pi d^2$$。\n此处推导略去（汗，我不会啊。），那么G和F的理论值按照泊松分布应该是：\n$$G = F = 1-e^{-\\lambda \\pi d^2}$$\n有了理论值，有了实际值，我们就可以对比二者之间的差距。进而推论空间事件的点分布是否是随机的了。\n这个推断的过程使用spatstat这个R包进行：\nrequire(spatstat) #the analysis of point patterns geo = data.frame(dat$p1, dat$p2) # Convert data to ppp format geo_ppp = ppp(geo[,1], geo[,2], c(min(geo[,1]), max(geo[,1])), c(min(geo[,2]), max(geo[,2])) ) # slow # G function method g = Gest(geo_ppp) plot(g) # F function method f = Fest(geo_ppp) plot(f)  这里可以使用envelope的方法，使用蒙特卡洛的方法，根据一些算法来随机生成n个（比如100个）数据，以保证分析的准确性。\ng = envelope(geo_ppp, Gest, nsim = 100) plot(g)  f = envelope(geo_ppp, Fest, nsim = 100) plot(f)  显然发推特的空间位置的分布并非随机的，具有较明显的聚集现象，所以G方程一开始就增长很快，而虚空空间函数F方程则增长缓慢。\n空间点过程分析 这毕竟还是有点不够形象，有没有高大上的形象的方法？试试kernel smoother of point density:\nplot(density.ppp(geo_ppp), main = \u0026quot;\u0026quot;)  注意density.ppp返回的不是一个概率密度。它是对点密度的估计。密度是每个单位空间里随机点的期望。密度通常与空间位置有关。使用空间面积对密度函数积分，得到的是落入该区域的点的数量。\n于是乎，规律就更明显了：不仅仅是简单的点聚集，而且是箭靶形式的聚集，像北京环城路一样。越是中心，点就越密集。\n不过不要高兴太早，因为这个结果还是太粗糙。我们明明看到点的聚集情况并非如此完美的圆环。因为使用kernel平滑方法估计点的密度这种方法对于频宽（bandwidth）的大小特别敏感。有必要加以控制。另外，这里涉及到两种kernel的方法：四次多项式平滑和高斯平滑。这里要使用splancs这个R包。\n############## \u0026quot;quartic and Gaussian kernels\u0026quot; ############## library(splancs)  抱怨一下，因为以下用到的bw.diggle这个用来为kernel密度来选择经过交叉检验的频宽（Cross Validated Bandwidth Selection for Kernel Density）的命令，我不得不使用部分数据，因为它实在太消耗内存了。\n# subset a week-long small data dat1 = subset(dat, dat$day \u0026gt;=as.Date(\u0026quot;2013-12-01\u0026quot;)\u0026amp;dat$day \u0026lt;=as.Date(\u0026quot;2013-12-07\u0026quot;)) geo = data.frame(dat1$p1, dat1$p2) geo_ppp = ppp(geo[,1], geo[,2], c(min(geo[,1]), max(geo[,1])), c(min(geo[,2]), max(geo[,2])) ) # slow ## Quartic kernel mserwq\u0026lt;-mse2d(as.points(coordinates(geo)), as.points(list(x=c(0,1,1,0), y=c(0,0,1,1))), 100, range = .001) # flexible range bwq\u0026lt;-mserwq$h[which.min(mserwq$mse)] bwq ## Gaussian kernel mserw\u0026lt;-bw.diggle(as(geo_ppp, \u0026quot;ppp\u0026quot;)) # Reached total allocation of 32765Mb: see help(memory.size) bw\u0026lt;-as.numeric(mserw) bw \u0026quot;plot the Mean Square Error-Bandwidth\u0026quot; par(mfrow=c(1, 2)) plot(mserwq$h, mserwq$mse, xlab=\u0026quot;Bandwidth\u0026quot;, ylab=\u0026quot;MSE\u0026quot;, type=\u0026quot;l\u0026quot;, main=\u0026quot;Quartic kernel\u0026quot;) i\u0026lt;-which.min(mserwq$mse) points(mserwq$h[i], mserwq$mse[i], col = \u0026quot;red\u0026quot;) plot(mserw, main=\u0026quot;Gaussian kernel\u0026quot;, xlab=\u0026quot;Bandwidth\u0026quot;, ylab=\u0026quot;MSE\u0026quot;) points(attr(mserw, \u0026quot;h\u0026quot;)[attr(mserw, \u0026quot;iopt\u0026quot;)], bw, col = \u0026quot;red\u0026quot;)  看，最优化的频宽选择并不太有用，不过频宽真得很小。\ngeos = SpatialPointsDataFrame(geo, geo) poly = as.points(list(x = c(0, 0, 1, 1), y = c(0, 1, 1, 0))) sG \u0026lt;- Sobj_SpatialGrid(geos, maxDim=100)$SG grd \u0026lt;- slot(sG, \u0026quot;grid\u0026quot;) summary(grd) # k0 \u0026lt;- spkernel2d(geos, poly, h0=bw, grd) # k1 \u0026lt;- spkernel2d(geos, poly, h0=.05, grd) # k2 \u0026lt;- spkernel2d(geos, poly, h0=.1, grd) # k3 \u0026lt;- spkernel2d(geos, poly, h0=.15, grd) # df \u0026lt;- data.frame(k0=k0, k1=k1, k2=k2, k3=k3) # kernels \u0026lt;- SpatialGridDataFrame(grd, data=df) # summary(kernels) # 这里都是NA,四次多项式的结果并不好 ################################## cc \u0026lt;- coordinates(sG); head(cc) xy\u0026lt;-list(x=cc[,1], y=cc[,2]) k0\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw, dimyx=c(100, 100), xy=xy) k1\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*200, dimyx=c(100, 100), xy=xy) k2\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*500, dimyx=c(100, 100), xy=xy) k3\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*600, dimyx=c(100, 100), xy=xy) k4\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*800, dimyx=c(100, 100), xy=xy) k5\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*1000, dimyx=c(100, 100), xy=xy) k6\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*1500, dimyx=c(100, 100), xy=xy) k7\u0026lt;-density(as(geos, \u0026quot;ppp\u0026quot;), .5*bw*2000, dimyx=c(100, 100), xy=xy) \u0026quot;plot the MSE-Bandwidth\u0026quot; png(file = \u0026quot;./gaussian_kernel_density_first_week_in_december2.png\u0026quot;, width=8, height=16, units=\u0026quot;in\u0026quot;, res=700) par(mfrow=c(4, 2), mar=rep(1, 4)) plot(k0) plot(k1) plot(k2) plot(k3) plot(k4) plot(k5) plot(k6) plot(k7) dev.off()  这里列出几个比较小的频宽的核密度图：这与我们的观察比较一致。\n# kernels$k7\u0026lt;-as(k7, \u0026quot;SpatialGridDataFrame\u0026quot;)$v df \u0026lt;- data.frame(k0=k0, k1=k1, k2=k2, k3=k3, k4=k4, k5=k5， k6 = k6, k7 = k7) kernels \u0026lt;- SpatialGridDataFrame(grd, data=df) summary(kernels)  参考文献\n Lloyd，D.C.(2007) Local Models for Spatial Analysis. CRC press\nBaddeley, A. (2010) Analysing spatial point patterns in R. Workshop notes. CSIRO online technical publication. URL: www.csiro.au/resources/pf16h.html\nDiggle, P.J. (1985) A kernel method for smoothing point process data. Applied Statistics (Journal of the Royal Statistical Society, Series C) 34 (1985) 138–147.\nDiggle, P.J. (2003) Statistical analysis of spatial point patterns, Second edition. Arnold.\n","date":1394582400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1394582400,"objectID":"df27644028e5d2b737c1615a793e0355","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-03-12-first-step-spatial-analysis-with-r/","publishdate":"2014-03-12T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-03-12-first-step-spatial-analysis-with-r/","section":"post","summary":"","tags":null,"title":"空间分析初步：空间点类型分析","type":"post"},{"authors":null,"categories":null,"content":" Here are a few tips for migrating an existing website from Jekyll to Hugo. These tips can be applied in conjunction with following Hugo Academic\u0026rsquo;s [getting started guide].\nMove static content to static Jekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/ ▾ images/ logo.png  should become\n▾ \u0026lt;root\u0026gt;/ ▾ static/ ▾ images/ logo.png  Additionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nFix content Depending on the amount of customization that was done for each post in Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch and the Hugo Academic example site are your friends. Test your changes and fix errors as needed.\nPublish The default is for Jekyll to publish the website to a _site directory, whereas Hugo publishes to a public directory.\nA practical example Alexandre Normand migrated his website from Jekyll to Hugo in less than a day. You can see all his changes by looking at this GitHub diff. However, bear in mind that this example is not specific to the Academic theme nor does it use the latest version of Hugo.\n","date":1394380800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1394380800,"objectID":"783948818dc5db3c6cea9afeefe0fd16","permalink":"https://chengjunwang.com/zh/zh/post/migrate-from-jekyll/","publishdate":"2014-03-10T00:00:00+08:00","relpermalink":"/zh/zh/post/migrate-from-jekyll/","section":"zh","summary":"Learn how to migrate an existing website from Jekyll to Hugo.\n","tags":["jekyll"],"title":"Migrate from Jekyll to Hugo","type":"zh"},{"authors":null,"categories":null,"content":" Here are a few tips for migrating an existing website from Jekyll to Hugo. These tips can be applied in conjunction with following Hugo Academic\u0026rsquo;s [getting started guide].\nMove static content to static Jekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/ ▾ images/ logo.png  should become\n▾ \u0026lt;root\u0026gt;/ ▾ static/ ▾ images/ logo.png  Additionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nFix content Depending on the amount of customization that was done for each post in Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch and the Hugo Academic example site are your friends. Test your changes and fix errors as needed.\nPublish The default is for Jekyll to publish the website to a _site directory, whereas Hugo publishes to a public directory.\nA practical example Alexandre Normand migrated his website from Jekyll to Hugo in less than a day. You can see all his changes by looking at this GitHub diff. However, bear in mind that this example is not specific to the Academic theme nor does it use the latest version of Hugo.\n","date":1394380800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1394380800,"objectID":"b4f386db3024374b17c5853e24a09975","permalink":"https://chengjunwang.com/zh/post/migrate-from-jekyll/","publishdate":"2014-03-10T00:00:00+08:00","relpermalink":"/zh/post/migrate-from-jekyll/","section":"post","summary":"Learn how to migrate an existing website from Jekyll to Hugo.\n","tags":["jekyll"],"title":"Migrate from Jekyll to Hugo","type":"post"},{"authors":null,"categories":null,"content":"与普通的扩散研究不同，网络扩散开始考虑网络结构对于扩散过程的影响。\n这里介绍一个使用R模拟网络扩散的例子。基本的算法非常简单：\n 生成一个网络:g(V, E)。 随机选择一个或几个节点作为种子（seeds）。 每个感染者以概率p（可视作该节点的传染能力,通常表示为$$\\beta$$）影响与其相连的节点。  其实这是一个最简单的SI模型在网络中的实现。S表示可感染（susceptible）, I表示被感染（infected）。SI模型描述了个体的状态从S到I之间的转变。因为形式简单，SI模型是可以求出其解析解的。考虑一个封闭的群体，没有出生、死亡和迁移。并假设个体是均匀混合的（homogeneous mixing),也就是要求个体的地理分布均匀，且被感染的概率也相同(T. G. Lewis, 2011)。那么β表示传染率（transmission rate)。SI模型可以表达为：\n$$\\frac{dS}{dt}=-\\beta SI$$\n$$\\frac{dI}{dt}=\\beta SI$$\n且满足 I + S = 1，那么以上方程$$\\frac{dI}{dt}=\\beta SI$$可以表达为：\n$$\\frac{dI}{dt}=\\beta I(1-I)$$\n解这个微分方程，我们可以得到累计增长曲线的表达式。有趣的是，这是一个logistic增长，具有明显的S型曲线（S-shaped curve）特征。该模型在初期跨越临界点之后增长较快，后期则变得缓慢。 因而可以用来描述和拟合创新扩散过程（diffusion of innovations）。\n当然，对疾病传播而言，SI模型是非常初级的（naive），主要因为受感染的个体以一定的概率恢复健康，或者继续进入可以被感染状态(S，据此扩展为SIS模型)或者转为免疫状态（R,据此扩展为SIR模型）。 免疫表示为R，用$$\\gamma$$代表免疫概率（removal or recovery rate)。对于信息扩散而言，这种考虑暂时是不需要的。\n第一步，生成网络。\nrequire(igraph) # generate a social graph size = 50 # 规则网 g = graph.tree(size, children = 2); plot(g) g = graph.star(size); plot(g) g = graph.full(size); plot(g) g = graph.ring(size); plot(g) g = connect.neighborhood(graph.ring(size), 2); plot(g) # 最近邻耦合网络 # 随机网络 g = erdos.renyi.game(size, 0.1) # 小世界网络 g = rewire.edges(erdos.renyi.game(size, 0.1), prob = 0.8 ) # 无标度网络 g = barabasi.game(size) ; plot(g)  第二步，随机选取一个或n个种子。\n# initiate the diffusers seeds_num = 1 set.seed(2014); diffusers = sample(V(g),seeds_num) ; diffusers infected =list() infected[[1]]= diffusers  第三步，在这个简单的例子中，每个节点的传染能力是0.5，即与其相连的节点以0.5的概率被其感染。在R中的实现是通过抛硬币的方式来实现的。\n# for example, set percolation probability = 0.5 coins = c(0,1) n = length(coins) sample(coins, 1, replace=TRUE, prob=rep(1/n, n))  显然，这很容易扩展到更一般的情况，比如节点的平均感染能力是0.128，那么可以这么写：\np = 0.128 coins = c(rep(1, p*1000), rep(0,(1-p)*1000)) n = length(coins) sample(coins, 1, replace=TRUE, prob=rep(1/n, n))  当然最重要的一步是要能按照“时间”更新网络节点被感染的信息。\n# function for updating the diffusers update_diffusers = function(diffusers){ nearest_neighbors = neighborhood(g, 1, diffusers) nearest_neighbors = data.frame(table(unlist(nearest_neighbors))) nearest_neighbors = subset(nearest_neighbors, !(nearest_neighbors[,1]%in%diffusers)) # toss the coins toss = function(freq) { tossing = NULL for (i in 1:freq ) tossing[i] = sample(coins, 1, replace=TRUE, prob=rep(1/n, times=n)) tossing = sum(tossing) return (tossing) } keep = unlist(lapply(nearest_neighbors[,2], toss)) new_infected = as.numeric(as.character(nearest_neighbors[,1][keep \u0026gt;= 1])) diffusers = unique(c(diffusers, new_infected)) return(diffusers) }  完成了以上三步。准备好了吗，现在开始开启扩散过程！\n## Start the contagion! i = 1 while(length(infected[[i]]) \u0026lt; size){ infected[[i+1]] = sort(update_diffusers(infected[[i]])) cat(length(infected[[i+1]]), \u0026quot;\\n\u0026quot;) i = i + 1 }  先看看S曲线吧：\n# \u0026quot;growth_curve\u0026quot; num_cum = unlist(lapply(1:i, function(x) length(infected［x］) )) p_cum = num_cum/max(num_cum) time = 1:i png(file = \u0026quot;./temporal_growth_curve.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=300) plot(p_cum~time, type = \u0026quot;b\u0026quot;) dev.off()  为了可视化这个扩散的过程，我们用红色来标记被感染者。\n# generate a palette E(g)$color = \u0026quot;blueviolet\u0026quot; V(g)$color = \u0026quot;white\u0026quot; set.seed(2014); layout.old = layout.fruchterman.reingold(g) V(g)$color[V(g)%in%diffusers] = \u0026quot;red\u0026quot; plot(g, layout =layout.old)  使用谢益辉开发的animation的R包可视化。\nlibrary(animation) saveGIF({ ani.options(interval = 0.5, convert = shQuote(\u0026quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe\u0026quot;)) # start the plot m = 1 while(m \u0026lt;= length(infected)){ V(g)$color = \u0026quot;white\u0026quot; V(g)$color[V(g)%in%infected[[m]]] = \u0026quot;red\u0026quot; plot(g, layout =layout.old) m = m + 1} })  如同在Netlogo里一样，我们可以把网络扩散与增长曲线同时展示出来：\nsaveGIF({ ani.options(interval = 0.5, convert = shQuote(\u0026quot;C:/Program Files/ImageMagick-6.8.8-Q16/convert.exe\u0026quot;)) # start the plot m = 1 while(m \u0026lt;= length(infected)){ # start the plot layout(matrix(c(1, 2, 1, 3), 2,2, byrow = TRUE), widths=c(3,1), heights=c(1, 1)) V(g)$color = \u0026quot;white\u0026quot; V(g)$color[V(g)%in%infected[[m]]] = \u0026quot;red\u0026quot; num_cum = unlist(lapply(1:m, function(x) length(infected[[x]]) )) p_cum = num_cum/size p = diff(c(0, p_cum)) time = 1:m plot(g, layout =layout.old, edge.arrow.size=0.2) title(paste(\u0026quot;Scale-free Network \\n Day\u0026quot;, m)) plot(p_cum~time, type = \u0026quot;b\u0026quot;, ylab = \u0026quot;CDF\u0026quot;, xlab = \u0026quot;Time\u0026quot;, xlim = c(0,i), ylim =c(0,1)) plot(p~time, type = \u0026quot;h\u0026quot;, ylab = \u0026quot;PDF\u0026quot;, xlab = \u0026quot;Time\u0026quot;, xlim = c(0,i), ylim =c(0,1), frame.plot = FALSE) m = m + 1} }, ani.width = 800, ani.height = 500)  ","date":1393545600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1393545600,"objectID":"58b92ca0bcb845caa044a79c5aa3006b","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2014-02-28-simulate-network-diffusion-with-r/","publishdate":"2014-02-28T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2014-02-28-simulate-network-diffusion-with-r/","section":"post","summary":"","tags":null,"title":"使用R模拟网络扩散","type":"post"},{"authors":null,"categories":null,"content":"邱怡轩在统计之都中展示了对宋词进行的分析（参见http://cos.name/tag/%E5%AE%8B%E8%AF%8D/），因为当时缺乏中文分词的工具，他独辟蹊径，假设宋词中任意两个相邻的汉字构成一个词语，进而找到了宋词当中的高频词。本文则尝试使用他所提供的宋词语料（http://cos.name/wp-content/uploads/2011/03/SongPoem.tar.gz），分析一下使用R进行中文分词、构建词云、高频词语聚类以及主题模型分析。\n首先要载入使用的R包并读入数据。\nlibrary(Rwordseg) require(rJava) library(tm) library(slam) library(topicmodels) library(wordcloud) library(igraph) setwd(\u0026quot;D:/github/text mining/song\u0026quot;) # 更改为你的工作路径，并存放数据在此。 txt=read.csv(\u0026quot;SongPoem.csv\u0026quot;,colClasses=\u0026quot;character\u0026quot;)  {:lang=\u0026laquo;ruby\u0026raquo;}\n然后进行对数据的操作。当然，第一步是进行中文分词，主要使用Rwordseg这个R包，其分词效果不错。分词的过程可以自动去掉标点符号。\npoem_words \u0026lt;- lapply(1:length(txt$Sentence), function(i) segmentCN(txt$Sentence[i], nature = TRUE))  {:lang=\u0026laquo;ruby\u0026raquo;}\n然后，我们将数据通过tm这个R包转化为文本-词矩阵（DocumentTermMatrix）。 wordcorpus \u0026lt;- Corpus(VectorSource(poem_words), encoding = \u0026laquo;UTF-8\u0026raquo;) # 组成语料库格式\nSys.setlocale(locale=\u0026quot;Chinese\u0026quot;) dtm1 \u0026lt;- DocumentTermMatrix(wordcorpus, control = list( wordLengths=c(1, Inf), # to allow long words bounds = list(global = c(5,Inf)), # each term appears in at least 5 docs removeNumbers = TRUE, # removePunctuation = list(preserve_intra_word_dashes = FALSE), weighting = weightTf, encoding = \u0026quot;UTF-8\u0026quot;) ) colnames(dtm1) findFreqTerms(dtm1, 1000) # 看一下高频词  {:lang=\u0026laquo;ruby\u0026raquo;}\n这里需要注意的是，这里我们默认词语的长度为1到无穷大，稍后，我们可以对其长度进行修改。例如，本文中，作者对改为长度为2以上以及长度为3以上，分别得到另外两个文本-词矩阵：dtm2和dtm3。随后，我们可以在文本-词矩阵进行一系列的分析。这里，先做一个简单的词云分析。为更好展示效果，最多只列出100个词。\nm \u0026lt;- as.matrix(dtm1) v \u0026lt;- sort(colSums(m), decreasing=TRUE) myNames \u0026lt;- names(v) d \u0026lt;- data.frame(word=myNames, freq=v) par(mar = rep(2, 4)) png(paste(getwd(), \u0026quot;/wordcloud50_\u0026quot;, \u0026quot;.png\u0026quot;, sep = ''), width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) pal2 \u0026lt;- brewer.pal(8,\u0026quot;Dark2\u0026quot;) wordcloud(d$word,d$freq, scale=c(5,.2), min.freq=mean(d$freq), max.words=100, random.order=FALSE, rot.per=.15, colors=pal2) dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n我们可以看一下效果，如下图所示，主要是一个字长度的词。最多的是“人”和“不”， 然后是“春”和“花”。\n但我们也许对长度大于2的词以及长度大于3的词更感兴趣（同时这样也可以和邱怡轩做的结果做一下比较）。使用前面步骤中生成的dtm2重复构建词云的R程序，我们可以得到以下两个词云：\n同样，对dtm3构建词云，效果如下：\n以上结果和邱怡轩得到的结果类似，可见对高频词的处理方面，他的方法的确有创见。对词云分析之后，我们还可以尝试根据词与词之间共同出现的概率对词进行聚类。这里我们展示长度大于2的词的聚类结果。\ndtm01 \u0026lt;- weightTfIdf(dtm2) N = 0.9 dtm02 \u0026lt;- removeSparseTerms(dtm01, N);dtm02 # 注意，为展示方便，这里我调节N的大小，使得dtm02中的词语数量在50左右。 tdm = as.TermDocumentMatrix(dtm02) tdm \u0026lt;- weightTfIdf(tdm) # convert the sparse term-document matrix to a standard data frame mydata.df \u0026lt;- as.data.frame(inspect(tdm)) mydata.df.scale \u0026lt;- scale(mydata.df) d \u0026lt;- dist(mydata.df.scale, method = \u0026quot;euclidean\u0026quot;) # distance matrix fit \u0026lt;- hclust(d, method=\u0026quot;ward\u0026quot;) png(paste(\u0026quot;d:/chengjun/honglou/honglou_termcluster_50_\u0026quot;, \u0026quot;.png\u0026quot;, sep = ''), width=10, height=10, units=\u0026quot;in\u0026quot;, res=700) plot(fit) # display dendogram? dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n对长度大于2的词的聚类结果如下图所示，可见宋词的确注重“风流倜傥”，连分类都和风向有关系。\n当然读者还可以尝试对长度大于1词和长度大于3的词聚类，对长度大于1词聚类的效果图如下所示：\n长度大于3的词聚类结果如下：\n完成这一步之后，作者还尝试对宋词进行简单的主题模型分析，首先还是从长度大于2的词开始吧。第一步是确定主题的数量。先对文本-词矩阵进行简单处理，以消除高频词被高估和低频词被低估的问题。\ndtm = dtm2 term_tfidf \u0026lt;-tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) * log2(nDocs(dtm)/col_sums(dtm \u0026gt; 0)) l1=term_tfidf \u0026gt;= quantile(term_tfidf, 0.5) # second quantile, ie. median dtm \u0026lt;- dtm[,l1] dtm = dtm[row_sums(dtm)\u0026gt;0, ]; dim(dtm) # 2246 6210 summary(col_sums(dtm))  {:lang=\u0026laquo;ruby\u0026raquo;}\n之后就可以正式地开始确定主题数量的R程序了。这里，笔者主要参考了朱雪宁《微博名人那些事儿》一文中的R程序（http://cos.name/2013/08/something_about_weibo/）。\nfold_num = 10 kv_num = c(5, 10*c(1:5, 10)) seed_num = 2003 try_num = 1 smp\u0026lt;-function(cross=fold_num,n,seed) { set.seed(seed) dd=list() aa0=sample(rep(1:cross,ceiling(n/cross))[1:n],n) for (i in 1:cross) dd[[i]]=(1:n)[aa0==i] return(dd) } selectK\u0026lt;-function(dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp) # change 60 to 15 { per_ctm=NULL log_ctm=NULL for (k in kv) { per=NULL loglik=NULL for (i in 1:try_num) #only run for 3 replications# { cat(\u0026quot;R is running for\u0026quot;, \u0026quot;topic\u0026quot;, k, \u0026quot;fold\u0026quot;, i, as.character(as.POSIXlt(Sys.time(), \u0026quot;Asia/Shanghai\u0026quot;)),\u0026quot;\\n\u0026quot;) te=sp[[i]] tr=setdiff(1:dtm$nrow, te) # setdiff(nrow(dtm),te) ## fix here when restart r session # VEM = LDA(dtm[tr, ], k = k, control = list(seed = SEED)), # VEM_fixed = LDA(dtm[tr,], k = k, control = list(estimate.alpha = FALSE, seed = SEED)), # CTM = CTM(dtm[tr,], k = k, # control = list(seed = SEED, var = list(tol = 10^-4), em = list(tol = 10^-3))) # Gibbs = LDA(dtm[tr,], k = k, method = \u0026quot;Gibbs\u0026quot;, control = list(seed = SEED, burnin = 1000,thin = 100, iter = 1000)) per=c(per,perplexity(Gibbs,newdata=dtm[te,])) loglik=c(loglik,logLik(Gibbs,newdata=dtm[te,])) } per_ctm=rbind(per_ctm,per) log_ctm=rbind(log_ctm,loglik) } return(list(perplex=per_ctm,loglik=log_ctm)) } sp=smp(n=dtm$nrow, seed=seed_num) # n = nrow(dtm) system.time((ctmK=selectK(dtm=dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp=sp))) ## plot the perplexity m_per=apply(ctmK[[1]],1,mean) m_log=apply(ctmK[[2]],1,mean) k=c(kv_num) df = ctmK[[1]] # perplexity matrix logLik = ctmK[[2]] # perplexity matrix write.csv(data.frame(k, df, logLik), paste(getwd(), \u0026quot;/Perplexity2_\u0026quot;,\u0026quot;gibbs5_100\u0026quot;, \u0026quot;.csv\u0026quot;, sep = \u0026quot;\u0026quot;)) # save the figure png(paste(getwd(), \u0026quot;/Perplexity2_\u0026quot;,try_num, \u0026quot;_gibbs5_100\u0026quot;,\u0026quot;.png\u0026quot;, sep = ''), width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) matplot(k, df, type = c(\u0026quot;b\u0026quot;), xlab = \u0026quot;Number of topics\u0026quot;, ylab = \u0026quot;Perplexity\u0026quot;, pch=1:try_num,col = 1, main = '') legend(\u0026quot;topright\u0026quot;, legend = paste(\u0026quot;fold\u0026quot;, 1:try_num), col=1, pch=1:try_num) dev.off() png(paste(getwd(), \u0026quot;/LogLikelihood2_\u0026quot;, \u0026quot;gibbs5_100\u0026quot;,\u0026quot;.png\u0026quot;, sep = ''), width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) matplot(k, logLik, type = c(\u0026quot;b\u0026quot;), xlab = \u0026quot;Number of topics\u0026quot;, ylab = \u0026quot;Log-Likelihood\u0026quot;, pch=1:try_num,col = 1, main = '') legend(\u0026quot;topright\u0026quot;, legend = paste(\u0026quot;fold\u0026quot;, 1:try_num), col=1, pch=1:try_num) dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n于是可以得到对数似然率和主题数量的关系图，如下所示。可见选择10作为主题数量是比较合适的。\n以下，我们将主要对主题数量为10的主题模型进行估计。topicmodels这个R包是由Bettina Grun和 Johannes Kepler两个人贡献的，目前支持VEM, VEM (fixed alpha)，Gibbs和CTM四种主题模型，关于其详细介绍，可以阅读他们的论文，关于主题模型的更多背景知识可以阅读Blei的相关文章。闲话少叙，看一下R代码：\n# 'Refer to http://cos.name/2013/08/something_about_weibo/' k = 10 SEED \u0026lt;- 2003 jss_TM2 \u0026lt;- list( VEM = LDA(dtm, k = k, control = list(seed = SEED)), VEM_fixed = LDA(dtm, k = k, control = list(estimate.alpha = FALSE, seed = SEED)), Gibbs = LDA(dtm, k = k, method = \u0026quot;Gibbs\u0026quot;, control = list(seed = SEED, burnin = 1000, thin = 100, iter = 1000)), CTM = CTM(dtm, k = k, control = list(seed = SEED, var = list(tol = 10^-4), em = list(tol = 10^-3))) ) save(jss_TM2, file = paste(getwd(), \u0026quot;/jss_TM2.Rdata\u0026quot;, sep = \u0026quot;\u0026quot;)) save(jss_TM, file = paste(getwd(), \u0026quot;/jss_TM1.Rdata\u0026quot;, sep = \u0026quot;\u0026quot;)) termsForSave1\u0026lt;- terms(jss_TM2[[\u0026quot;VEM\u0026quot;]], 10) termsForSave2\u0026lt;- terms(jss_TM2[[\u0026quot;VEM_fixed\u0026quot;]], 10) termsForSave3\u0026lt;- terms(jss_TM2[[\u0026quot;Gibbs\u0026quot;]], 10) termsForSave4\u0026lt;- terms(jss_TM2[[\u0026quot;CTM\u0026quot;]], 10) write.csv(as.data.frame(t(termsForSave1)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_VEM_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;) write.csv(as.data.frame(t(termsForSave2)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_VEM_fixed_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;) write.csv(as.data.frame(t(termsForSave3)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_Gibbs_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;) write.csv(as.data.frame(t(termsForSave4)), paste(getwd(), \u0026quot;/topic-document_\u0026quot;, \u0026quot;_CTM_\u0026quot;, k, \u0026quot;_2.csv\u0026quot;, sep=\u0026quot;\u0026quot;), fileEncoding = \u0026quot;UTF-8\u0026quot;)  {:lang=\u0026laquo;ruby\u0026raquo;}\n对主题模型进行估计之后，一般选择展示每个主题的前10个词语。因为主题之间可以共享相同词语，所以构成网络关系，因此这里我选择用网络的方法展示其结果。首先看一下吉布斯抽样算法得到的主题网络图，其R程序如下：\n#'topic graphs' tfs = as.data.frame(termsForSave3, stringsAsFactors = F); tfs[,1] adjacent_list = lapply(1:10, function(i) embed(tfs[,i], 2)[, 2:1]) edgelist = as.data.frame(do.call(rbind, adjacent_list), stringsAsFactors =F) # topic = unlist(lapply(1:10, function(i) rep(i, 9))) edgelist$topic = topic g \u0026lt;-graph.data.frame(edgelist,directed=T ) l\u0026lt;-layout.fruchterman.reingold(g) # edge.color=\u0026quot;black\u0026quot; nodesize = centralization.degree(g)$res V(g)$size = log( centralization.degree(g)$res ) nodeLabel = V(g)$name E(g)$color = unlist(lapply(sample(colors()[26:137], 10), function(i) rep(i, 9))); unique(E(g)$color) # 保存图片格式 png( paste(getwd(), \u0026quot;/topic_graph_gibbs.png\u0026quot;, sep=\u0026quot;\u0026quot;）, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) plot(g, vertex.label= nodeLabel, edge.curved=TRUE, vertex.label.cex =0.5, edge.arrow.size=0.2, layout=l ) # 结束保存图片 dev.off()  {:lang=\u0026laquo;ruby\u0026raquo;}\n得到的图形如下：\n当然，我们还可以看一下其他算法得到的网络图，这里我们看一下根据VEM和CTM两个主题模型得到的网络图。\nCTM模型的主题网络图：\nVEM模型的主题网络图：\n","date":1380240000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1380240000,"objectID":"2a554f0d23f5b7ab51674e80c5669c9b","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-27-topic-modeling-of-song-peom/","publishdate":"2013-09-27T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2013-09-27-topic-modeling-of-song-peom/","section":"post","summary":"","tags":null,"title":"东风夜放花千树：对宋词进行主题分析初探","type":"post"},{"authors":null,"categories":null,"content":"使用主题模型（topic models）可以较为高效地划分文本的主题，但一个不得不面对的问题是有时候主题的划分过细，使得解读和归类成为困难。其实，聚类分析作为一个“古老”的分析方法可以较为简洁的解决这个问题。\n举一个小例子，我们主要使用tm这个R包来完成文本挖掘的前期任务。在得到DocumentTermMatrix之后，可以通过计算cosine 相似度的方法来计算文本之间的不一致性（dissimilarity）。\n# Using cluster analysis to classify topics generated by topic modeling # 2013 Sep 08 # Cheng-Jun Wang library(tm) library(topicmodels) require(proxy) data(acq) data(crude) m \u0026lt;- c(acq, crude) dtm \u0026lt;- DocumentTermMatrix(m) dtm \u0026lt;- removeSparseTerms(dtm, 0.8) inspect(dtm[1:5, 1:5]) # cluster analysis of documents based on DocumentTermMatrix dist_dtm \u0026lt;- dissimilarity(mtd, method = 'cosine') hc \u0026lt;- hclust(dist_dtm, method = 'ave') plot(hc, xlab = '')  {:lang=\u0026laquo;ruby\u0026raquo;}\n我在做RA的时候，面临的一个问题就是在做主体模型的时候出现的：模型拟合得到的主题数量太多。我们用下面这个例子进行简单的介绍。\n# topic modeling topic_num = 50 for (k in c(topic_num)) { # k \u0026lt;- 10 SEED \u0026lt;- 2010 jss_TM \u0026lt;- list( VEM = LDA(dtm, k = k, control = list(seed = SEED)), VEM_fixed = LDA(dtm, k = k, control = list(estimate.alpha = FALSE, seed = SEED)), Gibbs = LDA(dtm, k = k, method = \u0026quot;Gibbs\u0026quot;, control = list(seed = SEED, burnin = 1000, thin = 100, iter = 1000)) ) } rs = posterior(jss_TM$Gibbs, dtm) mtd = t(rs$topics) # topics and documents mtt = rs$terms # topic and terms  {:lang=\u0026laquo;ruby\u0026raquo;}\n使用k mean聚类方法的好处是可以较为方便地知道聚类的数量\n######################################### # # K means analysis for rownames of a matrix # ######################################### # Determine number of clusters mydata = mtt wss \u0026lt;- (nrow(mydata)-1)*sum(apply(mydata,2,var)) max_group = nrow(mydata)-1 for (i in 2:max_group) wss[i] \u0026lt;- sum(kmeans(mydata, centers=i)$withinss) plot(1:max_group, wss, type=\u0026quot;b\u0026quot;, xlab=\u0026quot;Number of Clusters\u0026quot;, ylab=\u0026quot;Within groups sum of squares\u0026quot;) ## # K-Means Cluster Analysis fit \u0026lt;- kmeans(mydata, 5) # 5 cluster solution # get cluster means cluster_means = aggregate(mydata,by=list(fit$cluster),FUN=mean) # append cluster assignment mydata \u0026lt;- data.frame(rownames(mydata), fit$cluster)  {:lang=\u0026laquo;ruby\u0026raquo;}\n以下，我们对矩阵计算cosine similarity并使用阶层聚类方法得到结果。\n############################################ # # Hierarchical Clustering # ############################################ cos.sim \u0026lt;- function(ix) { A = X[ix[1],] B = X[ix[2],] return( sum(A*B)/sqrt(sum(A^2)*sum(B^2)) ) } mdt = as.matrix(dtm) X = mtt # whether to scale it n \u0026lt;- nrow(X) cmb \u0026lt;- expand.grid(i=1:n, j=1:n) simdt \u0026lt;- matrix(apply(cmb,1,cos.sim),n,n) rownames(simdt) = rownames(mtt) hc \u0026lt;- hclust(dist(simdt, method = \u0026quot;euclidean\u0026quot;), method = 'ave') # hc \u0026lt;- hclust(dist(simdt)^2, method = 'cen') plot(hc, xlab = '') k = 10 groups \u0026lt;- cutree(hc, k=k) # cut tree into 5 clusters rect.hclust(hc, k=k, border=\u0026quot;red\u0026quot;) # draw dendogram with red borders  {:lang=\u0026laquo;ruby\u0026raquo;}\n看一下效果吧：\n当然了，如果你觉得这个方法过于粗暴，还可以尝试构建主题网络并进行社区划分的方法。不再赘述。\n","date":1378598400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1378598400,"objectID":"43528e9dbe217109b6e1c9bde4549c9a","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-08-using-cluster-analysis-to-classify-topics-generated-by-topic-modeling/","publishdate":"2013-09-08T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2013-09-08-using-cluster-analysis-to-classify-topics-generated-by-topic-modeling/","section":"post","summary":"","tags":null,"title":"使用聚类分析为主题模型划分主题类型","type":"post"},{"authors":null,"categories":null,"content":"使用R软件进行自然语言处理（文本挖掘）是比较方便的。其中一个比较基础的分析是采用part-of-speech tagging的思路进行词性标注。在本文中，我将简单地介绍使用R软件及其子包openNLP进行词性标注。这里的测试语料依然是英文，采用的算法主要是最大熵的方法。\nopenNLP的发展开始回归到底层的基本功能，之前搭建起来的比较方便实用的函数被取消了，比如tagPOS命令消失了。所以，需要自己来重新写这个方程。这也不太难，根据R文档对Maxent_POS_Tag_Annotator的介绍中的例子重新组合一下，就可以得到。\n动词和名词的使用在文本挖掘中异常重要，单纯的名词语料可以用于进一步的文本挖掘，如我要做的是采用它们继续做主题挖掘（topic modeling）。\n第一步，当然是重组这个tagPOS命令。\nlibrary(openNLP) library(tm) require(NLP) # Compose the tagPOS function tagPOS \u0026lt;- function(text.var, pos_tag_annotator, ...) { s \u0026lt;- as.String(text.var) ## Set up the POS annotator if missing (for parallel) PTA \u0026lt;- Maxent_POS_Tag_Annotator() ## Need sentence and word token annotations. word_token_annotator \u0026lt;- Maxent_Word_Token_Annotator() a2 \u0026lt;- Annotation(1L, \u0026quot;sentence\u0026quot;, 1L, nchar(s)) a2 \u0026lt;- annotate(s, word_token_annotator, a2) a3 \u0026lt;- annotate(s, PTA, a2) ## Determine the distribution of POS tags for word tokens. a3w \u0026lt;- a3[a3$type == \u0026quot;word\u0026quot;] pos_tag \u0026lt;- unlist(lapply(a3w$features, \u0026quot;[[\u0026quot;, \u0026quot;POS\u0026quot;)) ## Extract token/POS pairs (all of them): easy. pos_term \u0026lt;- list(term = s[a3w], tag = pos_tag) return (pos_term) }  {:lang=\u0026laquo;ruby\u0026raquo;}\n第二步，为了保留文本序列，这里还需要一个函数。\n# run tagPOS function for a list of texts # do so to facilitate the conversion to generate corpus for topic modeling run_pos = function(n){ cat(\u0026quot;R is running for part-of-speech tagging\u0026quot;, n, as.character(as.POSIXlt(Sys.time(), \u0026quot;Asia/Shanghai\u0026quot;)), sep = \u0026quot;\\n\u0026quot;) df = tagPOS(text[n]) nn = (df$term[which(df$tag == \u0026quot;NN\u0026quot;)]) vb = (df$term[which(df$tag == \u0026quot;VB\u0026quot;)]) nnvb = (c(nn, vb)) result = list(nn, vb, nnvb) return(result) }  {:lang=\u0026laquo;ruby\u0026raquo;}\n第三步，开始测试结果（这里用一个很短的语料），并将其转化为三个tm下的Corpus。\n# test with a simple collection of text text \u0026lt;- c(\u0026quot;I like it.\u0026quot;, \u0026quot;This is outstanding soup!\u0026quot;, \u0026quot;I really must get the recipe.\u0026quot;) # run the functions df = lapply(c(1:3), run_pos) data = data.frame(do.call(rbind, df)) names(data) = c(\u0026quot;nn\u0026quot;, \u0026quot;vb\u0026quot;, \u0026quot;nnvb\u0026quot;) # make three corpus of nouns, verbs, and both of them corpus_nn \u0026lt;- Corpus( VectorSource( data$nn ) ) corpus_vb \u0026lt;- Corpus( VectorSource( data$vb ) ) corpus_nnvb \u0026lt;- Corpus( VectorSource( data$nnvb ) )  {:lang=\u0026laquo;ruby\u0026raquo;}\n","date":1378512000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1378512000,"objectID":"f42a75a0bfa5d235d693254b53edcfab","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2013-09-07-part-of-speech-analysis-with-opennlp/","publishdate":"2013-09-07T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2013-09-07-part-of-speech-analysis-with-opennlp/","section":"post","summary":"","tags":null,"title":"文本挖掘基础：使用openNLP进行词性标注","type":"post"},{"authors":null,"categories":null,"content":"1. 筛选单词 在数据清理（pre-processing）之后，需要对数据进行适当筛选。对数据的筛选包括至少两个步骤：\n第一步，在DocumentTermMatrix中设定\n使用R的topicmodels发现设定在DocumentTermMatrix里的约束条件失效，解决方法在此，其实在topicmodels的包里也粗略提及，只是用习惯了tm包的人觉得二者是无缝对接的。其实还很多差异，比如在tm里相似功能称之为TermDocumentMatrix\ndtm \u0026lt;- DocumentTermMatrix(corpus, control = list(stemming = TRUE, stopwords = TRUE, wordLengths=c(4, 15), bounds = list(global = c(5,Inf)), # each term appears in at least 5 docs removeNumbers = TRUE, removePunctuation = list(preserve_intra_word_dashes = FALSE) #,encoding = \u0026quot;UTF-8\u0026quot; ) ) colnames(dtm) ## inspect all the words for errors dim(dtm)  {:lang=\u0026laquo;ruby\u0026raquo;}\n第二步，通过tf-idf和col_sums选择高频词\n这背后的逻辑在于主题模型是要对文本进行分类，频次较少的词的贡献并不大。但会显著的占用计算资源。\nterm_tfidf \u0026lt;-tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) * log2(nDocs(dtm)/col_sums(dtm \u0026gt; 0)) l1=term_tfidf \u0026gt;= quantile(term_tfidf, 0.1) # fix this! dtm \u0026lt;- dtm[,l1] l2=col_sums(dtm) \u0026gt;= quantile(col_sums(dtm), 0.1) # fix this! dtm \u0026lt;- dtm[,l2] dtm = dtm[row_sums(dtm)\u0026gt;0, ]; dim(dtm) # 2246 6210 range(col_sums(dtm))  {:lang=\u0026laquo;ruby\u0026raquo;}\n2. 确定主题数量 在对单个词进行筛选之后，就可以正式进行主题模型的设定了。这是一步非常耗时间的工作，但第一步当然是理解主题模型的基本思路。\n主题模型是在概率潜在语义分析（probabilistic latent semanticanalysis，PLSI）的基础上发展起来的。从对矩阵进行因子分解的角度而言，可以看做是对离散数据进行主成分分析。其具体内容可以参见Blei发表在Communication of ACM上的文献回顾文章（Blei(2012) Probalistic topic models. Communication of ACM, 55, 77-84）。\n简而言之，我们看到是单词在文本中的分布。1. 我们认为在单词和文本之间存在潜在的主题，并且每个主题$$β{1:K}$$可以表达为一些词语在这个文本里的分布；2. 一篇文章可能对应多个主题，假设我们已经知道了存在哪些主题，那么一个主题在一个文本中的比例$$θ{d:k}$$也应该知道；3. 我们将主题和词语对应起来，建立一个映射$$z{d:n}$$，这样我们就知道把文章d中的第n个词赋给哪个主题；4.但实际上前三步都是不能直接观察到的，之间看到的就是词语在文本中的分布$$w{d:n}$$ ，例如文本d当中第n个词语是什么，即词在文本中的分布。\n前三个隐变量和第四个先变量之间的联合分布（joint distribution）就是主题生成的过程，这个过程还可以使用概率图模型的方法进行建模。如下图所示：\n其主要逻辑是机器学习的思路：给定了可以观察到的词语在文本中的分布$$w_{d:n}$$，主题结构可以表达为一个条件分布：$$p(\\beta _{1:K},\\theta {1:D},z{1:D} \\mid w_{1:D})$$。这是后验分布的分析思路。因为可能的主题结构太多，这个后验分布无法计算出来，而主题模型的主要目的也只是逼近这个后验分布。\n通常逼近这个后验分布的方法可以分为两类：1. 变异算法（variational algorithms）,这是一种决定论式的方法。变异式算法假设一些参数分布，并根据这些理想中的分布与后验的数据相比较，并从中找到最接近的。由此，将一个估计问题转化为最优化问题。最主要的算法是变异式的期望最大化算法(variational expectation-maximization，VEM)。这个方法是最主要使用的方法。在R软件的tomicmodels包中被重点使用。 2. 基于抽样的算法。抽样的算法，如吉布斯抽样（gibbs sampling）主要是构造一个马尔科夫链，从后验的实证的分布中抽取一些样本，以之估计后验分布。吉布斯抽样的方法在R软件的lda包中广泛使用。\n常用的主题模型是LDA, 可以使用VEM和gibbs两种方法估计。之后的模型的发展，主要是要放松严格的模型假设，其中之一是允许主题之间存在相关。由此Blei等人提出了相关的主题模型（correalted topic model，CTM），可以使用VEM方法估计。在本文当中，我们采用CTM为例。\nfold_num = 10 kv_num = c(5, 10*c(1:5, 10)) seed_num = 2003 smp\u0026lt;-function(cross=fold_num,n,seed) { set.seed(seed) dd=list() aa0=sample(rep(1:cross,ceiling(n/cross))[1:n],n) for (i in 1:cross) dd[[i]]=(1:n)[aa0==i] return(dd) } selectK\u0026lt;-function(dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp) # change 60 to 15 { per_ctm=NULL log_ctm=NULL for (k in kv) { per=NULL loglik=NULL for (i in 1:3) #only run for 3 replications# { cat(\u0026quot;R is running for\u0026quot;, \u0026quot;topic\u0026quot;, k, \u0026quot;fold\u0026quot;, i, as.character(as.POSIXlt(Sys.time(), \u0026quot;Asia/Shanghai\u0026quot;)),\u0026quot;\\n\u0026quot;) te=sp[[i]] tr=setdiff(1:nrow(dtm),te) # VEM = LDA(dtm[tr, ], k = k, control = list(seed = SEED)), # VEM_fixed = LDA(dtm[tr,], k = k, control = list(estimate.alpha = FALSE, seed = SEED)), CTM = CTM(dtm[tr,], k = k, control = list(seed = SEED, var = list(tol = 10^-4), em = list(tol = 10^-3))) # Gibbs = LDA(dtm[tr,], k = k, method = \u0026quot;Gibbs\u0026quot;, # control = list(seed = SEED, burnin = 1000,thin = 100, iter = 1000)) per=c(per,perplexity(CTM,newdata=dtm[te,])) loglik=c(loglik,logLik(CTM,newdata=dtm[te,])) } per_ctm=rbind(per_ctm,per) log_ctm=rbind(log_ctm,loglik) } return(list(perplex=per_ctm,loglik=log_ctm)) } sp=smp(n=nrow(dtm),seed=seed_num) system.time((ctmK=selectK(dtm=dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp=sp))) ## plot the perplexity m_per=apply(ctmK[[1]],1,mean) m_log=apply(ctmK[[2]],1,mean) k=c(kv_num) df = ctmK[[1]] # perplexity matrix matplot(k, df, type = c(\u0026quot;b\u0026quot;), xlab = \u0026quot;Number of topics\u0026quot;, ylab = \u0026quot;Perplexity\u0026quot;, pch=1:5,col = 1, main = '') legend(\u0026quot;bottomright\u0026quot;, legend = paste(\u0026quot;fold\u0026quot;, 1:5), col=1, pch=1:5)  {:lang=\u0026laquo;ruby\u0026raquo;}\n有趣的是计算时间：\n\u0026gt; system.time((ctmK=selectK(dtm=dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp=sp))) R is running for topic 5 fold 1 2013-08-31 18:26:32 R is running for topic 5 fold 2 2013-08-31 18:26:39 R is running for topic 5 fold 3 2013-08-31 18:26:45 R is running for topic 10 fold 1 2013-08-31 18:26:50 R is running for topic 10 fold 2 2013-08-31 18:27:14 R is running for topic 10 fold 3 2013-08-31 18:27:36 R is running for topic 20 fold 1 2013-08-31 18:27:57 R is running for topic 20 fold 2 2013-08-31 18:29:42 R is running for topic 20 fold 3 2013-08-31 18:32:00 R is running for topic 30 fold 1 2013-08-31 18:33:42 R is running for topic 30 fold 2 2013-08-31 18:37:39 R is running for topic 30 fold 3 2013-08-31 18:45:46 R is running for topic 40 fold 1 2013-08-31 18:52:52 R is running for topic 40 fold 2 2013-08-31 18:57:26 R is running for topic 40 fold 3 2013-08-31 19:00:31 R is running for topic 50 fold 1 2013-08-31 19:03:47 R is running for topic 50 fold 2 2013-08-31 19:04:02 R is running for topic 50 fold 3 2013-08-31 19:04:52 R is running for topic 100 fold 1 2013-08-31 19:05:42 R is running for topic 100 fold 2 2013-08-31 19:06:05 R is running for topic 100 fold 3 2013-08-31 19:06:28 user system elapsed 2417.801.13 2419.28  {:lang=\u0026laquo;ruby\u0026raquo;}\n看一下最终绘制的perplexity的图，如下可见，在本例当中，当主题数量为30的时候，perplexity最小，模型的最大似然率最高，由此确定主题数量为30。\n","date":1377907200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1377907200,"objectID":"cb20714ded8088c6031d07b621446231","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-31-topic-modeling-with-r/","publishdate":"2013-08-31T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2013-08-31-topic-modeling-with-r/","section":"post","summary":"","tags":null,"title":"使用R做主题模型：词语筛选和主题数量确定","type":"post"},{"authors":null,"categories":null,"content":"引言 遭遇“邪恶的拉丁引号” 我遇到的问题比较复杂，因为原文里混合了latin1和UTF-8两种encoding的字形，最初我统一再读入text数据的时候采用encoding =\u0026laquo;UTF-8\u0026raquo;的方法，结果发现了很多奇诡的单引号和双引号错误。在生成的DocumentTermMatrix里出现了很多以引号开始或结束的terms，例如：“grandfather， “deputy with the constitution” 。用Encoding命令看一下它的原形是：\n\u0026gt; Encoding(\u0026quot;“\u0026quot;) [1] \u0026quot;latin1\u0026quot;  只所以说是原形，是因为它们可以变形！\u0026raquo;â€œ\u0026raquo;， \u0026laquo;â€™\u0026raquo;， \u0026laquo;â€\\u009d\u0026raquo;， \u0026laquo;â€\u0026raquo;都是它在不设定Encoding的环境下的形状。但我觉得不足以刻画我对它的厌恶，特别附图一张：\n直到最后，我也没彻底搞定这些邪恶的拉丁引号，但我使用了一些tricks解决的我的问题。\n1. 读入数据不设定encoding！ 因为邪恶的拉丁引号在UTF-8格式下根本就无法对付，在不设encoding方法的时候，它们现身为â€“, â€™, â€œ等形式，还可以对付。\ndat1 = read.csv(\u0026quot;D:/chengjun/Crystal/Schwab_data_cleaningSep.csv\u0026quot;, header = F, sep = \u0026quot;|\u0026quot;, quote = \u0026quot;\u0026quot;, stringsAsFactors=F, fileEncoding = \u0026quot;\u0026quot;) # , encoding =\u0026quot;UTF-8\u0026quot;); dim(dat1) names(dat1) = c('name', 'organization', 'year', 'country', 'website', 'shortIntro', 'focus', 'geo', 'model', 'benefit', 'budget', 'revenue', 'recognization', 'background', 'innovation', 'entrepreneur')  2. 文本数据清理第一步：载入R包，选取变量 library(tm) library(topicmodels) text = dat1$entrepreneur  3. 终于可以删除部分邪恶的拉丁引号 text = gsub(\u0026quot;.\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;!\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;?\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€œ\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€™\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€\\u009d\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;â€\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;\u0026lt;/b\u0026gt;\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) text = gsub(\u0026quot;\u0026lt;b\u0026gt;\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE )  注意：1. 这些不规则的latin表达在r的script里再次打开会改变。所以，每次使用都要来这个网页里粘贴复制，也算是一种state-of-art，markdown都比R script保存的持久啊。2.使用gsub的代价是corpus被再度转化为character。所以这段代码如放在下面使用还要用Corpus命令再度转回来。\ncorpus \u0026lt;- Corpus( VectorSource( text ) ) # corpus[[1]] ## inspect the first corpus # make each letter lowercase corpus \u0026lt;- tm_map(corpus, tolower)  4. 我这里根据研究需要，要剔除人名、地名、组织名。 # remove generic and custom stopwords human_find_special_cases = c(\u0026quot;Fundação Pró-Cerrado\u0026quot;, \u0026quot;Fundação PróCerrado\u0026quot;, \u0026quot;FundaÃ§Ã£o PrÃ³-Cerrado\u0026quot;) my_stopwords \u0026lt;- c(dat1$country, dat1$organization, dat1$name, human_find_special_cases) my_stopwords \u0026lt;- Corpus( VectorSource(my_stopwords) ) my_stopwords \u0026lt;- tm_map(my_stopwords, tolower) # to lowercase my_stopwords here # Finally we can delete the country/org/person names corpus \u0026lt;- tm_map(corpus, removeWords, my_stopwords); corpus[[1]] corpus \u0026lt;- tm_map(corpus, removePunctuation)  5. 将语料转化为DocumentTermMatrix # install.packages(\u0026quot;SnowballC\u0026quot;) Sys.setlocale(\u0026quot;LC_COLLATE\u0026quot;, \u0026quot;C\u0026quot;) # set this for reproducible results corpus \u0026lt;- Corpus( VectorSource( corpus ) ) # corpus[[1]] ## inspect the first corpus  另外，到这里还是会有孤立的邪恶的拉丁单引号存在，但已经和其它term分开了，在以下DocumentTermMatrix的通过设置minWordLength = 3可以将其完全清理。\n# corpus = tm_map(corpus, function(x) iconv(enc2utf8(x), sub = \u0026quot;byte\u0026quot;)) # very important to convert encoding JSS_dtm \u0026lt;- DocumentTermMatrix(corpus, control = list(stemming = TRUE, stopwords = TRUE, minWordLength = 3, removeNumbers = TRUE, removePunctuation = TRUE # weighting = # function(x) # weightTfIdf(x, normalize =FALSE), ,encoding = \u0026quot;UTF-8\u0026quot; ) ) findFreqTerms(JSS_dtm, lowfreq=0) # 一定要看一下还有没有错误。inspect all the words for errors  6. 你需要的一些背景知识 6.1 如何识别和转化encoding的类型? iconvlist() # 看一下玲琅满目的encoding方法 iconv(x, from, to, sub=NA) # Convert Character Vector between Encodings ## convert from Latin-2 to UTF-8: two of the glibc iconv variants. iconv(x, \u0026quot;ISO_8859-2\u0026quot;, \u0026quot;UTF-8\u0026quot;) iconv(x, \u0026quot;LATIN2\u0026quot;, \u0026quot;UTF-8\u0026quot;) ## Both x below are in latin1 and will only display correctly in a ## latin1 locale. (x \u0026lt;- \u0026quot;fa\\xE7ile\u0026quot;) charToRaw(xx \u0026lt;- iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;UTF-8\u0026quot;)) ## in a UTF-8 locale, print(xx) iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;) # NA iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, \u0026quot;?\u0026quot;) # \u0026quot;fa?ile\u0026quot; iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, \u0026quot;\u0026quot;) # \u0026quot;faile\u0026quot; iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, \u0026quot;byte\u0026quot;) # \u0026quot;fa\u0026lt;e7\u0026gt;ile\u0026quot; # Extracts from R help files (x \u0026lt;- c(\u0026quot;Ekstr\\xf8m\u0026quot;, \u0026quot;J\\xf6reskog\u0026quot;, \u0026quot;bi\\xdfchen Z\\xfcrcher\u0026quot;)) iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII//TRANSLIT\u0026quot;) iconv(x, \u0026quot;latin1\u0026quot;, \u0026quot;ASCII\u0026quot;, sub=\u0026quot;byte\u0026quot;) ## End(Not run)  6.2 如何看DocumentTermMatrix的内容？ inspect(JSS_dtm) colnames(JSS_dtm) # we can find that: [3206] \u0026quot;works\\u009d\u0026quot; [3207] \u0026quot;work\\u009d\u0026quot; inspect(JSS_dtm[,3206]) inspect(JSS_dtm[,\u0026quot;works\\u009d\u0026quot;])  6.3 关于一些需要跳出的符号 unlist(strsplit(\u0026quot;a.b.c\u0026quot;, \u0026quot;.\u0026quot;)) ## [1] \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; ## Note that 'split' is a regexp! ## If you really want to split on '.', use unlist(strsplit(\u0026quot;a.b.c\u0026quot;, \u0026quot;[.]\u0026quot;)) ## [1] \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot; ## or unlist(strsplit(\u0026quot;a.b.c\u0026quot;, \u0026quot;.\u0026quot;, fixed = TRUE))  同理，gsub查找替换掉句点comma的时候也有类似的问题。我在使用python处理相邻多个段落的时候，直接使用了list的append的方法，导致两个自然段之间没有空格。这可要害苦我了。很多可以作为段落结尾的标点都要转化为空格。幸好老外写文章没有那么多问号和叹号结尾。\nfixed = TRUE意味着要use exact matching.\ntext1 = gsub(\u0026quot;[.]\u0026quot;, \u0026quot; \u0026quot;, text） text1 = gsub(\u0026quot;[.]\u0026quot;, \u0026quot; \u0026quot;, text, fixed = TRUE ) ","date":1377734400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1377734400,"objectID":"a55268be814c70b53ee488f2246600db","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-29-encoding-in-r-for-text-mining/","publishdate":"2013-08-29T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2013-08-29-encoding-in-r-for-text-mining/","section":"post","summary":"","tags":null,"title":"使用R做主题模型：举一个处理Encoding问题的例子","type":"post"},{"authors":null,"categories":null,"content":"王成军\n香港城市大学媒体与传播系\n在上一章当中，我们对于网络的基本知识进行了介绍，这些知识构建起了网络科学的基础，同时也孕育着巨大的潜能。社会科学追求理论的建构，但疏于思考理论层次的丰富性。以社会学为例，一度在宏大理论和抽象实证主义之间摇摆（参见米尔斯所著《社会学的想象力》）。大数据时代的到来，再一次使得少数人开始对理论的认识产生动摇，以为只要把握住数据就足够了。这与可计算性社会科学都是相互矛盾的。可计算性社会科学研究社会现实，紧紧抓住数据，但是绝不束缚于数据。\n数据（data）、模式（pattern）、法则（law）、机制（mechanism）和隐含的原理(principle)构成了科学研究等级，如图11-1所示。科学理论的等级在这里又被粗略地划分为四个等级：模式、法则、机制和原理。网络科学以关系来度量物理世界和社会现实（social reality）。这些稳定的关系——表现为网络中的链接——构成了网络科学可计算性的基础。沿着网络中的链接出发，网络科学正在尝试突破社会现实混沌的迷宫，从社会现实的数据出发，发掘社会系统内部的模式、法则、机制、原理。\n图 11-1. 科学研究的金字塔\n网络科学所采用的方法非常多样，除了经典的统计方法之外，很多物理学的方法也被广泛的应用在网络研究当中。具体而言，网络科学有两个方法来源，一个是传统的社会网络分析，一个是近十几年里面迅猛发展起来的复杂网络研究。这两股研究的脉络构成了网络科学的两条主线。网络科学已经走出传统的社会网研究的藩篱。互联网浪潮的袭来推动传统网络研究与互联网科学（web science)的融合。一种以复杂网络（complex network）为代表的新型网络科学开始迅速成长(Barabasi, 2003)。例如，巴拉巴西等人采用动力系统的研究方法分析复杂网络的增长机制(Barabási \u0026amp; Albert, 1999)。但在本章当中，我将主要关注统计网络模型（statistical network models），并通过介绍处理社会化网络数据的例子来深化我们对于网络的认识。\n本章的结构安排如下：一、通过介绍网络科学的异军突起来思考可计算性在不同学科的发展，以便于启发我们对于可计算社会科学的认识；二、我们介绍数字化媒体的发展，以及由此带来的大数据浪潮的挑战和机遇；三、我们开始介绍网络链接的属性，拓展对于网络的认识；四、简略介绍QAP检验；五、介绍指数随机图模型；六、结论和讨论。\n 网络科学的异军突起：反思可计算性 数字化媒体和大数据 扩展对于网络的认识（二模网络与多模网络和时间序列网络） QAP检验 指数随机图模型（ERGM） 一条开放的道路  ###一、网络科学的异军突起：反思可计算性\n事实上，作为一个后起之声，可计算性社会科学（computational social science）已经在各个分支学科和新的交叉性学科中如火如荼！关于计算社会科学的介绍可见Lazer等人(2009)发表在《科学》杂志上的一文。Lazer等人综述了可计算性社会科学的涌现和发展，尤其强调了网络科学研究在其中所扮演的角色和数字媒体所提供的机遇。网络科学和可计算性社会科学的兴起都使得我们开始更加严肃地思考可计算性在科学版图当中的作用。\n对于可计算性的追求在自然科学一直是主流。物理学具有着最强的可计算性。物质世界的稳定性给了物理学发展提供了得天独厚的条件。物理学家采用各种稳定的手段测量物理世界的状态：长度、面积、体积、质量、速度、时间、能量。从牛顿力学到相对论，电磁学、再到量子力学，物理学展现了理论和数据的高度统一：我们可以精确地知道桥梁的重量、地球到月球的距离和卫星发射的速度。这种成就在一开始就激励着社会科学的发展。生物学诞生之初，研究者多少博物学家，忙着收集标本，区分生物所属的界、门、纲、目、科、属、种的类别。即使到了达尔文提出物种起源假说，生物学的发展依然备受局限。是什么使得生物学步入可计算化的路径，进而实现新的飞跃？一个可能的答案是“基因”。抓住这个计算性的本源，生物学开始迅速崛起。\n社会科学则是另一番图景。试思考为什么经济学是社会科学中发展较好的？答案是货币。用货币度量经济行为使经济学具有了天然的可计算性；其次是心理学，不是量表，而是实验，使得心理学具有了“模糊的”比较能力。而其他传统的社会科学，如传播学，则处于摇摆当中缓慢发展。\n值得注意的是三个迅速发展的学科：计算机科学、统计语言学、和我们正在谈论的网络科学。毋庸置疑，计算机科学是二十世纪发展最快的学科之一。其中一个重要的原因就在于计算机科学所对付的对象是离散的0和1。0和1通过二进制的运算构成了现代计算机的基础，也使得计算机科学从诞生之初，其“基因”当中就蕴含了强大的可计算性。在此基础上，计算机科学可以相对容易地与数学相结合研究信息和通信问题，并借助计算性思维（computational thinking）通过算法设计来自动化地解决问题(Wing, 2006)。统计语言学是传统语言学与计算机科学相互融合的结果。通过建立关于语言学的数学模型，并通过计算机来进行运算，统计语言学使得语言学在过去的三十年当中取得长足进步(吴军, 2012)，例如自然语言处理（natural language processing）已经广泛地应用在互联网产业当中和其他学科的研究当中。最近升起的新星则当属网络科学。网络科学对社会关系进行运算，借用统计物理的方法，很快发现复杂网络（例如，大规模的社会网络就是一种复杂网络）具有明显的小世界特征(Watts \u0026amp; Strogatz, 1998)和无标度特征(Barabási \u0026amp; Albert, 1999)。\n概括以上内容，我们可以发现：可计算性植根于不同的学科当中。发掘可计算性对于不同的学科具有举足轻重的意义。基于可计算性的研究才有较高的信度和效度，才能得到更确实的（solid）发现，才能和数学工具和物理学工具更好的结合，才能更深刻地探寻社会模式背后的法则、机制、规律。\n图 11-2. 学科历史与其可计算性的关系\n###二、数字化媒体和大数据 互联网的发展使得人类社会进入了一个新的时代：数字媒体时代（the era of digital media）。这种变化的影响已经被诸多预言者和研究者所分析，也为这个时代的个体所体认与观察。人类的交往模式，商业行为，舆论空间等，都因互联网而改变。但本文由数字化痕迹开始讲起。\n数字化媒体（digital media）的崛起正在深刻变革的社会科学的研究视野。因为数字化技术的发展（比如互联网）使得很多的人类行为变得可以观察，因而给我们更真实地认识世界提供了一个崭新的入口——数字化痕迹（digital traces）。比如，你在网络上购物的经历，你在社交媒体上的使用记录。这些数字化痕迹（又称数字化指纹（digital fingerprint），或数字化脚印（digital footprint）），使得研究者可以追逐这种痕迹，分析其行为背后隐藏的社会规律，进而提供了一个巨大的资源。这种资源的出现正在变革着不同学科的研究视角和研究疆域。比如，网络化的大规模数据的数字化痕迹（digital traces）第一次使得传播行为获得了计算性。而记录（document）、收集（collect）、分析（analyze）、可视化（visualize）这些传播行为就成为了计算传播学的主要工作。按照这个设想，社会科学必须走出传统的研究套路，获得在网络上保存、抓取、分析、可视化大规模电子化数据的能力，也需要支持这些工作的工具。毫无疑问，社会科学因此将和计算机科学开始交汇，至少需要程序员投入到这种大规模数据的挖掘工作中来。计算机科学家越来越将更多的注意力放在社交媒体的使用研究方面来。一系列的计算机会议以社交媒体研究作为重心。其它的学科分支也马上意识到互联网带来的机遇和挑战。这里要首先谈人类认知世界的一个重要方法——观察法。\n观察法是社会研究和自然研究最古老的方法。在社会研究领域，这种方法因其复杂和难以操控，往往只是适用于研究初期。研究中后期往往使用调查和实验方法，但后面这两种方法的优点是根据研究者的视角进行操控（manipulate），但缺点也在这里。因为访谈或问卷或实验，往往会降低研究的效度。而数字化痕迹使得这种限制减少，使得研究者真正在研究活生生的人类行为，并且研究的规模非常巨大，且往往具有时间序列的信息。数字化痕迹使得非介入的观察（unobtrusive observation）成为可能，因而给研究者带来的巨大的机遇。机遇是数据的获取为检验和发展经典理论提供了土壤。但同时也伴随着挑战。这种挑战则首先主要来自这种数字痕迹的获取、分析和储存上。\n当然第一关是数据的获取。资源虽然存在，却并不能为所有的人所使用。因为这里有一个天然的、历史原因造成的技术屏障——计算机技术。数字化痕迹的还有一些其它特点。比如规模巨大，难以分析，当然这涉及到数据的分析问题，不是本文的重点。另外一个方面，这些数字指纹往往是流数据，这意味着如果此刻不获取这些数据，过一段时间这些数据就很难或者没有可能获取了。甚至因为数据规模庞大，一些互联网公司也并不会储存所有的数据。这也为数据获取者提供了一种学习的急迫性。\n其中最简单的是研究者的编程技术。传统的社会科学研究者和读者往往忽略计算机技术尤其是编程能力的培养。因而，在学科转型之初，第一步就是这种开始学习崭新的东西。这多多少少让新手感到畏惧。需要指出的是，这种畏惧是不必要的。因为技术的发展趋势是越来越人性化和具有可读性。这给编程语言的学习带来便利。社会科学研究者可以选取简单的编程语言（R、Python、Ruby）开始计算机编程的学习。一个问题是是否可以采用即成的数据抓取软件呢？我的理解是，就目前而言，打包好的数据抓取软件过于死板，且效率低下，并且多数价格不菲、不是开源的软件。因而不是首选。现在很多统计语言往往也可以从事数据抓取的工作，比如R社趣发展了twiiteR的包和Rweibo的包。虽然其接口并不完善，但研究者根据自我需求进行自由的开发。\n社交网站为了自身的发展，往往选择向外界开放部分资源，以方便第三方发展基于该社交网站的产品，进而更好吸引使用者使用。比如新浪微博上有着纵多的应用，这些应用的数据接口就是由新浪微博所提供的。当然这种数据提供需要注册和认证，例如，对新浪微博而言可到应用开发页面注册 。因而，数据抓取的第一步，就是建立数据连接的工作，以获取社交网站开放数据流的许可。现在流行的方式是使用OAuth获取连接社会化媒体的API的使用权限。这种机制的好处是直接从网站数据库获取数据，因而数据结构化较好，不需要经过复杂繁琐的处理。且更好保护了使用者的隐私(Russell, 2011)。获取数据使用许可之后，其使用就非常方便灵活了。\n在本章当中，我们使用李舰 (Li, 2013)编写的Rweibo来连接新浪微博的API接口，并获取我们所需要的信息。Rweibo是一个新浪微博针对R语言的软件开发工具包（Software Development Kit, SDK）。作为一个R的软件包，Rweibo可以在R软件当中自由安装和调用。\n新浪微博的API的使用需通过OAuth的方式进行授权。使用者需要首先到新浪微博开放平台申请一个新的应用：在新浪微博应用页面（http://open.weibo.com/development）点击“创建应用”并选择“网页应用”。创建应用后，在应用信息中可以找到该应用的App Key和App Secret。在本章当中我们创建一个应用名称为cssbook的应用。\n注意：Rweibo的授权回调页在R软件中默认为http://127.0.0.1/library/Rweibo/doc/callback.html，不允许用户修改。所以在创建应用的时候要一定要设置“授权回调页”为这个页面。否则，会造成授权回调页不匹配的错误。\n然后在R软件中通过Rweibo软件包通过编写R脚本来连接新浪API接口并进行数据获取等各项操作。第一步是在R软件当中安装Rweibo这个软件包。因为Rweibo使用过程中还会用到其它几个相关的包，如RCurl、rjson、XML、digest，在此也一并安装。\n# R程序11-1：在R软件当中安装并调用Rweibo软件包 install.packages(\u0026quot;Rweibo\u0026quot;, repos = \u0026quot;http://R-Forge.R-project.org\u0026quot;) library(Rweibo) # 使用Rweibo还需要安装其它几个相关的R包 install.packages(\u0026quot;RCurl\u0026quot;) install.packages(\u0026quot;rjson\u0026quot;) install.packages(\u0026quot;XML\u0026quot;) install.packages(\u0026quot;digest\u0026quot;)  第二步是在R当中输入App Key和App Secret进行OAuth认证。执行以下R代码。\n注意：createOAuth代码中的access_name必须改成你自己的新浪微博账号。\n# R程序11-2：在R中进行OAuth认证 registerApp(app_name = \u0026quot;cssbook\u0026quot;, app_key = \u0026quot;307359760\u0026quot;, app_secret = \u0026quot;82dfbc7194b2f3c37029b9f8c880c385\u0026quot;) roauth \u0026lt;- createOAuth(app_name = \u0026quot;cssbook\u0026quot;, access_name = \u0026quot;wangchj04\u0026quot;) # 一定要将网页应用的“授权回调页”设为：http://127.0.0.1/library/Rweibo/doc/callback.html  这样，在执行createOAuth代码后，就会自动弹出一个授权网页。在用户授权后，就会转到包含CODE的授权回调页，复制该页面的CODE并粘贴到R界面（R console），单击回车键，就可以完成授权。\n小练习：向R软件提问：用户可以通过listApp(\u0026laquo;cssbook\u0026raquo;)命令查看这个应用的信息；如果用户需要删除这个注册，可以执行deleteApp(\u0026laquo;cssbook\u0026raquo;)。当然，用户还可以通过执行modifyApp（）命令来修改关于这个应用注册信息。要了解关于modifyApp的用法，读者可以在R界面中输入？modifyApp来查看其使用方法。当然，如果读者对于其它的R命令的使用不熟悉，也可以使用这个方法问一下R软件。\n在成功通过OAuth2.0认证之后，用户就可以较为自由地调用和使用Rweibo的相关命令。以下R程序展现的是如何查看OAuth的注册信息、API的权限设置、查看用户关注的朋友所发布的微博、自己通过Rweibo发布一条测试信息。\n# R程序11-3： 测试Rweibo # 查看所注册的OAuth的信息 roauth # 查看API权限设置 roauth$getLimits(TRUE) # 查看自己所关注的朋友所发布的信息 sf = statuses.friends_timeline(roauth, count = 5) sft[[1]] # 发布一条微博 su \u0026lt;- statuses.update(roauth, status = \u0026quot;Test Rweibo for cssbook\u0026quot;) # 获取一条微博的被转发列表 # 这条源微博为：http://weibo.com/1869170057/zvzbUqqwC，查看页面源代码可以找到其mid ana1 \u0026lt;- analysis.getReposts(roauth, mid = \u0026quot;3575234466298494\u0026quot;)  通过analysis.getReposts命令，我们获取了@统计之都在新浪微博上所发的一条微博的转发列表，该微博位于http://weibo.com/1869170057/zvzbUqqwC，通过查看该页源代码可以找到这条微博的mid为3575234466298494。使用names(ana1)命令，可以查看数据ana1当中的变量信息。该数据主要包括两大部分信息：一部分是微博转发信息，包括转发时间、转发微博mid、转发微博内容text、转发微博再次被转发数量、转发微博被评论数量等。如下所示：\n\u0026quot;created_at\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;text\u0026quot;, \u0026quot;reposts_count\u0026quot;, \u0026quot;comments_count\u0026quot;, \u0026quot;attitudes_count\u0026quot;, \u0026quot;in_reply_to_status_id\u0026quot;, \u0026quot;in_reply_to_user_id\u0026quot;,\u0026quot;in_reply_to_screen_name\u0026quot;  另一部分信息为转发者信息，包括转发者的user id，转发者的screen name、转发者的地理信息、转发者的性别、转发者的粉丝数量和朋友数量等。具体信息如下：\n\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;,\u0026quot;User_province\u0026quot;, \u0026quot;User_city\u0026quot;, \u0026quot;User_location\u0026quot;,\u0026quot;User_description\u0026quot;, \u0026quot;User_gender\u0026quot;, \u0026quot;User_followers_count\u0026quot;, \u0026quot;User_friends_count\u0026quot;, \u0026quot;User_statuses_count\u0026quot;, \u0026quot;User_favourites_count\u0026quot;, \u0026quot;User_geo_enabled\u0026quot;, \u0026quot;User_created_at\u0026quot;, \u0026quot;User_following\u0026quot;, \u0026quot;User_follow_me\u0026quot;, \u0026quot;User_bi_followers_count\u0026quot;, \u0026quot;User_verified\u0026quot;, \u0026quot;User_verified_type\u0026quot;, \u0026quot;User_verified_reason\u0026quot;  我们将转发源微博的微博称之为“转发微博”。那么，值得注意的是analysis.getReposts命令获取的是一个转发列表，即所有的转发微博和转发者的信息，但我们仍然不知道具体的转发网络。\n就新浪微博单条微博而言，获取转发网络有两种方法：第一种是将所有的转发微博的被转发情况再抓取一次，这种方法的有点是精确，缺点是需要多次调用API接口；第二种方法是解析（parse）转发微博的内容，如果转发者不修改上家的转发内容的话，比如一个转发微博的内容为：“//@黠之大者: 我喜欢使用R软件。”我们可以认为这条微博转发自微博用户“黠之大者”。这种方法的优点是不需要继续调用API接口，缺点是会由于转发者修改转发内容，尤其是删除其转发源，而造成错误的结果。\n在本章当中，我们主要使用第一种方法。但我们不需要把所有的转发微博都再抓取一次，因为analysis.getReposts命令已经可以使我们知道每条转发微博之后的被转发次数。具体而言，只有那些reposts_count大于零的转发微博之后被其他用户转发。就我们这个具体的例子而言，1020个转发微博当中（870个独立转发者），只有139个转发微博被再度转发。86.4%的转发产生于第一步转发（即不经过中间转发者而直接转发源微博）。\n# R程序11-4：抓取二度转发者id ana2 = subset(ana1, ana1$reposts_count!= \u0026quot;0\u0026quot;) offspringlist = list() for (n in 1:length(ana2$mid)){ counts = ana2$reposts_count[n] result = statuses.repost_timeline(roauth, id = as.character(ana2$mid)[[n]], count = counts ) for (m in 1:counts){ offspring = result[[m]]$user$idstr addin = c(n, m, offspring) offspringlist = rbind(offspringlist, addin)} } data = data.frame(offspringlist, nrow=262, byrow=T)[,1:3] names(data) = c(\u0026quot;n\u0026quot;, \u0026quot;m\u0026quot;, \u0026quot;offspring\u0026quot;) # 二度转发的源头 dat = data.frame(ana2$User_idstr) dat$n = c(1:length(ana2$User_idstr)) names(dat) = c(\u0026quot;source\u0026quot;, \u0026quot;n\u0026quot;) dats = merge(dat, data, by = c(\u0026quot;n\u0026quot;)) dat1 = dats[,c('source','offspring')]  我们已经获取了所有的转发微博被再度转发的网络。对于所有的转发者而言，必然存在一个来源。如果一个节点在二度转网络当中没有来源，那么它的来源节点就是原微博的作者。由此，我们可以进一步获得一度转发网络：\n# R程序11-5： 获取一度转发网络 # 每个节点都有来源，如果一个节点无来源，则来自源节点1869170057 idsUnique = unique(ana1$User_idstr)# 870 unique diffusers offspring = subset(dats$offspring, dats$offspring != dats$source) idsWithoutSource = subset(idsUnique, !(idsUnique %in% offspring) ) dat2 = as.data.frame(cbind(1869170057,idsWithoutSource)) names(dat2) = c(\u0026quot;source\u0026quot;, \u0026quot;offspring\u0026quot;) # 合并一度转发网络及二度转发网络 dat3 = rbind(dat1, dat2)  基于总的转发信息和二度转发信息，我们可以绘制转发网络。\n# R程序11-6：绘制转发网络 # 绘制总的转发网络 library(igraph) g\u0026lt;-graph.data.frame(dat3) l\u0026lt;-layout.fruchterman.reingold(g) # 明确节点属性 vertex\u0026lt;-as.numeric(V(g)$name) V(g)$size = log(degree(g, v=V(g), mode = c(\u0026quot;out\u0026quot;)) + 1 ) nodeName = unique(ana1[,c(\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;)]) node = as.data.frame(V(g)$name) names(node) = c(\u0026quot;User_idstr\u0026quot;) nodeLabel = merge(node, nodeName, by = \u0026quot;User_idstr\u0026quot;, sort = F) nodeLabel$nodeSize = V(g)$size nodeLabel$User_screen_name[nodeLabel$nodeSize \u0026lt; 1]=\u0026quot;\u0026quot; nodeLabel = nodeLabel$User_screen_name # 保存图片格式 png(\u0026quot;d:/repostGraph.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) plot(g, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l ) # 结束保存图片 dev.off()  图 11-3. 微博转发网络\n# 绘制二度转发网络（剔除了第一步转发） g1\u0026lt;-graph.data.frame(dat1) l1\u0026lt;-layout.fruchterman.reingold(g1) # 明确节点属性 vertex\u0026lt;-as.numeric(V(g1)$name) V(g1)$size = degree(g1, v=V(g1), mode = c(\u0026quot;out\u0026quot;)) nodeName = unique(ana1[,c(\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;)]) node = as.data.frame(V(g1)$name) names(node) = c(\u0026quot;User_idstr\u0026quot;) nodeLabel = merge(node, nodeName, by = \u0026quot;User_idstr\u0026quot;, sort = F, all = FALSE) nodeLabel$nodeSize = V(g1)$size nodeLabel$User_screen_name[log(nodeLabel$nodeSize+1) \u0026lt; 1]=\u0026quot;\u0026quot; nodeLabel = nodeLabel$User_screen_name # 保存图片格式 png(\u0026quot;d:/repostGraph2step.png\u0026quot;, width=5, height=5, units=\u0026quot;in\u0026quot;, res=700) # 绘制图片 plot(g1, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l1 ) # 结束保存图片 dev.off()  图 11-4. 微博二度转发网络（剔除了第一步转发）\n当然，我们还可以通过解析微博内容的方法来提取转发网络。这需要我们对转发微博的内容进行分析，提取其中“//@”后出现的微博用户名。我们借助gsubfn这个R包中的strapply来实现这个过程。\n# R程序11-7：通过解析微博内容提取转发网络 library(gsubfn) findSource = function(n){ res1=strapply(ana1$text[n], paste(\u0026quot;\\\\w*\u0026quot;, \u0026quot;//@\u0026quot;, \u0026quot;\\\\w*\u0026quot;, sep = \u0026quot;\u0026quot;), c, simplify = unlist) res2 = ifelse(is.null(res1) == TRUE, 0,unlist(strsplit(res1[1], \u0026quot;@\u0026quot;))[2] ) return(res2) } source = unlist(lapply(c(1:length(ana1$text)), findSource)) dat4 = as.data.frame(cbind(source, ana1$User_screen_name)) # 总的转发网络 dat4$source[as.character(dat4$source) == \u0026quot;0\u0026quot;] = \u0026quot;统计之都\u0026quot; dat5 = subset(dat4, dat4$source != \u0026quot;统计之都\u0026quot;) # 二度转发网络 # 绘制总的转发网络 library(igraph) g4\u0026lt;-graph.data.frame(dat4) l\u0026lt;-layout.fruchterman.reingold(g4) plot(g4, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l ) # 绘制二度转发网络 library(igraph) g5\u0026lt;-graph.data.frame(dat5) l\u0026lt;-layout.fruchterman.reingold(g5) plot(g5, vertex.label= NA,edge.arrow.size=0.02,vertex.size = 0.5, layout=l )  这种直接使用编程语言上手的方法符合“通过实践学习”（learning by doing）的哲学。为社会科学研究者和广大的读者提供了一个轻巧的入门的道路。遇到问题，解决问题，学习者也可以在实际的练习当中进步。当然，千言万语不如付诸行动。只有开始了第一步的下载和安装python，安装一些包，写出第一个有用的程序的时候，才算真正不虚此行。最具有吸引力的是一通百通，会从Twitter上获取信息，你也就具有了从其他网站（如新浪微博）上获取信息的能力。当你走完这一步，我们可以相信，一个可计算的社会科学研究就从你自己这里开始起步了。\n三、重新认识网络：一个整体的视角 网络科学（network science）是可计算性社会科学(computational social science)的一个重要组成部分。它不仅提供了一个崭新的视角，还为社会科学提供了一系列的理论和方法。网络科学提供了新的认识社会的视角，即对关系进行计算。通过对关系进行计算,网络科学丰富了人类认识世界的维度。网络无时无刻不存在于我们生活的每个细节：我们生活在一个社会网络当中，没有人是绝对孤立的点，每个个体时刻都在与其他人进行着互动；我们生活的大自然有一个食物网络，能量沿着食物网当中的链接由植物向高级的动物流动；我们的生活处于一个物流网络当中，交通干线承担着人口迁移和物质供给的职能，世界贸易网络刻画着国家间的贸易往来和经济依赖关系，等等。\n这种网络的链接有时候充当渠道的作用，网络的流可以藉此得以流通。这种网络当中的流可以具有多种表现形式：信息、商品，货币、信任、命令等。这些网络的流，往往充当着稀缺的社会资源的角色，具有明确而重要的社会功能。网络渠道对于网络的流具有引导和塑形的作用。比如，我们在日常生活中主动地建立自己的社会联系。有时候我们只能观察到其中之一，或者是网络渠道，或者是网络中流，因而链接预测（link prediction）成为网络科学研究当中一个重要议题(Lü \u0026amp; Zhou, 2011)。\n把握和认识这种关系能够为我们带来洞察，发现隐藏在事物表象下的模式。关系以链接的形式呈现于网络当中。例如，中国乡土社会当中的人和人之间的关系可以通过新年拜年的网络链接展现，通过观察礼物的类别、价格以及送礼人所使用的语言，我们可以对这种关系进行测量。类似的，恐怖分子通过隐秘的互动网络进行组织，通过观察其互动的频次、方向和时间，我们可以对互动双方的职能进行划分，进而发现其中的等级关系。这种对于网络当中链接所隐含的信息的应用非常普遍。例如，警察破案，很关键的一点是理清犯罪嫌疑人的人际关系网络。在模式的基础上，网络科学家开始更深入地探索网络科学中的法则，例如复杂网络的幂律分布。事实上，此时我们开始触及之前章节关于图论的知识，尤其是关于复杂网络的研究。最简单的网络是规则网，最混沌的网络在随机网。而复杂网络（包括社会网络）则处于从规则走向混沌的过渡阶段。Watts和Strogatz的研究表明将规则网络中的链接（按照一定的概率）随机重连就可以得到小世界网络(Watts \u0026amp; Strogatz, 1998)。Barabási和Albert随后的研究表明复杂网络中节点的度分布具有无标度特征(Barabási \u0026amp; Albert, 1999)。其后，一系列关于复杂网络的小世界特征和无标度性进行推动了网络科学的发展。从网络链接当中找到统一的模式和法则是认识网络的第一步，接下来需要理解网络链接的形成机制。\n网络链接的形成机制非常多样：1. 网络节点的流行程度（popularity）如社会影响力（social influence）(Barabási \u0026amp; Albert, 1999; Goodreau SM, 2009; Papadopoulos, Kitsak, Serrano, Boguná, \u0026amp; Krioukov, 2012)、2. 相似性（similarity）或同质性（homophily）(Goodreau SM, 2009; McPherson, Smith-Lovin, \u0026amp; Cook, 2001)、4. 地理空间接近性和社会接近性（spatial and social proximity）(Crandall et al., 2010; Rivera, Soderstrom, \u0026amp; Uzzi, 2010). 当然，除此之外还有很多其它的影响因素来源于: 5. 网络结构，如结构洞（Structural holes）(Burt, 1992)。尤其应当强调的是，基于社会规范（如社会交换）的互惠性（Reciprocity）在网络的行程中发挥着重要作用，因为基于社会规范，我们总是倾向于投桃报李、彼此合作、互利共赢(Cranmer, Heinrich, \u0026amp; Desmarais, 2013)；类似的，社会个体倾向于维持认知平衡并避免冲突关系(Davis, 1963; Newcomb, 1953)，因而关系的传递性（Transitivity）同样起着重要的作用。例如，在社会网络当中，人们倾向于和朋友的朋友建立网络关系(Goodreau SM, 2009)。\n四、QAP检验：两个网络之间的关联 通常一组个体具有多种类型的关系，例如友谊关系和经济往来关系。我们通常会对这两种网络关系在多大程度上相互关联感兴趣。当我们知道一组个体之间的两种关系网络，我们就可以计算这个两个关系网络之间的相关程度。在统计学当中，皮尔森相关系数是用来反映两个变量线性相关程度的统计量。与之类似，对于由一组个体所组成的两个网络，也可以计算其相应的相关皮尔逊相关系数。当然，还可以计算其他你感兴趣的统计量，如协相关系数。\n我们使用sna这个R软件包来计算网络相关系数（并调用qaptest命令）。通过安装和使用statnet这个R软件包，就会自动加载sna等子软件包。另外，statnet当中还集成了其他的几个相关的R软件包，包括进行动态网络建模的tergm子软件包。\n# R程序11-8：计算网络的皮尔逊相关系数 install.packages(\u0026quot;statnet\u0026quot;) library(statnet) # 首先随机生成3个由10个节点构成的有向网络 g = array(dim=c(3,10,10)) g[1,,] = rgraph(10) g[2,,] = rgraph(10,tprob=g[1,,]*0.8) # 设置g1和g2两个网络强相关 g[3,,] = 1; g[3,1,2] = 0 # g3接近于一个派系（clique） # 绘制这3个网络 par(mfrow=c(1,3)) for(i in 1:3) { gplot(g[i,,],usecurv=TRUE, mode = \u0026quot;fruchtermanreingold\u0026quot;, vertex.sides=3:8)} #计算网络的相关矩阵 gcor(g)  在通常使用皮尔逊相关系数的时候，可以用t统计量对总体相关系数为0的原假设进行检验。但在计算网络的相关系数（graph correlations）时，经典的零假设检验方法往往会带来偏差，因而并不适用。通常使用非参数检验的方法，比如QAP(Quadratic Assignment Procedure)检验。\n矩阵的随机排列（Random matrix permutations）是QAP检验的关键部分，在子软件包sna中主要通过rmperm来进行。通过矩阵的随机排列，可以对网络中的节点（的编号）进行随机置换（relabelling），并得到一组（比如1000个）重连后的网络。\n# R程序11-9：矩阵的随机置换方法 j = rgraph(5) # 随机生成一个网络 j #看一下这个网络的矩阵形式 rmperm(j) #随机置换后的网络的矩阵形式  对这一组重构的网络可以计算其网络级别的参数（如两个网络的相关参数，协相关参数），并因此得到一个参数分布。QAP检验的零假设是实际观测到的网络参数（如）来自于这一个参数分布。也就是说，原假设认为这种观测到的相关关系是由随机因素带来的，因而这种网络相关并不显著。拒绝原假设，就从统计的角度证明了观测到的网络相关系数是显著的。\n# R程序11-10：QAP检验 q.12 = qaptest(g, gcor, g1 = 1, g2 = 2) q.13 = qaptest(g, gcor, g1 = 1, g2 = 3) # 看一下QAP输出的结果 par(mfrow=c(1,2)) summary(q.12) plot(q.12) # 拒绝原假设，图1和图2显著相关 summary(q.13) plot(q.13) # 接受原假设，图1和图3不相关  在检验这个关于两个网络是否存在相关的零假设的时候，我们计算置换后的参数分布中大于这个实际观测到的参数的比例，以及小于这个实际观测到的参数的比例。QAP检验返回实际数据中观测到的参数f(d)、通过置换所得到的参数f(perm)的数学分布、以及单尾的P值。其中单尾的p值包括两种情况：p(f(perm) \u0026gt;= f(d))和p(f(perm) \u0026lt;= f(d))。\n其中P(f(perm) \u0026gt;= f(d))表示随机置换矩阵的相关系数的大于与等于观测值的p值，也就是本研究的检验显著性。一般而言，当p(f(perm) \u0026gt;= f(d))小于p(f(perm) \u0026lt;= f(d))时，拒绝原假设。\n思考另外一个问题：如果两个节点之间存在一种关系（例如A和B之间存在相互关注的的朋友关系），是否暗示着他们之间是否可能存在另一种关系（例如A和B之间存在相互转发信息的传播关系）？这样，我们试图去找到一种关系对于另一种关系的影响。例如，两个作者来自同一所学校对于他们之间的合作关系是否具有显著的影响。除此之外，还有节点的属性的影响，网络规模的影响，网络中二元组和三元组的影响等等。指数随机图模型作为一个网络统计模型可以较好地综合不同层级的影响因素，因为成为统计网络数据分析的主要模型。\n五、指数随机图模型 指数随机图模型（exponential random graph models, ERGMs）是一种使用蒙特卡罗最大似然(MCMC)方法的logit模型(Frank \u0026amp; Strauss, 1986; Goodreau SM, 2009; Wasserman \u0026amp; Pattison, 1996)。指数随机图模型的因变量是两个节点之间形成链接（tie-formation）的概率。采用马尔科夫链蒙特卡洛（Markov chain Monte Carlo， MCMC）方法，指数随机图模型挑选可以最大化得生成实际观察到的网络的模型(Snijders, 2002)。\n定义$$\\mathbf{Y}$$为网络中所有可能的链接关系，$$\\mathbf{y}$$是网络节点间（实际存在或可观察到的）一种具体的链接关系。定义$$\\mathbf{X}$$为网络节点属性，它是一个矩阵。在以上定义基础上，定义$$g(\\mathbf{y}, \\mathbf{X})$$为网络的统计量，它是一个向量。这些网络统计量包括两部分：一部分是网络结构的统计量，如链接的数量、二元组数量、三元组数量等；另一部分是网络节点属性的统计量，例如在微博信息转发网络中，网络节点属性包括微博转发者的年龄、性别、地理位置、活跃性、流行程度等。这些网络统计量构成了指数随机图模型的自变量，根据它们，指数随机图模型预测因变量，即节点之间构成链接的概率。\n为了进行模型估计，还需要引入一些参数（parameter）。为此，我们定义$$\\theta$$为网络统计量的系数，它是一个向量。此外，$$k(\\theta )$$是归一化常数，它可以确保模型中各种网络统计量形成链接的概率之和为1。这样，关于观察到一组网络链接的概率可以用指数随机模型表示为以下公式：\n$$ P(\\mathbf{Y} = \\mathbf{y}|\\mathbf{X}) = exp[{\\theta } ^{T} g(\\mathbf{y},\\mathbf{X})]/k(\\theta ) $$\n以上模型还可以表达为logit模型的形式。如果两个节点i和j之间存在链接的概率表示为$$p{ij}$$，那么不存在链接的概率可以表示为$$1-p{ij}$$。$$p{ij} / (1-p{ij})$$表示事件发生的相对似然率（the relative likelihood），又被称之为优势比（odds ratio）。比如，在信息转发的情境当中，A总共发了10条信息，B转发了其中的8条，那么优势比就是0.8\u0026frasl;0.2 = 4。Logit模型当中的因变量是优势比的自然对数形式，相应的模型表达为以下形式：\n$$ logit(Y{ij} = 1) = ln(\\frac{p{ij}}{1-p{ij}}) = {\\theta }^{T} \\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]{ij} $$\n以上公式当中，定义$$Y{ij}$$为节点i和j之间形成链接的一个随机变量。当$$y{ij}$$取值由0变为1的时候，所带来的$$g(\\mathbf{y},\\mathbf{X})$$的变化表示为$$\\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]_{ij}$$。\nstatnet是一个R包 (Goodreau, Handcock, Hunter, Butts, \u0026amp; Morris, 2008)，其中包含了三个子包：network, sna, 和ergm。本部分我们主要使用network来建立网络对象，并使用ergm针对网络对象建立指数随机图模型。\n使用network子包建立网络模型主要是将边的列表或者邻接矩阵的数据转化为statnet所默认的网络对象形式。例如，在以下程序中，我们将所抓取的微博转发网络数据转化为网络对象形式。\n#R程序 11-11：建立微博转发网络的ERG模型 library(\u0026quot;statnet\u0026quot;) # memory.limit(2000) #设置R调用内存的上限2GB # 将数值类型的变量转化为字符类型的变量以避免\u0026quot;vector size specified is too large\u0026quot; dat3[,1] = as.character(dat3[,1])　dat3[,2] = as.character(dat3[,2]) # 将edgelist类型的数据转化为一个网络对象 n = network(dat3, vertex.attr=NULL, vertex.attrnames=NULL, matrix.type=\u0026quot;edgelist\u0026quot;, directed=TRUE) summary(n) # 看一下网络的基本信息  指数随机图模型的一个优势是可以综合不同层级的影响因素（比如节点属性，链接或二元组属性、三元组属性、网络规模属性），其中的之一就是将网络节点属性纳入分析。其中的一个容易被忽略的关键点是将网络对象中的节点与原数据对应起来。\n此处，我们首先要明确网络对象中的节点（通过以下程序中的network.vertex.name来获取）并得到一个列数为1的网络节点数据。然后，我们将原始数据中的节点属性并入到网络节点数据中（通过merge命令来合并数据）。特别注意是此处推荐使用plyr包里面的join命令，因为在使用merge命令来合并数据的时候，即使设置“sort = F”其排序依然会出问题。最后，采用set.vertex.attribute命令就可以对节点属性进行设定。\n# 网络对象中的节点 node = data.frame(network.vertex.names(n), stringsAsFactors = F) names(node) = c(\u0026quot;User_idstr\u0026quot;) # 选取纳入分析的节点属性 att = unique(ana1[,c(\u0026quot;User_idstr\u0026quot;, \u0026quot;User_screen_name\u0026quot;, \u0026quot;User_gender\u0026quot;, \u0026quot;User_followers_count\u0026quot;, \u0026quot;User_friends_count\u0026quot;, \u0026quot;User_statuses_count\u0026quot;, \u0026quot;User_verified\u0026quot; )]) # 合并节点属性到网络节点数据 # Add province name province = read.csv(\u0026quot;D:/chengjun/css/part05/chapter11/data/weiboprovince.csv\u0026quot;, stringsAsFactors= F, header = F, sep = \u0026quot;,\u0026quot;) names(province) = c(\u0026quot;User_province\u0026quot;, \u0026quot;User_province_name\u0026quot;) library(plyr) att1 = join(att, province, by = \u0026quot;User_province\u0026quot; ) nodeAtt = join(node, att, by = \u0026quot;User_idstr\u0026quot;) set.vertex.attribute(n,\u0026quot;User_gender\u0026quot;,nodeAtt$User_gender) nodeAtt$User_verified[is.na(nodeAtt$User_verified)]=\u0026quot;FALSE\u0026quot; set.vertex.attribute(n,\u0026quot;User_verified\u0026quot;,nodeAtt$User_verified) nodeAtt$User_friends[is.na(nodeAtt$User_friends)]=0 set.vertex.attribute(n,\u0026quot;User_friends\u0026quot;,nodeAtt$User_friends) set.vertex.attribute(n,\u0026quot;User_city\u0026quot;,nodeAtt$User_city) set.vertex.attribute(n,\u0026quot;User_province\u0026quot;,nodeAtt$User_province) set.vertex.attribute(n,\u0026quot;User_bi_followers\u0026quot;,nodeAtt$User_bi_followers_count) nodeAtt$User_followers_count[is.na(nodeAtt$User_followers_count)]=0 set.vertex.attribute(n,\u0026quot;User_followers\u0026quot;,nodeAtt$User_followers_count) set.vertex.attribute(n,\u0026quot;User_statuses\u0026quot;,nodeAtt$User_statuses_count) set.vertex.attribute(n,\u0026quot;User_favourites\u0026quot;,nodeAtt$User_favourites_count)  当数据的准备工作做好之后，这个时候我们可以重新查看网络对象（在我们的饿例子中是n）的属性。在R console当中，输入summary(n)即可查看网络属性：\n Network attributes: vertices = 870 directed = TRUE hyper = FALSE loops = FALSE multiple = FALSE bipartite = FALSE total edges= 890 missing edges= 0 non-missing edges= 890 density = 0.001177202 Vertex attribute names: User_followers User_friends User_gender User_statuses User_verified vertex.names  此时，我们就可以正式开始模型设定和参数估计。这里，我们首先建立一个最为简单的网络模型m0。m0仅仅考虑最简单的网络参数，即网络当中的链接的数量。模型m0假设网络中的链接是随机生成的，也就是Erdős Rényi 随机网络模型（random graph）的基本要求，因而这个模型所生成的网络必然具备随机网络模型的特点(Erdős \u0026amp; Rényi, 1959)。\n# ERG模型的模型设定（Model Specification） m0\u0026lt;-ergm(n ~ edges, parallel=10) summary(m0) ========================== Summary of model fit ========================== Formula: n ~ edges Iterations: 20 Monte Carlo MLE Results: Estimate Std. Error MCMC % p-value edges -6.75703 0.03377 NA \u0026lt;1e-04 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Null Deviance: 1048080 on 756030 degrees of freedom Residual Deviance: 13622 on 756029 degrees of freedom AIC: 13624 BIC: 13636 (Smaller is better.)  该模型结果表明按照随机网络模型生成的网络，其中每一个网络链接（即信息转发）的log-odds是$$-6.75703\\mathbf{\\delta} [g(\\mathbf{y},\\mathbf{X})]{ij}$$。因为每增加任意一个链接，本模型的网络统计量（也就是网络中的链接的数量）增加1，所以$$\\mathbf{\\delta} [g(\\mathbf{y}, \\mathbf{X})]{ij}$$等于1。所以生成每条网络链接的对数优势比就是-6.75703。由此，不难算出生成每条网络链接的概率为exp(-6.75703)/(exp(-6.75703) + 1) = 0.001161327,而这个数值与实际的信息转发网络（有向）的网络密度（density）0.001177202非常接近。\n除了零模型中的边数之外，指数随机图模型还可以控制其它网络结构的因素，如网络中的的二元组的数量（通过mutual来在ergm中设定）和三元组的数量（通过gwesp在ergm中设定）。\n另外，指数随机图模型可以很容易的分析节点属性对于网络中的链接形成的影响，主要分析两种网络构成机制：流行性（popularity）和相似性（similarity）(Papadopoulos, et al., 2012)。首先，流行性主要分析一个节点的某种流行性的属性，比如一个信息转发者的粉丝的数量，在指数随机图模型中主要通过nodefactor和nodecov来设定。nodefactor主要分析针对的是类别变量，如性别、籍贯等；而nodecov主要针对的是连续型变量，如年龄、收入等。在有向网络当中，根据节点的入度和出度的区分，nodefactor和nodecov又可以区分为nodeicov和nodeocov，以及nodeifactor和nodeofactor。其次，相似性主要强调的是网络节点的两两之间在某种属性上的相似程度，在statnet的ergm命令当中主要通过nodematch来设定。如果说nodefactor和nodecov测量的是节点属性的主效应（main effect）的话，那么nodematch测量的主要是节点属性在网络链接水平上的匹配程度，也可以理解为交互效应。\n举一个例子来理解流行性和相似性作为两种一般性的影响因素在指数随机图模型当中的刻画，读者可以参阅 Goodreau (2009)关于青少年个体属性（性别、种族、年级）对于社会网络构成的影响。Goodreau认为个体属性的主要效应在友谊形成网络当中主要可以区分为两类：社交性（sociality）和同质性（homophily）。其中前者对应于流行性，而后者对应于相似性。与之相应，在指数随机图模型的设定当中，前者通过nodefactor/nodecov测量，而后者主要通过nodematch测量。\n# ERG Model Specification m0\u0026lt;-ergm(n ~ edges + nodematch(\u0026quot;User_province\u0026quot;) + mutual + gwesp(fixed=T, cutoff=30), parallel=10) summary(m0) mcmc.diagnostics(m0)  模型的运行结果如下：\n Estimate Std. Error MCMC % p-value edges -6.93374 0.03907 0 \u0026lt;1e-04 *** nodematch.User_province 0.95514 0.07629 0 \u0026lt;1e-04 *** mutual 0.42916 1.00405 0 0.669 gwesp.fixed.0 0.56772 0.72052 0 0.431 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Null Deviance: 1048080 on 756030 degrees of freedom Residual Deviance: 13498 on 756026 degrees of freedom AIC: 13506 BIC: 13552 (Smaller is better.) mcmc.diagnostics(m0)  当然了，我们可以根据研究目的建立更加完整的网络模型。例如，在以下的模型m1当中，我们开始考虑朋友数量、粉丝数量、用户性别、用户级别（是否认证用户）对于网络模型中链接形成的影响。需要注意的是该模型的运行时间很长，读者需要耐心等待。\nm1\u0026lt;-ergm(n ~ edges + nodecov(\u0026quot;User_friends\u0026quot;)+ nodecov(\u0026quot;User_followers\u0026quot;) + nodematch(\u0026quot;User_province\u0026quot;) + nodefactor(\u0026quot;User_province\u0026quot;) + nodematch(\u0026quot;User_gender\u0026quot;)+ nodematch(\u0026quot;User_verified\u0026quot;) + mutual + gwesp(fixed=T, cutoff=30), parallel=10) summary(m1) mcmc.diagnostics(m1)  模型的运行结果如下：\n# ========================== # Summary of model fit # ========================== # # Formula: n ~ edges + nodecov(\u0026quot;User_friends\u0026quot;) + nodecov(\u0026quot;User_followers\u0026quot;) + # nodematch(\u0026quot;User_province\u0026quot;) + nodefactor(\u0026quot;User_province\u0026quot;) + # nodematch(\u0026quot;User_gender\u0026quot;) + nodematch(\u0026quot;User_verified\u0026quot;) + mutual + # gwesp(fixed = T, cutoff = 30) # # Iterations: 20 # # Monte Carlo MLE Results: # Estimate Std. Error MCMC % p-value # edges -1.716e+01 3.984e-01 0 \u0026lt; 1e-04 *** # nodecov.User_friends -1.626e-03 1.846e-04 0 \u0026lt; 1e-04 *** # nodecov.User_followers 5.482e-04 1.216e-05 0 \u0026lt; 1e-04 *** # nodematch.User_province 3.831e-01 1.835e-01 0 0.036892 * # nodefactor.User_province.12 2.132e-01 3.502e-01 0 0.542661 # nodefactor.User_province.13 -7.425e-01 6.034e-01 0 0.218500 # nodefactor.User_province.14 -8.294e-01 1.031e+00 0 0.421116 # nodefactor.User_province.15 -5.463e-01 1.254e+00 0 0.663011 # nodefactor.User_province.21 -7.493e-01 5.439e-01 0 0.168295 # nodefactor.User_province.22 8.519e-02 3.643e-01 0 0.815101 # nodefactor.User_province.23 -2.727e-01 3.946e-01 0 0.489453 # nodefactor.User_province.31 -3.235e-01 1.719e-01 0 0.059810 . # nodefactor.User_province.32 -1.399e-01 2.522e-01 0 0.579093 # nodefactor.User_province.33 -1.466e-01 2.267e-01 0 0.517730 # nodefactor.User_province.34 -2.558e-01 4.437e-01 0 0.564221 # nodefactor.User_province.35 -4.032e-01 3.437e-01 0 0.240691 # nodefactor.User_province.36 3.205e-01 5.578e-01 0 0.565517 # nodefactor.User_province.37 -1.294e-01 4.125e-01 0 0.753818 # nodefactor.User_province.41 -3.616e-01 4.546e-01 0 0.426427 # nodefactor.User_province.42 -3.622e-01 3.374e-01 0 0.283047 # nodefactor.User_province.43 -3.551e-01 4.317e-01 0 0.410737 # nodefactor.User_province.44 -6.743e-02 1.567e-01 0 0.667042 # nodefactor.User_province.45 1.205e-01 1.106e+00 0 0.913280 # nodefactor.User_province.46 -2.464e-01 9.628e-01 0 0.798021 # nodefactor.User_province.50 -4.050e-01 5.908e-01 0 0.492984 # nodefactor.User_province.51 -6.097e-01 3.412e-01 0 0.074006 . # nodefactor.User_province.52 -3.054e-01 7.901e-01 0 0.699042 # nodefactor.User_province.53 3.954e-01 5.112e-01 0 0.439207 # nodefactor.User_province.61 -9.135e-02 4.958e-01 0 0.853833 # nodefactor.User_province.62 -7.939e-01 1.505e+00 0 0.597808 # nodefactor.User_province.64 -1.170e-01 1.641e+00 0 0.943158 # nodefactor.User_province.71 2.458e+00 1.607e+00 0 0.126091 # nodefactor.User_province.81 2.587e-03 4.796e-01 0 0.995696 # nodefactor.User_province.100 3.966e-01 1.915e-01 0 0.038304 * # nodefactor.User_province.400 -4.561e-01 2.430e-01 0 0.060461 . # nodematch.User_gender 5.707e-01 1.598e-01 0 0.000355 *** # nodematch.User_verified 9.986e+00 3.039e-01 0 \u0026lt; 1e-04 *** # mutual -8.400e+00 2.566e+00 0 0.001063 ** # gwesp.fixed.0 -4.064e+00 8.897e-01 0 \u0026lt; 1e-04 *** # --- # Signif. codes: 0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1 # # Null Deviance: 1048080 on 756030 degrees of freedom # Residual Deviance: 7680 on 755991 degrees of freedom # # AIC: 7758 BIC: 8208 (Smaller is better.)  六、讨论和结论 本章以网络科学为核心，勾勒了科学与可计算性的关系，描绘了数字化媒体和大数据的广泛应用，在此基础上重新思考了网络科学所蕴含的意义，并结合实际的案例介绍统计学方法在网络科学当中的应用。\n应当注意的是，本文只是一个基础的引论，而非全面而严格的介绍。本文的意义在于启发读者和勾勒大的图景。限于篇幅，对于很多具体的数学细节和理论问题并没有足够的论述。读者需要根据本文的参考文献按图索骥。通过进一步的阅读和学习来加深对网络科学的理解，并根据自己的需要在实践当中学习。\n参考文献  Barabási, A.-L., \u0026amp; Albert, R. (1999). Emergence of scaling in random networks. science, 286(5439), 509-512.\nBarabasi, A.-L. (2003). Linked: How everything is connected to everything else and what it means for business, science, and everyday life. New York: Plume.\nBurt, R. S. (1992). Structural holes. Boston: Harvard University Press.\nCrandall, D. J., Backstrom, L., Cosley, D., Suri, S., Huttenlocher, D., \u0026amp; Kleinberg, J. (2010). Inferring social ties from geographic coincidences. Proceedings of the National Academy of Sciences, 107(52), 22436-22441.\nCranmer, S. J., Heinrich, T., \u0026amp; Desmarais, B. A. (2013). Reciprocity and the structural determinants of the international sanctions network. Social Networks, http://www.sciencedirect.com/science/article/pii/S0378873313000026.\nDavis, J. A. (1963). Structural balance, mechanical solidarity, and interpersonal relations. American Journal of Sociology, 68, 444-462.\nErdős, P., \u0026amp; Rényi, A. (1959). On random graphs. Publicationes Mathematicae Debrecen, 6, 290-297.\nFrank, O., \u0026amp; Strauss, D. (1986). Markov graphs. Journal of the american Statistical association, 81(395), 832-842.\nGoodreau, S. M., Handcock, M. S., Hunter, D. R., Butts, C. T., \u0026amp; Morris, M. (2008). A statnet tutorial. Journal of statistical software, 24(9), 1-26.\nGoodreau SM, K. J., Morris M (2009). Birds of a feather, or friend of a friend? Using exponential random graph models to investigate adolescent social networks. Demography, 46, 103-125.\nLü, L., \u0026amp; Zhou, T. (2011). Link prediction in complex networks: A survey. Physica A: Statistical Mechanics and its Applications, 390(6), 1150-1170.\nLazer, D., \u0026amp; Pentland, A. S., Adamic, Lada., Aral, Sinan., Barabasi, Albert Laszlo., Brewer, Devon., Christakis, Nicholas., Contractor, Noshir., Fowler, James., Gutmann, Myron. (2009). Life in the network: The coming age of computational social science. Science, 323(5915), 721.\nLi, J. (2013). Rweibo: An interface to the Weibo open platform. http://jliblog.com/app/rweibo.\nMcPherson, M., Smith-Lovin, L., \u0026amp; Cook, J. M. (2001). Birds of a feather: Homophily in social networks. Annual review of sociology, 27, 415-444.\nNewcomb, T. M. (1953). An approach to the study of communicative acts. Psychological review, 60(6), 393.\nPapadopoulos, F., Kitsak, M., Serrano, M. Á., Boguná, M., \u0026amp; Krioukov, D. (2012). Popularity versus similarity in growing networks. Nature, 489(7417), 537-540.\nRivera, M. T., Soderstrom, S. B., \u0026amp; Uzzi, B. (2010). Dynamics of dyads in social networks: Assortative, relational, and proximity mechanisms. Annual review of sociology, 36, 91-115.\nRussell, M. A. (2011). Mining the social web: Analyzing data from Facebook, Twitter, LinkedIn, and other social media sites. Cambridge: O\u0026rsquo;Reilly.\nSnijders, T. A. (2002). Markov chain Monte Carlo estimation of exponential random graph models. Journal of Social Structure, 3(2), 1-40.\nWasserman, S., \u0026amp; Pattison, P. (1996). Logit models and logistic regressions for social networks: I. An introduction to Markov graphs and p*. Psychometrika, 61(3), 401-425.\nWatts, D. J., \u0026amp; Strogatz, S. H. (1998). Collective dynamics of ‘small-world’networks. Nature, 393(6684), 440-442.\nWing, J. M. (2006). Computational thinking. Communications of the ACM, 49(3), 33-35. 吴军. (2012). 数学之美. 北京: 人民邮电出版社.\n ","date":1376006400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1376006400,"objectID":"152497610c9b3204e66e4ed8beefa5ef","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-09-sna-book-chapter/","publishdate":"2013-08-09T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2013-08-09-sna-book-chapter/","section":"post","summary":"","tags":null,"title":"探寻社交网络中的关系: 统计网络模型初探","type":"post"},{"authors":null,"categories":null,"content":"QAP检验：两个网络之间的关联 通常一组个体具有多种类型的关系，例如友谊关系和经济往来关系。我们通常会对这两种网络关系在多大程度上相互关联感兴趣。当我们知道一组个体之间的两种关系网络，我们就可以计算这个两个关系网络之间的相关程度。在统计学当中，皮尔森相关系数是用来反映两个变量线性相关程度的统计量。与之类似，对于由一组个体所组成的两个网络，也可以计算其相应的相关皮尔逊相关系数。当然，还可以计算其他你感兴趣的统计量，如协相关系数。\n我们使用sna这个R软件包来计算网络相关系数（并调用qaptest命令）。通过安装和使用statnet这个R软件包，就会自动加载sna等子软件包。另外，statnet当中还集成了其他的几个相关的R软件包，包括进行动态网络建模的tergm子软件包。\n# R程序11-8：计算网络的皮尔逊相关系数 install.packages(\u0026quot;statnet\u0026quot;) library(statnet) # 首先随机生成3个由10个节点构成的有向网络 g=array(dim=c(3,10,10)) g[1,,] = rgraph(10) g[2,,] = rgraph(10,tprob=g[1,,]*0.8) # 设置g1和g2两个网络强相关 g[3,,] = 1; g[3,1,2] = 0 # g3接近于一个派系（clique） # 绘制这3个网络 par(mfrow=c(1,3)) for(i in 1:3) { gplot(g[i,,],usecurv=TRUE, mode = \u0026quot;fruchtermanreingold\u0026quot;, vertex.sides=3:8)} #计算网络的相关矩阵 gcor(g)  在通常使用皮尔逊相关系数的时候，可以用t统计量对总体相关系数为0的原假设进行检验。但在计算网络的相关系数（graph correlations）时，经典的零假设检验方法往往会带来偏差，因而并不适用。通常使用非参数检验的方法，比如QAP(Quadratic Assignment Procedure)检验。\n矩阵的随机排列（Random matrix permutations）是QAP检验的关键部分，在子软件包sna中主要通过rmperm来进行。通过矩阵的随机排列，可以对网络中的节点编号（而不是链接！！）进行随机置换（relabelling）或重新“洗牌”（reshuffling），并得到一组（比如1000个）重连后的网络。因为只是置换节点，这种操作只是重新标记节点的编号（relabelling）。\n# R程序11-9：矩阵的随机置换方法 j = rgraph(5) # 随机生成一个网络 j #看一下这个网络的矩阵形式 rmperm(j) #随机置换后的网络的矩阵形式  对这一组重构的网络可以计算其网络级别的参数（如两个网络的相关参数，协相关参数），并因此得到一个参数分布。QAP检验的零假设是实际观测到的网络参数（如）来自于这一个参数分布。也就是说，原假设认为这种观测到的相关关系是由随机因素带来的，因而这种网络相关并不显著。拒绝原假设，就从统计的角度证明了观测到的网络相关系数是显著的。\n# R程序11-10：QAP检验 q.12 = qaptest(g, gcor, g1 = 1, g2 = 2) q.13 = qaptest(g, gcor, g1 = 1, g2 = 3) # 看一下QAP输出的结果 par(mfrow=c(1,2)) summary(q.12) plot(q.12) # 拒绝原假设，图1和图2显著相关 summary(q.13) plot(q.13) # 接受原假设，图1和图3不相关  在检验这个关于两个网络是否存在相关的零假设的时候，我们计算置换后的参数分布中大于这个实际观测到的参数的比例，以及小于这个实际观测到的参数的比例。QAP检验返回实际数据中观测到的参数f(d)、通过置换所得到的参数f(perm)的数学分布、以及单尾的P值。其中单尾的p值包括两种情况：p(f(perm) \u0026gt;= f(d))和p(f(perm) \u0026lt;= f(d))。\n其中P(f(perm) \u0026gt;= f(d))表示随机置换矩阵的相关系数的大于与等于观测值的p值，也就是本研究的检验显著性。一般而言，当p(f(perm) \u0026gt;= f(d))小于p(f(perm) \u0026lt;= f(d))时，拒绝原假设。\n","date":1375574400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1375574400,"objectID":"dd06697a8ceeb6d9d76c4e4a9b17af2b","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2013-08-04-qap-test-of-network-analysis/","publishdate":"2013-08-04T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2013-08-04-qap-test-of-network-analysis/","section":"post","summary":"","tags":null,"title":"QAP检验：计算两个网络的关联","type":"post"},{"authors":null,"categories":null,"content":"作者： 黠之大者（网名），王成军，香港城市大学博士（在读）\n本文载于《数字媒体阅读报告》\nThe Laws of the Web Patterns in the Ecology of Information Bernardo A. Huberman (Author)\nPaperback: 115 pages\nPublisher: The MIT Press (April 1, 2001)\nLanguage: English\nISBN-10: 0262582252\n伯纳德-胡伯曼是惠普实验室的科学家，同时是斯坦福大学应用物理系的顾问教授（Consulting Professor）。他培养了很多学生，其中比较有名的当属Lada Adamic。他们两个在1999年以来的关于互联网的研究使之成为网络科学研究的重要成员，也奠定了本书基本的架构。他的第一篇论文发表于1970年，可以说是一个常青树。直到现在，依然保持着较高的学术产量。\n浏览其发表的论文，会很明显得发现他从物理学转型到互联网的结构和动态的研究，而现在则主要关注注意力经济的研究。从Strong Regularities in World Wide Web Surfing （1998， 《科学》），Evolutionary Dynamics of the World Wide Web （1999， 《自然》）等文章开始，胡伯曼的研究成为与其它主流研究者（如巴拉巴西）对话的重要人物，尤其是关于互联网的直径问题和互联网的增长机制问题 （读者可参见更好地一篇书评 ）。在其1998年的文章中，胡伯曼就提出了互联网的访问量满足幂律分布，而1999年的文章则表明互联网的结构同样满足幂律分布。这种普世的现象，胡伯曼将之称之为法则（law）。\n在讨论网络的演化与结构的过程中，胡伯曼强调关于市场中的个体的计划和策略的相吸信息不足以帮助我们理解一个市场的行为。主要是因为集体行为是互动的结果，单纯的个体信息只抓住了节点，而忽略的动态的互动。因此，追踪一些单个的个体的网页浏览行为也不能预测整体上的网络浏览规律。胡伯曼说，“我们必须放弃这些个体信息，而代之以更为整体的、系统水平的行为特征 ”（p. 23）。他将这种思路称之为整体的思路（the aggregate way），并认为这是一个强大的方法论，可以用来解决的大的分布系统，如股票市场、计算机网络、社会组织。不得不说，这是一种过于简略的思路。胡伯曼在这个问题上似乎对于微观的机制并没有太多兴趣，他执意要绕开从微观行为到宏观结果的涌现，而在系统层面讨论系统问题。恰因如此，他能够顺畅地讨论网络增长和网路规模这种系统水平的问题，而避开令人畏惧的个体行为。\n在等待牛顿的道路上，这对于普通研究者而言，不失为一种明智之举。却也显露出胡伯曼的局限。不过，这也是不绝对的，科学的道路，在发现法则之后，必然要走向背后的机制（mechanism）和普世的原理（principle）。物理学方法重视动力学方程的建立，他们以另外一种方式——数学和理论的途径面对微观的问题，但十分清楚这个从微观到宏观的过程不是简单的个体信息能顺利解决的。网络的另一特特征是小世界特性，胡伯曼指出目前的研究，尤其是巴拉巴西等人提出的优先链接机制不能较好的揭示网络的聚类特征，因此网络科学仍在寻找一个能够综合小世界特征和无标度特征的网络生成机制。其它几章讲解互联网阻塞、信息下载和互联网市场的问题，也多真知灼见。整体来看，这是一本非常简明的小书（正文只有95页）。作为较早的对网络科学研究的一个总结，值得读一下。\n","date":1355616000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1355616000,"objectID":"fb93bf70e5ca817e9baf6f4c3866a375","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-12-06-intenet-ecology/","publishdate":"2012-12-16T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-12-06-intenet-ecology/","section":"post","summary":"","tags":null,"title":"互联网的法则：网络生态学的起点","type":"post"},{"authors":null,"categories":null,"content":"本文载于《传媒透视》\n作者：王成军、张昕之 （作者皆为 香港城市大学 媒体与传播系 博士候选人）\n2011年8月22日，利比亚反对派军队攻占卡扎菲官邸。初传卡扎菲被击毙，后又有消息称，卡扎菲实已经密道逃亡，截止本文完成之时（8月27日），仍无其最新下落。\n如今微博已成为普通受众获知新闻、分享内容、沟通友人的重要渠道。利比亚内战一事在微博上迅速成为热门话题。然而微博用户众多，每个人的职业、地域、社会经济地位、社会网络、认知水平乃至动机，均有参差。尽管每个人用户都看似卷入了对重大事件的讨论，但是其发言的“质量”（如逻辑、可信度等）值得商榷。同时，微博有“V认证”以标识媒体工作者、社会名流、公共知识分子等人。这些人或因粉丝众多、或因观点犀利、或因独家爆料，其发言常被众多用户转发或评论，比起普通用户的“众说纷纭”，可谓“一言九鼎”。那么，事件发生后，在一个特定的微博用户群中，究竟是每个人平等参与了新闻的讨论和扩散抑或仅有几个活跃用户推进参与讨论的过程？新闻的信源与信息发布者之间、活跃用户与其粉丝之间、粉丝与粉丝之间——的互动关系在某个特定时间段表现为何种形式？\n为回答以上问题，作为一个探索研究，本文采用新浪微博API，抓取短短4分钟内（2011/8/22 15:06—15:10）所有新浪微博上对于卡扎菲官邸攻陷事件的信息发布、转发、评论，共计738条微博。四分钟的信息流，处于信息扩散阶段的一个短暂的瞬间，因而无法窥见整体层面的信息扩散规律。但因所采集的数据为随着时间有规律增长的宏大信息流的片段，同样可能起到窥一斑而见全豹的目的，其独特意义在于：海量数据流给信息处理和网络抽样带来巨大挑战，面对庞大的关系数据，传统统计方法不再适用；了解瞬间的数据流的特点是理解海量信息流的基础。本文从“瞬间数据流”的整体（而非样本）出发，探究其内在特点，可为网络舆论研究提供新视角。抛开技术的细枝末节，我们有四个重要发现:\n##发现一：自发性信息推荐群体的出现：从“自说自话”到“信息推荐” 738条微博信息中，转发的内容达262条，占三成，剩余约三分之二为原创新内容（476条）。主动的受众积极地转载来自其他渠道的信息。例如，其中有152条微博带有网络链接，30条提及电视台，26条提及路透社，23条提及齐鲁晚报。这表明有一个活跃的、自发性的“信息推荐群体”存在着，他们看似“自言自语”的原创微博发挥着信息推荐的作用。\n##发现二： “一言九鼎”的“舆论领袖” 在短短4分钟内，就有44条帖子被转发262次，平均每条帖子被转发6次。最多的一条帖子——华尔街日报关于卡扎菲倒、油价可能上涨的消息,在四分钟内被转发了43次；该消息发布于本研究抓取数据一个小时前的14:18， 一个小时中累计被转发290次，被评论105次。四分钟内转发数量超过9条的微博客用户，主要为媒体、媒体评论人，几乎全是加V的新浪认证用户（只有 “愤青3D”例外），并具有超过百万的粉丝数量。转发情况如图1。\n图 1 微博用户及其微博被转发次数（Top 10）\n##发现三：活跃的信息转发者：多次转发同一条信息的个体 本文分析了信息转发的网络关系，该有向网络由99个节点构成，拥有262条边，然而出乎意料的是这仅仅构成了一个稀疏的信息扩散网络：该网络的网络密度仅为0.027。网络密度衡量的是网络中真实存在的边与可能存在的边的数量的比值，本转发网络密度(0.027)低于期望值（0.054），说明有些节点之间存在多条链接，即某一个特定人物发布的某一条重要的信息，被“同一个转发者”多次转发。比如新闻评论人李承鹏所发的一条微博在4分钟内被转发15次。这15次并非被15个人“一人转发一次”，而是其中被一个ID为“古火拉兹-五毛”的人转发高达9次之上，剩下的几次由另两个ID（“慧-丽” 和“跪下去求婚站起来演说”）所转发。\n图 2 微博转发网络（箭头代表信息流动方向）\n##发现四: 原创型微博和被转发微博的语义网络：经济的还是政治的？ 上文中我们提到了两类微博：一是“推荐者”们原创的微博，二是意见领袖被转发的微博。为粗略地比较两类微博内容的区别，本文对这四分钟内抽取的微博内容，通过提取高频词，构建语义网络进行分析。发现：两类微博除了都关注新闻事件本身的基本经过、“5W”之外，“原创”微博关注政治及社会自由方面（图3）， 而社会名人被转发的微博主要针对新闻事件对经济的影响（图4）。\n图 3原创型微博的语义网络\n图 4 被转发微博的语义网络\n##总结 本例中，微博资讯的传播和扩散主要始于少数的意见领袖，跨国大型新闻机构亦是主要消息来源。微博时代，传统媒体如果善用网络平台仍可成为主要的信息来源。作为信息聚合作用的草根媒体开始出现，并扮演对传统媒体之信息进行过滤的把关人角色。此外，一些知名的草根ID通过自身的独特定位和宣传包装技巧，同样开始广泛的发挥舆论领袖的作用。值得注意的是，公共讨论和自言自语相互结合的原创类型微博占到了信息流的主体。“自媒体”从“自广播”开始起步，普通的微博使用者开始运用微博转载新闻、表明态度，使得微博成为孕育公共讨论的新机制。这种底层的广泛的信息转载虽然在四分钟内未获得转发，但在其各自子群中，都扮演着信息推荐者的角色。\n最后，作为一个探索性的研究，后续研究仍需要大量的文献梳理和技术支持。未来可以考量更为漫长的时间段内信息的扩散过程。另外，对制度性的不同话语主体之间（如政府、媒介、国际机构等）的互动，不同类型事件、乃至国内（敏感新闻、突发新闻更甚）新闻的扩散机制——凡此种种，均可成为后续研究之鉴。\n","date":1355529600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1355529600,"objectID":"4a9568445e65c630bb80297fc16b14ed","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2011-08-22-gaddafi-diffusion/","publishdate":"2012-12-15T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2011-08-22-gaddafi-diffusion/","section":"post","summary":"","tags":null,"title":"“众说纷纭”抑或“一言九鼎”？——以卡扎菲官邸攻陷事件在新浪微博上的信息扩散为例","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n王成军\n作者: 吴军\n出版社: 人民邮电出版社\n出版年: 2012-5\n页数: 304\n定价: 45.00元\nISBN: 9787115282828\n语言学是传播学的近邻，很多传播学研究都要借助于语言学的工作。经典的语言学或传统的语言学大师——乔姆斯基的跨界之作《媒介控制》也被传播学研究者奉为经典（读者可参见笔者之前的书评）。然而，在过去的三十年里，语言学经历的翻天覆地的变化，一个最明显的趋势是与计算机科学、数学的联姻——计算语言学在诸多藩篱中开花发枝长叶，变得日益蓬勃，并伴随着互联网的发展，成为一门支脉显学。\n这恐怕是这个学科的创建者及其论辩对象都没有想到的。当然直到现在，传统的语言学研究者和计算语言学的研究者依然剑拔弩张，大家去不同的会议，论文发表在不同的期刊。在第二章《自然语言处理——从规则到统计》中，吴军简略介绍了这两种思路的起源、冲突和发展。\n统计语言学之所以重要，是因为它开始充分利用语言学本身所特有的可计算性。可计算性是衡量一门科学发展阶段的重要尺度。如下图所示，我列出了几个学科的诞生时间和可计算性程度。当然数学和哲学不包括在内，因为数学超脱于可计算性，而哲学，在更大程度上不具有可计算性。网络科学以度为计量单位，经济学以货币为计量基础，物理学以时空为测量手段。值得一提的是，不是所有科学一诞生就有可计算性的，比如生物科学，刚开始的阶段要经历博物学这个考察物种的漫长阶段，直到沃森和克里克的工作揭示DNA的基本结构之后，生物科学才真正具备了可计算性。可计算性，非常关键，它可以使得学科在短期飞跃发展，分子生物学如此，计算机科学如此。正是将计算机科学置于比特这个基本的测量尺度上，计算机科学后起而领袖群雄。\n值得一提的是，语言学的可计算性程度要高于网络科学和经济学。然而，传统的语言学研究在更大程度上忽略了这种天然的优势，直到计算机科学诞生之后，学科的融合、产业的需求才开始催生它的发展。吴军尤其强调的是数学的作用，有了优质的数据的金矿并不必然会做出与之相应的结果或产品。“自然语言处理和通信的世界级专家……都有一个共同的特点就是数学非常好，同时解决了很多实际问题”。吴军认为是数学之美是其中的关键原因。\n图 1 不同学科可计算性的程度\n写到这里，或许我们可以谈一下科学的境界的问题。虽然饱经争议。但这的确是一个值得思考的问题。除计算机科学考虑算法及其计算复杂性，工程类科学考虑实际应用意外，大多数的理科和社会科学都考虑理论的发展问题 （其实信息论恰是纯粹的理论导向，但具有巨大的应用能力）。然而大家对理论是什么却显然有着很多模糊的理解，尤其在社会科学。所谓的理论往往被简化为概念之间的关系，于是置身于虚悬的概念游戏里再也脱不出来，还可美其名曰“理论研究者”。谬矣！与米尔斯所言之抽象实证主义相对的宏大理论学派同样好不到哪里去，甚至更差。历经波折，白首穷经的老社会科学家们到最好才悟到中层理论的优势，要能上下接通。然而仅仅是middle-range theory还是远远不够的，它顶多是一剂泻火的凉茶。社会科学的一个严峻问题依然是计算性的问题以及基于计算性探寻规律(pattern)、法则（law）、机制（mechanism）和原理（principle）的过程。于是，听众问：我们的理论哪里去了。答曰：规律(pattern)、法则（law）、机制（mechanism）和原理（principle）才是理论！可比较，有层级，能预测，可推导。这才是让人不失兴趣的理论研究。任何一个研究，如不能在这四个层级做出实在的贡献就是扯淡，是在学术的场域里耍流氓。\n吴军在书中谈及google创业之初很多工作没有系统的模型和理论基础。“这些方法比没有做任何事情好一些，但是几乎没有完善和提高的可能，而且使程序的逻辑非常混乱”（p 259 后记）。而一个巨大的压力是很多人在其成长的过程中失去了思考的能力！对周遭不好奇不敏感。《数学之美》一书结合具体的计算语言学在互联网中的应用问题给出了一个个生动活泼的例子，如中文分词、语音识别、网络爬虫、网页排名、网页相关性计算、地图搜索、新闻分类、词汇聚类、搜索引擎反作弊、拼音输入法、CDMA、搜索广告、MapReduce算法等诸多有着实际意义和巨大商业价值的问题。但胡乱地思考这些问题并不能揭示背后的理论。只有回到背后的原理，机制、法则（模型、算法皆在此列）、规律才能谈清楚这些问题。\n除了介绍这些理论和应用之外，吴军不失幽默地回顾了统计语言学派的大师们和现在的众多领军人物。贾里尼克和马库斯的经历让人倍感振奋，如此不虚人生一场追寻。诸多轶事趣闻读来让人浮想联翩，为之莞尔。吴军是 贾里尼克所在的霍普金斯大学拿到的博士学位，其后他加入了google，开创网络搜索反作弊的算法。例如，在youtube上面，一个盗版的视频的上传者是无法获取广告收入的，他获取的点击量将被归属于原始的上传者。之后，吴军加入了腾讯公司。除了这本《数学之美》之外，他还写了《浪潮之巅》，介绍众多互联网公司在数字浪潮中的创造的一个个神话。本文的副标题是——写在《数学之美》的边缘上， 因为实在是远远未能窥及书中的奥妙及其背后的东西。作为一本近乎科普的书，背后牵连的是宽广的知识网络：信息论、机器学习、数理统计，不一而足。相信认真对过本书的人能走得更远。\n","date":1355529600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1355529600,"objectID":"6ce87ad2f3f87bf983477c8fa2f7f896","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-12-15-beautiful-math/","publishdate":"2012-12-15T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-12-15-beautiful-math/","section":"post","summary":"","tags":null,"title":"通往统计语言学的桥梁——写在《数学之美》的边缘上","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\nBursts: The Hidden Pattern Behind Everything We Do\n作者: [美] 艾伯特-拉斯洛•巴拉巴西\n黠之大者\n人类动力学是一个迷人的研究领域，其中孕育了一系列有意义的研究。《爆发：人类90%的行为是可以预测的》一书正是其中一本重要著作。\n本书作者巴拉巴西是复杂网络研究的重要领军人物，1999年之后先后在《自然》、《科学》杂志上发表重要论文，指出诸如社会网络、神经网络、交通网络等多种复杂网络的节点密度的幂律分布，及其网络演化增长的优先链接机制。他和其博士阿尔伯特提出了“无标度网络”的概念，以及巴拉巴西-阿尔伯特模型（通常简写为BA模型）被广泛引用和报道，影响深远。其论文和书籍引发复杂网络研究在过去十余年中的研究热潮。巴拉巴西关于复杂网络研究的介绍可见其书籍《链接：网络新科学》，该书已经被湖南科技出版社翻译为中文，感兴趣的读者可以参阅。 巴拉巴西1967年生于罗马尼亚，从小就对物理学感兴趣。在欧洲获取本科和硕士学位后，巴拉巴西于1991年来到美国的波斯顿大学师从统计物理学家斯坦利攻读博士学位。事实证明，斯坦利对于巴拉巴西的研究兴趣影响深远，因为斯坦利本人就是一个跨学科研究者。虽然专注于复杂系统的研究，但斯坦利的研究覆盖众多领域，囊括物理学、生物学和社会科学，值得一提的是斯坦利本人就是经济物理学的创立者之一。笔者曾读过斯坦利关于海鸟迁徙行为的论文，非常具有想象力（或许这也跟后来巴拉巴西及其团队研究人类移动行为有关系）。1994年获得博士学位以后，巴拉巴西于次年加入圣母大学，开始其独立而不乏传奇色彩的学术研究之旅。圣母大学的13年执教时间，是巴拉巴西做出最多的学术贡献的阶段。2007年的秋天，巴拉巴西由位于美国印第安那州的圣母大学转入现在的东北大学，并创立了现在的复杂网络研究中心。现在的东北大学已经成为复杂网络研究的重镇。其研究小组非常强大，网罗了众多网络科学的研究者和访问学者。\n2005年作为一个物理学家，巴拉巴西在《自然》杂志上发表了一篇题为《人类动态中的重尾现象和爆发现象的起源》的论文，同一年就同一话题在《自然》杂志上发表题为《达尔文和爱因斯坦通信行为特征》的另一研究论文。两篇论文都是针对人类传播行为，指出这种人类传播行为在时间维度上具有明显的爆发特征，即短期内很多通信行为，而在相当长的时间间隔内则没有任何人类传播行为。这种爆发显现显然无法用描述随机过程的泊松过程来刻画，因为人类通信行为的间隔时间（或等待时间）的数学分布并非泊松分布，而是幂律分布。那么这种行为的特征背后的社会意义是什么呢？为此巴拉巴西进行了长久地思考。其结果就是于此相关的一系列论文和这本有趣的小书《爆发：人类90%的行为是可以预测的》。\n在本书中巴拉巴西介绍了自己研究这种人类行为在时间尺度上的爆发现象的很多细节和隐含的哲学。如同爱好旅行、浪迹天涯的网络科学研究者厄多斯一样，巴拉巴西的很多工作都是在旅途中，尤其是飞机上做出的。例如他关于网络增长的优先链接的模型的灵感就来源于在飞机上的思考，这个关于人类行为在时间尺度上爆发显现的研究与之类似。但因为当时在飞机上的他随身携带的电脑上的没有安装他所偏好的软件，他不得不去使用一个他当时还不太熟练的软件——Mathematica。后者是天才物理学家斯蒂芬•沃尔夫勒姆（Stephen Wolfram ）做创造的，具有非常强大的符号和数值计算软件，适合于做各种数学分析和模拟工作。不过，可惜巴拉巴西当时因为一个编程的细节错误而未能得到理想的结果。之后，这个研究一直萦绕到他的脑中，直到最后发现原来真理和谬误只差一个编程的细节。\n巴拉巴西善于描写人和事，其写作具有异乎寻常的天分，状人写物常有出神之处。这本书中写了一个关于泊松分布的提出者泊松的故事，十分有趣。泊松是一个法国数学家，同时也是一个物理学家，他的研究覆盖范围同样异乎广泛，非常高产，例如刻画随机过程的泊松分布就是他首先引入的。虽然巴拉巴西不太喜欢泊松分布，觉得有些过于简单而枯燥，但巴拉巴西对泊松本人的研究和生活却似乎很有兴趣。\n巴拉巴西在书中介绍了泊松的“成功秘诀”，原来泊松有一个习惯，当他想到一个好的研究问题的时候，泊松总是先按捺住内心的兴趣，只是将这个问题记在一个笔记本中，然后继续专注于自己在研究问题。直到把手头的工作完全解决，泊松才会回到那个记录着很多有趣研究问题的笔记本中，从中挑出一个最有趣的研究问题，继续开始研究。泊松给每个问题按照优先度排序，先去完成优先度最高的。这个故事或许启发我们如何才能够更有效率，更成功，那就是要专注，不要被枝节的问题所吸引注意力，但巴拉巴西却看得更远，他看到了人类行为在时间尺度上的爆发现象的深层社会原因，即个体给将要去完成的事件按优先性排序！按照排队理论，巴拉巴西马上建立数学模型，得到了想要的结果。\n对于社会现象的研究在社会科学中常常被变异性所牵引，给人造成一种社会科学没有统一规律的误解。巴拉巴西及其合作者对于人类行为的一系列研究无疑为其注入了一股清新的解毒剂。复杂网络处于规则与随机（或者说混沌）的边缘，同样人类的行为特征也具有类似特点。精确刻画出这种行为的统计特征，预测才变得可能。但其实预测与了解行为背后的机制相比，并非那么重要。巴拉巴西等人的工作至少似的人类行为的研究站在稳定的数学特征上开始追问其隐藏的机制。虽然距离揭示一种普遍的准则还有一段很远的距离，但所取得的成果依然非常令人振奋。因为人类90%的行为是可以预测的！本书的副标题的翻译比较灵活，因为其英文版的副标题则为“我们所做的所有事情背后所隐藏的规律”。但这种翻译并非耸人听闻，因为根据巴拉巴西和其合作者的对于人类移动行为的一项研究，这种预测能力可以高达93%。\n当前大数据和云计算成为关键词，作为普通的个体，我们依然需要一种分辨什么样的研究和事情才是重要的排序能力！值得注意的是伴随着网络科学在过去十几年间的崛起，可计算性社会科学变得成为可能。伴随着人类传播行为的研究在很多方面被不断推广和深入，作为其分支的计算传播学也开始变得呼之欲出。我们可以期待，一种扎根于可依赖的测量基础上的人类传播行为的中孕育着更多的、隐藏的、稳定的规律。揭示这种规律背后的机制和法则将是未来计算传播学的重要工作。\n本书当中还有很多真知灼见、有趣见闻，可以使得我们窥见最优秀的研究者的思维特点和点滴的经验教训。笔者从事信息扩散的研究，读这本小书常为之击节。人类行为的集体爆发显现非常广泛，不管在新闻扩散，还是在视频浏览数量增长方面，都在不断得到印证，并引发更多相关的研究涌现。如果读者对于网络科学和人类行为感兴趣的话，这本书应引起重视；如果读者觉得不够尽兴的话，一定不要错过巴拉巴西的网站和其所发表的一系列论文。不过，个人喜欢归个人喜欢，大多数的读者似乎并不觉得这本书怎么样，尤其是面对高昂的定价和过高的期待之时，甚至有人觉得《黑天鹅》也比这本书好，笔者无意冒犯，却实实在在不敢苟同，或许只有平心静气地读过相关的论文才能更好地理解本书中谈到的各种细节，而这对于很多人来说，似乎是不可能做到的，惜乎。\n","date":1346371200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1346371200,"objectID":"50656d4e321a7b0bbbd4c3a0986db4e2","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-08-31-burst/","publishdate":"2012-08-31T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-08-31-burst/","section":"post","summary":"","tags":null,"title":"爆发：人类行为在时间尺度上的特征","type":"post"},{"authors":null,"categories":null,"content":" 在前面章节中，我们主要分析了社会网络中的个体特征。从这一章开始， 我们将开始循序渐进探讨网络中的更大的分析单元，不仅分析个体及其相互联系特征，还要分析所有子图和聚类的特征。我们将探索处于一个三元组当中到底意味着什么，以及作为结构洞的好处和压力。\n 首先，我们将通过逐步去除部分网络的方法来解构网络，以便找到网络的核心(有时有多个核心)；接着，我们将使用网络的组分（二元组、三元组、派系、家族和聚类）来重构网络。\n4.1 组元和子图 为了将网络分解为可分析的单元，我们将首先给出一些定义：\n• 子图 子图（subgraph）是由一个网络的部分节点及这些节点之间的链接构成。任意一组节点都可以构成子图，稍后我们会介绍一些使用子图的有趣的方法。\n• 组元 组元（components)）是由网络当中相互分隔的部分构成。比如，在罗密欧和朱丽叶相遇之前，他们所在的两个家族没有联系（互相仇视，水火不容），因而可以被看作两个组元。\n许多真实的网络，尤其是那些通过随机抽样搜集到的网络数据，有很多组元存在。有些人可以质疑这是抽样误差（这是很有可能的）造成，但同时，这也可能只是意味着这些组元之间的链接在样本框之外，因此实际上这些组元之间本来就没有关联。\n使用Python分析组元 埃及暴动的推特转发网络是一个具有很多组元的网络的好例子。本书所讨论的推特转发网络数据，因为只收集了1%的推特用户所发的微博信息，所以很不完整。让我们读入并检查该数据。NetworkX包含一个分析孤立的相互关联的组元的命令（connected_component_subgraphs(e); 这个命令可以根据各个相互关联的组元返回其相应的图对象的数组）：\n\u0026gt;\u0026gt;\u0026gt; e=net.read_pajek(\u0026quot;egypt_retweets.net\u0026quot;) \u0026gt;\u0026gt;\u0026gt; len(e) 25178 \u0026gt;\u0026gt;\u0026gt; len(net.connected_component_subgraphs(e)) 3122  以上程序表明这个转发网络包含约25000个节点，但这个网络被分割成为超过3000个组元的子图。我们现在可以分析这些组元的规模大小的分布：\n\u0026gt;\u0026gt;\u0026gt; import matplotlib.pyplot as plot \u0026gt;\u0026gt;\u0026gt; x=[len(c) for c in net.connected_component_subgraphs(e)] \u0026gt;\u0026gt;\u0026gt; plot.hist()  在约3100个组元中，有2471个组元的规模是1——这些节点被称之为“孤立点”，并且应该从网络的剔除。有546个组元的大小是2（也就是只有一个转发），67个组元的规模是3， 14个组元的规模是4，11个组元的规模是5。组元的规模等于或大于10的情况，其频数非常小：\n\u0026gt;\u0026gt;\u0026gt; [len(c) for c in net.connected_component_subgraphs(e) if len(c) \u0026gt; 10] [17762, 64, 16, 16, 14, 13, 11, 11]  以上代码表明存在一个大小超过17000的巨大组元，7个组元的规模小于100，规模介于100到17000之间，不存在任何组元。\n在这个特例中，我们可以将这个巨大组元看作整个网络进行分析；但这个网络仍然因为规模太大而不能得出有趣的推论。\n网络中的岛屿 一个分析网络的技术被称之为“岛屿方法”（参见图 4-1）；这种方法尤其适合于分析权重网络，比如我们作为例子的埃及革命的推特转发网络。 岛屿方法按照以下过程工作：将我们的网络想象成一个具有复杂地形的岛屿，地形中每一个点的高度被定义为节点的数值（比如程度中心性）或边（比如转发量）。现在环绕这个岛屿的海平面高度随着时间缓慢增加，使得岛屿随着时间逐渐没于水面以下。到岛上的低谷被海水覆盖，这个岛屿就被分割为众多小岛——使得岛屿的最高峰显露出来，并且随着时间增长，这些显露于海面以上的高峰逐渐变小。\n图 4-1 岛屿方法\n当海水高度足够高之后，整个岛屿都可能完全消失在海水下面。因为，为了得到有意义的结果，这种方法需要被恰当地使用。\n对于网络而言，使用岛屿方法（ island method ）意味着大的组元将被分割为小的组分，并且具有最多的转发量的区域（子核）成为他们各自可以被单独分析的组元。\n使用岛屿方法时，我们所需要做的第一件事情是建立一个命令来提高“水平面高度”。这个命令使用一个门槛数值（也就是“水平面高度”）对图进行操作，使得权重超过该门槛值的边保存下来，移除掉剩余的其它的边。不用担心，这个命令会保存原来的图，因此它是非破坏性的（即并不损失信息）：\ndef trim_edges(g, weight=1): g2=net.Graph() for f, to, edata in g.edges(data=True): if edata['weight'] \u0026gt; weight: g2.add_edge(f,to,edata) return g2  现在，我们开始定义“水平面”如何被提高。我们将要生成一组均匀分布的门槛值作为“水平面”，并依据这些“水平面”生成一组网络：\ndef island_method(g, iterations=5): weights= [edata['weight'] for f,to,edata in g.edges(data=True)] mn=int(min(weights)) mx=int(max(weights)) #compute the size of the step, so we get a reasonable step in iterations step=int((mx-mn)/iterations) return [[threshold, trim_edges(g, threshold)] for threshold in range(mn,mx,step)]  以上程序中的函数将返回一组图对象，每一个图对应着一个特定的“水平面”。\n现在我们针对埃及革命的推特转发网络中的最大的组元进行分析，先使用岛屿方法将其分割为子部分：\n\u0026gt;\u0026gt;\u0026gt; cc=net.connected_component_subgraphs(e)[0] \u0026gt;\u0026gt;\u0026gt; islands=island_method(cc) \u0026gt;\u0026gt;\u0026gt; for i in islands: ... # 输出水平面高度、图大小、连接的组件的数量 ... print i[0], len(i[1]), len(net.connected_component_subgraphs(i[1])) 1 12360 314 62 27 11 123 8 3 184 5 2 245 5 2  以上程序是什么意思？当门槛值取值为1时，所有取值为1的网络链接（即一步转发的推特）被剥离，这个最大的组元被分割为314个“岛”的子图——每一个代表一组持续地相互转发的人群。因为一次转发可以被认为偶然的，所以这是一个很有用的结果——持续的转发，更常见于那些经常交流并因此培养出某种信任关系的群体当中。\n门槛值取值为62（即每对节点之间的最小转发为62）时，只有27个节点保留下来，分布于11个“岛屿”之中。在这个例子当中，62是最有意义的门槛值——剩下的27个节点是最积极地卷入解放广场示威的人和报道这个事件的记者。\n这可能需要经过一个试错的过程，但一个设置合理的“水平面”可以针对大的网络生成一个非常有意义的结果——立刻找到网络中最活跃的核心节点。\n4.2 子图——自我中心网 自我中心网（Ego networks）是一个以某一特定节点为核心的子网络。在脸书和LinkedIn上面，自我中心网通常被描述为“你的网络”——但是你只能看到你自己的自我中心网，而不能做一个覆盖范围更为广阔的调查。拥有一个大的数据可以使得我们测量和比较不同人的自我中心网。 我们通过运行一个广度优先搜索（参见本书第2章：广度优先搜索）并且限制搜索的深度（网络半径）为一个通常不超过3的数值的方式，来获得自我中心网。不同的是，在通常的广度优先搜索当中，我们通过构建一个链接树的方式找到要搜索的节点，而为了生成一个自我中心网，我们需要获取特定的中心节点的所有邻居之间的所有链接。\n为了理解采用一个小的搜索深度的方法获取自我中心网背后的逻辑，我们需要重温在网络中与其它节点连接意味着什么，以及网络距离的意义是什么。通常情况下，网络链接的一个例子是“爱丽丝是鲍勃的朋友”，一个数值为2的网络距离的一个例子则是“卡洛尔是爱丽丝的一个朋友的朋友”，而一个数值为3的网络距离的例子是“戴夫是爱丽丝的一个朋友的朋友的朋友”。直觉上讲，我们将其理解为虽然我们对我们的朋友了解很多，我们对我们的一些朋友的朋友的情况也略有所知，但我们几乎不知道任何我们朋友的朋友的朋友的事情。\n严格地说，网络距离这个概念被表达为“可观测性的界限” （Horizon of Observability），是一个从物理学和“可观测的宇宙”这个提法当中灵活借鉴而来的概念。诺亚•弗里德（Noah Friedkin）发现在社会网络中，人们对于自己所在的自我中心网非常了解（错误率约为30%），其所报告数据质量与通过自我报告的方式收集的数据质量一样好。二度网络距离的错误率跃为70%，三度网络距离的错误率则高达100%。\n在诸如推特这种在线社会网络，因为对于朋友的定义非常松散以及电脑辅助的信息保存方式，自我中心网的半径要大很多。信任和影响力所流经的人际网络渠道并不太稳固，所以分析一个网络半径大于3的自我中心网的将会是一个错误。当我们研究通过一系列转发的形式而进行的信息扩散时（我们将在第6章介绍），深度优先的搜索方式将替代广度优先的策略而被使用。\n使用Python提取和可视化自我中心网 提取自我中心网非常简单，因为NetworkX提供一个现成的内置函数来完成这个工作：\n\u0026gt;\u0026gt;\u0026gt; net.ego_graph(cc,'justinbieber') \u0026lt;networkx.classes.multigraph.MultiGraph object at 0x1ad54090\u0026gt;  是的，不管信不信，贾斯汀•比伯（Justin Bieber）也在埃及转发网络数据当中。他的自我中心网早已经出现于本书中，见图1-11。 这个ego_graph函数返回一个NetworkX图对象，并且所有的常见的度量（程度中心性，居间中心性等）能够通过它计算。\n但是，一些其它的简单的度量并未被纳入其中。知道一个自我中心网的规模对于理解一个人转发的（或收到的）信息能够传播的范围非常重要。 另外一个度量被称为聚类系数（clustering coefficient）——本质上，它测量了你的朋友彼此之间也是朋友的比例（也就是人们之间的相互信任程度）。这个度量可以被应用于整个网络当中——但是对于一个密度差异很大并且有多个核心的大的网络，平均的聚类系数很难解读。在自我中心网当中，对于聚类系数的解释非常简单——一个自我中心网，稠密且嵌入了很多相互信任的节点，具有一个较高的聚类系数。由一个单一向外“广播”的核心节点和众多“听众”构成的星型网络，则具有一个较低的聚类系数。 让我们开始探索一下埃及数据中的一些自我中心网：\n## 我们需要将自我中心网从一个多图转化为一个简单的图。 \u0026gt;\u0026gt;\u0026gt; bieb = net.Graph(net.ego_graph(cc,'justinbieber', radius=2)) \u0026gt;\u0026gt;\u0026gt; len(bieb) 22 \u0026gt;\u0026gt;\u0026gt; net.average_clustering(bieb) 0.0  贾斯汀•比伯(Justin Bieber)的名人地位并未能够在这个特定例子中帮到他——在他的九百万个关注者当中，仅仅有二十二个人转发了他的关于埃及革命的信息。他的聚类系数表明他是一位纯粹的“广播者”，并未被嵌入他的粉丝的信任网络中——或者，至少，他并不在一个关心世界政治的信任网络中。\n让我们现在探索一个不同类型的名人——威尔•戈宁(Wael Ghonim)，新一代的埃及人，Google的主管，推特的重度使用者：\n\u0026gt;\u0026gt;\u0026gt; ghonim= net.Graph(net.ego_graph(cc,'Ghonim', radius=2)) \u0026gt;\u0026gt;\u0026gt; len(ghonim) 3450 \u0026gt;\u0026gt;\u0026gt; net.average_clustering(ghonim) 0.22613518489812276  威尔• 戈宁不仅有一个巨大的转发网络（尽管比贾斯汀•比伯的粉丝少100倍），他的自我中心网是一个人们从他这里以及其他人那里转发信息的信任网络，一个革命的信息可以很容易扩散和持续的网络。\n在下一部分我们要讨论的结构洞和三元组分析对于自我中心网同样非常适用——所以敬请期待并且开始分析你自己的数据！\n4.3 三元组 一个三元组其实就是三个节点以某种形式相互链接。无论如何，在三元组分析中，情况并非如此简单。图4-2列出了所有可能的无向（undirected ）的三元组；正如你所看到的，仅有前两个类型当中的所有节点是相互链接的， 并因此具有独特的意义。有向的三元组共有16种，但我们将在本章稍后的部分讨论。\n图 4-2 三元组的形式\n图字翻译：\n闭合的三元组（图4-2中左侧）展现的是一个完全连接的群体：A，B，和C以相同强度的边相互连接。闭合的三元组的一个最简单的例子是“核心家庭”——妈妈（爱丽丝），爸爸（鲍勃）和一个孩子（卡洛尔）。当然，这些三元组可以相互重合——例如，同一个妈妈和爸爸可能还有另外一个儿子（大卫），这种情况下三元组不止有一个，而是四个：\n[爱丽丝，鲍勃，卡洛尔] [爱丽丝，鲍勃，大卫] [卡洛尔，大卫，爱丽丝] [卡洛尔，大卫，鲍勃]  这个网络结构或许代表了社会网络研究领域当中最古老的一种研究。在1908年，乔治•齐美尔，一位与马克斯•韦伯同时代的人， 与他的知识分子圈的一位成员一起写作了一篇论文《三元组论》。\n齐美尔认为在一个二元组（dyad ）（也就是两个节点相互连接在一起）中，每个人都能够保持他们的个体性并维持一段亲密关系。二元组有助于信息和意见的交流，但它并未使得个体融入群体。在三元组当中，第三个个体成为一个平衡的本源（提供不同的意见并舒缓精神）。但第三个节点也是一个反馈的渠道——来自A的信息传递到B，然后到C，并以一种非常扭曲的形式回到A——正如一个儿童的游戏“打电话”所表明的一样。\n作为一种不断扭曲的结果，一个三元组随着时间的推移生成一组三元组所特有的人造品——方言土语或绰号昵称，局部的规范和行为准则，共享的意义。在一个宏大的语境里，社会学家把这种人造品的累积称为文化。 或许在一个三元组的语境里，三元组是一个非常大的词语——但可以想象一下你自己的家庭或者你的朋友的家庭。或者，下载一集ABC播出的真人秀《交换女主人》（Wife Swap, 幸运地在2009年取消了），并观看两个家庭文化的在真人秀中的碰撞。\n大学生联谊会研究——链接的稳定性与三元组 另外一个相似的研究由纽科姆完成。 实际上，这个研究与现代真人秀电视节目有些（惊人的）相似，但是发生于二十世纪六十年代早期。想象一家位于密歇根的大学生联谊会 （是的，有啤酒 ） 。在学期开始，17个学生（都是白人）被招募住在一个大学生联谊会的房子里长达一个学期时间， 以交换他们的个人信息数据为条件。每周，研究者访问每一个学生成员并让他们对与之互动的成员按照1（最好）到16(最差)的顺序进行排序。\n这个研究发现：\n• 不对称的链接（例如“我喜欢你多过你喜欢我”）最不稳定，维系不超过两周时间。\n• 对称的链接（二元组中的两个人以相同的程度喜欢彼此）明显更稳定。\n• 三元组结构随着时间的推移是最稳定的，三元组中的学生们一起消弭冲突，组织活动，并奠定兄弟会内部相互交往的风气。\n三元组和恐怖分子 在本书第1章的“恐怖组织的信息网络”， 我们提到基地组织（Al Qaeda cells）在训练和准备恐怖袭击的时候被隔绝于一个安全的藏身处。这种隔绝迫使组织形成一种稠密的三元组结构，每个人都与其他人一起嵌入在三元组中。加上实际上的感觉剥夺（所有来自外部世界的信息被组织的领导者过滤），这个群体生成他们自己的超越了绰号和共有的故事的文化人造品——继续强化他们作为宗教极端分子的身份并加强他们完成袭击的决心。\n引用马克•萨基曼（Mark Sageman） 的话来说，汉堡支部（谋划并最终参与执行了911恐怖袭击）就是——“一群人”。在分析了17个恐怖分子的生活之后，萨基曼发现驱动他们的最主要因素是他们在恐怖组织内部的社会关系。大多数人开始的时候是朋友，同事，或者亲属——并且关系因为友谊、忠诚、团结和信任的纽带而更亲密，并获得强烈的归属感和集体身份。\n图4-3 911劫机者的社会网络\n在本书的Github库 (https://github.com/maksim2042/SNABook/chapter4)当中,你可以找到用来生成图4-3 的数据 ，并且自己分析它。数据以边列表的形式存储于文件当中，其格式如下所示：\nHani Hanjour,Majed Moqed,5,1 Hani Hanjour,Nawaf Alhazmi,5,1 Hani Hanjour,Khalid Al-Mihdhar,5,1  第一列是有向边指出的节点的名字，第二列是有向边指入的节点的名字，并且接下来的两个数字表示边的强度（5=最强的边，1=最弱的边）和边被确认的程度（1=被确认的亲密关联，2=各种被记录的交往活动， 3=潜在的或计划的或未确认的交往活动）。\n导入这个文件时，我们无法使用NetworkX内置的文件读入功能，但我们可以用短短几行代码构建一个：\nimport csv ## 我们将使用内置的 CSV库 import networkx as net # 打开文件 in_file=csv.reader(open('9_11_edgelist.txt','rb')) g=net.Graph() for line in in_file: g.add_edge(line[0],line[1],weight=line[2],conf=line[3])  我们还有一个标明19个劫机者曾经乘坐过的航班的属性文件。让我们也把这个数据读入：\n# 首先，我们应该确认所有的额节点都具有“flight”属性 for n in g.nodes_iter(): g.node[n]['flight']='None' attrb=csv.reader(open('9_11_attrib.txt','rb')) for line in attrb: g.node[line[0]]['flight']=line[1]  tips： 通常有两种方法列出图中的节点。g.nodes()提供了一列节点，而g.nodes_iter()生成一个Python迭代器。迭代器仅限于在循环当中——但仅仅使用很少的内存并且在大图当中运行更快。\n如果你现在使用默认的net.draw(g)函数将这个网络画出来，你会发现这个网络包含了几个互补相连的组元。这是因为这个数据是支离破碎和不完整的；我们仅仅关注网络中的最大组元：\n# Connected_component_subgraphs()返回一系列的组元， # 按照从最大到最小的顺序排列 components=net.connected_component_subgraphs(g) # 找出第一个也是最大的组元 cc = components[0] 我们使用multimode.py中的一个惯用的绘图函数来绘制这张图片。这个函数读入节点属性，并根据节点属性的取值分配颜色，迅速地绘制一个惯用的彩色图片： import networkx as net import matplotlib.pyplot as plot from collections import defaultdict def plot_multimode(m,layout=net.spring_layout, type_string='type',filename_prefix='',output_type='pdf'): ## 创造一个默认的颜色序列和一个空的彩色图 colors=['r','g','b','c','m','y','k'] colormap={} d=net.degree(m) #we use degree for sizing nodes pos=layout(m) #compute layout # 现在我们需要找出需要绘制不同颜色的节点构成的群体 nodesets=defaultdict(list) for n in m.nodes(): t=m.node[n][type_string] nodesets[t].append(n) ## 使用相应的颜色设置，将每组中的节点分开绘制 print(\u0026quot;drawing nodes...\u0026quot;) i=0 for key in nodesets.keys(): ns=[d[n]*100 for n in nodesets[key]] net.draw_networkx_nodes(m,pos,nodelist=nodesets[key], node_size=ns, node_color=colors[i], alpha=0.6) colormap[key]=colors[i] i+=1 if i==len(colors): i=0 ### 如果我们用光了所有的颜色，那么循环使用这些颜色 print colormap ## 使用一个默认的绘图机制绘制边 print \u0026quot;drawing edges...\u0026quot; net.draw_networkx_edges(m,pos,width=0.5,alpha=0.5) net.draw_networkx_labels(m,pos,font_size=8) plot.axis('off') if filename_prefix is not '': plot.savefig(filename_prefix+'.'+output_type) 最后，我们绘制出网络： import multimode as mm # type-string 指引函数某种需要辨别的属性 mm.plot_multimode(cc,type_string='flight')  一旦我们建立了用于三元组分析的工具，你可以使用这个数据作为一个理解三元组如何工作的测试，并与关于恐怖主义研究的大量文献潜在地联系起来。\n“禁止进入的三元组”和结构洞 我的朋友鲍勃 有一个问题。你明白的，他爱上了两个女人。一个是精力充沛的东欧美女（让我们称她为爱丽丝），另一个是来自南美洲的乐天派女孩卡若琳娜。这两位女孩中的任何一个对于鲍勃来说都是绝配，但是他无法决定。当鲍勃和爱丽丝在一块的时候，他渴望见到卡洛琳娜和她无忧无虑的态度；但他和卡洛琳娜在一起的时候，他思念爱丽丝和她美丽以及有深度的谈吐。结果，几年过去了，鲍勃依然处于病态的单身状态中。\n从网络角度而言，鲍勃的窘况在于他处于图4-2的第二个三元组中。B与A和C相连——但A与C之间并没有任何连接，并且鲍勃作为图中的B应该维持这种状况如果他想继续同爱丽丝和卡洛琳娜两个人同时交往。每天，鲍勃需要调整他的日程表以确保A和C不会相见，这给鲍勃的生活带来越来越多的压力，但他同样需要确保他不会因为忘记他告诉A或C的事情或者A或者C偶尔告诉他的事情而露馅。结果，鲍勃身处焦虑之中，然而所有的事情并没有按照鲍勃所希望的那样发展。\n我另外一个银行家朋友（Banker）身处与之相似的网络链接当中，但却对此非常高兴。他的A是AmeriCorp公司，而C是CorpAmerica公司。AmeriCorp公司在他的银行里存款并期望5%的利率。而CorpAmerica公司则按照7%的利率从他的银行借款。这样我这个银行家朋友B就获得其中的利率差——C支付的利率和A期望得到的利率之间的2%的差别。对我这个朋友而言，这2%的利率差足够他购买一个房子、一个最新款的宝马车、一个精英俱乐部的成员资格和其它的他非常喜欢的物质财富。假设A和C因为打高尔夫球而认识，他们就会同意A以6%的利率直接借款给C，并意识到撇开中间人对他们双方都有利。如果这件事情发生了，银行家B就会非常沮丧。\n尽管在三元组背后的故事完全不同，鲍勃和银行家朋友的意愿却完全相同。他们都需要确保他们的开放的三元组的末端不能直接联系——也就是说A和C之间不会建立网络链接。\n不同的人给这个三元组所取的名字不同。一些研究者称它为“禁止进入的三元组”——因为像鲍勃一样，他们认为这个三元组与压力、焦虑和同时与两个女人约会所带来的道德问题相互关联。其他人称它为“结构洞”或者“中间人结构”，并且认为一个个体所占据的结构洞的数量与其作为企业、银行、经纪人或地产代理的业绩相互关联。\n罗纳德•伯特（Ronald Burst） 的研究表明在一个竞争性的市场当中，占据更多结构洞的商人具有更显著的高成功率。商人的成功是是通过两件事情来预测的——商人在不对称信息的条件下的开拓能力和交易能力，和商人对于创造和维持“套利机遇”过程中多带来的压力的高度容忍度。\n结构洞和边界跨越 结构洞具有另一个重要的使命——因为他们能够降低信息不对称性（例如，因为我的两个朋友都能够提供信息），他们也能够连接不同的社群。本书的两位作者即是社会网络研究领域的专业人士（马克斯教社会网络分析的课，艾利克斯编写社会网络分析的软件），又是专业的音乐家。事实上，我们两个是在一个摇滚音乐节上相遇的，那时我们两个各自的乐队正在那里表演。\n所以，一个包括马克斯、马克斯在学术研究方面最亲密的合作者和他乐队中的鼓手的三元组实际上是一个结构洞。这些科学家和鼓手对于英语有基本的了解（不存在语言障碍），但找不到足够的谈论的话题。因为社会距离（social distance）（我们将在第6章讨论信息扩散的时候进一步涉及的一个术语）的原因，在他们之间存在网络链接的可能性基本为零。 我们的社群（科学家和音乐家）经常交叉。马克斯之前所在的一个乐队是全部由教授构成的，之后所在的一个摇滚乐队全部由神经科学家构成（称为“Amygdaloids” ），乐队也因此而知名。\n但是，与那些仅仅是专业的音乐家或者科学家的人的规模相比，这些跨界者（懂科学的音乐家和懂音乐的科学家）很少。结果，这两个社群的交叉看上去像图4-4。\n图4-4 跨界者示意图\n事实上，这种事情在不同层面存在着。如果我们仔细考察科学家群体，我们发现它包含了各个主要的领域（生物学、计算机科学、人类学等），并且如果我们更仔细地看这些领域所包含的子领域，我们会发现它们都通过结构洞联系在一起。\n在科学社群中，这非常重要。因为许多新的发现本质上都是跨学科的。例如，詹姆斯•富勒（James Fowler） 致力于神经科学与社会网络分析交叉领域的研究。\n一些其他的领域（例如经济学）不鼓励跨越不同子领域的对话和论文发表，并对他们的理论过度保护。在这种情况下，比如存在于奥地利学派和新古典经济学之间的结构洞位置将会充满压力并很难维持——这更像鲍勃的困境而非银行家的顺境。\n政治中的三元组 图4-5展现了一个不同国家在高加索（ Caucasus）的政治合作网络 。 从现代地缘政治的角度讲，高加索是一个非常有趣的地方（看图4-6中的地图）。这是一个很小的地方，具有异常美丽的山地地貌，它夹在北面的俄罗斯 （Russia）和南面的土耳其（Turkey）和伊朗（Iran ）之间。其居民主要是基督徒和穆斯林民族的混乱得混合，并且他们开始逐渐拥护西方的国家。俄罗斯，或者土耳其（从苏联解体开始）在这里创造了一种令人诧异的地缘政治景观（大多数是令人不高兴的，至少对于当地人来说）。\n图 4-5 在高加索的政治合作网络\n图 4-6 高加索—一个种族和语言的熔炉\n图中的网络通过其它国家和高加索、俄罗斯、土耳其、欧盟和美国之间签订的政治合作协议和声明关系而构建，明显表明俄罗斯与其它西方国家之间的政治治理风格的差异。俄罗斯为中心的一方的网络充满了结构洞，俄罗斯实际上控制着这个网络，而边缘国家节点之间的网络链接几乎不存在。\n唯一横向的网络链接存在于南奥塞梯（South Ossetia）和阿布哈兹(Abkhazia)之间。在本研究进行的时候，这两个地方都还是格鲁吉亚的一部分——但实际上，它们当时明显不忠于格鲁吉亚。南奥塞梯的分裂运动（或者，这是一个俄罗斯人为了巩固在该地区的影响而进行的挑拨，这取决于读者的新闻来源是俄罗斯媒体还是美国媒体）在两年内遭到了格鲁吉亚军队一个短暂而血腥的镇压。之后，南奥塞梯和阿布哈兹这两个地方都宣布独立并正式与俄罗斯建立盟友关系。\n同时，西方国家一方的网络表现出一种具有较多亲密关系和横向连接的特征。这将减弱超级大国的影响力，因为横向的网络链接降低了（超级国家）的效率和直接影响。同时，这种三元组结构更加稳定并且不需要很多的力量去维持。\n有向的三元组 理论足够了，让我们开始编写一些代码！\n图4-7给出了所有的可能的有向的三元组。在一个有向的三元组当中，我们同时考虑单向的边和双向的边；因此总共有16种可能的情况，而非4种情况。我们将对这些形状进行一些解读，但首先让我们定义一种对其进行分类的方法。这种计数和分类的方法或许有一些晦涩难懂，但自从1972年开始，它就成为了这个领域的学术文献中的一种标准 。\n图4-7 有向网络中所有可能存在的三元组\n这些三元组按照1到16 的顺序进行编号，每一个都有一个代码。这些代码按照如下方式进行阅读：\n• 第一个数字代表了双向链接的总数量。\n• 第二个数字代表了单向链接的总数量。\n• 第三个数字代表了不存在的网络链接的总数量。\n• 字母用来区分相同三元组的不同形式——U代表了“向上”，D代表了“向下”，C代表了“传递”（也就是说有两条路径指向相同的节点）\n图中的三元组1到3是未连在一起的，三元组4到8和11代表结构洞的不同形式。三元组9、10和12到16是紧密型三元组的不同形式。\n分析真实网络中的三元组 对于一个真实网络的三元组分析的过程成为“三元组普查（triad census）”。在这个过程当中，对于每一个节点，我们计算16种类型三元组出现的频数以决定这个节点在网络中的角色。例如，一个节点具有较多的三元组4、7和11（也就是说有较多的流出的网络链接和结构洞）是一个信息的来源或者潜在的小组领导者。\n执行三元组普查，我们需要一种仍未被纳入NetworkX的一种算法——三元组普查算法 。从Github下载第4章所要用的算法包 ，修改系统目录为下载文件所在的路径，并开启Python：\n\u0026gt;\u0026gt;\u0026gt; import networkx as net \u0026gt;\u0026gt;\u0026gt; import tradic \u0026gt;\u0026gt;\u0026gt; import draw_triads  这个draw_triads函数可以重新绘制出图4-7.\n现在，让我们应用三元组普查到一些抽样数据当中去（比如图4-8当中的风筝网络）：\n## 生成一个有向的风筝网络 \u0026gt;\u0026gt;\u0026gt; g=net.DiGraph(net.krackhardt_kite_graph()) ## 执行三元组普查程序 \u0026gt;\u0026gt;\u0026gt; census, node_census = triadic.triadic_census(g) \u0026gt;\u0026gt;\u0026gt; census {'201': 24, '021C': 0, '021D': 0, '210': 0, '120U': 0, '030C': 0, '003': 22, '300': 11, '012': 0, '021U': 0, '120D': 0, '102': 63, '111U': 0, '030T': 0, '120C': 0, '111D': 0}  图 4-8 魁克哈特风筝社会网络\n三元组普查函数返回了两个结果——一个包含了网络的所有结果的Python字典，和一个包含了个体节点的所有结果的字典的字典。\n在风筝图当中，这个程序找到24个结构洞类型三元组（代码为201）和11个紧密型三元组（代码为300）。这意味着在网络中存在着一些联系特别紧密的区域和一些充满很多结构洞的区域。当然这个发现对于这个图来说是显而易见得到——但对于一些大的网络来说就不是如此明显。\n结构洞型三元组和紧密型三元组的比例也是非常重要的——一个等级制度主要是由结构洞构成的，而平等主义的网络结构中紧密型三元组具有较高的比例。\n简而言之，一个三元组普查使得我们可以对一个网络结构的宏观层面做出一种高级的结论。但是，这在微观水平上同样有趣。下面的代码生成一个三元组普查表格，其结果在表4-1中：\nkeys=node_census.values()[1].keys() ## 生成一个表格的标题 print '| Node |', ' | '.join(keys) ## 生成表格的内容 ## 需要一点小技巧区将整数转为字符 for k in node_census.keys(): print '|', k, '|',' | '.join([str(v) for v in node_census[k].values()])  节点 201 021C 021D 210 120U 030C 003 300 012 021U 120D 102 111U 030T 120C 111D\n0 8 0 0 0 0 0 0 4 0 0 0 14 0 0 0 0 1 4 0 0 0 0 0 0 3 0 0 0 11 0 0 0 0 2 4 0 0 0 0 0 0 1 0 0 0 7 0 0 0 0 3 3 0 0 0 0 0 0 2 0 0 0 7 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 5 1 0 0 0 0 0 0 1 0 0 0 5 0 0 0 0 6 1 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 7 1 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  表4-1 风筝网络内部的三元组普查\n现在让我看一下主要的三元组类型:紧密型三元组（代码为300）和结构洞型三元组（代码为201）。\n真实数据 让我们现在对在本章前面部分用到的9/11劫机数据执行一次三元组普查，并找出谁拥有最多的派系（紧密型三元组，代码为300）：\ncensus, node_census = triadic.triadic_census(cc) ## 仅仅得到紧密型三元组的数量，并按照其数值进行降序排列 closed_triads=[[-k,v] for k,v in sorted([[-node_census[k]['300'],k] for k in node_census.keys()])]  列表中排名最高的人有一个我们很熟悉的姓氏：穆罕默德•阿塔（Mohammed Atta）是最初策划911袭击的汉堡支部的一份子，并且是美国航空公司的第11次航班劫机后的飞行员，他驾驶着飞机撞在了世贸中心的北楼上。\n4.4 派系 虽然我们或许可以直觉地将社会网络中的派系理解为彼此紧密相连的、有黏着力的一群人，在社会网络分析领域对已派系有一个正式的、更为严格的数学定义。\n对于一个给定的图来说，一个派系被定义为其中的一个最大的完全子图（ maximal complete subgraph ）——也就是说，群体中的每个个体都与其他的每一个人相连。“最大”意味着这个派系无法再增加节点，因为如果将其它节点也算入派系，将降低派系内部连通的紧密程度。从本质上讲，一个派系包含着几个相互重叠的紧密型三元组，并且继承着紧密型三元组的许多文化生成功能和放大特征。\n一个派系必须生成共识，否则就会解体——这是为什么在方言里，派系经常被认为与其他派系存在冲突。其实派系与冲突的关系非常容易理解：拥有一个共同的敌人（或者一组共同的敌人）使得派系内部更加团结。我们将在第6章讨论一些关于冲突和派系的含义。但是现在，让我们看一下是否可以在一些样本网络中找到派系。\n检测派系 作为测试，让我们再看一下高加索地缘政治的数据。这一次，我们将要探索不同国家之间的经济关系（图4-9）。在这个数据当中，经济合作水平的取值范围为0到1之间——1表示一个紧密的或者说独占的网络链接，0表示完全没有经济合作关系：\n\u0026gt;\u0026gt;\u0026gt; eco=net.read_pajek(\u0026quot;economic.net\u0026quot;) \u0026gt;\u0026gt;\u0026gt; net.draw(eco)  图 4-9 高加索地区的经济联盟与联合行动\n这个数据清晰地表明在这个地区存在着两个不同的力量——以西方国家为中心的一方和以俄罗斯为中心的一方；当地和地方性的经济联系经常是不存在的，作为最近的地理上的邻居（例如亚美尼亚（Armenia）和阿塞拜疆（Azerbaijan）），往往将彼此看作敌人并按此选择与不同的超级大国建立关系。伊朗和土耳其扮演着“捣乱分子”的角色——一个与伊朗有较多经济联系的国家不会和美国有联系，并因此被迫与俄罗斯结盟。当然，石油和天然气也起着非常重要的作用。 一个像这样的结构容易孕育派系。我们看一下是否能够从其中找到派系。首先，我们要丢掉低水平的联系（边的权重 \u0026lt; 0.5）以凸显网络的核心：\n\u0026gt;\u0026gt;\u0026gt; e2=trim_edges(eco, weight=0.5) \u0026gt;\u0026gt;\u0026gt; cliques = list(net.find_cliques(eco)) \u0026gt;\u0026gt;\u0026gt; cliques [['EU', 'Turkey', 'Russia'], ['EU', 'Turkey', 'USA'], ['EU', 'Azerbajan'], ['EU', 'Georgia'], ['EU', 'Kazakhstan', 'Russia'], ['EU', 'Kazakhstan', 'USA'], ['EU', 'Armenia'], ['South Osetia', 'Russia'], ['Nagorni Karabakh', 'Armenia'], ['Chechnya', 'Russia'], ['Abkhazia', 'Russia']]  我们大略地看一下派系的结果：\n• [EU, Turkey, Russia], [EU, Turkey, USA]– 代表着（两个）超级大国和对于土耳其是否应该成为欧盟成员的论辩的双方。\n• [EU, Azerbaijan], [EU, Georgia]– 在高加索地区与西方结盟的国家；阿塞拜疆（Azerbaijan）是主要的石油生产国，并且一个英国石油公司所拥有的石油管道穿过阿塞拜疆从格鲁吉亚到达黑海。\n• [South Ossetia, Russia], [Nagorni Karabakh, Armenia], [Chechnya, Russia], [Abkhazia, Russia]– 所有的最近的冲突 起源于当地的小的共和政体从拥护西方转而拥护俄罗斯（自愿地或者被强迫地）。\n• [EU, Kazakhstan, Russia], [EU, Kazakhstan, USA]– 哈萨克斯坦是一个主要的天然气生产国，其天然气主要通过俄罗斯拥有的石油管道和液态天然气设施卖给欧盟和美国。\n简而言之，派系算法生成的结果可以很快地被一个熟悉该领域的人解读。\n不幸的是，这些派系之间大多是重叠的，并且一个单一的事件或现象可能导致多个派系。其他的算法（n-clans, k_plexes等）可以帮助解决这个问题——但它们尚未被融入到NetworkX当中，并且它们的应用也超出了本书的范围。\n我们将在下一个部分通过聚类的方法解决这个问题。\n4.5 分层聚类 我们将要接触的（虽然很简略地）另一个类型的算法是聚类算法。聚类算法包罗万象、异常宽广，或许在其它的书籍中被阐述得更好——但我会简单地介绍聚类算法在社会网络分析中的应用，并提供一个从聚类算法中可以得出有用结论的简单例子。\n首先我们回到“距离”的概念。我们可以用很多办法定义距离——从地理距离到在地面上旅行经过的距离，再到以时间计量的距离（例如，从一个地方A到达另一个地方B所要花费的时间），等。在社会网络分析中，我们发现两种距离的概念最为有用：一个是节点之间的图距离（或路径距离）；另一个是以相似度计量的距离（也就是说，如果节点之间在某个方面上相似，我们就认为它们靠得更紧密）。\n在之前的章节中我们使用的高加索网络中，图距离的矩阵如表4-2所示：\n TR SO GE IR TK US AZ CH AR EU NK KZ RU AB TR 0 2 1 1 1 1 1 2 1 1 2 1 1 2 SO 2 0 2 2 2 2 2 2 2 2 3 2 1 2 GE 1 2 0 1 1 1 1 2 1 1 2 1 1 2 IR 1 2 1 0 1 2 1 2 1 1 2 1 1 2 TK 1 2 1 1 0 1 1 2 1 1 2 1 1 0 US 1 2 1 2 1 0 1 2 1 1 2 1 1 2 AZ 1 2 1 1 1 1 0 2 2 1 3 1 1 3 CH 2 2 2 2 2 2 2 0 2 2 3 2 1 2 AR 1 2 1 1 1 1 2 2 0 1 1 1 1 2 EU 1 2 1 1 1 1 1 2 1 0 2 1 1 2 NK 2 3 2 2 2 2 3 3 1 2 0 2 2 2 KZ 1 2 1 1 1 1 1 2 1 1 2 0 1 2 RU 1 1 1 1 1 1 1 1 1 1 2 1 0 1 AB 2 2 2 2 0 2 3 2 2 2 2 2 1 0  表 4-2 高加索网络中的网络距离\n这当然和地理距离非常不同，并且描绘了在高加索区域中国家之间的合作和拥护关系是交织在一起的，每个个体不是被其本地的联盟国家所环绕，而是被潜在的对手所环绕。\n让我们看一下是否可以在经济网络中找到这些相互敌对的群集（cluster，或译作“簇”）。我们将会使用SciPy包中一个的分层聚类方法和一小段由德鲁•康威（Drew Conway） 原创、在本书中被大幅改进的代码。\n算法 图4-10展现了（以一种程式化的方式）分层聚类的算法。算法大致按照以下步骤运行：\n 从最低层开始，每一个节点被分配为一个只包含自己的群集。 使用距离表（表4-2）找到距离最近的一对节点并将它们合并为一个群集。 重新就算距离表，把刚刚合并的群集看作一个新的节点。 重复步骤2和3，直到所有的网络中的节点都已经被合并到一个大得多的群集中（示意图中的最高层） 选择介于最高层和最底层之间的一个有用的聚类门槛——这需要人工干预而无法机器自动完成。  图 4-10 分层聚类\n步骤3值得更多的思考。如何计算一个群集和一个节点之间的距离？如何计算两个群集之间的距离？有三个方法可以做这件事情：\n• 单个链接：按照最小的最低配对距离（minimum pairwise distance）合并两个群集。\n• 平均链接：按照最小的平均配对距离（average pairwise distance）合并两个群集。\n• 最大链接或完全链接： 按照最小的最高配对距离（maximum pairwise distance）合并两个群集。\n完全链接方法被认为对异常值非常敏感；单个链接方法容易形成链状的、一长串的群集，这与我们关于群集的意义的直觉理解不同；平均链接方法是其它两种方法的折中，也是最常用的方法。\n城市聚类 为了更好地展现聚类是如何实现的，让我们来思考一个美国本土城市的聚类问题。初始的距离表如下所示；我们将使用单个链接的聚类方法：\n【此处 插入p83表格】\n在前两步当中，我们要合并波斯顿、纽约和华盛顿为一个群集。我们将会发现东海岸城市被合并为一个它们自己的群集：\n【此处插入p84表格1】\n跳过一些步骤，芝加哥进入东海岸城市群集，而旧金山和西雅图构成了西海岸城市群集。严格的说，芝加哥和丹佛应该形成一个中西部城市群集——但因为我们使用了单个链接距离量度，芝加哥结果与东海岸城市群集的距离比与丹佛的距离更近。\n【此处插入p84表格2】\n此时，仅仅剩下迈阿密和丹佛的群集仍未分配。在接下来的几步当中，丹佛加入芝加哥所在的东海岸城市群集。此时，我认为进一步的聚类不再有任何意义。\n长距离的链条（从东海岸城市群集到芝加哥，再到丹佛，最后到达西海岸城市群集）是单个距离量度方法的一个众所周知的不足之处。如果我们此时使用平均链接方法，聚类的结果将会更为清晰。获得更为清晰结果的代价是较高的计算复杂性——这使得平均链接聚类方法不适用于非常大的数据。\n准备数据和聚类 让我们现在开始在高加索网络数据中应用分层聚类的方法。首先，需要计算距离矩阵。NetworkX提供了一个函数可以生成这样的一个矩阵——但返回的结果是一个嵌入字典的字典（dict of dicts）。这种返回数据的格式不适于做进一步的运算，并且需要被转换到SciPy的矩阵中来。因为矩阵形式的数据不会保留节点的标签，我们构建了另外一个数组来保存这些节点的标签。\n最后，我们执行SciPy的分层聚类算法并得到所有聚类结果的树形图，这个树形图与图4-10类似。我们需要确定一个门槛值——此处，我们任意挑选一个数值，但是因为它是一个参数，所以很容易被改进以得到更有意义的结果。\n例4-1 分层聚类算法\n__author__ = \u0026quot;\u0026quot;\u0026quot;\\n\u0026quot;\u0026quot;\u0026quot;.join(['Maksim Tsvetovat \u0026lt;maksim@tsvetovat.org', 'Drew Conway \u0026lt;drew.conway@nyu.edu\u0026gt;', 'Aric Hagberg \u0026lt;hagberg@lanl.gov\u0026gt;']) from collections import defaultdict import networkx as nx import numpy from scipy.cluster import hierarchy from scipy.spatial import distance import matplotlib.pyplot as plt def create_hc(G, t=1.0): \u0026quot;\u0026quot;\u0026quot; 从距离矩阵中创造一个图G的分层聚类 马克西姆注：对带有标签的图进行聚类的前处理和后处理，并返回聚类的结果 参数化门槛值之后，其取值范围应该通过对每个数据进行尝试的基础上确定 \u0026quot;\u0026quot;\u0026quot; \u0026quot;\u0026quot;\u0026quot;在对德鲁•康威（Drew Conway）编写的代码进行优化的基础上而来\u0026quot;\u0026quot;\u0026quot; ## 创造最短路径距离矩阵，但是保留节点标签 labels=G.nodes() path_length=nx.all_pairs_shortest_path_length(G) distances=numpy.zeros((len(G),len(G))) i=0 for u,p in path_length.items(): j=0 for v,d in p.items(): distances[i][j]=d distances[j][i]=d if i==j: distances[i][j]=0 j+=1 i+=1 # 创造分层聚类 Y=distance.squareform(distances) Z=hierarchy.complete(Y) # Creates HC using farthest point linkage # 这种划分的选择是任意的，仅仅为了说明 的目的 membership=list(hierarchy.fcluster(Z,t=t)) # 为块模型（blockmodel）创造一系列的列表 partition=defaultdict(list) for n,p in zip(list(range(len(G))),membership): partition[p].append(labels[n]) return list(partition.values()) # Create collection of lists for blockmodel partition=defaultdict(list) for n,p in zip(list(range(len(G))),membership): partition[p].append(labels[n]) return list(partition.values())  运行上述分层聚类算法：\n\u0026gt;\u0026gt;\u0026gt; import hc \u0026gt;\u0026gt;\u0026gt; hc.create_hc(eco) [['Turkmenistan', 'Nagorni Karabakh', 'Russia', 'Abkhazia'], ['USA', 'Armenia', 'EU', 'Kazakhstan'], ['Turkey', 'Georgia', 'Iran', 'Azerbaijan'], ['Chechnya'], ['South Osetia']]  这个结果从直觉上来说非常容易理解——[[\u0026lsquo;Turkmenistan\u0026rsquo;, \u0026lsquo;Nagorni Karabakh\u0026rsquo;, \u0026lsquo;Russia\u0026rsquo;, \u0026lsquo;Abkhazia\u0026rsquo;]是一个以俄罗斯为中心的群集；而[\u0026lsquo;USA\u0026rsquo;, \u0026lsquo;Armenia\u0026rsquo;, \u0026lsquo;EU\u0026rsquo;, \u0026lsquo;Kazakhstan\u0026rsquo;]这个群集主要是跟天然气买卖和运输有关系的；[\u0026lsquo;Turkey\u0026rsquo;, \u0026lsquo;Georgia\u0026rsquo;, \u0026lsquo;Iran\u0026rsquo;, \u0026lsquo;Azerbaijan\u0026rsquo;]这个群集代表的是支持伊斯兰和波斯的态度。对格鲁吉亚（Georgia）的聚类有一些不合适，因为它在政治上是与天主教和西方国家结盟的，但它在经济上与阿塞拜疆和土耳其联系紧密，因而抵消了它亲西方的面貌。剩下的聚类结果则充满了异常值 ——实际上，这些小国家也给这个世界带来了不少麻烦。\n块模型 一个块模型（block model）是一个从原始网络中提取出来的简化的网络，其中处于同一个群集中的节点被看作是一个节点，而所有的原始的节点之间的关系也被累加为块之间的关系。 在我们作为例子的数据当中，一个块模型所展现的是俄罗斯为中心的群集（0）、西方为中心的群集（1）和伊斯兰为中心的群集(2)之间的关系。而群集3和4主要是一些小的、与俄罗斯联系紧密的、但彼此之间几乎不存在任何联系的共和国——因为俄罗斯对于周边的附属国家的管理是高度中心化的。\n计算块模型，首先需要计算并保存分层聚类的结果，然后需要将群集划分的结果存储为一个列表并在此基础上对原始的图运行块模型。结果如图4-11所示。\n\u0026gt;\u0026gt;\u0026gt; clusters=hc.create_hc(eco) \u0026gt;\u0026gt;\u0026gt; M=nx.blockmodel(eco,clusters) \u0026gt;\u0026gt;\u0026gt; net.draw(M)  图4-11 高加索网络的块模型\nhiclus_blockmodel.py提供了一个可以被应用到所有图的一个更精细的绘图方法：\n例4-2 同时绘制一个网络图及其块模型\n __author__ = \u0026quot;\u0026quot;\u0026quot;\\n\u0026quot;\u0026quot;\u0026quot;.join(['Maksim Tsvetovat \u0026lt;maksim@tsvetovat.org', 'Drew Conway \u0026lt;drew.conway@nyu.edu\u0026gt;', 'Aric Hagberg \u0026lt;hagberg@lanl.gov\u0026gt;']) from collections import defaultdict import networkx as nx import numpy from scipy.cluster import hierarchy from scipy.spatial import distance import matplotlib.pyplot as plt import hc \u0026quot;\u0026quot;\u0026quot;在原始网络旁边绘制一个块模型\u0026quot;\u0026quot;\u0026quot; def hiclus_blockmodel(G): # 提取最大的联通组元 H=nx.connected_component_subgraphs(G)[0] # 使用分层聚类进行分隔 partitions=hc.create_hc(H) # 构建块模型图 BM=nx.blockmodel(H,partitions) # 绘制原始图 pos=nx.spring_layout(H,iterations=100) fig=plt.figure(1,figsize=(6,10)) ax=fig.add_subplot(211) nx.draw(H,pos,with_labels=False,node_size=10) plt.xlim(0,1) plt.ylim(0,1) # 绘制块模型 # 使用带有权重的边 # 以群集中包含的节点数量表示块模型中的节点大小 node_size=[BM.node[x]['nnodes']*10 for x in BM.nodes()] edge_width=[(2*d['weight']) for (u,v,d) in BM.edges(data=True)] # Set positions to mean of positions of internal nodes from original graph posBM={} for n in BM: xy=numpy.array([pos[u] for u in BM.node[n]['graph']]) posBM[n]=xy.mean(axis=0) ax=fig.add_subplot(212) nx.draw(BM,posBM,node_size=node_size,width=edge_width,with_labels=False) plt.xlim(0,1) plt.ylim(0,1) plt.axis('off')  4.6 三元组、网络密度和冲突 在本章中——实际上对于本书中截止现在所涉及的所有内容——我们所讨论的都是关于包含一种类型节点和一种类型的边的均匀网络（uniform network）。但是，后面涉及的内容会变得越来越有趣。\n设想我们有两种类型的边而不是一种类型的边——友谊和冲突。我们也将在二元组和三元组的层面上引入更多变化。\n我们都已经经历过社会混乱——或者甚至曾经卷入其中。比如一对结婚很久的夫妇决定离婚，于是他们的朋友们马上面临决策的困难。置身于这对夫妇的任何一方都会感到压力，于是可能给持续很久的友谊关系带来破坏，并把一个本来联系紧密的网络分割成丈夫阵营和妻子阵营。当分裂造成的伤害被平复，建立新的友谊关系和恋爱关系的空间重新出现，于是类似的循环再次开始。 我们可以使用一些非常简单的规则来为这个过程建立模型（以下规则是有先后顺序的）：\n 我的朋友的朋友也是我的朋友（使得一个结构洞闭合）。 我的朋友的敌人也是我的敌人（使得三元组到达平衡状态）。 我的敌人的朋友是我的敌人。 我的敌人的敌人是我的朋友。  实际上，从另一种角度看，规则2,3和4描述的是相同的（无向的）三元组，因此我们把它们都称之为“规则2”（如图4-12）。这些规则实际上很早就用来尝试描述文明史中的社会复杂性；第一次提及这些规则是在《圣经》当中（出埃及 23:22，在其它的章节中也曾出现）\n图 4-12 三元组演化的规则（伴随着冲突）\n让我们从一个违反了规则1或者规则2的社会网络中的行为开始：如果我们从一组互不相连的节点开始，并且以一个固定的概率随机的连接这些节点，最后我们会得到一个节点度分布为正态分布的简单的随机图（一个厄多斯随机图）。网络的密度（也就是网络中实际存在链接数量除以可能存在的链接数量）将会上升直到每个节点都和其它节点相连（一个完全图或者派系）。当然，这并没有那么有趣。\n让我们现在回到规则1。如果存在一个开放的三元组 A→B→C，按照某种概率，我们也将添加一条链接A→C。我们仍旧可以随机地添加链接，所以，最初这个网络将会线性地增长。直到某一个时刻达到链接的临界点，然后每个新增加的链接都会制造出一个开放的三元组。这个开放的三元组将会按照规则1的要求被闭合，其结果是制造出更多的开放的三元组，这些新增的三元组随后被闭合，这个过程将不断进行下去。\n在某种意义上讲，网络从线性增长过渡到指数形式的增长。它像病毒一样传播开来（图4-13）！链接的密度迅速增长，直到没有新的链接可以增加并且我们得到一个全联通的图。当然，在现实当中，对于一个网络存在一个可能的链接数量的限制，也就是饱和密度（saturation density）。这个密度可以是网络自身的特征，或者是这个网络所在的环境——或者是规则2的结果（正如在我们的模型当中）。\n图 4-13 按照规则1使三元组闭合\n通过改变一个友谊关系为敌对关系，冲突以一个恒定的概率被引入网络演化当中。图4-14刻画了可能的演化形式。在这个简单的例子当中，一个包含4个闭合三元组的网络被作用于其一个边上的冲突所扰动。三元组A-B-C开始因为B和C之间的冲突而变得不平衡；因此A被迫以一种随机的方式选择站在冲突双方的哪一边，并选择与B和C中的哪一个继续保持朋友关系。在A-C这条边上施加一个冲突迫使另一个三元组（A-C-D）变得不平衡，并将节点D引入到冲突中来。如果节点D选择把节点C从整个网络中孤立出来，冲突的蔓延终止。但是，如果D选择孤立节点A， 这将导致冲入进一步蔓延并破坏更多的网络链接。拥有更多的链接增加一个节点形成更多的网络链接的概率，但是也增加了两个节点之间的冲突蔓延到整个网络的可能性（如图4-14）。\n图 4-14 冲突的蔓延\n冲突蔓延的结果是网络密度再也不可能增长到接近100%的程度；但相反，一旦它到达了一个“第二临界值”，冲突会变得更加突出（如图4-15所示）并使得网络密度降低。这类行为被称为自组织的临界性——我的模型仅仅提供一种在社会网络中生成这种效果的简单方法。这与森林火模型中的方法类似：森林的密度越大，下一场森林火演变为灾难的可能性越大——允许小的火灾降低森林密度到某种水平上使得大多数火灾被相对得很好地控制。\n图 4-15 按照规则2运行的冲突的蔓延\n我们将在第6章讨论更多的网络动态——但同时，现在是开始了解包含不同类型节点的社会网络数据的时候了——这些数据更接近于我们所熟悉的社会网络。\n","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1341100800,"objectID":"ebbd9eda9d3ac7f7ed54e14f228f61d1","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-07-01-snabook-chapter4/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-07-01-snabook-chapter4/","section":"post","summary":"","tags":null,"title":"第4章 派系、聚类和组元","type":"post"},{"authors":null,"categories":null,"content":"在本章中，我们将探索分析具有两种及两种以上节点类型的复杂网络的方法。但首先，我们先从一个故事开始。\n###竞选资金是否影响选举？\n “我们有一个用金钱能买到的最好的政府。”——马克•吐温\n 每年四月份，在芝加哥帕尔默家园希尔顿酒店(The Palmer House Hilton)，政治科学家在中西部政治学年会（讨论特殊利益集团政治和竞选资金的顶级会议）上准备好辩论马克•吐温的话是否正确，或者美国政治系统实际上对于金钱的影响是否免疫。\n带着一个关于竞选资金及其对选举结果影响的大规模社会网络研究，我们 在2006年加入这场辩论。在本节中，我们将简要回顾这个研究，并介绍得出这些结果所使用的方法。\n但首先，让我们开始玩一个小游戏。\n看一下图5-1。这个图中的节点是积极卷入2000年美国国会选举和总统选举的政治组织或政治行动委员会（political action committee， PAC）。红色和蓝色的节点分别代表共和党和民主党（州和全国），绿色节点代表单个事件群体，紫色节点代表工业协会，黄色节点代表非盈利组织。政治行动委员会之间的网络链接表示它们花钱的地方——如果A和B向同一个候选人捐款，在它们之间就存在一条链接——并且他们越相似，网络链接的权重越大。权重大的网络链接在图中用粗的线条表示（我们将在稍后介绍这是如何做的）。\nP93 图5-1 竞选资金——政治行动委员会网络\n这个研究是基于依照麦肯恩-法因戈尔德竞选改革法案由联邦选举委员会所公布的数据 。这个数据是基于政治行动委员会每次向一个候选人捐款时按照要求提交的表格。这个数据在每个选举年份可从http://fec.gov/获取，但是数据信息的质量和覆盖范围因选举年的政治环境的不同而存在差异。\n正如你所看到的，单个事件政治行动委员会主导整个网络。右方是共和党群集，以共和党国家委员会（RNC）为首，而左方是民主党群集和民主党国家委员会（DNC）。但是，三个政治行动委员会紧挨着并且与这些“国家队队员”有着紧密联系，它们看上去支配着这个网络里非常多的权力。\n你能猜出它们是谁吗？\n答案在图5-2当中。在紧密相连的三元组的左方和右方的节点分别是全美堕胎及生殖权行动联盟（NARAL）和国家生命权利委员会——代表了关于堕胎问题的两个阵营，这在2000年和现在都是美国政治中最富争议的问题之一。\n图 5-2 竞选资金——美国政治行动委员会网络（核心网络）\n在中间的是美国劳工联合会—产业工业联合会（AFL-CIO），它代表了美国最大的工会和它所代表的超过一千一百万选民。这个组织在历史上倾向于支持民主党，但是共和党需要赢得重要的、像俄亥俄和密歇根这样的工业发达的州的选票以便于控制国会并让共和党候选人当选总统，这意味着要从传统选区那里吸引工会的选票。这需要一个“杠杆问题”：一个能够使得工会成员打破对于政党的附属关系的非常争议的问题，比如堕胎。\n可能是因为精心设计或者命运的偶然，我们现在可以说即使堕胎问题不是一个有争议性的问题，也是一个影响2000年大选的少数问题之一 。\n一点点额外的娱乐，我想要你注意一下图 5-2中做下角。这一个政治行动委员会的群集（除了纽约州民主委员会（New York State Democratic Committee）之外）仅仅为了一个原因而存在——打败希拉里•克林顿（Hillary Colinton）。\n我们将再稍后重新回到这个竞选数据，但首先让我们看一下如何来完成这些研究。\n###二模网络的理论\n现存的大多数网络数据都是二模的（双峰的或双向的）形式——也就是说，存在两种不同类型的节点，并且网络链接表示一群节点和另外一群节点之间的关系。\n例如，一个数据当中可能包含多种关系，例如政治贡献（例如政治行动委员会资助候选人）、雇佣关系（个体被组织所雇佣）或社会化媒体使用行为（用户对某些页面的喜爱）。这些网络经常包含两种以上类型的节点，例如天使投资人向创业者所创建的公司投资（这更有趣，因为成功的创业者最后自己也成了天使投资人）。但是，方法基本没有什么改变。\n社会学家提出一个概念：个体和群体的二元性 。从本质上讲，这个概念是指人们的想法、态度和社会关系是由个体在群体中的身份所决定的，而群体的形成源于是由成员的态度。这适用于公司、帮派、政党、社交俱乐部等。因为人们往往不仅具有一种群体成员身份，群体成员的身份可以被看作一种分析和汇总个体之间的相似性和差异性的一种方法。\n###隶属网络 ( affiliation network )\n图 5-3 展示的是一个简单的二模网络——个体A和B都是一个俱乐部的成员。这实质上构成了一个开放式的三元组，或者一个结构洞——但我们可以推断如果A和B是同一家俱乐部的会员，他/她们可能知道彼此，因而推断这个三元组实际上是闭合的。这当然是一种很弱的推断：举一个更具体的例子，还应该考虑A和B是否在同一个时间段里是这个俱乐部的成员，或者这个俱乐部在不同的城市里有多个分会，等等。但这只是一个开始。\n图 5-3 三元组的闭合与共同成员身份\n现在想象一个人是多个俱乐部的成员（在图5-4中，节点E，F,H是两个俱乐部的成员）。据此我们可以推断他们之间存在较强的联系，或许暗示着一种共享的群体身份。我们可以继续增加成员关系直到我们确信这些联系是真实的，并给推断出的链接赋予权重。\n图 5-4 从二模网络中创造一个隶属网络\n图 5-4 展示了由原始的二模网络推断出来的两个网络——一个是是由个体之间共享的群体身份决定的人际网络，另一个是不同的组织之间所共同包括的成员所决定的群体网络。创造这种网络，我们只需要统计每个人或每个俱乐部的共享成员身份的数量。\n正如其它的社会网络一样，这些网络也可以采用相同的分析方法，并且非常适合采用“岛屿方法”（参见第四章 网络上的岛屿 一节）和聚类方法（参见第四章 分层聚类 一节）。这是因为这些网络实质上是基于相似度或者相关程度的网络，因而其意义很容易理解。\n###属性网络\n二模网络分析的另外一个应用是基于同质性（homophily，希腊文， “喜欢相似的人或物”）的想法——这个想法认为相对于具有不同兴趣或属性的人，具有相同兴趣或属性的人倾向于和相似的人交流并建立联系。那么如何理解“异性相吸”等说法呢？这个理论似乎适用于一些情况，但并不适用于另外一些情况，因此这个理论并非是一个普适的法则。我们也知道如果人们更紧密地在一起，他们就会在意见、观点上更相似——但这种影响存在一定限度的。\n但是，如果你想要建立一种线上社会网络里的朋友推荐机制，把属性矩阵或兴趣矩阵转化为一个二模网络是一个有用的方法。所需要做的就是把每一份信息（标签、关键词等）看作是二模网络中的节点，从中得到一个人和人之间的隶属网络，应用岛屿方法或者聚类方法找到潜在地属于同一个群体的人。在此基础上推荐朋友，只需要从隶属网络中挑选最强的网络链接。\n一个（与二模网络）逆向的隶属网络——用属性作为边来连接个体——能够提供更多有趣的洞察。试想我们想要测量推特上的政治话语。我们提取包含“选举”这个井号标签（#， hashtag）的由几万人所发的推特，构造一个从使用者个体到井号标签的二模网络，并在此基础上计算一个“用井号标签作为边连接个体”的隶属网络。在这样的网络中，群集成为整个话语空间的中介——并能够将推特使用者区分为自由和保守两派。进一步的分析可能这两个派系内部相互分隔的原因，比如茶党作为一个独立的主体涌现并分布于主流的共和党的话语中。\n###一点数学\n让我们用一个邻接矩阵来表达一个网络（参考 第二章 邻接矩阵 部分）：\n 1 2 3 4 5 A 0 0 0 0 1 B 1 0 0 0 0 C 1 1 0 0 0 D 0 1 1 1 1 E 0 0 1 0 0 F 0 0 1 1 0  现在，让我们比较节点D和F;我们可以通过将这D、F两行在表格中相乘的方法来完成：\n 1 2 3 4 5 Sum D 0 1 1 1 1 = 4 F 0 0 1 1 0 = 4 D*F 0 0 1 1 0 = 2  D和F共享两个边。现在我们来对任意一对节点进行上述操作，并将它们放在一个如下的矩阵中：\n A B C D E F A 0 0 0 1 0 0 B 0 0 1 0 0 0 C 0 1 0 1 0 0 D 1 0 1 0 1 2 E 0 0 0 1 0 1 F 0 0 0 2 1 0  得到的这个邻接矩阵代表了节点A到F所构成的隶属网络，并且这个操作仅仅需要做矩阵的乘法。在这个练习中，我们将邻接矩阵A和其转置矩阵（At）相乘：AA=A* At\n【警告标志】在本书中，我们采用一种在数学上并非严格定义但是可读性好的概念：一个包含人和俱乐部的二模网络被称为PC；由这个网络得到的人和人相连的隶属网络称为PP，等。\n这个计算需要花费较多的时间。实际上，这个操作的计算复杂性是O(n*m*n)。其中n是“外边界”（在这个例子中是政治行动委员会），m是这个乘法的“内边界”。从一个10*5的二模的网络中提取隶属网络需要在矩阵的“长边”进行10*5*10=500次操作，在矩阵的“短边”上进行5*10*5=250次操作。在这种情况下，一次操作需要在一个找到给定两个节点a和b的边（a,b）的取值，并且如果如果这个操作需要对文本进行操作，得到隶属网络的计算将会变得非常昂贵。合理的索引（使用Python的词典或者SQL的索引）可以使得这个操作变得很快，一般可以将计算时间减少2或3个数量级。\n【警告标志】如果你以前未接触过矩阵代数（我承认它非常枯燥，虽然也非常有用），可按照如下方法思考矩阵乘法：如果我们用PC乘以CP，“内边界”（P）必须相同。两个矩阵的内部边界相互抵消，我们将得到一个方阵CC。那么AB*BC*CD*DA等于什么呢？AB*BC=AC;AC*CD=AD;AD*DA=AA;我们走过了一个循环。这种创造一个长的相乘的序列的特性在第XX页的“扩展多模网络”一节中变得非常有用。\n###二模网络实战\nNetworkX提供另一个很多用于二模网络的函数。使用这些函数，需要安装版本为1.5或者更高版本的NetworkX。让我们尝试一个简单的例子。\n所使用的数据来自于我们前面所提到的竞选资金数据的一部分。原始的数据包含50万次交易。我们仅仅使用基于几百个交易数据所构建的二模网络。在这个例子中，每个政治行动委员会和每个候选人都被分配了一个编号(ID)。实际上，这些独特的编号是由联邦选举委员会给定的。候选人的编号实际上非常容易辨识。例如，候选人H6IL14095Z在第14区、参选伊利诺伊州（ILlinois）的众议院（House）——这些信息足够帮助我们找到这个候选人是共和党人丹尼斯∙哈斯泰特（Dennis Hastert）。联邦选举委员会同时也提供一个包含所有候选人信息的详尽数据库（具体到候选人的家庭住址） ，但我们在这本书中将不会分析这个数据（因为涉嫌网络跟踪）。\n我们将要使用的数据存储为CSV（逗号分隔）格式（见表 5-1），包含了我们所需要的所有变量，其中一些变量我们现在不会考虑。第一列是每个行动委员会的编号，第13列是收到捐款的候选人的编号，第11列是捐款的金额。2000年的数据格式与现在的数据格式可能存在一些差异，但基本上一致。你可以通过修改以下代码的方式来分析现在的数据：\nimport csv import math import networkx as net ## 引入二分（双峰）函数 from networkx.algorithms import bipartite as bi ## 从csv文件中读取数据 ## 我们使用rU模式读入数据，因为很多CSV文件是通过Excel创造的 r=csv.reader(open('campaign_short.csv','rU')) ## 二模网络通常是有向的。这里边的方向表示资金流动的方向 g=net.Graph() ## 我们需要分开追踪不同类型节点 pacs=[] candidates=[] ## 使用CSV文件中的边构建一个有向的图 for row in r: if row[0] not in pacs: pacs.append(row[0]) if row[12] not in candidates: candidates.append(row[12]) g.add_edge(row[0],row[12], weight=int(row[10]))  表 5-1 竞选资金交易记录（前20行）\n###政治行动委员会网络\n现在我们已经构建了一个图对象，我们能用它做什么呢？让我们开始计算一个政治行动委员会网络的隶属网络：\npacnet=bi.weighted_projected_graph(g, pacs, ratio=False)  这个网络有一个大的组元和一些孤立的节点。这些孤立的节点是我们随意地去除一部分数据用作例子的人为产物——并且我们同样可以在这里把它们扔掉，而仅仅保留那个最大的连通的组元：\npacnet=net.connected_component_subgraphs(pacnet)[0]  我们想要画出最后的这个网络，并且通过颜色和边的宽度来展现关系的强度。因为边的取值范围非常广，所以需要使用取其对数的方法来压缩其数值范围:\nweights=[math.log(edata['weight']) for f,t,edata in pacnet.edges(data=True)]  最后，我们将画出这个网络图：\nnet.draw_networkx(p,width=weights, edge_color=weights)  这个图应与本书中的图5-5相似。粗的红色边代表强关系；在这个数据当中，最强的关系存在于节点C00000422和C00000372之间，前者是哥伦比亚的克雷格∙安德森（Craig Anderson）博士，后者是道路维护政治联盟——一个位于密歇根州绍斯菲尔德地区的铁路工人工会组成的政治行动委员会。\n###候选人网络\n为了计算候选人网络，我们需要简单地逆转投射的方向并根据候选人表格而非政治行动委员会表格来计算一个投射的隶属网络。\ncannet=bi.weighted_projected_graph(g, candidates, ratio=False) cannet=net.connected_component_subgraphs(cannet)[0] weights=[math.log(edata['weight']) for f,t,edata in cannet.edges(data=True)] net.draw_networkx(cannet,width=weights, edge_color=weights)  结果得到的图要明显大得多并需要花费更长的时间绘制出来。它看上去有些像一个毛球 。非常明显，这个网络存在着一些明确的群集；我们现在将要使用第xxx页“网络中的岛屿”一节中提到的“岛屿方法”。首先，让我们看一下边的数值的柱状图——这将帮助我们确定“水平面”的大小。图 5-6表明大约80%的边的权重小于0.9，所以我们可以安全地去掉它们：\nP102\n图 5-5 政治行动委员会的部分隶属网络\n图 5-6 国会候选人网络中边的权重的柱状图\ndef trim_edges(g, weight=1): g2=net.Graph() for f, to, edata in g.edges(data=True): if edata['weight'] \u0026gt; weight: g2.add_edge(f,to,edata) return g2 plot.hist(weights) ## 这个柱状图中的边的权重是取对数的； ## 我们可以计算初始的权重=e^log_weight cannet_trim=trim_edges(cannet, weight=math.exp(0.9)) ## 基于这个新网络重新计算 weights=[edata['weight'] for f,t,edata in cannet_trim.edges(data=True)] net.draw_networkx(cannet_trim,width=weights, edge_color=weights)  这个核心的网络（图 5-7）清晰地包含着一些由跨越边界的候选人联系在一起的紧密的群集。在2000年的时候，许多民主党人趋于保守——结果导致使得他们从一些共和党支持者那里获得很多资金。这当然未能使得他们赢得选举。\n图 5-7 国会候选人网络（核心）\nP 104\n从现在开始，我们可以使用分层聚类的方法（见第XXX页“分层聚类”一节）来寻找处于这些群集的人。跨越边界者可以通过使用中介中心度（见第XX页“寻找传播的瓶颈和/或社区的桥梁”一节）。因为这些方法已经在前面的章节中讲过，我们把这一部分作为留给读者的练习 。\n###扩展多模网络\n在前面几节当中，我们讨论了如何处理二模网络。但是，我们都知道这个世界其实更复杂，网络中的节点和边的类型非常多。幸运的是，我们在之前的几节中讨论的方法可以很容易的扩展到任何网络数据模型中。我们只要小心地确保每个网络以及隶属网络的意义是什么——并且不会再矩阵乘法的海洋中迷失。\n我想要用取自大卫∙魁克哈特（David Krackhardt）和凯思琳∙卡莉(Kathleen Carley) 的一个研究中的关于一个组织的数据模型作为一个例子。\n让我们想象ACME公司，一个制作装饰品的一个小公司。一些人通过某种彼此传达命令的形式正在为这个公司工作。这些人在公司内部和外部都存在友谊关系，在某个专业领域里受过正式的教育，并拥有一些资源。公司所生产的装饰品包括一些部件或分拆的任务，其中每一个单独的任务都需要一些人运用一种技能和资源才能完成（例如，制作一个链轮齿，一个人需要了解如何操作车床，具有钢原料，并花费足够多的时间）。\n你是否注意到所有的黑色斜体的词？从多模网络而言，这些词都可以被看作是节点，在此基础上，我们可以构建一个代表了ACME的社会网络，有些像图 5-8。图 5-8中的实体-关系示意图仅仅展现了组合中的四种实体，这种关系图可以变得非常复杂。在这个例子中，我们不会穷尽所有可能的关系——但我么将说明如何得出新的推论的方法（这种方法适用于其它的场景）。\nP 105\n图 5-8 一个简单组织的实体-关系示意图\n以一种矩阵的形式，这个组织模型看上去像表格 5-2。\n表格 5-2 作为一个邻接矩阵的实体和关系\n人(P) 技能(S) 资源(R) 任务(T)   人(P) PP：谁了解谁？ PS：谁了解什么？ PR：谁拥有什么？ PT：谁做什么工作？\n 技能(S) SS：什么样的技能同时被需要？ SR：某一种资源需要什么技能？ ST：一个任务需要什么样的技能？\n 资源\u0026reg; RR：什么资源同时被需要？ RT：一个任务需要什么资源？\n 任务(T) TT：任务之间的优先次序\n  每个矩阵都只不过是记录着乔（Joe）在多大程度上了解如何操作车床或者乔是否有铁原料制作链轮齿的一个表格。\n我们现在可以把以前几节中的每一个网络看作一个二元网络（bipartite network）。不幸的是，NetworkX尚未为分析多元网络（multipartite network）提供一个扩展的函数，所以我们必须回到矩阵的水平上进行计算：\nimport numpy as num pc=net.adj_matrix(g) #从网络中提取邻接矩阵 cp = pc.transpose() #得到转置矩阵 cc= pc*cp # 计算一个政治行动网络之间的网络 cc_graph = net.Graph(cc) #从一个邻接矩阵中重新创作一个NetworkX对象  现在让我们好好玩一下。因为我们可以进行无限长度的矩阵乘法以满足我们的需求，所以我们可以对数据进行很多的推论。比如：\n• PP * PP = PP: 这个心的网络的意义是“谁是朋友的朋友？”\n• PT * PTt = PT * TP = PP: 它的意义是“谁和谁在一起工作，完成多少任务？”\n• PT * TT = PT: 对每个人来说，对于他们来说至关重要的是那些任务？\n• TT * TT = TT: 相互依赖的任务\n• PT * TT * TP = PP:对一个人来说至关重要的是哪些人？\n• PT * TT * TT’ * TP = PP: 对于同时进行的任务，那些人在一起协同工作？\n####练习\n在这个模型当中，你如何判断那些任务是不可能完成的？让我们假设一项任务可以被完成如果被委派完成此任务的人拥有完成这个任务的资源。\n【警告标志】这个方程RTt* PRt = TR * RP = TP代表能够被一个人完成的任务。这个方程TP * PT = TT将生成一个矩阵。这个矩阵的对角线完成一个任务可能存在的方法的数量。如果这个数字是0表明这个任务是不可能完成的。\n可计算的组织理论的整个领域环绕着这种类型的模型成长起来。正如许多其它的模型，不管是静态的还是动态的，本书开始部分关于恐怖主义者网络的模拟是根据类似的原则（但在更高的水平上）建立的。资源分配和可行性评估现在已成为微软项目的一部分。\n这里有一个警告如果有人想要在咨询实践中使用这种方法。不管现在运行多么完好，没有一个商业拥有它的商业模型、社会网络、嵌入雇员的心智中的知识的完全信息。一些人想要通过积极地改造企业的结构的方式来巩固其组织模式——但是，正如我们在前面讲到非正式网络时提到过的，这将被非正式的组织结构直接规避。\n","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1341100800,"objectID":"715460b601529f0eaf2908ce146f3852","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-07-01-snabook-chapter5/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-07-01-snabook-chapter5/","section":"post","summary":"","tags":null,"title":"第5章 二模网络","type":"post"},{"authors":null,"categories":null,"content":"这一章或许是你挑选这本书的首要原因。很多人好奇事物（视频、网站、新闻等）如何像病毒一样在网络上传播开来——迅速扩散并成为文化中的一部分（同时在这个过程中，使得创造它们的作者富有）。我们应该预先告诉你我们并没有现成的答案。实际上没有任何人知道答案，并且这个过程中有一些运气的成分在——但在本章中，我们将要尝试使你更加理解驱动扩散的原因以及你的决策如何驱动购买行为。\n##6.1病毒视频剖析 假设给你的猫拍摄了一段非常可爱的视频，上传到YouTube网站上并通过推特进行宣传。你是否正走在通往财富的道路上？答案是，不一定。\n这主要取决于谁看到了这个视频，以及他们在看完之后做了什么。首先，唯一看到视频的是位于你的自我中心网（ego network）中的成员——比如你的朋友。这样的观看总数的增长是非常缓慢的；观看总次数随着时间是线性增长的，这意味着每个时间段的观看次数接近一个固定常数。在这种情况下， 我们可以将观看次数描述为一个泊松过程，其中的每个观看你的视频的浏览行为彼此之间是独立的。最后，你的视频所获得的总浏览数量与你的粉丝的数量（你的程度中心性）存在数学上的关联。\n但如果发生了一些其它的事情并且你的朋友们转发了这个视频给他们的朋友（等等，使得越来越多的人知晓这个视频），你的猫的视频将马上成为YouTube上面最流行的视频，并且好莱坞的制片人前来你家拜访。或者这一些都没有发生。\n有一个奇怪的事情在这个过程中间的某处发生了。你的一个朋友说“你看过这个视频吗？”，另一个朋友回答“是的，我已经看过了”，这强化了这个视频是一个“觅母”（meme） ——一个新的、独立的文化人造产品的观念。突然之间，让别人接触这个觅母就成一个人的第二天性或者甚至是一种必须的行为。\n从一个无足轻重的事物（但是可爱或有趣）变成一个必须分享的事物的质变过程是增长曲线的一个剧烈的转折，也被称为“临界质量”（critical mass）。如果在一定量的时间里，觅母未能在一定的时间范围里到达临界质量，它的采纳率开始下降并最终消亡。\n但是如果到达了临界质量，它将指数增长直到达到饱和点——也就是几乎每个可能采纳这个觅母的人都已经采纳。从这一点开始，觅母将会开始走下坡路。\n需要注意的是临界质量和饱和的概念适用于每个网络和社群——一个觅母在一个社群到达饱和点而在另一个社群里无人知晓是可能的。但是，因为社群是相互连接的，所以觅母通过跨界者从一个社群传入另一个社群并确立一个新的临界质量和更高的饱和点是可能的。\n###脸书做对了什么 在脸书（Facebook）出现之前，存在着其它社会网络。我们中的一切人或许还有聚友网（MySpace）的账号。一些人还记得Friendster。在Friendster之前，在所有其它SNS之前还有一个叫SixDegrees的网站。SixDegrees创立于1997年，它承诺将连接人们和他们的朋友、以及他们的朋友之间、最好的律师、医生、水暖工等。这样做，它将提供帮助人们通过社会网络完成任务的有用的功能。\nSixDegrees早于时代5年时间，并且尽管采用了全国范围内的广告宣传、良好的设计（对1997年而言）、在博客（令人尊重的Slashdot网站和波音波音（BoingBoing）网站都曾重点推介过它）和杂志（连线杂志）中良好的形象，它从未迎来增长的临界点。\n哪里出错了呢？答案非常简单——Sixdegrees未能到达它的临界质量。网站本身是全国性的，他们却实际上试图建立一个蔓延全国的地方化的市场，结果未能完成这个任务——实际上几乎不可能在这个网站上找到一个水暖工，部分原因是那时很少有水暖工使用互联网（或者觉得建立一个网络SNS账号很麻烦），部分原因是SNS的使用强度非常低。\n当脸书2003年建立的时候（仍使用最初的名字“Facemash”），它是一个哈佛本科生组成的小而紧密的网络社群。创立于一个较小的地区使得他们可以快速到达增长的临界质量。实际上，在它上线约四个小时内，就已经吸引了450个访问者，或者大约6%全部的本科生。记住6%这个数字，它非常重要。\n在哈佛内部，早期的脸书经历了一系列反复，直到找到一个易于扩展的设计并最终覆盖50%的哈佛本科生而达到饱和。从那开始，它的触角开始伸向其它常青藤高校，一个接一个，最终覆盖了美国所有大学。最后在2005年，它开始面向高中生——并奠定了它主宰世界的基础。\n脸书所遵循的规则——也是脸书不同于Sixdegrees和Friendster的地方——是在一个社群里到达饱和点之后才移入一个更大的社群。通过这种方式，临界质量从未被错过，并且新的成员完美地嵌入他们来自其他学校的伙伴建构的社会结构之中。\n###如何估计临界质量 在“三元组、网络密度和冲突”一节中，我们讨论了冲突如何在社会网络中蔓延及其对于网络链接的密度的影响。如果你回去重新仔细看图4-13，你会发现一个非常相似的增长方程——相同的S形曲线，如同我们在图 6-1中所观察到的一样。\n图 6-1 扩散曲线——临界质量、繁荣和萧条\n图字翻译：\n如果从线性的蔓延到指数（病毒式的）增长的确依赖于封闭的三元组（也就是说，朋友的朋友也是我的朋友） ，这样连接的临界质量的可以通过测量随机增加一个链接（比如，从A到B）与其它节点之间所形成的一个或多个开放三元组的概率的方法加以估计。这个概率与已经彼此相连的节点的数量（我们用2与节点数量相乘是因为每个边占用两个节点）：\nP(开放三元组) ~= 链接的数量/(2*节点的数量)\n这样，当四分之一的节点彼此相连的时候构成一个开放的三元组概率是50%——并且每一个新的链接使得闭合三元组能够创造甚至更多的链接，进一步增加形成级联（Cascade）的概率。\n我们在实验中发现当网络密度接近7%的时候将从线性增长（每一次增加一条链接）转化为病毒式扩散——也就是说，当有意采纳这个“觅母”、转发一个视频、加入一个网络社群等的人的比例达到7%的时候，其他人将会在关键阶段马上跟进。\n这是一个推动脸书走出哈佛的、神奇的数字。在我们的研究过程中，我们发现的一些其它的例子也表明当网络中的采纳比例小于10%时会发生病毒式扩散。\n从这一点可以得到的一个推论是在一个较小的社群里更容易达到临界质量——马克•扎克伯格（Mark Zuckerber）本能地知道或者（更可能）偶然发现。\ntips： 对于一个新兴公司（尤指新兴网络公司）的创立者而言，这是违背直觉的。每一个风险投资者都想知道整个市场到底有多大以及新兴公司完成市场渗透的计划。追逐小的自给自足的细分市场看上去与指数式的增长背道而驰。但是，一个细分市场的高饱和度是通往其它细分市场的一个好跳板——如果它们在地理上接近或者其利益非常吸引人。\n###维基经济的临界质量 关于临界质量的问题还有一种看法——参与成本理论。即使在一个提供免费服务品的世界，任何事物都有成本。这种成本包括金钱成本、时间成本、或者机会成本（也就是说，花费时间在脸书上，就无法花费时间在酒吧里——至少在移动手机变得普遍之前）。其它形式的参与文化，比如维基百科，需要其作者和编辑花费更多的时间，但得到的收益却非常短暂。\n一个过时但依然有说服力的例子是传真机的出现。当第一个传真机在上世纪七十年代中期，从施乐的装配线上生产出来之后，其成本高达几千美元并且完全得没有什么用处。另外不要忘记，如果一个传真从它那里发出，并没有位于另一端的一个传真机接受它。当第二台传真机在几分钟之后从生产线上滑落的时候，两台传真机的价值都无限增加了——现在一个银行可以（通过传真机）与其分支网点通讯了。但是，这台机器的用处随着越来越多的机器被生产出来而不断增加，直到传真机成为一种不可或缺的办公用品。\n在传真机的例子中，传真机最初被应用于大公司的总部连接其分支机构（代替了庞大的电传机）。所以每个公司独立地、按照自己的时间到达它们自己的临界质量——如果公司已经投资足够多资金到传真机设备上，在更大的范围销售传真机将会变得非常困难或者不可能。 一个经济学家会使用交易成本的概念讨论这件事情，并画出如图 6-2的曲线。\n图 6-2 成本曲线——社会化媒介的经济学\n图字翻译：\n假设参与成本是一个固定的值。在一些例子中（例如，传真机），当大规模生产时生产成本降低，但在参与式的文化（例如，维基百科）中，成本实际上随着生产规模膨胀而变大了——但我们可以在短期里认为它是常数。\n对于一个早期采纳者而言，成本是非常真实的，而利润还没有实现。当有更多人加入这个网络之后，收益以连接的数量的函数的形式增加，这使得新观念、觅母、社会网络网站的渗透漫漫长路中的每一步都变得更为容易。\n当使用一个产品带来的收益超过其成本的时候，扩散将接近临界质量。此时，每增加一个链接将会带来更多的链接，进一步增加收益——而成本却保持不变。\n如果没有到达成本/收益的平衡点，在网络中存在多少链接都是没有意义的——因为，最终在这个网络中的扩散都会失败。\n###内容（依旧）为王 当我开始1995年开始为网络项目而工作时 ，曾经有一个说法叫做“内容为王”。内容可以吸引使用者、留住使用者、挽回使用者。那时候流行很多理论——其中一个说应该确保用户点击鼠标不超过6次就能够找到他/她想要的内容，另一个说重要的信息不要被屏幕翻页所分割（载入的计算机屏幕的第一页之后部分信息）。不管是在过去还是在现在，这些都是好的设计准则。但是如果网站的内容非常吸引人，其它的这些都不再重要。如果翻页后的内容很有价值，人们就会点击和滚动鼠标去看。\n这种观点在今天同样存在：如果内容在某些方面是引人入胜的，这将提高收益并使得成本和收益的平衡更快到达，并因此将链接的临界质量从7%降低到3%或4%。如果内容的质量不是那么好，那么可能根本就无法到达临界质量。\n这是社会网络的定量分析止步的地方，也是关于信息重要性的理论过度盛行的领域。下面的这个理论是许多试图定性地解释信息扩散的一种方式。\n当我们想要知道一个信息是否可以在一个网络中扩散时，实际上我们的问题是“这个信息是否会和网络中的成员引起共鸣？”。或者，更准确地说，“个体如何获取信息？”。我们可以将信息的作用分解为几个维度的变量：\n• 相关性（Relevance） 我是否关心？（以及其变体，显著性（saliency）——我现在是否在乎？）\n• 共鸣（Resonance） 信息的内容和我所相信的内容是否一致？\n• 严重性(Severity) 信息的内容有多好或多坏？\n• 紧迫性（Immediacy） 这个信息是否需要（人们）马上行动？与严重性一起，表示（看到信息后）不做出任何行动的后果。\n• 确定性（certainty） 这个信息的效果是否会导致某种痛苦或者快乐？或者这种概率非常小？\n• 信源（source） 信息来自哪里？我是否信任发出信息的人？这是否曾被人们所验证？\n• 娱乐价值（Entertainment value） 信息是否好玩？是否耐读？\n###异质性偏好 我在以前的小节中的提到的评价方式适用于特定的信息（m）和人（p）。但是在实际生活当中，每个收到信息的人按照他们自己特殊的偏好来给信息打分。在经济学中，汇总异质化的个体偏好是一个困难的问题。为了简化这个问题，让我们假设以上所提到的所有变量都可以写成数值形式（我们规定其范围为0到1）。那么，每条信息都可以被评价为：\n公式6-1\n公式6-2\nBeta数值代表对于一个具体的个体，当他/她采用一条信息时每一个变量的重要性。有些人非常脆弱、害怕恐吓战术（具有很强紧迫性和严重性的信息，即使相关性不高并且也不相信信源），而有些人当信息来自于他们并不完全相信的信源时，毫不犹豫拒绝相信。\n让我们看一下是否我们可以将这个公式应用于一些可能的场景中去：\n####突尼斯和埃及革命 这些事件高度依赖于信息的扩散。在这个例子中，大多数信息可以被评价为高相关性、高紧迫性，一些信息会被评价为高严重性（比如，军事活动或者警察镇压活动中的信息）。但是，在任何一个像这样的快速改变的条件下，确定性很低并且对于信源的可信性超过信息本身的可信性。也就是说，一条来自你的阿姨的话比来自一个记者的信息更可信。谣言泛滥，并且有时候误导了许多人。\n这样，我们能够解释每一场革命都需要一个前后一致的领导——在一个混沌的时代，一条来自领导人的信息既负载着确定性（因为领导者肯定具有更多的信息或者令人信服的假信息），也负载着对于信源的超凡的信任。\n####保罗∙里维尔的乘骑 保罗•里维尔（Paul Revere）（1735年1月1日——1818年5月10日）是一名美国银器匠，也是美国革命战争中的爱国者。他最出名的事迹是在莱克辛顿和康科德之战前通知当地殖民军英军即将到来。（译者补注）这是关于高严重性、高紧迫性、高相关性、高确定性信息的一个最好的例子。即使信源并不太出名，信息很快就到达了临界质量。共鸣非常高，因为人们已经相信英国人的袭击迫在眉睫。有必要注意的是保罗∙里维尔并非是向世界发出一条微博，而是造访一系列的城镇——到达一大群分散的、小的地方的临界质量，这些地方稍后团结起来一起反抗英国军队。 ####电视广告 电视广告对大多数读者（一些正在选择新的、正在播出的电视的人例外）来说相关度不高，重要性不高，迫切性也不高。为克服这些缺点，广告主需要设计信息内容以提高信息的确定性（例如，“这将改善你的生活”）、信源的可信性（“六个医生有五个会推荐……”）、信息的娱乐价值。对于二手车销售者来说，其它的策略也很合适，例如放大严重性和迫切性（“现在行动，否则就没有机会了”）。\n对于广告的响应一般非常低，因为很多人对于品牌名字漠不关心。当然，在这种情况下，能够对抗这一规律的品牌将占据市场的主导地位。苹果公司花费数年时间和几百万美元培养了一群粉丝，正如多数体育队和一些其它公司所做的那样。迎合粉丝的品牌成功地获取回报，即使信息内容很普通——只要这些信息强化了粉丝已有的信念（我们将在本章“Python中的一个简单的动态模型”一节中讨论具体内容）。\n最后，多数广告无人理会——但是偶尔会有一个广告超出广告商的宣传活动，像病毒一样在互联网上传播。这经常意味着广告具有较高的娱乐价值并且值得人们在它上面花费时间（参照前面关于成本/收益分析部分），即使它不具备其它方面的因素。\n####连锁信 连锁信是这个类别中的一个奇特成员。来自于你认识并信任的人的信息非常重要。它通过一个好故事的娱乐价值吸引你，但如果你不转寄这封信会有严重和紧迫的后果。在这种情况下，造成伤害的确定性很低 ，但转寄电子邮件的成本同样很低(如果这个信件是真的呢？)。 ####搞笑猫图片 我不知道说什么好。从个人来讲，我不认为它们值得下载，但我猜我不是一个互联网媒介的典型消费者。对于一些人来说，搞笑猫图片的娱乐价值非常高，以至于你不仅仅满足于欣赏它们或者传播它们，还要去创造新的图片。我手上有额外的时间吗？\n许多其它的信息以相同的方式传播——思考一下宗教类的信息并且把天主教信息和热心的牧师的话对比。虽然信息的内容或许相同，信息所表达的意义却完全不同。有的信息强调商品的价值，有的信息剖析最新的流行时尚。\n##6.2信息如何影响网络 信息、观念和看法的改变相对得很快，并且在这个过程中，影响网络解构。同时，网络结构也制约着信息扩散的过程。结果构成了一个双重反馈回路：社会结构影响信息扩散，而信息则影响社会结构的变化。在这一节中，我们将要讨论内在机制——并尝试构建一个信息扩散的简单的动态模型。\n##具有相同羽毛的鸟 在第5章的“二模网络的理论”一节，我们简要得提及了同质性的概念——节点之间的链接的建立基于节点之间的相似度。但这个观念已经存在了几百年了（俗语说“羽毛相同的鸟总飞成一群”），在科学研究方面，拉扎斯菲尔德（Lazarsfeld）和墨顿（Merton）于1954年分析了这一下现象 ，他们区分了两种类型：身份同质性和价值同质性。\n身份同质性表示具有相同社会阶层、财富和地位的人（与随机的情况相比）更倾向于彼此相互联系。价值同质性表示倾向于与以相同方式思考或者喜欢相同的东西的人彼此相互联系，不管阶层和地位如何。\n美国文化当然更显著地受到价值同质性的影响，而在其它社会当中，个人的教育和阶层身份经常更清晰明确地影响他们所能接触到的信息或者文化人造品的类别。这在网络上更为明显，因为在互联网上“没有人知道你是一条狗”。一个人的网络身份虽然现在变得很普遍并接近于永久，但与线下的身份相比，仍然非常容易改变。\n地位同质性和价值同质性的一个区别正是在于“可塑性”（malleability） 。社会阶层和类别可被认为是永久的属性——社会流动通常是一个很缓慢的过程，因而无法通过社会网络分析把握。与之相反，价值同质性则以互联网的速度变化着。\n###同质性 VS. 好奇心 社会学家观察到另外一个有趣的现象——虽然同质性是一个很强的社会因素，但如果两个人不太像，但差异也没有达到使得两个人找不到谈话的话题时，另外一个因素将会发挥作用。这个因素是好奇心（获取信息的内在动机），结果使得形成链接的可能性呈现图 6-3中所示的双峰形状。对每个人来说，“好奇心山峰”的高度和位置是不同的，并且与我们的猎奇及规避猎奇的趋势有关（事实上，这可能是我们基因组成的一部分，尤其是我们大脑中的D1多巴胺受体的数量有关）——但它总以某种形状存在着。\n图 6-3 同质性与好奇心\n图字翻译：\n最主要的特征是“无聊的陷阱”。遇到一个和你在各个方面几乎一模一样无法提供新的信息或者刺激——于是建立链接的可能性迅速降低。人与人之间无聊的陷阱的位置和程度也不一样，并与我们的大脑对新奇性的需求和处理有关系。\n自我中心主义者的这个波动的极值是无法控制的，他们以没有能力处理新奇性和很难形成社会纽带并理解他人为特征。对威廉斯氏综合症患者来说，寻求新奇性和群集性走到了极端（缺乏抽象和空间逻辑能力）。\n你也可以把它看作一个随着时间的演变过程。想象一对刚刚遇到对方的男女。他们或许有一些相似的特质（都很年轻漂亮，如果没有其它地方相似），但总体上讲他们的同质化水平可能很低；相反，他们的好奇心都达到了顶峰。随着关系的进展，他们对彼此的了解不断加深，即使对于他们从来不会交流的事情。最终，男孩知道了他的女朋友背负着大笔的学生贷款，女孩了解到她的男朋友把脏袜子到处丢的坏习惯。这或许是位于好奇心和真的同质性之间的低谷。如果他们的关系走过了这个低谷，他们会变得能够接受了解对方所有的事情并且幸福得白头偕老。除了在之后的十几年里，他们没有对彼此说过一句话——如果他们相互之间没有什么新的消息为什么要说话呢？\n###跨界者\n我们每个人的基因组成和个性差异使得我们的社会网络也是不一样的，并且同质性到目前为止也不是普遍的。一些人喜欢做跨界者，他们和不同的群体存在联系，表现出来非常低的同质性。他们不仅是关键的信息通道，他们也可以利用作为中介和套利的机遇——这意味着在石器时代与不同部落建立贸易往来或者在现代在华尔街工作。我们已经在第4章的“禁止进入的三元组”和“结构洞”讨论过这个问题——但跨界行为也可以透过信息扩散的透镜来理解。\n###弱关系 在二十世纪七十年代，马克∙格兰诺维特（Mark Granovetter）开展了一项关于在南波斯顿某一个社群工作的蓝领工人的研究。他的大多数调查对象是爱尔兰移民，在建筑业或者其它技术工行业工作，并且花费大量的时间在酒吧里。工作，尤其是建筑业的工作，非常不稳定，在任何时间都有一部分人处于失业和找工作的状态中。这个研究项目的目标是研究工作信息如何在社会网络中流动。\n当地的酒吧是社交中心——每个人都定期地参加聚会并认识大多数其他去酒吧的人。所以最初的研究目的是分析酒吧里的谈话对于个人找工作能力的影响。\n但是结果非常令人吃惊——通过经常联系的酒吧里的朋友找到新工作仅占30%。大多数时候，工作信息来自于疏远的社会关系——远亲、朋友的姻亲等（也就是说，与他们存在弱的网络关系的人）。\n格兰诺维特推理强关系增加同质化程度——所以当一个人需要新的信息（比如，当找工作的时候），与处于中心的个体存在强关系的人缺乏任何新的信息。同时，通过弱关系联系的人们则完全不同（从信息连接的角度而言）。\n###邓巴数字和弱关系 在罗宾∙邓巴（Robin Dunbar）的论文中（现在已成为经典） ，人类社会网络的平均规模（也就是平均的程度中心性）是150——并且从认知学角度来看，这个数字为前额皮质的大小或者我们推理其他人和关系的天赋才能所局限。\n但这不是那么简单的事情。我想用一个金字塔来展示邓巴数字的各段（见图 6-4）。在顶端，最强的关系是我们直系亲属和最好的朋友，我们每天与他们打交道，并认为他们是最亲密可信的人。邓巴发现这个亲密的群体的大小平均是7——它包括我们的配偶、父母、兄弟姐妹和子女。注意，这个数字和人类工作记忆的容量大小相同（7+/-3） ，所以我们可以推断我们的直接的和最亲密的社会联系是那些我们能够或必须存储在工作记忆中的。\n图 6-4 邓巴金字塔\n图字翻译：\n这个列表进一步分层为“扩展家庭”（extended family，这个群体包括朋友、表兄妹、姻亲等）：他们不是你每天都打交道的人，也不是你认为最亲密的人。再往下一层是“伙伴”，包括同事、一个更大的朋友和陌生人圈子、远亲。最下面一层包括其他所有的人，主要是你的弱关系。\n但是你的脸书朋友和推特朋友在哪里呢？多数情况下，他们位于金字塔的最底部。正如你从上面关于四种关系的描述中所看到的，当我们从金字塔上走下来，不同的社会关系所附带的情绪性和信息分享类信息不断降低，而人数不断增加。所以你的837个推特朋友所包含的情绪性注意力有多少呢？其实很少。\n对于一个服务行业的商业公司而言，社会化媒体的个体接触主要也是因为这个原因。当一个公司的代表与一个推特粉丝在个体层面上互动（例如，回应一个抱怨）的时候，他或她就在这种关系中投入了一些情绪性的能量。因为这种互动是公开的，它不仅维系着与一个现在的消费者之间的关系，还支撑着与其它的推特粉丝之间建立关系的（想象中的）可能性。\n因为每个人对于亲密的个体联系具有不同的偏好，这个金字塔对于每个人可能完全不同。我认识的一些人的最主要的社会联系来自于脸书和博客，他们的线上关系和“扩展家庭”开始融合。因为维持一个线上关系需要很少的情感投入，他们线上朋友可能有几千个却很少跟他们的直系亲属联系。近几年，网络流浪者开始变得与现实中睡在沙发上、一年周游国家数次的流浪者一样。\n##6.3 Python中的一个简单的动态模型 既然我们已经了解了相关的理论和例子，让我们开始尝试为社会网络中的信息扩散建立模型。我们将建立一个非常简单的多主体模型，在这个模型当中，社会网络中的主体之间相互影响并达成共识（如果这是可能的）。\n这个模型最初是由诺亚∙弗里德金（Noah Friedkin）于1998年提出来的 。这个模型遵守一个非常简单的前提：每个参加讨论的人对于问题都有自己的看法（或者他们自己的态度），并且每个人都在一定程度上接受来自其社会网络的朋友的影响。我们同时做出一个假设，模型中的主体所要交流的信息是一个介于0和1之间的数值。它可以是股票市场上升的可能性，或者一个主体使用一种非法药物的概率（这个模型曾用于研究信息在这两种情况下的扩散）。\n让我们开始建立我们的简单模型。我们并不会使用一个多主体建模的软件包，或者模拟包——其实我们也并不需要用它们来建立模型。\n让我们从为一个人定义一个Python的类开始：\nclass Person(object): def __init__(self, id): #从一个单一的初始偏好开始 self.id=id self.i = r.random() self.a = self.i #我们将初始意见和随后的信息对等 self.alpha=0.8 def __str__(self): return(str(self.id))  一个人有一个编号ID和三个重要的额数字：self.i是一个初始态度，self.a是一个演化出来的态度（它累积了这个人所有朋友的影响），最后self.alpha是我称之为“轻信程度因子”（也就是说，alpha越高，我越相信我的朋友的意见，并且越不相信自己最初的知识）。首先，我们假设每个人的轻信程度是完全相同的。\n现在，让我们创造一个以人为节点的网络。NetworkX允许我们使用任何对象作为一个网络节点，而我们将要利用这一特点:\ndensity=0.9 g=net.Graph() ## 创造一个以人为对象的网络 for i in range(10): p=Person(i) g.add_node(p) ##这是一个简单的随机网络，每对节点之间存在链接的概率相同 for x in g.nodes(): for y in g.nodes(): if r.random()\u0026lt;=density: g.add_edge(x,y) ## 画出这个生成的网络并按照节点的数字给节点赋予颜色 col=[n.a for n in g.nodes()] pos=net.spring_layout(g) net.draw_networkx(g,pos=pos, node_color=col)  首先，我们初始化一个空的网络图，并在其中增加10个以人为类型的对象。然后，我们循环遍历每一个可能的两个节点之间的组合。使得概率等于密度的参数，我们将在两个节点之间添加一条链接。这种生成图的算法称之为厄多斯-任易（Erdos-Renyi）算法 ，是生成一个随机图的最简单的方法，并产生一个正态分布的度分布。\n厄多斯-任易（Erdos-Renyi）随机图已经成为许多图的算法和模型的一个基准，但我们现在知道，作为真实社会网络的代表它们非常不实际，因为多数社会网络具有一个长尾的度分布（也就是幂律）。但是，因为其它生成网络的方法更加复杂并超过了这个模型的范围，我们将在此使用这个简单的模型。这个网络看上去应与图 6-5相似。\n图 6-5 一个扩散模型的多主体的网络\n现在准备工作已经做完了，让我们开始创造模拟部分。在人这个类别中插入下面这个函数：\ndef step(self): # 循环遍历所有的邻居并累加他们的偏好 neighbors=g[self] # 所有的邻居节点的权重相同 w=1/float((len(neighbors)+1)) s=w*self.a for node in neighbors: s+=w*node.a # 更新我的意见为初始意见加上所有其它影响之和 self.a=(1-self.alpha)*self.i + self.alpha*s  这个函数基于他或她的朋友的态度加权总数和他或她的轻信程度因子（alpha）而更新一个个体的态度（a）。首先，我们将计算权重的大小。为了计算简便，每个人的意见所占的权重相等（第五行代码）。然后，我们计算一个个体自我意见，以及他或她的邻居中每个人的意见的加权之和（第6到第8行代码）。接着，我们更新现在的意见（第11行代码）:个体在时间t的意见等于客观知识乘以轻信因子，再加上他或她的所有朋友意见的加权之和。最后，让我们用一个循环的方式跑这段代码来看一下这个网络如何随着时间变化：\n##重复30个时间段 for i in range(30): ## 循环遍历所有的网络节点让它们走一步 for node in g.nodes(): node.step() ## 汇总演化而来的态度数值，输出到终端并画出结果。 col=[n.a for n in g.nodes()] print col plot.plot(col)  跑这个模型30个时间段所得的结果看上去如图 6-6所示。随着时间变化，主体之间的意见越来越彼此相近，虽然它们从未达到共识。\n图 6-6 扩散模型运转一步\n让我们现在开始调整一下模型参数。如果所有的主体都非常轻信并接受他们的朋友所说的一切，那么结果会是怎样？让我们设置alpha = 1并看一下结果如何变化。图 6-7表明每个人很快达到共识——即使基于事实来看这个共识是完全错误的。\n图 6-7 扩散模型中的共识\n###处于中间的影响者 现在我们假设一些宣传主体（影响者、福音传教士）被嵌入到网络当中。每一个这样的节点都具有重要影响。在这个模型中，这些主体的意见是1，而其他所有主体的意见分布于0到1之间。 我们在模型中定义一个影响者为一种特殊类型的人：\nclass Influencer(Person): def __init__(self,id): self.id=id self.i = r.random() self.a = 1 ## 它们的意见很强并且不可动摇 def step(self): pass  接着，我们添加一些影响者到这个网络中并将他们同其他主体相连：\ninfluencers=2 connections=4 ##将影响者加入到网络之中并将他们与其它3个节点相连 for i in range(influencers): inf=Influencer(\u0026quot;Inf\u0026quot;+str(i)) for x in range(connections): g.add_edge(r.choice(g.nodes()), inf)  之后，像以前一样跑这个模型：\n## 重复30个时间段 for i in range(30): ## 循环遍历网络中所有节点并让他们运转一步 for node in g.nodes(): node.step() ##汇总演化而来的态度数值，输出到终端并画出结果。 col=[n.a for n in g.nodes()] print col plot.plot(col)  图 6-8表明这两个影响者具有一个很强的效果——但是，初始位置并不允许主体完全地朝着极值迁移。影响者的数量越多，模型朝向一个极值的共识演化的可能性越高。\n图 6-8 添加两个影响者进入网络中以加速网络朝向极值的演化\n这个模型非常简单，没有考虑许多其它影响信息扩散的因素。其中没有同质化的影响，也没有临界质量的作用，并且模型的演化是线性的。但是，这是一个开始，我们要进一步优化这个模型。\n###练习 我在这里所展现的这个模型的实现方式过于简单。读者可以尝试下面这些主意：\n• 使得轻信程度因子异质化而不是所有的主体的轻信程度因子相同。\n• 试验使用多个参数调节的无标度网络而不是使用简单的随机网路。\n• 对于朋友的意见应用信任权重（也就是说，不是给所有的意见的相同权重）而不是基于主体之间的链接的强度。\n• 使用多个维度的态度进行计算——一个真实的人对于不同的事情有多种态度，模型中的主体也是这样。\n##6.4网络和信息的共同演化 现在我们将要优化这个模型中的影响因素，以便允许不同的网络类型、个体的态度和网络中的信息内容。首先，我们将把step函数从之前的模型中去掉，与之相反，引入一个和单一主体交换信息的互动函数，而不是和所有的邻居交换信息。轻信程度因子的作用在这里同样适用：\n## 随机的挑选一个节点交换信息， ## 而不是和所有的节点交换信息。 ## 这将创造一条边并根据他们之间的相似性赋予权重。 def interact(self): partner=r.choice(g.nodes()) s=0.5*(self.a + partner.a) # # 更新我的意见为初始意见加上所有其它影响之和 self.a=(1-self.alpha)*self.i + self.alpha*s g.add_edge(self,partner,weight=(1-self.a-partner.a))  到现在为止，这是一个随机的选择。在信息的交换和接收之后，我们将在两个节点之间创造一条链接。这条边将被按照相似度赋予权重——节点之间的相似程度越高，他们之间建立的链接的强度越高。\n但是，我们也知道在一段时间过去之后，链接会逐渐减少，一个最简单的方法是用一个为常数的衰变率（decay rate）来描述：\nv(t+1)=v(t)*(1-decay_rate)\n衰变率在现实网络中是非常低的，但是在线上社会网络中会明显得要高（因为在脸书上取消朋友关系或者只是忽视他们的信息与跟现实世界中的朋友吵架相比，要简单很多）。但是，这个模型非常抽象，所以我们将选择一个简单的数字。我们设置网络的衰变率在每个时间段为1%。\ntips: 一个模拟中的时间段是完全随意的。但是，人们也可以将它（以及衰变率）与作为交往频率的函数的链接的强度的概念相联系，见第2章“什么是图”一节的描述。\n所以，以之前的方式，让我们初始化这个网络，并运行这个模拟。图 6-9表明一个与其他节点联系紧密的节点，如何在他/她周围分布着一小群意见相似的粉丝，而那些与其他节点联系并不紧密的节点保持着与众不同的意见。这样，带有完全不同意见的节点可以和平共处并且共识会涌现（如图 6-10）。\n图 6-9 这个网络表明意见相似的节点之间联系紧密而意见不同的节点分布于边缘上\n图 6-10 网络和态度的改变允许冲突的态度和多种共识并存\n但是，这也依赖于传播参与者的随机选择这个概念——我们知道这是不正确的（见本章“信息如何影响网络（反之亦然）？”一节）。所以，现在让我们引入同质性的概念。这样做，每个人都维持着自己与他/她所知道的一系列的人的关系，以及自己在多大程度上与他们相似。在这个例子当中，我们已将同质化程度数值存储在图的链接属性中，通过下面这行代码:\ng.add_edge(self,partner,weight=(1-self.a-partner.a))  但是在我们开始利用这个信息选取互动对象之前，我们来讨论一点关于选择的事情。正如我们在 本章前面“信息如何影响网络（反之亦然）？”一节所讨论的一样，我们以更高的概率选择与我们相似的人——但是兴趣中的第二个峰值使我们与和我们非常不同的人交谈。一些传播行为也可能是随机的。为了允许我们按照正比于和其他人的相似度（或不相似度）水平的概率挑选互动对象，我们应用一个叫做“轮盘赌选择”的程序。\n图 6-11 选择网络伙伴的有权重的轮盘赌\n想象一个轮盘赌的轮子的各个扇区之间的权重是不同的（图 6-11）。这样，将赌注押在一些扇区上赢得概率更高，轮盘的旋转是公平的（也就是均匀分布的）。我们通过按照相似度水平构建一个传播伙伴的列表（如果需要，多次重复他们的名字）的方法应用轮盘赌方法。这样，一个从列表中进行的一致的随机选择，将返回一个权重分配合理的轮盘赌选择：\ndef _roulette_choice(self,names,values, inverse=False): \u0026quot;\u0026quot;\u0026quot; 轮盘赌方法基于一组数字得到不同权重的选择 名字和数值应该是等长的列表 数值的范围在0到1之间 如果 inverse=False, 数值较高的名字具有更高的选择概率 如果inverse=True，数值更低的名字具有更高的选择概率 \u0026quot;\u0026quot;\u0026quot; wheel=names for i in range(len(names)): if not inverse: wheel.extend([names[i] for x in range(1+int(values[i]*10))]) else: wheel.extend([names[i] for x in range(1+int((1-values[i])*10))]) return(r.choice(wheel))  最后，我们需要优化interact（）方法一允许我们使用轮盘赌方法。我们再一次掷骰子并决定是否传播伙伴是相似的（以一个0.6的概率）或不相似的（以一个0.3的概率）或完全随机的（以一个0.1的概率）。如果一个人不和任何人说话，他/她将随机地挑选并建立一些网络链接：\ndef interact(self): \u0026quot;\u0026quot;\u0026quot; 随机的挑选一个节点交换信息， 而不是和所有的节点交换信息。 这将创造一条边并根据他们之间的相似性赋予权重。 阶段 II –使用轮盘赌选择而非随机选择 \u0026quot;\u0026quot;\u0026quot; neighbors=g[self].keys() values=[v['weight'] for v in g[self].values()] ##掷骰子已决定互动的概率 ## 相似 (0.6), 不相似(0.3)或随机 (0.1) roll=r.random() if r \u0026lt;= 0.1 or len(neighbors)==0: partner=r.choice(g.nodes()) elif r\u0026lt;=0.4: partner=self._roulette_choice(neighbors,values,inverse=True) else: partner=self._roulette_choice(neighbors,values,inverse=False) w=0.5 s=self.a*w + partner.a*w # 更新我的意见为初始意见加上所有其它影响之和 self.a=(1-self.alpha)*self.i + self.alpha*s g.add_edge(self,partner,weight=(1-self.a-partner.a))  让我们也优化这个模型以便生成更多的一些图。第一个是“共识图”——展示的是网络中每个人的平均意见，以及最大和最小值：\ndef consensus(g): \u0026quot;\u0026quot;\u0026quot; 计算图中的作为共识的意见 \u0026quot;\u0026quot;\u0026quot; aa=[n.a for n in g.nodes()] return min(aa),max(aa),sum(aa)/len(aa)  我们将模型的每一次迭代生成的网络共识的数值添加到一个列表里，并在后面绘制出结果：\ncons=[] for i in range(runtime): for node in g.nodes(): node.interact() .... ....模拟代码在这里.... .... cons.append(consensus(g)) .... .... 模型的最后一次运转之后.... .... plot.figure(i+1) plot.plot(cons) 同时，让我们通过绘制直方图的方式来看一下边的数值。 plot.figure(i+2) plot.hist([e['weight'] for f,t,e in g.edges(data=True)]  tips: 完整的模型代码可以从Github下载（https://github.com/maksim2042/SNABook/chapter6）\n让我们现在重新载入并运转这个模型。结果如图 6-12和6-13所示。\n图 6-12 最终的网络中，节点的意见可以非常不一样\n图 6-13 网络收敛到一个在可接受范围内的意见，但允许内部存在一些多样性\n我们的第一个观察是网络迅速地到达了稳定状态——但这个稳定状态并非形成共识，而是排除了最高和最低极端意见的一种分布广泛的可接受的意见，这种状态适于形成一种让人感到舒适的平均意见。在缺少意见领袖的条件下，平均意见的选取是非常随机的——但是我们可以非常肯定的是，如果我们的随机数生成器是公平的，取得的结果是远离极值的。\n网络并未变成群集内部同质化——相反，如果节点的意见在可接受范围内，那么它们可以共存于一个稳定的动态均衡中。这是如何实现的呢？\n我们在本章中讨论了这个机制——它是弱关系。如果你以直方图的形式绘制出这个网络的链接的强度（图 6-14），你会发现强关系非常少见（特别弱的关系也很少见）。相反，链接的强度似乎分布于一个0.3的均值左右，这是一个很好的、稳定的弱关系。\n图 6-14 多数链接是弱关系或者中等弱关系，正如邓巴金字塔所展示的。\n这进一步加强了链接强度的邓巴金字塔——强关系很少见并且需要完全的共识（这也是很少见的），相反弱关系很容易建立并维持。\n##练习 • 加入影响者。他们如何改变演化动态？如果一些影响者互相冲突（具有截然相反地意见），网络会分化吗？\n• 在模型中加入大的冲击。例如，一个主体可以在一个随机的时刻将自己的意见改变为极值。他/她的朋友们是否回来劝阻他/她？\n• 加入不同传播能力的主体。例如，广播者可以一次同所有的人讲话。\n• 在这个模型的基础上构建一个选举模型。一些候选人为了获得全体的注意力而竞争。他们应采用什么样的竞选策略以影响结果？\n###为什么为网络建立模型 在本节里，我们已经表明使用寥寥数行代码，我们能够概述关于网络动态和变化的理论，并尝试去通过模拟的方法检验它们。经常地，在一个需要和很多实证数据打交道的环境里，形成一个关于驱动网络变化以及变化方向的简洁的理论变得非常困难。模拟模型帮助我们发展出更简洁的理论，并允许我们很快地检验多种不同的观点 。\n这个模型可以作为建立其它信息扩散模型的实验基地。例如，想象一个网络当中的一些节点出现然后又消失以传递一些独特的信息。或者一个在一段时间内可以不受干扰地演化的网络，之后注入一个重要的信息（例如，“传教士和野人”问题 ）。或者，想象着是一个模拟毒品贩运网络的模型，作为一个警察局的网络专家，你需要破坏网络中的信息流动。类似的可能性是无穷无尽的。\n可计算社会科学（Computational Social Science ，简称为CCS）的整个领域已经从社会网络分析、人工生命、人工智能以及其它的一些领域的交汇中开始升起。这或许将成为我们下一本书的主题。\n","date":1341100800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1341100800,"objectID":"acd6b5fbc1a99254c2f5164e2e45b14e","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-07-01-snabook-chapter6/","publishdate":"2012-07-01T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-07-01-snabook-chapter6/","section":"post","summary":"","tags":null,"title":"第6章 信息扩散：像病毒一样传播开来","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\nHow Nature Works: The Science of Self-Organized Criticality 作者: Per Bak\n黠之大者\n任何一个学科都需要从其它学科学习其精髓，对于在走向可计算化道路的社会科学，尤其是传播学而言，这种开放性更是时代的压力和必然的结果。因为网络时代的到来所带了的传播关系的变革、数字化的行为印记（digital traces or digital footprint）、大规模的网络数据的开放都推动着学科的变革。无疑对于传播学而言，这是一个必须抓住的机遇。\n爱因斯坦在老年时在一个自述中讨论了一个问题，即为什么他念了物理没有念数学。他说:“在数学领域里，我的直觉不够，不能辨别哪些是真正重要的研究，哪些只是不重要的。在物理领域里，我很快学到怎样找到基本的问题来下功夫。”我想这几句话的意思应该是每一个大学教授，每一个大学研究生应该仔细想法体会的。如果思考重要的问题，自然做出的东西不容易琐碎（trivial）。虽然最终问题的本质可以用一个美妙的数学形式表达（不应该是统计方程），但从那么多的相（万象）中找到基本的相，稳定的相（pattern)。依然是一个不容易的事情。 到幂律分布（power law）之类的发现依然是唯相的阶段。社会科学的冒进在于每次都妄想一个理论框架。每次都拿理论发现来宽慰自己。殊不知己之理论与彼之理论，相差如同天壤。大数据（big data）引发了很多欢呼和争论，虽然这是机遇，但也隐含着危险。大数据（big data）如果是无偏的，有代表性的，那么就蕴含着机遇。常见的一个错误是误以为google成功于海量数据，谬矣。信度和效度的问题，在我的理解里，这都是你选择的测量的可计算性的问题。好的测量（measure）往往一针见血，如货币，如基因，如能量，如比特。在互联网里目前最成功的测量是什么？我以为是pagerank。借助用户的评价，一下子就抓住了一个网页的重要性！googe最成功的是pagerank这个好的测量。这样好的测量才能赚钱，才有可计算性，基于兹的研究才有信度和效度。类似的测量当属度了，度分布的幂律分布（power law）被无数的研究所发现，可以算到了唯相了。\n作者愚见，觉得扩散是最为普遍而重要的现象，它广泛地存在于各个学科中，并几乎都成为最重要也是研究的最彻底的、最吸引人注意力的领域。我自己对于扩散有着超乎直觉的兴趣。借用古希腊哲学家的话：万物皆流，万物皆变。身在浩浩汤汤的洪流中的个体很容易对流产生兴趣。因而，我将研究流的扩散，更具体的说信息的扩散，作为了自己博士研究的主要工作。 而选择研究信息扩散的一个驱动力就是巴克（Per Bak）的这本书《大自然是如何工作的》，这本书通过沙堆模型讲自组织临界性，对我的启发很大。当我对信息扩散的数据浸淫日久之后，深感必须重返沙堆模型，才能真正理解信息的扩散，因此便有了本文。在本文当中，我将归纳关于扩散研究的三种路径。\n##一、描述式的社会科学套路 如经典的新闻扩散（news diffusion）的研究、两级传播理论（two-step flow）、创新的扩散（diffusion of innovations）。这些研究主要是为了描述现实，沿着这条道路走下去，可以更真实地理解5w，却很难理解1h（即how）。\n虽然社会科学因为无历史包袱，所以视角更为多元，比如两级传播理论所揭示的媒介的直接影响非常不同于自然系统的扩散的特点， 经典的新闻扩散研究发现的J曲线指出人际作用和媒介作用的对立，以及其对传播规模的非线性影响也很有想象力。但社会科学却在可计算化方面做得并不好（读者可参见本文作者在上一期杂志上关于计算传播学的文章）。比如经典的创新的扩散理论中所着重论述的s曲线实在是一个坏到家的定义。因为并未能给出s曲线的数学表达，而几乎不管什么曲线方程（如罗杰斯蒂方程，但注意s曲线不是罗杰斯蒂曲线），只要使用超过三个数学参数就可以拟合任何曲线，这使得大家即喜欢这个s曲线的比喻，又根本抓不住什么才是s曲线。成为了难以比较，不可琢磨的臆测。\n二、微分方程的数学视角。 比如Bass扩散模型(bass diffusion model), 这实在是一个了不起的工作。我写一个的短评，如下：\n从bass diffusion model开始讲，这个与生存（survival analysis）里的hazard rate息息相关。因为F\u0026rsquo;(t)/(1-F(t))被定义为hazard rate。其实是一个条件概率，就是没有采纳的人（没被传染的人）（1-F(t)）在时间点t采纳（被传染）的概率。\n关于hazard rate设置的方法导致Bass扩散模型(bass diffusion model)，前几天刚看了，h(t)=p+q*F(t)。解这个微分方程，可以求出F(t)和f(t)。这个东西可以预测增长曲线。p和q分别代表创新性和模仿性。感觉很好玩。p=0, 即没有创新性的时候，是罗杰斯蒂增长（logistic growth）；q=0, 即没有模仿性，只有创新性的时候，是指数增长（exponential growth）。\n讲到谣言传播的第一种模型的时候，hazard rate=d，这个时候就是指数增长；但这样设置有些随意（arbitrary），因为有些人拒绝传播。就有了一个叫拒绝率r的东西，这个我还是第一次看到，因此它是在试图修正hazard rate。那么r是什么呢？没有讲清楚。我试图从R(t)=r*F(t）/(1-F(t))这个我自己构造的公式来理解。r*F(t)衡量的是已经知道谣言的人拒绝传播的概率, 再除以1-F(t)就是不知道谣言的人受拒绝传播的人影响的概率。 那么就有h(t)=d-R(t)。 但这种工作有点arbitrary，因为你说p是创新性，q是模仿性，然后就开始推导了 （推导可见我的一篇博文， 另电子杂志可以加链接于我而言是意见快乐的事情） 下面沿着率方程的道路走下去的是一个伟大的传统，即传染模型（epidemic model）。最主要的是sis和sir。其主要思路是将传染的过程分为3个阶段：susceptible\u0026mdash;\u0026gt;infectious\u0026mdash;-\u0026gt;recovered (and immune)。sir说一次恢复，永远免疫，再也不怕了；sis则不然，好了还会被再次感染。传染病模型中一个主要的工作是确定一个传播率，它是感染率和治愈率的比值。这个传播率一般存在一个threshold，当高于这个threshold的时候，能够全局传播；否则只能感染少输人。\n网络科学开始考虑人际接触关系（contact relationship）是如何受网络度分布的影响的，加入度分布的因素之后开始考虑统合门槛(threshold)的大小问题，一个著名的工作是Romualdo etc在2001年发表的一篇题为epidemic spreading in scale-free networks的论文，被广泛引用，因为他们发现scale-free network里的感染门槛是0！！！没错，就是0，也就是说全局传播不是问题。\n不过，要小心，这个模型是根据sis做的，如果是sir情况是如何呢？（留作思考，其实我也不知道）这一点很重要，因为当你把它用在信息的渗流的时候，是有风险的。举例子说：Romero \u0026amp;Jon kleinberg （2011）等人研究hashtag(e.g. #ows)在twitter上的扩散，发现多次接触具有很高的边际作用，发现多次接触信息对于信息转发具有显著效果（Repeated exposures to a hashtag on Twitter has significant effects）。那么多次接触单个的信息（repeated exposure to a specific tweet）呢？其情况会大有不同。因为hashtag是一个类别（category），下面有很多子类别。正如感冒细菌下面包含各种各样的细菌一样。加到一块的影响，使得影响很大，但对于单个类别的感冒细菌来说，你得了一次，就不会再得第二次了。即对于单个信息来说，多次接触没有那么大的影响。\n##三、平均场理论视角下的门槛模型（threshold model） 门槛模型（threshold model）最好的诠释仍然是元胞自动机（cellular automaton）， Thomas Schelling的分隔模型（Models of segregation）说每个人都有一个关于周围邻居肤色比例的偏好（peference），超过一定比例后，就会迁移。最简单的就是Granovetter等提出的门槛模型了，计算每个个体（agent）行为改变时其朋友中行为改变比率，但按照平均场视角，这其实不重要，重要的是平均起来的总体效果，最简单的就是门槛的数学分布，按照格兰诺维特的想法，这个数学分布最终决定了扩散的规模。\n自组织临界性最早是BTW sandpile model所提出的，沙堆理论是一个非常强大的metaphor，其主要提出者bak写了另外一本非常强大的书籍介绍其核心思想：其所覆盖的范围真是超乎想象。\n自组织的魅力在于可以对扰动做出最丰富的反应!反应是很平常的，难在最丰富的反应。那是什么样的呢？其实是空间和时间两种分布的幂律特征。\n沙堆模型(Bak等人1988年的论文）所描述的自组织系统中流的规模分布（Size distribution，e.g., earthquake,financial markets,landscape formation;forest fires;landslides;epidemics; andbiological evolution）和流的持续时间分布（Duration distribution）都满足幂律的关系。 有趣的是我在新浪微博的扩散的研究中印证了扩散规模（diffusion range or cascade size）的幂律分布，这暗示着新浪微博中的信息扩散是连续的，同样的规律也存在于twitter中。\nBak曾说自己对自组织临界性的理解是压力和压力的释放。比如向沙堆上加沙子，这种动力推动系统重新演化到平衡状态。这种释放压力的系统被称为耗散系统（dissipative system。这是一个很好的概念和视角：其实森林火、地震、河流涌动，信息传播，树叶中的营养输送，等可以以之概括。\n自组织临界可以按照平均场方法进行解析式的理解。平均场方法首先要确定的是phase transition的问题。第一步，便是要有一个稳定的pattern作为起点。因为相变是由一个序转变为另外一个序。而用来标识这种转变的变量称之为“相变序参量” （sigma），一个相到另一个相的转变需要一个驱动，而这个驱动变量即称为“相变驱动参量。比如铁磁相变中： sigma=（t-tc)^r 这种标度律的稳定的关系吸引着科学家的注意力。 平均场方法认为跨越一切尺度的个体的相互作用结果的总体效果（即”平均场\u0026raquo;），而不简单的是每个个体的局部信息（local information），决定着相变。\n##结尾 It puzzles me that geophysicists show little interest in underlying principles of their science. Perhaps they take it for granted that the earth is so complicated and messy that no general principles apply. ——Bak， How nature works\n本文开始引用了Bak在其书中的一句戏谑地理学研究的一句话。其实地理科学家们当中也有一些有先见者。比如hack’s law揭示的流的直径和覆盖面积之间的标度关系。 用C来表示单位时间的平均流，A表示网络覆盖面积，之间也满足标度关系关系。\n相反，这句话是留给社会科学家（不是哲学家或价值批判研究者）的，对于网络科学所刻画的可计算性的传播行为的研究，在通往可计算性传播学研究的道路上，只有实在性是最好的没得。不能停留在表面，必须深入到简单的相下面的基本规律中去。\n","date":1337126400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1337126400,"objectID":"e55dba04ea59ea0c567975b82a198008","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-05-16-return-to-the-sandpile/","publishdate":"2012-05-16T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-05-16-return-to-the-sandpile/","section":"post","summary":"","tags":null,"title":"重返沙堆：通往理解信息扩散的实在之路","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n黠之大者\n引言：大道\n听李金铨(CC.Lee)老师讲治学，喟叹“大道不过三两句，说破能值几文钱？”这是一个开放性的问题，道出了社会科学家(social scientist)的无奈。诸多好玩的东西，归结到最后只有所为“理论”的贡献，而没有应用的价值。CC.Lee一语也是一种挑战：希望学术有助于现世之生活。\n但显然学术应辅助于生活，被认为是传播学创始人之一的卢因博士曾言： Many psychologists working today in an applied area are keenly aware of the need for close cooperation between theoretical and applied psychology. This can be accomplished in psychology, as it has been accomplished in physics, if the theorist does not look toward applied problems with highbrow aversion or with a fear of social problems, and if the applied psychologist realizes that there is nothing so practical as a good theory. ——Kurt Lewin (1943-44), Problems of research in social psychology\n实际上关注应用的理论研究才是真正的有价值的研究。然而学术研究如果止步于此，也多没有生命力，因为我们并没有探究真正的规律（the common pattern）。 一个人如果只是思考琐碎（trivial）的问题，自然不会有大的发现。拉普拉斯曾思考过太阳升起的概率，牛顿执着于重力，爱因斯坦对时间念念不放，这才可能做出真正的研究发现。然而显而易见的是一个可以稳定地（consistently）存在的一般规律（general law）不会是简单的定性描述可以刻画的。它们共享一个优秀品质，即可计算性（computational）。\n对于可计算性的追求在自然科学一直是主流。生物学也开始通过计算生物学的路径开始实现新的飞跃。试思考为什么经济学是自然科学中发展较好的？答案是货币。用货币度量经济行为使经济学具有了天然的可计算性；其次是心理学，不是量表，而是实验，使得心理学具有了“模糊的”比较能力（这种实验计算性的模糊性，局限了心理学的发展路径）。\n事实上，作为一个后起之声，计算社会科学（computational social science）已经在各个分支学科和新的交叉性学科中如火如荼！关于计算社会科学的介绍见Lazer, et al.2009年发表在《科学》杂志上的一文。其中包括：计算语言学（computational linguistics）、计算社会学，计算心理学，计算传播学等。\n也许看到这里，众多也许是全部社会科学家都会想到自然科学和社会科学的区别来。虽然牛顿(Issac Newton)说Truth is ever to be found in simplicity, and not in the multiplicity and confusion of things 。但社会科学家却“深信”社会如此复杂，无法定量甚至实证研究。对此，证明其观点的荒谬远不如开始努力做些东西来得实在。毕竟，你不能因为做一个东西困难就放弃努力。\n##计算传播学 本文的计算传播学不是虚拟之物，它有很多具体的分支。本文所主张的计算传播学是以网络科学为基础骨架，以计算新闻学为实践的知识框架。\n###网络科学（network science） 网络科学已经走出狭隘的传统的社会网研究（social network study）的藩篱，更主要是互联网浪潮的袭来（可参见吴军《浪潮之巅》一书），社会网络开始拥抱互联网网络科学（web science),一种以复杂网络（complex network）为代表的新型网络科学开始迅速成长（参见barabasi的《链接：网络新科学》一书）。\n听得春雷响，老树发新枝。各个分支的社会科学都开始出现网络社会学，网络传播学之类的新的研究版图。然而，此刻之网络科学却远远超越传统社会科学家（包括媒介研究者（media scholars））所理解的范畴。人类传播动态行为（human communication dynamics）开始成为人类动力学（human dynamics）关注的焦点。\n毫不夸张地说，人类的生活已经不可避免地大范围的网络化：网络购物，网络购票，网络交友，网络表达，网络新闻，网络游戏，网络电影，网络音乐，等，不一而足。其直接结果就是所谓的虚拟，变成了现实。其中包含了众多的传播学研究问题（其中之一就是我在关注的网络信息流动的问题）。\n数据新闻学或称数据驱动的新闻学（data driven journalism），被认为是计算传播学的一个具体应用。通过挖掘和展示数据背后的pattern，和丰富的、具有互动性的可视化，数据新闻学成为新闻学的新的疆域和应用范例。 挑战与机遇\n任何新的科学研究的兴起，总是伴随着新的挑战。不仅包括理论的，还包括方法的。普世法则（general law）的欠缺，海量数据（massive data）的逼迫，网络抽样，可视化。如何应对这种挑战？直面还是绕过，还是置之不理。\n###一、取法于自然科学\n网络科学开启了一个崭新的研究纪元，而网络公开数据和开源（open source）的精神都深刻地变革着既有的研究传统。复杂网络作为一个研究领域和研究视角一开始就吸引了众多目光。人类动力学（Human dynamics）与之相对的是人类传播行为(human communication behavior)所对应的传播网络(communication network)。如何借助既有的自然科学理论和模型，尤其是复杂网络中发展出来的模型来研究人类传播行为, 成为现在所面临的主要问题。\n就网络模型而言，图论，网络形态（规则网络、随机网络、无标度网络）、网络增长，网络内部结构特征（rich club、assortativity，etc）等研究，深入的丰富了我们对于传播网络的认识。\n就其研究背后的方法论而言，主要存在四种方法，大致可以分为两类，一类是动力学方法，有平均场方法和率方程方法，物理学家常用；另一类方法是概率论方法，有主方程方法和马氏链方法，数学家较喜欢。\n其研究发现也从各个方面深入地变革着既有的社会网络分析，使之进一步科学化，完备化，成为一个真正的网络科学（network science）。\n二、取法于计算机科学 深入变革网络科学的两大动力，除了物理学，主要是计算机科学。众多的计算机科学家，如Huberman，Lada Adamic，Jon Kleinberg， Hawoong Jeong， Jure Leskovec等人。 计算机科学革新了文本挖掘的技术，topic modeling, 情感分析等开始被广泛地应用到媒介内容的研究中来。试看现在的计算机科学的top conference，如WWW、SIGKDD等会议都开始研究社会化媒体（social media）。\n三、取法于数学 数学是变革网络科学的基础。看到这里，多少会有人开始畏惧。援引爱因斯坦的两句话共勉： Before God we are all equally wise and equally foolish. Do not worry about your difficulties in Mathematics. I can assure you mine are still greater.——Albert Einstein\n四、取法新的计算工具 目前常见的统计软件主要对付中等规模的数据，真正的大数据，其解决的究极之道依然是基于分布式计算的数据库技术。通常我们不会面临真正的大数据，因而现在的研究，即使是最为紧密的，也依然可以使用小数据来说明问题。但随着研究的深入，直接面对大数据依然是不可避免的。\n结语 人类不应停止对永恒的普适法则的追寻，不仅在学术，而且在生活中，曾如康德所言： A person acts morally when he or she acts as if his or her conduct was establishing a universal law governing others in similar circumstances. 大道在前，直面应对！千里之行，始于足下。\n","date":1328745600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1328745600,"objectID":"b520798b3c7dd90cf7ab316bfdabfdd2","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2012-02-19-computational-communication/","publishdate":"2012-02-09T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2012-02-19-computational-communication/","section":"post","summary":"","tags":null,"title":"计算传播学：宣言与版图 ","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n作者: Noam Chomsky; 出版社: Seven Stories Press; ISBN: 9781888363494\n黠之大者\n乔姆斯基（Noam Chomsky）在1991年开始出版第一版的《媒介控制》（Media Control: The Spectacular Achievements of Propaganda ）一书，讨论宣传的历史、旁观者民主（spectator democracy）、公关、被策划的观点（engineering opinion）、替代现实的再现（representation as reality）、异议文化、游行的敌人、选择性认知。之后讨论海湾战争，和想象中的传媒业——来自火星的记者。全书围绕媒介的作用展开，总共才101页，十分短小。\n乔氏的讨论问题比之经典的传播研究迟滞了至少70年，但讨论的视角更为广阔。例如乔氏讨论民主之理解，于细节处见思想的宏伟。乔氏将民主的理解非为两类：一类是参与的权力；一类是信息控制的权力。并认为信息控制是一个更为主导但被忽略的方面。这种思路是很有见地的。乔氏对于政治的叙述更多批判意识。例如他一针见血地指出特权阶级（specialized class）的存在，他欣赏李普曼对于大众的悲观思想（大众是惊恐的羊群；特权阶级必须安抚羊群以保护自己免于羊群的践踏）。这些羊群式的普罗大众，就是观察者。当这些羊群式的大众成为政治的参与者的时候，特权阶层必须考虑如何同化这些大众——通过被制造的合意（the manufacture of consent），使得社会被整合，大众被分心，最终使得羊群式的大众成为政治参与的观察者（spectators of action）。而制造合意的方法莫过于宣传。乔氏说宣传之于民主，恰若棒子之于专政。\n对于公关的讨论开始引入媒体作用，比如使个体原子化。这是最初的传播学研究的“巨大效果论”时期的滥觞。而实际却可能远非如此，虽然城市化开始使得人和人关系疏离。但人总是生活在社会的细胞之中，生活在参考群体（reference group）之中。乔氏认为世界进入一个商业化驱动的社会（business-run society）。将个体组织起来的力量是不存在的（unions are virtually nonexistent）。其中的一个问题是媒体所有权的控制问题。商业开始通过公关操纵政治，以至于政党也只是商业利益的代言人，进而大众不愿意选举因为它看起来无意义（Most of the population doesn’t even bother voting because it looks meaningless）。\n有能力策划合意的人（the people who are able to engineer consent）是占有资源和权力的。民众被认为从未被很好的安抚，屡有反抗，但媒介致力于改变之成为病态的居民，使之无力也无心反抗。例如，乔氏举例在海湾战争中华盛顿邮报鼓吹好战的精神（martial value）。之于关于作为显示的再现的讨论，大多是在回溯柏拉图问题——洞穴中被束缚的囚徒如何认识世界。但这些多很难有一致性的结论，因为媒体这样写了，读者未必这么认为。尤其是在媒体公信力下降的社会。\n乔氏之天才在于其视野之广阔。乔姆斯基反观历史，指出美国以非法占领和伤害人权作为参战理由。很多人也如是解读，这是宣传系统制造合意的力量。然而这种逻辑并没有被完全地应用于美国的行为。例如，1969年南非非法占领纳米比亚之时，美国政府并未作出任何反应，反而是二十年的冷外交。而在这二十年里，一百五十万非洲人被杀。再比如对于萨达姆-侯赛因的反对在美国的报纸上从来都有，在海湾战争之前就有，但是直到海湾战争时，美国人才认识到这是一个问题。似乎存在一个门槛（threshold），美国人对一些媒体上的问题视若无睹，直到美国的宣传工具开始告诉他们这是一个严重的问题。羊群式的美国人似乎真的没有认识能力（也许乔氏真得是唯一的例外）。以色列自从1978年就吞并了叙利亚戈兰高地和东耶路撒冷时，萨达姆宣称无法容忍以色列的吞并行为。伊拉克参战，继而美国参战，海湾战争爆发。乔氏认为萨达姆和布什总统的口号是一致的。然而美国人却毫不认同相同的口号。\n本书的局限很多，一个主要的方面是信手拈来，诸多不严谨之处。全书流于论辩、讲演式的思想铺陈，逻辑过于天马行空，缺乏现实的支撑。反观之现实，顿时觉得乔氏更像一个来自火星的记者，并没有去了解现实的受众。看似弱不禁风的羊群（herd），多大程度上被媒体的所指引？整体而言，这本书并未获得学术界的认可，因为乔氏的研究根本是与传统的研究是脱节的。书中主要的叙述手法仍然趋于评论性质，缺少严格的证据（evidence）。值得注意的是，1991年正是传播学发展由“有限效果论”、“一般效果论”再次进入“强大效果论”的时刻。回到一战和二战时的经典传播学研究，拉斯韦尔等人主要讨论宣传的作用（见《世界大战中的宣传技巧》一书），认为媒介的作用是“巨大效果”。但经历了严格的实证研究的洗礼，发现媒介的影响在很大程度上是受到局限的。因此经历了著名的传播学存在还是消亡的争论。但是伴随着议程设置理论的发展，媒体的作用开始被重新认识。但此时已非毫无限制的。经典的文献总结为“媒体也许并不能有效地控制人们如何想，但可以决定人们想什么”。在此之后的传播学理论也开始另辟蹊径，在媒介如何影响人们的认知框架（priming）和思维角度（framing）的角度展开，而非简单的媒介效果在行为层面的作用。但乔氏似乎也在另外的角度开始接近事实的真相。\n","date":1321488000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1321488000,"objectID":"be013fea774ff3a5d4494c997e0761ef","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2011-11-17-media-control/","publishdate":"2011-11-17T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2011-11-17-media-control/","section":"post","summary":"","tags":null,"title":"媒介控制：呓语抑或现实？","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n王成军\n起初对科幻并无太多的兴趣，在深圳的时候李晓煦博士推荐的苏联科幻电影Solaris，用了三个小时，感受了“聚念成人”的快乐与痛苦：一个中年男人来到一个名为Solaris的陌生星球，调查发生在宇航员身上的各种离奇事件：他每天清晨发现自己少年时候爱过的女人坐在窗前，穿着那件记忆中的衣服。然而，一切都是虚幻的，她只不过是这个名为Solaris的星球根据你的想象生成的虚假的实体。假的依然是假的，甚至比不过记忆中模糊的形体。男人将她们通过小型发射器放逐到太空中。故事的结局令人唏嘘：把录音带投入到Solaris星球，搅乱了星球对于人类思维的识别，最终了结了这种种离奇事件。这个故事对我的吸引力在于，如果是你，你能强大到拒绝她们吗？我时时怀疑。因为记忆中的美好的身影早已将自己迷惑。或许，我会选择永远生活在那里。我喜欢这个能直面人性真实的星球，它抚慰时间箭头带给我们的损伤。四十年过去了，她还在，还是那样年轻，风姿绰约。这样的美丽你如何拒绝? 我觉得苏联电影的好处是特别的粗糙所指向的极度的真实，影片之初对于暴雨前的深林的拍摄令人无限忧郁。\n媒介技术学派是一个充满个性的群体，然而这也许并非一个准确的称谓 。或许更恰当的称谓仍是多伦多学派，以英尼斯，麦克卢汉等人为代表，其著作分析媒介与文明的关系，媒介技术对于文化和社会的影响。本文无意分析、辨明其思想脉络，只想在这个专刊里，从其源头走向、并走出其中一个集大成者：麦克卢汉。\n##呓语：技术与疆界\n麦克卢汉如同一个呓语者，他的文笔过于随意，远远非学派开创者英尼斯之历史视角和细致有力的分析。伴随着那个思想涌动的时代，这个伴随着邻邦实证主义发展起来的分析视角到了麦克卢汉这里，怵然开始转折：文笔之大胆生动，远远超出了想象。“地球村”早成现实，“媒介即信息”也被广泛印证，“媒介即按摩”也可以自圆其说，然而总是透着一种不够严谨的感觉。麦克卢汉对语言的随意应用，使他的思想因其看似荒诞而广泛流传。麦克卢汉像一个高高的奇形怪状的灯塔，立在传播学的海洋边上。若问一个其他学科中的人对于传播学大师们的认识，恐怕无人能出麦克卢汉之右。\n技术毫无疑问在不断深入地形塑着传播学，拓展着传播学的疆界，在mass media出现之初，人类传播行为只限于人际传播和群体传播。然而从印刷技术，造纸技术开始，书、报、杂志、广播，电视开始勾勒出传播学的疆界。在过去的二十多年里，这个疆界因互联网之产生，而变得无远弗至。\n然而，或许，这只是传播学疆界扩展的开始阶段。一个更为大胆的设想是：宇宙传播学。在我所接触到的不多的科幻小说里 ，这种想法已经开始变得不那么流于空想。\n##幻想：传播即死亡 在这里要聊的是刘慈欣的《三体》三部曲。我是先读第二部黑暗森林，然后读第三部 死神永生，最后读了第一部《地球往事》。三体三部曲汪洋恣肆，想象力异常丰富。一开始就被认为是开创了所谓“宇宙社会学”，因为大刘构造了“黑暗森林”的假说。这个假说所处理的是地球与外星球文明的关系，在《三体》三部曲中就是名为三体的这个星球。\n宇宙的文明发展并非均衡的，三体文明超越了地球文明，然而，三体人的人际传播方式完全不同于地球文明。三体人之间可以完全读出对方内心，不需要经过言语的交流和表达。这使得三体文明出现了一种更加简洁的社会构造。然而，单纯的三体文明内部发展的故事并不足为奇，故事的巧妙之处仍在于地球文明和三体文明的冲突。刘慈欣将宇宙间文明互动的规则总结为“黑暗森林”假说：宇宙如同一个黑暗而庞大的森林，文明分布稀疏（这符合一个称之为“费米悖论”的解释，费米说：如果存在外星文明，它们也该出现了。它们一直未出现。因此并不存在这个外星文明。） ，每一个文明都像一个在黑暗森林里跋涉的猎人，手执猎枪，当他发现一个外星文明的时候，因为无法判别对方的善意，因此最好的方法是消灭这个被发现的文明。这就是一个信息博弈的悖论。\n《三体①》的主旋律是失望和复仇，女主角的父亲在文革中被打死，她因缘巧合卷入一个军事计划，却通过太阳作为信息放大器向宇宙发射了关于地球的信息。三体人收到信息，制造出智子，人类陷入科学封锁的困境。《三体②》的主体是被分隔的爱情。为了对抗三体人的科学封锁和信息监控，地球联盟选择了五个面壁者。其中的逻辑是一个令人敬畏的思考者，作为一个面壁者，他有着自己对于情感的追求。 在一个幽静的欧洲密林深处，他守候着自己的爱人，过着最为普通的生活。读到这些美丽的文字，我都在想，何必要有责任，眼前的红袖添香、西窗剪烛不是人生最大的快乐吗？但是，逻辑依然是逻辑，为了肩负的面壁者的使命，以及妻子和孩子的安全，只好选择了和她们分开。《三体③》最为浪漫，一个男人在去世之前送给一个女人一个星球。之后这个男人的大脑被送往三体人。他的基因被复原，并在三体人的领地生活。潜伏其中的他跟女主角有了一次接触，传递了画中人以维度杀人的秘密。\n仔细辨明这些黑暗森林假说和其信息博弈的过程，我们会发现，悖论来源于宇宙文明之间的传播障碍。这种传播障碍在危机来临的时候，超越了文明内的传播障碍 。对此，在三体中所描述的危机纪元有充分的描述：一个恐怖组织的精神领袖，在地球面临外星球文明威胁的时候，变得土崩瓦解。曾经组织内部铁血的斗争意志，在全人类面临危机的时候被消解。而内部的传播机制决定了一切的游戏规则。比如，女主角叶文洁向宇宙发出了地球的信息，被三体人所截获，暴露了地球文明的位置，引来了三体文明的入侵。地球文明对于宇宙文明的广播行为，或者说对话行为招来杀身之祸。然而罗辑巧妙地利用向宇宙中广播三体星球的位置的做法，使得地球转危为安。全书中如果描绘了一种“宇宙传播学”的话，那么，在刘慈欣眼里，显然是“传播即死亡”。\n宇宙文明之间的传播行为是一个囚徒困境，走不出来。一旦经由广播等传播行为而暴露，就以为着文明的消亡。这是一种富有张力的图景。但透着文明间对话困境的思索。用禅语说，就是“不可说”。 ##宇宙传播学：宇宙传播技术的诞生 然而，当死亡的阴影笼罩整个宇宙之后，文明方可真正经由死亡走向永生：废弃理性主导的荒诞，由杀戮走向合作。三体三最后描述了维度之剑下宇宙文明损失殆尽，小的文明火种经由构造狭小的宇宙空间而得存留。然而这种存留的代价是抢夺宇宙的物质。痛定思痛的宇宙各文明最终放弃苟延残喘，将物质归还宇宙，期待宇宙文明的重新孕育和诞生。\n刘慈欣在书中略微调侃人类的传播媒介，在所有的传播媒介中，只有石刻最能经受岁月的摧残。而电子设备与之相比，其储存的期限远远不可比拟。\n很显然刘慈欣是一个传播学视角下的悲观主义者，然而，人类文明已经不止一次向其它宇宙文明“表达”自身的存在和存在的善意。很显然，如果费米悖论正确，那么人类是宇宙的孤家寡人，如果错误，人类在自取死亡。唯一可抱希望的是，是否有一种宇宙语言诞生，让宇宙文明可以对话 。对此，建造圣经中的巴别塔是有必要的。上帝为防止人类合作建造巴别塔，而使人类说不同语言，失去交流的可能，而终结了不同语言的种族间合作的可能。\n回到媒介技术学派的思路：是否可能有一种宇宙传播技术的诞生，使得宇宙文明之间可以在一个没有猜疑的语义空间里对话？\n","date":1311033600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1311033600,"objectID":"37a1ed5b8797e664927a4095d0288304","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2011-07-09-universal-communication/","publishdate":"2011-07-19T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2011-07-09-universal-communication/","section":"post","summary":"","tags":null,"title":"呓语与幻想：传播学疆界的扩张","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n——读《治史三书》\n黠之大者\n史学的视野对于媒介研究具有重要意义。互联网时代之历史观照更是非常重要。时代变革对于社会中智识分子的考验往往首先是观察视角的转变。\n二十世纪六十年代社会科学实证研究狂飙突进，拉杂斯菲尔德开创性的将panel study运用到媒介效果研究中来，时间的维度成为因果判定的重要依据。然而，即使如此，依然忽略了大的历史背景。拉氏的同事怀特-米尔斯反戈一击，历史社会学开始盛行。互联网时代同样提出了新的时代问题：如何运用和分析网络时代的海量数据。这当然是一个见仁见智的问题，远不是个人努力和方法洞见多能解决。在这种转折的时刻，思考史学对于媒介研究的启发不无助益。\n本文是作者上李金铨博士在香港城市大学所开的课程的所做之阅读笔记，李金铨老师极为推崇严耕望先生研究历史的视角和方法。严耕望（1916-1996）先生生逢乱世，而潜心治学，体现了一个史家的坚韧。《治史三书》上两篇谈治史经验，后一篇述人生际遇。两相匹对，可窥见其一生治学得失的深刻思考。抛书沉思，可悟社会科学知识的增长。\n史学是一门通观古今的学科，西学东渐，西方社会科学的套路逐渐与东方的治学传统相互交融。虽有方法之差异，然于追求历史知识的增长方面则有更多共同点。历史有着自身独特的优势与劣势，优势在于煌煌五千年，积累了大量的有价值的研究问题，且国人重历史记录，积累了大量的历史资料（朝代通史，县志乡约，个人札记），因而历史学有充足的研究数据。但是面对这些“历史现实”如何才能从纷繁复杂、真假难辨的史料中悟出其规律，洞见其真假，则是一个超越了平常人认识能力的问题。 互联网时代的对于网民行为的记录已经积累了超过20多年，瞬间所为，即可与过往相比对。虽然很短，但对于只重视截面数据的研究而言，已经是一个很大的机遇。\n史家之所为：读史，做札记，收集史料，然后以以线索连而贯之。其过程很类似康德所言之科学知识的增长：个人为自然立法。以先天综合观念统合历史资料，务求其融洽自如，殊非常人所为。因为社会科学面对的是一个复杂的过程，超越了简单的决定论的视野。康德之言颇有洞见，社会科学知识的增长首先是研究者自身修为的增长，自身修为不增长，妄图将人类之理智投射到社会规律上去，只能适得其反。媒介研究于理论构建方面往往广泛吸收，然而仍缺乏系统性。如何洞见传播现象之下隐藏的规律，莫非有充分的积累，实在是难以把握。\n严耕望先生讲专精通博的问题，很像中国武侠里之修习上乘内功的过程。需要付出长期而且艰苦的努力。初闻觉不适合于我辈之快节奏，三年博士教育，做的却是社会科学的训练，本是需要一个漫长艰辛的读书、做笔记、做调查的体悟过程，却被压缩成一个一个deadline之前的追赶。然而每个人都如此，何以见高下？短期之中，的确是难见高下的。一个人可以选择一个讨巧的题目和方法，精读几篇文章，少选几门课，也可以相对轻松，然而如果以十年之期衡量，比较一个读书做笔记、勤思考、每天写东西的人，和一个仓皇应对的人，再思严耕望先生之言方觉良药苦口，实在是看上去慢，其实很快的捷径。\n然而本书作为大家之言，其中有很多大胆的见解。例如耕望先生说集中精力做面的研究，不要做点的究。目标要大些，范围要大些，大问题里有许多小问题。这是很关键的，因为如果你的研究没有足够的研究意义（significance），纵然做的再精致，再深入，再举一反三，都很不值得。反面的例子是史学大家、旷世奇才的陈寅恪先生晚年所著述之《柳如是别传》。陈寅恪先生中年体弱，老年目盲，然而以毕生心血写就七十万言的《柳如是别传》，考究精密，令人赞叹。然而耕望先生评此书“虽极见才学”却“影响作用不会太大。”因而发出感悟“何不尚太史公转悲愤为力量，选取一个重大题目，一抒长才。”转思诸己，媒介研究本就显狭隘，若再略去政治和历史的场景，其研究的很难被评价为重大研究。圣经云上帝告诫人类说“你们要进窄门”。一个年轻学者用这句话反思自我做研究太追新潮，每次都不能将问题说透，反倒不如从一个小问题出发，然而却能跟许多有重大意义的问题对话。这不失为一种智慧的策略，媒介研究也要一小见大，把小的问题说透彻，跟大的理论对话。\n研究要无孔不入，有缝必弥。年轻人做论文，多容易宽容自己的缺点和错误。而无追求完美、严格要求的心性。于是一片文章做好投出去之后，就收到大量的意见，诸多地方需要修改。改完了仍无法发表，原来有一个小地方无法自圆其说，于是论文被拒。再去看大家的务求完美，严格要求，便多了很多理解。\n耕望先生说社会科学理论只是历史研究的辅助工具，不能以运用理论为主导方法。这个看起来也是极大胆的说法。社会科学本是追求建构理论的，单纯的运用理论的确不能成为主导方法，然而如果理论只是辅助工具，那么主要工具是什么呢？换言之，是相信既有理论，还是相信史实（数据）。原来耕望先生认为理论是演绎的路数，而历史研究更多要依赖归纳的方法去求得新结论。所以，有理论并不一定好，没有理论一定不好，且一定要发展新理论，找到新的概念。另外，耕望先生谈及这个问题的背景是针对单纯用决定论的唯物史观推论历史的问题。但不管怎么说这个对于年轻学者是很有启发的。理论是最重要的，但不是保守既有理论，而是说发展新的理论。当理论与数据不合时，理论是应当被质疑的，所以不应唯理论，而应重发展理论。尽信书不如无书，唯理论或许还不如接受纷乱的史实（数据）。同样的思路，耕望先生提醒我们研究历史不要从哲学入手，以免犯先入为主的错误。\n每一个研究者都是在从不同的视角下出发，进而丰富我们对于社会事实的认识。耕望先生总结了自己的两个兴趣政治制度和历史地理。这很像米尔斯所言之社会学的想象力，向社会学加入历史视角。同样做历史研究的也要增加新的视角。因而，可以想象这种对于新视角的掌控运用能力，是区分学科发展阶段的重要依据。Live and let live. 物理学和信息科学的视角同样有益于媒介分析和传播研究。引入统计物理的视角研究传播网络同样是有裨益的。在过去的五十年里，传播学广泛的引入了政治学、社会学、心理学、历史学、经济学多种理论视角，我们这些年轻人也将见证未来五十年传播学的发展。未来的传播学研究的主导视角是什么，这实在是一个猜不透的问题。\n其余各章述及诸多学者修养和个人经历的经验教训，一代学人的洞见饱含各种启发。我们这些年轻人看严耕望先生谈做研究的史识之培养（理论洞见），考据之修习（历史现实，数据），于我们这些数字时代的观察者而言，颇有助益。\n","date":1305417600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1305417600,"objectID":"50fe8013ba158ffdc939d42aa31a5505","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2011-05-15-historical-insights/","publishdate":"2011-05-15T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2011-05-15-historical-insights/","section":"post","summary":"","tags":null,"title":"通识与考据：论社会科学知识的如何增长 ","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n黠之大者\nFBI在千禧年逮捕了一个加拿大少年黑客，他用不起眼的电脑当“弹弓”，打败了信息时代的巨人“歌利亚”，使一些网站因不断收到“好的，我听见了”而瘫痪；基督教的成功归功于一个保守而虔诚的犹太人：保罗。保罗最初反对基督教，后来却变为一个虔诚的基督徒。因为他对神学的熟悉和对社会网络的控制能力，基督教开始广为传播。保罗和黑客少年成功的关键隐藏在网络的结构和运行的拓扑结构中，也隐藏在他们操作网络的能力上。魔鬼就隐藏在“结构”之中，然而关于网络社会的研究长久以来被既有的科学框架的简化论所束缚。图或网络具有自身的属性，这种属性隐藏在它们自身的结构中，可以限制或增强我们使用网络的能力。尤其是在我们尚无法把握各种复杂网络的结构之前，理解网络结构就成了认识周围复杂世界的关键。\n《链接：网络新科学》一书作者艾伯特-拉斯洛•巴拉巴西（Barabási）是美国圣母院大学教授，致力于对于复杂网络的研究：找到下一场科学革命——网络新科学的奥秘。巴拉巴西和阿尔伯特、郑浩雄一起在1998年开始了对网络的研究，一年后在《科学》上发表了关于无标度网络的论文，掀起网络科学研究的新浪潮。诚如两千年前希腊哲学家引导我们“认识你自己”一样，《链接》一书引导我们认识世界的网络结构。\n##随机宇宙\n人类对于网络的认识最初源于规则网。例如哥斯堡七桥问题，一个四个点七个边的图，图上带有奇数边的点，不是行程的起点，就是终点。如果一个图中有两个以上这样的点，就不存在一次遍历七桥的路线。在哥斯堡图上，有4个这样的点，因而无法找到所需的路线。\n用规则网作为复杂网络的理想型显然存在不足。人类智识群体由规则网滑到另一个极端：随机网络。Eros和Renyi认为自然界所能提供的最简单解答：随机连接节点。他们得出结论，创造网络最简单的办法是掷骰子。规则网络图的特别之处就在于每个节点都有恰好同样书里那个的链接。而在随机网络图中，根本不存在这样的规则性。随机网络模型的柱状图遵循Poisson distribution，其分布有一个显著的峰值，表明大多数节点的平均链接数都是一样的。在峰值的两边，分布迅速下降，与平均值相差较大的值极为少见。这就是广为所知的ER模型（Eros-Renyi模型，下文简称为“ER模型”）。\n然而，如爱因斯坦却倾向于相反的观点：对于宇宙，上帝不喜欢掷骰子。社会网络极其复杂，没有任何成员能够游离在外，其中的每个节点都能被访问到，因此，世界上不存在完全和外部世界隔绝的孤岛。\n##六度分隔的小世界 郑浩雄创建了一个简单的网络爬虫，让它下载文件，查找文件中的所有链接，然后按照这些链接访问并下载指向的文档。就这样自动进行下去，直到得到所有关联的页面。用它获得网络的完整地图。首先，该机器人访问圣母院大学网站域名下的所有300000份文档，绘制出地图。我们只是关心网页上的链接，它们告诉我们如何从一个页面跳转到另一个页面。结果发现随着链接的增加，节点间的距离会骤然变小。巨大的网络变小了，造成了我们周围一个又一个网络的小小世界。 大量的社会链接能够将无比巨大的网络也缩小成小小世界。例如Renyi比Eros小7岁，但是在布达佩斯的时候，他们的父母早就有交往，因而两人得以结识。\n中心节点和连接者所造成的群集现象是ER模型的随机世界观的第一个裂隙。瓦茨和斯托加茨发现了一个惊人的特点：即使只是添加少数几个链接，就能把所有节点之间的平均间隔大大降低，这少数几个节点却不会改变网络的群集系数。\n规模不是演员网络最重要的因素，虽然三级片明星饰演过的影片数量惊人，但是他们没能靠近好莱坞的中心。网络真正的中心留给了在多个大型集群里都有自己的位置的节点。对于演员网络，这种节点就是饰演过多种类型影片的演员；根据美国电话电报公司的一项研究，一小部分电话号码打出或接听了极大量的电话，这主要包括电话销售公司和客户服务电话等；生态学家认为，食物链的中心节点就是其中的关键物种，该物种对于保持生态系统的稳定居功至伟。\n对于社会，这种节点就是那种和各个领域的人都有交往的人。万维网的拓扑结构具有高度的不均衡现象。对于万维网，这种节点不但提供独特的链接，而且提供各种不同类型链接的网站。 中心节点的确很特殊，在任何存在中心节点的网络中，它们都对网络结构起到关键作用，使该网络呈现小世界的特点。联结者现象（具有大量链接节点的存在）是对ER模型和watts和stogazt模型的致命打击，我们必须完全抛弃随机世界观。\n以上都是网络新科学的关于小世界网络的研究，但这种研究在社会科学中很早就有涉及。20世纪60年代，耶鲁大学的社会心理学家米尔格兰姆(Stanley Milgram)就设计了一个实验。他将一套信件随机发送给居住在内布拉斯加州奥马哈的160个人，信中放了一个波士顿股票经纪人的名字，信中要求每个收信人将这套信寄给自己认为是比较接近那个股票经纪人的朋友。朋友收信后照此办理。最终，大部分信在经过五、六个步骤后都抵达了该股票经纪人。于是米尔格兰姆提出六度分隔理论。然而，类似其它传统的社会网络研究，六度分隔理论仍然缺乏“可计算性”，网络新科学的研究深化了这些关于网络结构的认识，使得洞见具有了可证伪性。\n##幂律分布中的标度 通常各种社会现象都符合或者可以转化为正态分布，进而使用大数定律和中心极限定理为基础的统计方法，采用最小二乘法或者最大似然估计方法进行分析，正态分布的特点是其数学分布较为均匀，以人的身高为例，绝大多数正常的成年人都在一个稳定的范围内，即使存在高度如姚明的“小巨人”或者身高有限的侏儒，但并不存在真正的身高超过3米的巨人和身高小于5厘米的“米粒姑娘”。在分析符合正态分布的社会现象的时候，我们往往可以采用平均数（或众数）来测度群体的基本情况，在一个固定的分布中，总有一种处于理想状态的“平均人”或“常人”存在着，他代表着该群体的平均状况。\n如幂律分布（以经济学中的帕累托定律和语言学中的zipf律为代表）所揭示的，存在着诸多的社会现象不符合正态分布的状况，而幂律分布往往很难转化为正态分布来处理。在符合幂律分布的社会现象中存在真正的巨人，他们所占有的资源远远超过其他人所占有的资源的总和，恰如帕累托定律所揭示的，也许20%的人占有了整个社会的80%的财富，同样，可能仅仅是20%的人为整个社会贡献了80%的财富。做了20年铁路工程师的帕累托如此钟爱物理学中的数学之美，为了使经济学变成物理学一样严谨的科学，写成《普通社会学纲要》。他发现20%的豆荚结了80%的豆子，20%的人占有了80%土地，（后来发展成为墨菲管理定律，20%的员工创造了80%的利润），这就是帕累托分布的起源。1932年，哈佛大学的语言学专家Zipf在研究英文单词出现的频率时，发现如果把单词出现的频率按由大到小的顺序排列，则每个单词出现的频率与它的名次的常数次幂存在简单的反比关系，这种关系就称为Zipf定律。\nBarabási在其1999年发表在《科学》杂志上的一篇著名的论文《随机网络中尺度的涌现》一文中指出如基因网络和互联网这样具有复杂拓扑结构的网络中节点之间的联系符合一种普遍的无尺度的幂率分布。他认为这是由于两个原因造成的，一方面，新的节点持续不断地加入；另一方面，新的节点偏好选择那些已经具有良好连通性的网络。这篇论文引起巨大轰动，此后从这一角度出发，学界将之应用自然科学以外的到各个领域，其中不乏运用复杂网络的方法分析人类传播行为的研究出现。\n幂律分布的最突出特点，不仅是其中有许多小事件，而且是许多小事件伴随着少数极大的事件。这种超乎寻常的大事件是不可能存在于钟形曲线内的。在这分布图的末端，幂律分布和钟形分布也存在重要的性质差异，钟形曲线末端呈指数递减，递减速度比幂律分布曲线大。出现这种呈指数级递减的末端，原因在于钟形曲线上缺乏中心节点。相比之下，幂律分布曲线递减速度较慢，允许罕见事件如中心节点的存在。\n在随机网络中，分布的峰值意味着大多数节点的链接数量都相当，偏离此数值的节点极其少见。因此，随机网络的节点连通性具有自身的尺度特征，这种特征由普通节点体现出来，并受等级分布峰值的限制；而在幂律分布中，缺乏峰值，这说明在真实网络中，不存在带有随便性的典型节点，我们看到的是连续的有等级特征的节点，从罕见的中心节点到无数小节点一级一级分布开来。最大的中心节点后面紧跟着两三个较小的中心节点，然后是十几个更小的节点，以此类推，直到最后无数小节点。\n在互联网中发现幂律的存在，不仅使我们吃惊，还迫使我们承认中心节点确实存在。缓慢降低的幂律分布很自然地能和高度链接的异常节点结合起来，它预言每个无尺度网络都会有几个大的中心节点确定网络的拓扑结构。该拓扑结构决定了真实网络的结构稳定性、动态行为、稳健性（robustness）、容错性以及承受攻击的能力。\n##阿基里斯的脚踵 1965年美国东北部大停电，凸显了人造复杂网络的一个问题：由连通性所导致的脆弱性。大停电事故是一个典型的级联故障；经济领域经常出现级联故障，如1997年亚洲金融危机；互联网也存在路由器破坏造成的级联故障，重新发送的信息进一步加剧网络拥挤。与之不同，尤卡坦陨星撞击灭绝了成千上万物种，其中就包括恐龙，但整个生态系统显示出人造系统所不具备的容错性。1911年禁止猎捕海獭，海獭物种迅速恢复，海胆减少，海藻增多，为海洋鱼类提供了食物，避免了加州海滩的退化，保护好一个处于中心节点的物种，就极大地改变了海岸的生态。\n这种容错性是通过高度互联的复杂网络保证的。 Shlomo Havlin等发现对于无尺度网络来说，如果次数幂小于等于3，这一阈值就不存在。而绝大多数无尺度网络，无论是互联网还是细胞，都是无尺度的，而且其次数幂都小于3。因此，这些网络只有当所有节点被移除后才会崩溃。但实际上，删除多个节点后，造成的破坏就开始明显显现出来，进一步删除更多中心节点，就目睹了网络的大崩溃，把互联网分割成了细小的互相隔绝的碎片。破坏少数几个中心节点，一个无尺度网络就能立即瘫痪。\n我们发现网络的崩溃不是渐进的过程，随机网络存在一个错误临界阈值，只随机删除几个节点对网络的整体性影响不大，直到超过这一阈值才会崩溃；但互联网络却拒绝崩溃，证明了互联网络和人类的其它系统不同，它具有高度的稳健性。偶尔删除一个中心节点也不会带来致命的危害，其它的按等级分布的中心节点依然维持着网络的整体性。\n无尺度网络结构中隐藏着人们未曾料到的阿基里斯的脚踵。邓肯-瓦茨证明删除的节点的连通性越高，就越有可能使整个系统瘫痪。其面对故障的稳健性和面临针对中心节点的攻击的脆弱性是共存的。针对中心节点的攻击可以使网络迅速崩溃。如细胞的蛋白质网络，在发生随机突变的情况下不会崩溃，但某种药物或疾病关闭了编码生成连通性最强的蛋白质的基因，细胞就无法生存了；针对中心节点进行攻击的菲律宾爱虫电脑病毒（Love bug）可以在几小时之内传遍全世界，造成全球互联网崩溃。　判断性网络是无尺度的，还是随机的，我们无需完整的性网络地图，我们只需检测这个网络的等级分布。Liljeros证明了性网络的无尺度特征，艾滋病病毒的传播网络的无尺度拓扑特征使这一病毒会不断传播，难以消亡。被治疗的中心节点越多，该传染病的阈值越高，这一病毒消亡的可能性越高。即便是我们无法找到所有的中心节点，但只要朝偏向高连通度的节点的这个方向去做，就能降低疾病传播的速率。\n《圣经》中描述了大卫与巨人歌利亚之间的战斗，大卫，取出弹弓，借助上帝的帮助轻而易举地将巨人歌利亚杀死。歌利亚的死去使得敌军土崩瓦解，大卫一战成名。庞大的互联网中心节点也如同歌利亚一般，异常强大，它们带领着一个无标度的网路大军，所到之处，无往不胜。面对如洪水猛兽般的网络大军，黑客们只需要寻找中心节点，取其上将首级。当这些少数的巨人歌利亚倒下之后，网络大军就走到了崩溃的边缘。\n##网络地图 米尔格兰姆的实验对象根本就不知道联系到目标对象的最短路径。即使手头有指南针，而且知道出口大体上是在北方，想找出出口也会耗费大量的事件，而且我们的行动效率也会很低，相反，如果手头有迷宫地图，不出5分钟，我们就能走出来；大多数疾病，并不是由特定的某一个疾病基因引起的，多基因通过隐藏在细胞中的复杂网络相互作用。后基因组计划即绘制细胞内部的网络地图，有了生命之书，我们现在需要的是生命地图。\n社会网络、蛋白质网络等大多数网络是无向的，万维网和食物链是有方向的。有向性使万维网成为一个非均匀网络。\n万维网被分隔成3个主要的大陆:IN大陆、中央大陆、OUT大陆、从IN大陆到OUT大陆的管道、IN大陆和OUT大陆上的触须、孤岛。互联网呈现碎片状的特征，孤岛和IN大陆部分处于隔离状态，无论网络机器人多么努力也找不到那上面的文档。无论网络是随机的还是无尺度的，只要链接是有向的，就会存在3个大陆，3个大陆并不是仅有的分隔，仔细观察还会发现大陆会进一步分为很小的村庄和大城市。\n现在我们开始把细胞看作似乎一个整体，即作为一个网络，而不是一袋子独立的化学物质。例如，过去认为控制癌症的p53基因远没有想象的那么大力量，摆脱对p53细胞周期调控因子的迷信，而关注p53网络，这使我们看到另一条道路：首先需要破译网络地图的拓扑结构，找到修复p53细胞周期调控因子功能的药物。\n##互联网的觉醒：自组织和适应性 我们先遮盖细节，只观察节点和链接；完成这一步之后，我们必须跨越拓扑结构，关注链接上的动能，弄清楚节点和节点之间的动力学机制。\n幂律的存在，将复杂网络从ER模型的随机性的丛林里拯救出来，将其放在色彩斑斓的，充满了丰富理论营养的自组织的舞台的中心。1965年，Leo Kadanoff突然意识到：在临界点附近，我们就不能再把原子当成独立的粒子看待，而应该把它们看作是属于一个个社区，共同行动的群体。可以把原子看作是装在一个个盒子里，每个盒子里的原子都有同样的行为方式。Kenneth Wilson的重正化理论证明了每当无序变成有序的临界点，即由混沌到有序的临界点的时候都会发现幂律的存在，他给相变理论的金字塔添上了顶端的最后一块石头，并于1982年获得诺贝尔物理学奖。一旦系统被迫发生相变，一切随之改变，继而出现幂律。相变理论表明了从混沌到有序的过程受到自组织的影响。爱因斯坦对印度不知名的物理学者玻色论文，并在其基础上写成论文《单原子气体量子论》。爱因斯坦预测，如果全部的粒子足够冷却，粒子中的一大部分会安顿在最低的能量点上，他们会形成新的形态，称作“玻色-爱因斯坦凝聚”。直到1995年才被证明，“玻色-爱因斯坦凝聚”成了物理学家的标准工具箱。\n我们遇到一个问题，幂律的存在是否意味着网络是从无序到有序的相变的产物？答案是网络并不处于由随机到有序的道路上，它们也不处于随机性和混沌的边缘，无尺度拓扑结构表明网络的形成源于自组织原则的作用，不管网络多大、多复杂，只要存在优先原则和增长因素，它就会保持中心节点和无尺度拓扑结构。\n在某些网络中胜者通吃，会获得所有链接，因而带有明显的“玻色-爱因斯坦凝聚”特征。但胜者通吃网络并不是无尺度的，这种网络只有一个中心节点和多个微型节点。而无尺度网络中，节点带有明显的等级分布。胜者通吃行为会破坏无尺度拓扑结构中中心节点的等级分布，使其变成星状网络，如微软公司。节点永远为了为获得联系而竞争，因为在相互联系的世界中，连接数量就代表了生存能力。公司争夺客户、演员争夺角色、普通人找你过多的社会链接。 与胜者通吃的星状网络相比，无尺度网络是一个适应性网络。\n自组织网络具有的适应性和对内部故障的容忍度是其天然优势，基地组织是一个没有蜘蛛的网络，没有变成中央集权的网络，没有军队和企业所采用的属性结构，它发展成为一个自组织的网络，网络中的等级化的中心节点使组织联系在一起。因此，即使去除了拉登和他最亲近的亲信，也可能无法根除它带来的威胁。我们最大的敌人，可能是对这种新秩序不熟悉，而且缺乏有效的语言来表述我们的经历。针对基地组织的战斗，其手段可能是尽可能多的去除网络中的中心节点；然而是基地组织崩溃并不能终结这场战争，只有充分消除其自组织的法则——伊斯兰好战分子的愤怒——才能根除恐怖分子节点建立链接的需求和渴望。\n你知道字母a存储在大脑的哪个位置吗？自组织结构也不知道答案从哪里来的。 我们无法预言网络何时会具有自我意识，但显然它已经有了自己的生命，它在不断成长，不断演化。《黑客帝国》描绘了全球互联网具有智能后的图景，也许这并不仅仅是想象。或许有一天，互联网会觉醒。\n","date":1299715200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1299715200,"objectID":"63190b85e61ce9ac203f0e8c0c124bab","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2011-03-10-network-giant/","publishdate":"2011-03-10T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2011-03-10-network-giant/","section":"post","summary":"","tags":null,"title":"遭遇巨人歌利亚——读《链接：网络新科学》","type":"post"},{"authors":null,"categories":null,"content":"本文载于《数字媒体阅读报告》\n本文是作者从技术和资本角度对于SNS浪潮的反思。其中部分内容取自作者硕士毕业论文，虽然名为《正在爆发的互联网革命》一书的读书笔记，但并不限于此。\n黠之大者\n“部落化——非部落化——重新部落化的三段论,是麦克卢汉的一个天才般的预言。人们曾经在部落化时代，面对面地进行口耳交流，而网络科技的发展虽然使在人们之间架起了信息的高速公路，却也把人类锁进了各自的“盒子”。地球变成了“地球村”，但村里的人却很少出门抛头露面，甚至不知道隔壁住的是男是女或者只是一条狗,亲近的信息距离与遥远的心理距离使网络社会进入令人尴尬的状态。社会性网络服务（SNS）的出现使人类在重新部落化的过程中，找回了村里的亲近感,回到了个人对个人真实交往的形态，这也显示出了人们对于回归真实人际交流的内在需求与渴望。（陈卉，2009）”\n这是一个对于互联网时代的网络社会交往的形象而生动的描述，表现了SNS在网络社会交往中的独特意义：相比于个人在社区生活“鸡犬相闻、老死不相往来”式的落寞，行动者个体在SNS上则表现出了超常的热情，加好友、写日志、发照片、更新状态、种菜偷菜，忙得不亦乐乎，很多人的SNS门户终日熙熙攘攘，一派繁忙景象，似乎真得通过网络实现了部落化，回归到奉行“差序格局”的传统村落。\nSNS 全称Social Networking Site，即社交网站，是基于六度空间理论下的典型媒介形态。随着互联网技术的进一步成熟，社交网站（SNS）迅速发展，继Facebook之后，其它SNS网站迅猛发展，2008年SNS的另一典型代表微博客twitter迅猛扩张。在中国以校内网和开心网为代表的SNS网站同样发展迅速，以校内网（www.xiaonei.com）为例，其实名制注册用户数1500多万，活跃用户高达880多万。\n技术与形式：SNS的流变 SNS的发展从1997年开始，SIX DEGREE网站创立，依靠站内信促成好友关系的形成，但由于其概念过于超前，未能获得广发扩散，于2000年被迫出售。随后出现一系列SNS网站，但未能掀起全球范围内的SNS“浪潮”，直到2003年3月Friendster.com诞生。Friendster.com获得极大成功，依然延续六度分割理论，使用率低，用户黏性弱，2004年因为访问量过大，服务器过载，导致用户流失。\nMyspace2003年7月在美国创立，是一个开放的交友网站，在2004年到2006年之间经历了高速增长期，允许用户以独特的页面和音乐展示自我，结交朋友和吸引异性，是一个基于兴趣为中心建立的SNS网站，但因陌生人的交友模式缺乏黏性，当用户的好奇心过去之后，就失去了吸引力。2008年6月，被Facebook所超越。\nFacebook创建于2004年2月，创建者为哈佛大学心理系的学生马克-扎克伯格（Mark Zuckberg），类似比尔-盖茨，他同样19岁辍学，开始创业，该网站的成功被认为是因为定位得当，致力于为主流用户群体为现实社会生活提供辅助的网络服务，而不是创建一个完全不存在的新社区，因而其网站经营策略更加务实，与Youtube等视频分享网站和Twitter等微博客的发展同步，SNS的发展进入到另外一个高潮。\nSNS发展过程可概括为：“早期概念化——SixDegrees代表的初探六度分隔理论阶段；结交陌生人——Friendster帮用户建立弱关系从而带来社会化实践价值的阶段；娱乐社交化——MySpace创造的丰富多媒体个性化空间吸引年轻人注意力的阶段；真实社交化——Facebook帮助用户将线下真实人际网络搬到线上，实现现实世界之外的社交阶段。”\n国外SNS的发展路径如下图所示：\n图 1 国外主要SNS网站的创建时间及社区网站转型为SNS网站的时间\n中国第一批SNS网站创业者模仿Friendster.com创立了UUme.com和亿友网等网站，但类似其模仿对象，最终未能幸存。在Myspace的发展迅猛的鼓舞之下，我国诞生了51.com、UU地带、魔时网、猫扑网等SNS网站，QQ也于200年推出QQ空间；此后，中国SNS网站再次复制Facebook的成功经验，校内网、5Q校园网、占座网、易聚网等众多SNS网站先后创立，其中，校内网的发展拔得头筹，但其创立者王兴最终因为资本瓶颈被迫将其出售给千橡互动集团，后者整合猫扑网、Kaixin.com、校内网，组建了现在的“人人网”。\n继校内网之后，另外一个以真实社会生活为SNS运作基础的网站Kaixin001.com成功攫取企业内部的社会网络关系这一细分市场，获得极大成功。模仿Youtube和Twitter，国内先后出现大批视频网站和微博客，类似国外SNS市场发展之势，中国SNS的发展风起云涌。\n我国校园SNS网站是指以我国校园大学生为主要目标用户群的交友网。国内最大的校园SNS网站是成立于2005年的校内网（www.xiaonei.com），2008年其实名制注册用户数1500 多万，几乎囊括中国所有的学校，成为一个极其活跃的大学生在线社会交往的网络社区。\nSNS的内部关系 但SNS的发展并不仅仅使得重新部落化的网络社会找回了真实交往的亲切感，它还将使用者之间的关系转化为资本——社会资本——这是SNS发展的一个真正更为宏大而深远的意义。\nSNS的整体发展路径，从形式上看，经历了从概念到现实的蜕变过程，这与中国互联网整体的发展趋势是相同的，从最初的通过Email和bbs互动，互联网的网络社交经历了不同 的网络服务形式，如下图所示：\n图 2 网络社交人脉演进简史\n在这种发展过程中，关系的强度对于SNS的发展存在着重要的作用，从最初SNS追逐概念开始，经历互联网市场严酷的大浪淘沙，生存下来的SNS网站所整个的关系强度大多较强，例如51.com是一个恋爱交友类网站，其关系相对较弱，校内网只所以能发展起来，其原因正是因为整合了现实的校园同学关系，其关系相对较强，Kaixin001.com致力于发展基于公司内部同事关系的社会网络，天际网则更有针对性地为白领等职业人士设计，以满足他们商业和职业方面的需要，帮助他们更有效地建立、管理、拓展人际关系网，后二者内部的社会关系更为密切。如下图所示：\n图 3 国内SNS用户群体分布\n在这里，值得注意的是豆瓣网，倘若从SNS的发展过程来看，豆瓣的幸存不啻是一个奇迹。豆瓣是一个以读书、电影、音乐兴趣为中心建立的SNS网站，在某种程度上与Myspace类似，但通过书评和音乐、电影评论，使其内部在陌生人之间建立起牢固的关系，豆瓣群组的关系更是促进使用者基于兴趣的交流，更为重要的是豆瓣将虚拟的网络关系引入现实，豆瓣上存在着大量以城市为中心的各种线下活动，这种以兴趣为基点，从线上关系到线下关系的过渡方式，使得豆瓣获得了长足的发展。\n社会性网络服务异军突起的原因在于社会性服务网络在人际传播方面的特殊优势。进一步摆脱虚拟束缚，沟通了线上与线下关系，通过线上线下的双重接触，更好的实现人际传播的最终目的。社会性网络服务不仅帮助用户权衡网络个人空间与公共领域，找到合适的传播的边界，还有助于他们拓展人际关系，分享个人信息，实现社会穿透。\n黑天鹅：重生抑或死亡？ SNS诞生之初，没人知道它会活下来，如同就在人类文明中的个体无法想象黑天鹅的存在。困于概念与技术黑洞中的个体将失去洞察社会趋势的能力。为潮流鼓噪呐喊者必为时代所遗忘，因为当你完全卷入时，也就失去了批判的能力。\nSNS并不是一个维系强关系最为经济和有效的手段，对于大学生群体的强关系而言，主要是跟自己关系紧密的身边的同学，多为同宿舍同学，舍弃直接的人际沟通而采用SNS并非最佳选择，校内网更为重要的作用在于维系弱关系。\nSNS本身是一个受到监视的私人空间和公共空间的融合，虽然可以通过写悄悄话、校内即时聊天、站内信的方式沟通，但是这种间接的沟通并不能满足维持强关系所需要的面对面的沟通，而维持紧密关系所使用的语言往往会因为预期到的他人的监视而有所增减，正如，校内个人主页上面可以设置特别好友，但是一旦你设置的特别好友之后，就意味着你明确告诉身边其他未能被你选为特别好友的同学你们之间的关系仅仅是弱关系，这有些类似《老友记》里Chandler与Joey争夺作为Ross的伴郎。校内网作为一个使得网络社会交往关系可视化的空间，赋予了其被监视的特点，这是有别于现实的交往空间的。\n图 4 校内网使用频率与满意度之间的对应关系\n校内网服务的使用频率来看，基本上都处于较低的水平上，如图校内网服务的使用频率所示，校内网服务的使用频率得分大多低于中等水平3分。浏览他人相册和评论他人相册功能的使用频率更高；此外是回复日志和留言功能、状态和分享功能。值得注意的这两项服务的功能都在于“监测环境”——即了解好友的动态、并对好友的动态做出简短的反应，这与使用校内网的最主要的目的在于了解朋友动态、与朋友联系是完全契合的。\n与此相比，校内网在表达自我、展现自我层面上则仍处于一个相对较弱的位置，虽然用户对于上传照片功能和写日志功能相对满意，但对于上传照片功能和写日志功能的使用则较少，对此的解释当然与中国特定的文化有关系，中庸的处世之道依然影响着中国大学生的交往行为，尤其是在SNS中的“印象管理”环节。印象管理不仅仅在中国是十分重要的影响因素，Anne Hewitt等发现三分之一的使用facebook的学生反对教师使用facebook，其主要的原因是个人隐私与印象管理。\n当然，对于用户对于上传照片功能和写日志功能使用较少的原因同样与用户的自我表达和自我展现的能力密切相关，毕竟有些人不善于叙述生活中的事情，不善于表达自我的情感。对此的一个佐证是几乎所有的用户对于“校内状态”功能的满意度和使用频率都相对较高。另外一个显著的调查发现时单身者更加倾向于使用校园类型SNS，这当然是校园类型SNS的生存之道，但也开启了其覆灭之门。\n商业逻辑同样会限制网络游戏类别的SNS的发展，上班族的偷菜行为虽然可以密切同事关系，增强组织效率，但同样面临因为投入时间过多，粘性过大，而损伤资本的商业利润。流畅的网络服务和角色扮演、深度介入的SNS游戏最终会被资本挤出工作的场所。\nSNS 因为使用者开辟一个新的自我展现和个体间互动的平台而崛起，但也最终为其膨胀设下一个最重要的障碍：当所有的人都只看不写的时候，传统的SNS就成了一片死地。\n技术乐观主义无法解救资本的陷阱中的黑天鹅。SNS躁动之时，没人知道它未来是否能活下来。流变，重生，抑或死亡。唯一可以确认的是未来的SNS绝非今日之SNS。\n参考文献 陈卉. 社会性网络服务（SNS）流行原因分析[J].新闻世界.2009.05:114-115.\n郑宇钧，林琳.当校园SNS 照进现实———校内网的人际传播模式探讨[J].广东技术师范学院学报，2008（3）.\n西门柳上，马国良，刘清华.正在爆发的互联网革命[M].北京：机械工业出版社.2009:96\nDanah, M. Boyd and Nicole, B. Ellison. 2007. Social Network Sites: Definition, History, and Scholarship Journal of Computer-Mediated Communication, 13(1), article 11, 2007\n李翔昊.SNS浪潮：拥抱社会化网络的新变革[M].北京：人民邮电出版社.2010:77\n","date":1299024000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1299024000,"objectID":"e40b3c17dc942cb9fd8f547f74dbf4eb","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2011-03-02-sns-as-a-bridge/","publishdate":"2011-03-02T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2011-03-02-sns-as-a-bridge/","section":"post","summary":"","tags":null,"title":"从概念到真实：SNS的形式蜕变","type":"post"},{"authors":null,"categories":null,"content":"民国时期的土匪（Bandits in Republican China，1988）英国学者贝思飞（Phil Billingsley）历时十年的作品，令人忍俊不禁、倍感亲切的是他边照顾孩子边写作的场景，这在大仲马是根本不可能的，想来贝思飞是一个模范好男人，他试图展现土匪群体的出现与壮大对现实的合理的反应，本书是根据其博士论文为雏形完成的，可见，学术大多是积累起来的。\n毛泽东将土匪归于游民阶层，指出其类似民族资产阶级的两面性和容易动摇的特点，贝思飞则将土匪分为偶尔为匪和惯匪，并将土匪群体分为三种基本类型：单纯的匪帮、综合的匪帮、匪军。\n全书就是以土匪为核心展开的，刻画了匪与农民、军阀、地方政府、兵、绅士、外国人、革命力量之间的立体的关系。从盗足石到童林响马，占山为王的匪在中国历史上并不少见，贝思飞区分了匪帮与秘密社团，指出前者的散漫无常与后者的长期维持的不同之处。\n从白朗到老洋人，樊钟秀，到临城劫车案的孙美瑶，匪在历史上留下了并不华丽却很抢眼的印迹。但究其为匪的原因，贫穷和饥饿是最主要的原因。平原多洪水多饥荒，遂多响马；边界地带三不管，遂多盘踞为匪者。有趣的是，匪的出现和农耕的周期密切相关，农民在春天吃完余粮，高粱高长时出现，到了5月收割小麦的时候消失。\n贝思飞讲到军阀统治时说，军阀统治有一种自身无法延续的悲剧，来自上层的暴力煽动下层的暴力，军阀征丁、牲畜，影响农业生产，入伍之后没有生计之道，遂为匪。形成一个恶性循环。张作霖在吉林大量流失枪支；冯玉祥在甘肃种鸦片引起叛乱；阎锡山在山西，红抢会涌现。河南、山东、江苏、安徽四省交界处形成了土匪中心。军阀割据下的土匪王国形成了一种地缘暴力政治。\n第三章讲了河南的土匪，主要讲了白朗及其后继者老洋人的故事。第一次听说白朗这个名字是在贾平凹的商州夜话一书中，没有想到白朗如此真切的存在过。在大刘庄，在车队，为匪，壮大，迁徙，叛变。一个最成功而传奇的土匪走不出匪之为匪的生命周期。\n衣食足而知荣辱，活不下去才会逼上梁山，去过颠沛流离的生活。匪帮的组成有着内部严密的规则，遵循着残酷的民主。土匪的生活是很凄惨的，他们注重内部的等级制度，为了突出这种等级，他们往往注重服饰，形成差别，这种差别往往到可笑的地步，除了服饰之外，土匪对于女性的态度也值得思索，很多土匪是为了娶老婆才加入土匪的。因为土匪的亡命生涯和土匪的道德劣势，他们对各种言语存在着禁忌，占卜、祈祷在土匪中是很常见的。视金钱如粪土的背后是土匪的生死无常和极度贫穷。\n土匪是一种艰苦而又危险的职业。地方统治是依靠乡绅的，也就是乡土绅士，传统 的乡土中国一直存在着权力不下县的说法：在这些土匪活动的基层地区，绅士、土匪、农民就构成了一个生态系统。地方官作为一个外来人，所关系的是金钱和仕途升迁，此外，他所掌握的少数武装力量使他缺乏对抗土匪的力量。地方官吏普遍的‘始而讳盗，继而纵盗，相习成风。\n兵与匪是相互依存的关系，没有了匪，兵的灰色收入就减少了；兵并不去全力剿匪，往往与匪还存在着默契甚至交易，比如出售枪支。匪与乡绅和农民也保持着辩证的关系，匪存在的主要经济来源来自于乡绅，通过打劫乡绅，匪获得自己的生命线，但当富人消失之后，匪往往退而求其次，压榨中等富裕甚至穷苦的人。\n对于绑票的介绍是十分有意思的，匪自身经常处于行走过程中，因此他们更倾向于绑票而不是抢劫其他不易携带之物，并且经常杀死因生病等不能跟上队伍者。已婚妇女一方面因裹脚，不便行走，并非理想的绑票对象，因为严格的道德对于已婚妇女有着严格的限制；未婚妇女则往往成为绑票对象。肉票还像期货一样在市场上流转，其他匪帮可以购买另一匪帮的肉票，以期勒索更高的价格。匪在绑票方面往往不择手段，儿童也会成为重要的绑票对象。后来，外国人也成为重点绑票的对象，例如孙美瑶在山东临城的劫车案中绑架外国人跟政府谈判，名利双收。除了绑架之外，敲诈也是匪的常用伎俩。\n事实证明匪对乡土有着强烈的依附。兔子不吃窝边草，离开的当地农民的帮助，匪往往会在中央剿匪的围攻下瓦解。例如，白朗杀富济贫使自己的匪在当地受到爱戴，农民往往积极参加其队伍，并为其免费侦查，但是当白朗开始扩大地盘，四处出击之后，往往面临着被当地农民所排斥的困境，尤其是其在甘肃遭遇了回民的排斥。土匪内部也存在着类似老乡的观念，例如白朗真正信任的人只是大刘乡的同乡。这种对乡土的依附和对迁移的不适应成为白朗起义失败的重要原因。此外，土匪的报复性行为往往使农民对匪产生强烈的恐惧和不信任，与传说中的大侠或者说罗宾汉相差甚远。\n随着袁世凯之后的军阀混战，土匪作为军事力量开始成为制度化的军事力量。但是值得注意的是这些土匪的战斗力往往很差，例如冯玉祥的第二、三师面对吴佩孚和张作霖的军队落荒而败，张宗昌的军队面对北伐军毫无抵抗之力。朱德和张作霖都注意到这个问题，后者清理了自己军队中的土匪成分。\n土匪只有利益，没有立场，镇嵩军从推翻清王朝的革命转变为出兵陕西围困冯玉祥，孙美瑶在临城劫车案被招安，去镇压其他匪帮，后被害。\n匪酋中的成功者莫过于张作霖、陆荣廷、杨虎城等人了，但大多数土匪头目都在社会的下层挣扎，往往在斗争中落败身亡，即使是聪敏如樊钟秀者在依靠本土的力量发展起来之后始终无法发展壮大，左右摇摆，最终还是失败了。\n兵匪不同于土匪，他们往往来自于解散的军队，具有更强的战斗力，对当地没有土匪那样的感性，往往会更为残酷的对待农民。如老洋人，快速行动，极度破坏，绑架洋人。\n日本为了占领东北，对土匪进行了有效的利用，如扶植张作霖、策划临城劫车案，利用日本浪人小日向白朗（当时成为满洲主要的土匪领袖）化解绑架外国人的事件，使土匪从南满迁到北京，清讨土匪。\n土匪生逢其时，遭遇了辛亥革命、二次革命、大革命、抗日战争、内战，在这个过程中作为地方势力的土匪往往革命的各个力量的游说的对象，很多土匪参与到革命的过程中来，虽然他们都有自己的考虑。白朗在二次革命中支持孙中山，成为袁世凯的眼中钉。游击战的方法和土匪的策略一脉相承，土匪经过军事化改造成为军队的重要来源。在49年之后，大陆仍有大量的土匪存在，经历了几年才完全镇压。\n像大门口的陌生人、中华帝国晚期的叛乱及其敌人、乡土中国一样，土匪一书也提供了我们看待近代史的一种视角，从这个视角里，我们能看到某种一直被我们所忽略的近代史生态链中不可或缺的一部分，他们当然不是这个社会和历史进步抑或退步的决定性力量，在某种程度上，他们一直在转变自己去适应历史的变化，但大多是失败的，然而，他们的确参与了历史过程。 ","date":1294444800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1294444800,"objectID":"da08aadb79d05da0464ba40460429a46","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2011-01-08-bandit-in-the-chinese-of-republic/","publishdate":"2011-01-08T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2011-01-08-bandit-in-the-chinese-of-republic/","section":"post","summary":"","tags":null,"title":"民国时期的土匪","type":"post"},{"authors":null,"categories":null,"content":"我不再像先前那样崇拜他了，但我自觉在深层的心理和情感距离上，似乎是离他越来越近；我也不再将他视作一个偶像，他分明就在我们中间，和我们一样在深重的危机中苦苦挣扎。 ——王晓明 自己在网上碰到这本书，就下了下来，但自己对于鲁迅的记忆却局限于高中教科书《社戏》、《从百草园到三味书屋》里面，恰若我们对于马克思同样很无知一样，我们距离这些曾经吸引民族目光的人物似乎很近，但又的确很远。但人生的某个阶段总会有难解的问题，这个时候就只好去走进这些被我们所远离的灵魂。\n鲁迅本姓周，名樟寿，后改为树人：号豫山，后改为豫才。鲁迅是他的笔名，一八八一年九月二十五日出生在绍兴城内周姓望族，祖父周介孚，出身翰林，让鲁迅在启蒙的时候先读历史，而不是四书五经；父亲周伯宜，对鲁迅非常宽厚，允许他读闲书；母亲鲁瑞更是喜欢他。少年鲁迅便生活在这种颇为繁华而宽厚的环境中读书长大，调皮好斗，有着少年所特有的骄傲。但祖父却因为一次科场行贿案下狱，父亲也吐血并终于去世，亲戚便不再对鲁迅家客气，分房子的时候给鲁迅家最差的房子。这种世态炎凉、由繁华转为凄苦的经历很容易让人想到曹雪芹，另一个在中国的晚期封建社会反儒家的困顿的斗士。后来在广州，青年学生问他为什么憎恶旧社会，他回答：“我小的时候，因为家境好，人们看我像王子一样，但是，一旦我家庭发生变故后，人们就把我看成叫花子都不如了，我感到这不是一个人住的社会，从那时起，我就恨这个社会。”今天再思考这个，我们究竟走出去多远呢？市场经济之后，实用主义潮起，我们仿佛又能看到那些忧伤的娜拉了。\n若以事件史的眼光看个体的人，就要重视他在十八岁的选择，这一年鲁迅乡试成绩为中上等，却因为一个弟弟的夭亡而放弃复试，家境的中落、人情的冷落也使他不能去经商或者像很多绍兴人一样选择去做师爷、幕僚。*如今日高考无望的情况相识，鲁迅只能选择去读江南水师学堂，差不多是免费。*王晓明写到：“可也惟其如此，学生多不愿以本名注册，而要改换姓名，鲁迅那个‘周树人’的名字，就是这样起的。”但不满意学堂教员的无知只好转到路矿学院，1902年，因为没有钱只好争取公费去那个极度自卑并极度自大的在7年前打败中国的地方留学去了，在日本呆了七年，因为日本人的傲慢、侮辱和留日学生的不成器的丑态而痛苦，终于无法忍受，放弃学医转而从文，要医治这个民族的精神状况。但如王晓明所言，“一九0六年初夏，鲁迅返回东京，这时候他已经二十六岁了。用去了八年的青春，从中国到日本，又从仙台回东京，四处寻求生路，却总是走不通，兜了一个大圈子，还是回到老地方：没有钱，也没有文凭，两手空空，一无所有。”在这一点上，马克思比鲁迅幸运多了，至少他在大学阶段找到了自己受用终生的道路——哲学。\n我们已经知道了鲁迅从少年时代就开始大量阅读各种杂书，他应该感谢自己的这种习惯，王晓明描绘了鲁迅的读书状况：林纾翻译的小说一本不落；梁启超主笔的《时务报》几乎是每期必读；他更用心读理论书，严复翻译的《天演论》和《法意》，他是读了又读，还郑重其事地向别人推荐，还曾给周作人推荐约翰•穆勒的《逻辑体系》。以今日状况来看，有多少人真正读过《进化论》和《论法的精神》呢？更不用说小穆勒的书了。尤其是达尔文的理论使鲁迅走出了历史悲观主义关于“今不胜昔”和“一乱一治”的历史循环主义，对于鲁迅来说这不啻是精神革命，正如马克思读了在大学里成为了一个激进的青年黑格尔主义者一样，鲁迅也成了一个“我以我血荐轩辕”的社会进化论者，从仙台来到东京，他毅然剪掉了辫子，严肃地和同学们一起思考民族的问题。\n话说回来，也许正如张饶庭所说，人本身就是loglinear，是非线性的，总是充满了矛盾。记得我自己更夸张的说过“人即回归”的话，都是一样的，只不过是加入了点宿命的色彩。传统与革命便如此自然地熔铸在鲁迅的遭遇中。热血青年鲁迅在日本思想开始倾向于革命，并且 *真真正正的加入了光复会*，然而当被要求回国像徐锡麟一样刺杀满清高官的时候，鲁迅却问了句：“如果我被抓住，被砍头，剩下我的母亲，谁负责赡养她呢？”领导收回成命，刺杀遂无疾而终。对此王晓明写道：他不能无条件地相信别人。即便一时冲动，时间稍长，他对卑劣人心的体验，对一切冠冕堂皇的东西的习惯性怀疑。正是在1906年，鲁迅被母亲以生病为由骗回家，娶了朱安，后者曾经拒绝按照鲁迅的意见进入新式学堂读书。鲁迅在婚后第四天就回了日本。\n一九○八年夏天，继续在东京读书学德语。从夏天开始，每星期日往章太炎在东京的寓所，听他讲学，历时大约半年。称章太炎为鲁迅的老师，跟这个有关系吧。1909年，与周作人合译的《域外小说集》第一册出版，不久《域外小说集》第二册出版。为了负担家庭经济，离开日本回国，结束了七年的留学生活。 回国后，就任杭州的浙江两级师范学堂的生理和化学教员，兼任日籍教师的翻译。1910年担任绍兴府中学堂的监学，兼教生物课。1911年，武昌起义爆发，绍兴城内一片混乱，遂应府中学堂学生的请求，回校暂管校务。 带领学生演说队上街宣传革命，安定民心。不久，受新任绍兴军政府都督王金发委任，担任山会初级师范学堂监督。但是，革命并没有给民族带来更多的东西，革命党的官员一样压抑自由和新思想，鲁迅最终选择离开。\n靠着朋友的推荐、应教育总长蔡元培邀请，去南京中华民国临时政府的教育部任职。从此，逃离绍兴。因教育部北迁，单身前往北京，住进宣武门外的绍兴会馆。 任北洋政府教育部佥事，兼第一科科长。这便是鲁迅中年一次重要选择：为官的仕途之路，所幸收入颇高。但鲁迅虽有怀疑的毛病，却无法接受现实的倾轧，他去研究石刻拓本、抄古碑，他每天上午九、十点钟起床，梳洗后直接去部里办公，到黄昏时返回会馆。吃过晚饭，八点钟开始抄碑，看佛经，读墓志，常常要到半夜一两点钟。对此，王晓明说：对自己的个人幸福，他也不能再抱什么希望了。他刻了一方石章，曰“堂”；又给自己选了一个号，叫做“俟堂”。笔划虽不同，意思是一个，就是“待死堂”。这个时候，鲁迅已经不得不去思考死亡、品味孤独、遭遇自我。生活、婚姻、国家的不顺遂和鲁迅的悲观主义都把他引入到了遭遇虚无的境地。从这个角度上讲，鲁迅和陀思妥耶夫斯基和托尔斯泰是有相近之处的。鲁迅的待死堂和陀思妥耶夫斯基的《死屋手记》中的死屋何其相似。\n对于在五四阶段鲁迅带着面具的呐喊，王晓明直言：对启蒙的信心，他其实比其他人小，对中国的前途，也看得比其他人糟。五四的成功使鲁迅获得了极高的文学声望，“他不再是绍兴会馆里那个默默无闻的“待死”者了，他现在成了大学讲台上的名教授，读者钦慕的名作家。”\n1925年，“鲁迅和女师大的学生许广平等人开始来往，通信日渐频繁，好感逐渐加深，他在感情上，也会不自觉地向这批学生倾斜，于是在五月十二日的《京报副刊》上，他公开表态支持学生，随后又联络其他一些教员，联名宣告反对杨荫榆。”这场纠纷使鲁迅失去了他的官位——章士钊撤了她的职。后来，鲁迅起诉了章士钊重新获得了这个职位。对此王晓明说：从少年时代起，他就吃够了贫困的苦头，他很早就懂得了没有钱，什么事都干不成，在那篇《娜拉走后怎样》的演讲中，他那样强调“经济权”，就正是出于自己的痛苦经验。\n人存在的意义是什么？王晓明说：“人的生存意义，就体现在他人对你的需要之中，即使鲁迅对社会的变革完全失去信心，对自己在这变革中的作用也不存指望，他的精神世界大概仍不会垮掉，还有一根坚固的支柱在支撑着他，那就是他对和睦的家庭生活的期待，对自己作为这个家庭的主要维持者的自豪。” 1923年，鲁迅和羽太信子发生严重的冲突 ，随之和周作人兄弟反目，他就迁往西城的砖塔胡同六十一号。鲁迅对自己的母亲并没有太大的好感，家庭的分裂，更让他陷入了痛苦的深渊之中。\n鲁迅从人道主义转向了个人主义，由启蒙的悲观主义，转向了存在的虚无主义。俄国作家阿尔志跋绥夫在小说《工人绥惠略夫》中，以主人公绥惠略夫表现的一种思想，用鲁迅的话说，就是“要救群众，而反被群众所迫害，终至成了单人，忿激之余，一转而仇视一切，无论对谁都开枪，自己也归于毁灭。” 王晓明写到：从启蒙者的悲观和绝望，从对尼采和绥惠略夫的共鸣和认同，鲁迅一步步走进了虚无感。\n鲁迅在虚无主义的鬼气中滑落的太远，但1925年，他还是找打了一个缺口：对女人的爱情，逃了出来。这一年他和许广平相爱了，许并不漂亮，但对于新思想、自由、革命的坚毅鼓舞了鲁迅。26年，鲁迅到厦门大学任教，后来又去了广州中山大学，此刻许广平已经陪伴在他身边了。因为老对手顾颉刚要到中大，鲁迅和许广平便到了上海。王晓明写道：“从某种意义上讲，鲁迅和许广平相爱而终于同居，在上海建立新的家庭，是他一生中最有光彩的举动。正是在这件事情上，他充分表现了生命意志的执拗的力量，表现了背叛传统礼教的坚决的勇气，表现了一个现代人追求个人自由的个性风采。但是，也恰恰在这件事情上，他内心深处的软弱和自卑，他对传统道德的下意识的认同，他对社会和人性的根深蒂固的不信任，都表现得格外触目。一个人一旦相信爱情，就不再是虚无主义者。”\n鲁迅的人生是在上海画上终点的，在这个时期，鲁迅不断遭遇到华盖运。早期，鲁迅是要医治民族性，对大众，他是轻蔑的，他依靠知识分子的，尤其是学生，但人生的种种遭遇却使他不断看到知识分子的局限性，读了一些马克思主义的东西之后，鲁迅转而提出大众才是推动历史变革者。但是这与他素有的思想是矛盾的。终于，他提出了新知识分子的说法。“一九三二年底，他第二次回北京探望母亲，去北京女子文理学院和北京师范大学演讲，都特别挑起知识阶级会不会灭亡的话题，反复强调说，有一种新的知识者，他们与群众结合，反对个人主义，能够把握住实际人生，因此在将来仍能生存。”\n一九三０年五月，他发起成立了左联的筹备会。他刚刚和共产党人结盟，共产党的一位领导人李立三，就秘密约见他，要他以周树人的名字写一篇骂蒋介石的文章，被鲁迅婉言拒绝。虽然他倾向于共产党，但他同样厌恶成仿吾和周扬那一类共产党人。\n在生命中的最后一年，1936年，鲁迅写了《死》，显示出一种非常特别的态度：既不回避，也不设法改造，就站在那里谈论自己的死。十月十九日，上午五时二十五分逝世。\n这便是鲁迅的一生，一个对我们来说应该熟悉、但其实显然十分陌生的人生，我们在他的身上看到了太多的矛盾，看到了存在主义哲学对人生的思考的深刻的印记。处于一个悲剧似的、似乎看不到希望地转折的时代，鲁迅经历了人生中的种种波折，大到祖国，中到家庭，小到个人，没有一个顺遂人心，这个小个子、坏脾气、多疑的人，在那个时代里耗尽了自己的所有生命力。鲁迅在他的人生的当中不可避免的遭遇虚无，国家风雨飘摇、鸡鸣不已，大众是冷漠的、愚蠢的群体，少年家道中落，慈母是误进的毒药，朱安是无法交流的对象，和弟弟周作人虽志趣相近却终于反目，最后自己所倾向的知识分子也多靠不住。鲁迅的幸运是青少年时的广泛读书、留学日本的经历、加入光复会的经验、许广平的爱情和共产主义的发展。\n鲁迅故去93年了，我们已经从鲁迅的铁屋走出了很远，但我们绝大多数人对鲁迅的认识依然很浅薄。娜拉出走之后怎样？我们挣脱了一个旧的世界，我们又能走多远？鲁迅今日若在，他又能写写什么呢？鲁迅说：“跨过那站着的前人。”我们真的超越了吗？\n","date":1234569600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1234569600,"objectID":"b11aafcc1852aef41f6d812697858d0f","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2009-02-14-read-luxun-in-text/","publishdate":"2009-02-14T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2009-02-14-read-luxun-in-text/","section":"post","summary":"","tags":null,"title":"我们能走多远——读王晓明的《鲁迅传》","type":"post"},{"authors":null,"categories":null,"content":"Githubarchive整理了github的历史数据，每一个小时一个数据文件，我下载了2011-2014年四年的数据，结果发现2012年的多数数据存在错误换行的问题，需要清洗。一般而言，正确的情况是一个字典格式的数据占一行，错误的情况就会是所有的字典格式的数据合并为了一行。似乎是缺乏换行符造成的。\nhttp://stackoverflow.com/questions/10432432/yajl-parse-error-with-githubarchive-org-json-stream-in-python# 这里详细记录了这个问题。\n按照这个帖子，我尝试了很多方法，yajl和ijson，但是都不能很优雅的解决我的问题。不妨采用暴力的方法。\nrirwin利用了{和}出现的偶数关系来分割字符串，但是这种方法容易遗漏数据且速度较慢。\n仔细思考这个问题就是：Parse multiple json objects that are in one line。 搜索之，发现了http://stackoverflow.com/questions/36967236/parse-multiple-json-objects-that-are-in-one-line\n其中，Francesco的解决方法比较高效：\nf = '/Users/chengjun/百度云同步盘/githubarchive/2012-03-10-22.json.gz' f = gzip.open(f, 'rb') f = f.readline() r = re.split('(\\{.*?\\})(?= *\\{)', f) accumulator = '' res = [] for subs in r: accumulator += subs try: res.append(json.loads(accumulator)) accumulator = '' except: pass len(res)   Out [29]: 1270\n 基于这种方法，可以写一个函数来实现对于数据的正确读取。\n#f = '/Users/chengjun/百度云同步盘/test.json' #f = open(f) f = '/Users/chengjun/百度云同步盘/githubarchive/2012-06-01-15.json.gz' f = gzip.open(f, 'rb') files = f.readlines() length = len(files) if length \u0026gt; 1: print 'Correct: ' + str(length) else: f2 = files[0] r = re.split('(\\{.*?\\})(?= *\\{)', f2) r = [i for i in r if i] # delete the '' accumulator = '' acts = [] for subs in r: accumulator += subs try: acts.append(json.loads(accumulator)) accumulator = '' except Exception, e: print e pass print 'Wrong: ' + str(len(acts))   Out [30]: Wrong: 4491\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"2fbc1f9ab0f00d18614fce93e3dff7fd","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2016-06-18-parsing-githubarchive-json/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2016-06-18-parsing-githubarchive-json/","section":"post","summary":"","tags":null,"title":"Parsing Githubarchive Data using Python","type":"post"},{"authors":null,"categories":null,"content":"“袁世凯在中国近代的历时转型期中，也算是一个悲剧人物。”——唐德刚 一 挟六镇军威 养敌以自重 袁世凯是一个以军功起家的人物，以小站练兵的方式建立了忠于自己的军队——北洋六镇，又被称之为北洋系，是民国后各系军阀之祖。在袁世凯的班底中，其文班底“嵩山四友”：徐世昌，李经羲，张謇，赵尔巽；武班底包括“北洋三杰”龙虎狗三将军：王士珍，段祺瑞，冯国璋。\n但袁世凯的仕途并没有我们所想的那般顺畅，1908年四十九岁的袁世凯被摄政王载沣开缺回籍。之后他以中国古代官僚所特有的政治智慧自诩“洹上钓叟”，于养寿园中悠游林泉。历时三年，方才应召回京，东山再起，是年10月10日武昌起义，受令讨伐武汉之起义军。狡猾的袁世凯称疾不就，养敌自重。 二 中山成黑马 国体师美国 革命军可基本上分为武汉方面（简称汉方）和上海方面（简称沪方）。汉方拥护黎元洪为革命军大元帅，沪方则抢先选举黄兴为大元帅。后双方到达南京重新选举，以黎，黄分任正负大元帅。 鉴于袁世凯的军威，清廷和革命军都在事实上不得不接受让袁世凯担任皇帝或者总统的现实。但是深谙中国五千年来的政治智慧的袁世凯却既不愿逼宫取位，他盘算着让溥仪退位禅让，自己则必须三辞而后受之；又不能鲁莽得接受国民党等革命军的议会选举，事缓则圆，袁世凯也不想仓促中激起清廷的对抗。 恰在袁世凯举旗观望和黎黄争位之时，孙中山兼程回国，“参议员诸公既然不能举孙为大元帅，就只有举他为临时大总统，以待袁驱除鞑虏后再来让贤了”，这样中山先生就只好以其建国学理和崇高威望戏剧性地成了中华民国第一任临时大总统了，当然选孙文为大总统的另一个原因是传言他获得海外华人百万捐款（实际上却是不名一钱）。 值得一书的是在大局未定之时沪汉双方都同意采纳美国的政治制度：议会制和总统制。这可以被认为中国的共和制度之始，实在是意义非凡。 ##三 不流血政变 袁世凯当权 南方已定，孙文电告袁世凯，暂代临时大总统，虚位以待袁。 此时的袁世凯也不得不加快逼宫的进程，裕隆太后为袁世凯所骗，先是拿出私帑以救武汉之急，后有听信革命军如何有钱，如何厉害，只有退位了。裕隆念念不忘袁世凯许诺的每年400万两的皇室优待费，同意让溥仪退位。是为1912年2月12日之宣统下诏退位，遂成中国之不流血的宫廷政变。 之后，做了45天大总统的孙文辞职，中华民国临时参议院在南京全票选举袁世凯为中华民国第二位临时大总统，并派人迎接袁世凯建都南京。狡猾的袁世凯制造了京津兵变，假称北方未定，不肯迁都南京，革命派只好顺从其意。 为了安抚孙大炮，袁世凯让他出任中国铁路总公司总理的优缺肥差。原来，理想主义的中山先生有一个20万里铁路计划，这不能不说是个万分宏伟的想法，因为中国在1998年方才规划到2002年实现铁路突破7万里。袁世凯明知孙中山之计划不切实际，不可能实现，却并不挑明。待得后来孙文浪费百十万两白银未修成一寸铁路，真可谓“君子可欺以其方”。黄兴则没有这么好远，被任命为南京留守，做安抚那些要被解散的革命军的吃力不讨好的事情，最后被裁撤了之。 但1912年3月11日，孙文任总统期间却公布了由《临时政府组织大纲》改订的《中华民国临时约法》，其核心是将政体由美国总统制改为法国式的内阁制，总统的权利受到内阁限制。由内阁总理直接向国会负责，总统成为虚位元首，这当然是为袁世凯而设计的。 但袁世凯却是一个离不开权利的人，不久唐绍仪内阁即告倒台。年轻的宋教仁从唐内阁中下岗之后就开始了收编小党，将同盟会该组成国民党的活动，后者在1913年在国会中大获全胜，而宋教仁在之前就对外宣称要组织清一色的国民党内阁，这些当然不免让袁世凯大叫其苦。 袁世凯于其时不怕重理论的孙大炮，却怕有组织才能并且锋芒毕露的宋教仁。收买不成，就只好假赵秉均之手杀之而后快了，是为震惊民国的“宋教仁案”。 唐德刚评论说：”在民国史上政变不循法律途径而用枪杆。袁之杀宋是一错，国民党之以暴易暴，兴兵讨袁，则是再错。”“接着三错，四错随之而来，就变成武力至上，军阀混战了。” 教仁即殁，黄兴等主和派主张以法律解决，孙中山等主战派则主张以武力讨伐之。但国民党其实无兵无地又无钱，而袁世凯却恰好获得六国银行团的贷款2500万金镑，未经一月革命党之二月革命即告破产，袁世凯却托中山之福剪除异己，削除藩镇，一举控制了广东江西和安徽这几那个云南，广西。南京的张勋，山西的阎锡山，奉天张作霖，云南唐继尧莫不胆寒，连黎菩萨元洪也被请到北京软禁起来，当然几乎同时被软禁起来的还有梁启超弟子，云南王蔡锷将军。 权倾朝野的袁大头终于登上正式大总统宝座，1914年公布的《中华民国约法》和同年12月29日《修正大总统选举法》袁遂成终身大总统并且可以传位于妻，子。但是贪心不足的袁世凯却在犹豫不定中想要走得更远。 ##四 称帝忧患间 墙倒众人推 民国创立后的第一次农民起义——白朗起义于1913年秋爆发了，次年8月被平定。但相较于内忧，外患才是最严重的：美国划定所谓的麦克马洪线侵占西藏；日本和俄国瓜分东北三省；俄国策划外蒙古独立；日本更是雪上加霜地侵占胶州湾取代了德国在山东的特权，袁世凯拖不过去到底签了丧权辱国的二十一条。凡此种种，袁世凯虽勉力维持，终不堪重负，贻人口舌。 在风雨飘摇之中的袁世凯却最终不合时宜地在摇摆不定地萌发了做皇帝的想法，由其控制的筹安会“六君子”，参政院和全国代表大会拥立袁世凯复辟。袁终于在１９１５年１２月１３日成为中华帝国的洪宪大皇帝。 袁世凯称帝自然为革命派所不容，但其内部的文武班底也反对。狗将军冯国璋和虎将军段祺瑞都恐与之交恶的袁世凯的大儿子袁克定继承大统之后对他们痛下杀手，遂成北洋系之窝里反。更加重袁世凯的担心的是日本也发表了对袁世凯称帝的反对。 外为舆论不容，内为自家人反对，袁世凯在风雨飘摇中走到了人生的终点。１９１６年９月６日，袁世凯病逝，符合袁世凯对冯国璋所说的袁家男人寿不过六十的话。正应了老子之言：物壮则老，谓之不道，不道早已。 是年，段祺瑞取而代之，民国遂入军阀混乱之迷局。惜哉。 ##五　帝制向后转　共和向前看 对于历史深层的国体政体之选择，唐德刚先生说，走过了两千年的封建和帝制的历史，中国已经驶入转型时期的历史三峡，“顺流而下，滩高浪险，掉头逆水，必然翻船，而袁世凯及其党不知也，悲夫。” 是啊，共和制也不是万能的，但共和制虽有诸多不合国情之处却毕竟是向前看的，恰若唐德刚先生所言，共和制是权力递减的制度安排，在一个转型的历史阶段，运用共和制有可能会带来暂时的权力的极度地扩张，恰如蒋介石的权力在某些方面比之古代君王有过之而无不及，但是到了其子蒋经国先生的时候，总统的权力就已经有效地减小了。看来，唐德刚先生是一个赞成政治上的休克疗法的学者。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"05e9ce338283bd7d6d0c180a1d52cb12","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2008-09-25-yuan-shikai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2008-09-25-yuan-shikai/","section":"post","summary":"","tags":null,"title":"写在《袁氏当国》之后","type":"post"},{"authors":null,"categories":null,"content":"黠之大者\n序言 这个短篇小说是我对本科生活的纪念。那时候的我蜗居在一个山村里。紧张得上着课，看各种不着边际的书。渴望未来，却看不到边界；憧憬爱情，却不善于表达。\n王二是我们在大学这座围城的缩影。本科的学习，我们仍无法窥见科学的全景，对各种工具也缺乏了解，更多的时候只是抱着人文取暖。大四的时候，看王小波的《黄金时代》，叙事的精巧，精神的贲张，让我为之击节。王二便是借了其中的主人公的名字，但缺少了其中的锋芒，多了更多的世俗和顽固。\n围城里有快乐吗？这是一个开放的问题。我想是有的，因为大学时一个改变的场所，身处其境，每时每刻都埋藏着思想和行为改变的种子。虽然身在其中却往往不得其所。这正是大学的魅力，让你身在囹圄，却得以茁壮成长。\n目录  chapter1 王二 chapter2 杨亦凌 chapter3 一条狗 chapter4 小六 chapter5 女大学生 chapter6 教学楼 chapter7 图书馆 chapter8 考研时期的爱情 chapter9 一切都如此重要 chapter10 毛片 chapter11 女人如衣服 chapter12 影吧 chapter13 毛片续 chapter13 鬼的存在 chapter15 失乐园 chapter16 失恋 chapter17 空档期 chapter18 烟 chapter19 自杀论 chapter20 功利主义 chapter21 挟持 chapter22 许三多和斯密 chapter25 纠缠不清 chapter26 旁观者 chapter27 不会经历的奇遇  chapter1:王二 “我们根本就生活在一个悲剧的时代，因此我们不愿惊惶自忧。大灾难已经来临，我们处于废墟之中，我们开始建立一些新的小小的栖息地，怀抱一些新的微小的希望。这是一种颇为艰难的工作。现在没有一条通向未来的康庄大道，但是我们却迂回前进，或攀援障碍而过。不管天翻地覆，我们都得生活。” ——《查泰莱夫人的情人》\n王二何许人也，已经无人考证，因为考证出了也不能写个论文、发个帖子什么的光耀门楣。重要的是王二生在了80年代，这注定了他在一个社会转型的黑铁时代兀自唏嘘。\n虽然王二不是一个经常多愁善感的人，做人也很低调，但是还是有好事者考证出了王二的出处：他是一个学生物的，L大学图书馆里的生物化学课本上都有王二的笔迹。后来我去找过，没发现。\n生在八十年代的王二干事情很认真，他是农民的儿子，是个穿着谈吐透着土气。王二04年高考了，之前他从来没有关心过别人，包括他的父母。王二想的很简单，考个好学校，找个好女人。王二要为他的简单付出代价。\n成绩下来，王二高兴地填了L大学。于是我今天才会写这个短篇。我想幸亏王二选了L大学。不然，我的书就有得换主角了，我很早就打算写本小说，换了很多主角了，从江隆基到李发伸，但是我终于发现我面对他们时丝毫没有激情。我不会写作了。但自从遇到王二，我知道我该写谁了。傻逼王二全身透着冲突，不然后来他不会自杀了。\n我想肯定是王二得罪了这个好事者。不过王二一向龌龊，这样似乎也在所难免。\n我第一次见王二是四年前，那时候的王二身高已经达到1.69m,比我低了一头。王二见到我时说：“丫的你留了多少级，长这么高。”我就只好给王二解释说，身高和营养有很大关系，要多喝牛奶，多锻炼。后来王二就常跟我们去锻炼，打篮球。但是四年过去了，我可以肯定的是：他一厘米也没再长高，还是比我低一头，我也没长高。大学四年了，我们似乎被凝固了，什么也没变。\nchapter2:杨亦凌 就是在球场上王二第一次遇到了杨亦凌。杨亦凌是新疆人，高高的鼻梁表明她有维族人的血统，杨亦凌的父亲是汉族人，母亲是维族。当兵的杨父在新疆看上了美丽的杨母就再也没回老家。杨亦凌跟其他女孩不同，她喜欢打篮球。那天杨亦凌正在跟几个维族帅哥一起打球。\n金黄色的头发使杨亦凌看起来很像是个老外。正因为如此土鳖王二大大咧咧的对我们说：丫的，看对面有个老外也打篮球。\n杨亦凌听了很生气，她冲着王二喊：come on, young man. Let me teach you how to play basketball.\n王二不服气，撺掇我们两群人打比赛。结果身高不足的王二被杨亦凌盖了几个大帽。\n杨亦凌的错误在于休息的时候对王二说，小子，不服再来。\n王二说，哼，不信打不过女人。\n我注意到那时杨亦凌的眼神闪过一丝杀意。\n球场失败的王二决定从哪跌倒就从哪里爬起来，他决定去追杨亦凌。这直接导致了王二后来成为彗星观察爱好者协会的会长。\n王二第一次吻杨亦凌是在十一去青海湖的火车上，杨亦凌后来说，那是第二次。我想知道第一次是什么时候就去问王二。那天王二正在刷牙，时间已经是大三上了，也就是06年深秋，王二吐着白沫说，没有第一次，因为他有很多次试图去吻杨亦凌都没成功。我忘了交代了，杨亦凌身高175cm，所以王二要想得手不仅要有天时还要有地利。\n杨亦凌那时候是个骗子，更确切地说是一个社团——彗星观察爱好者协会的社长。年纪轻轻就成了头，想必你也猜出了杨亦凌其实是王二的师姐了。那时王二大一，杨亦凌大三。但这就给了王二得逞的机会，虽然社团可以靠着骗取无知大学生的信任并收取会费生存，但是彗星本来就不多，想观察到就更难，何况已经有了一个天文爱好者协会。所以，临危受命并急于骗人的杨亦凌决定接受王二的入会申请。\nchapter3一条狗 我的大学生活越发无聊，在失恋之后我决定养狗。我发现，养狗的人都有点小资，够小资的人都在大三、大四。但我决定打破这个僵局。那年我大一。但我没想到我还打破了另外一个僵局。 事实上王二大一上的爱情生活并不顺利。他和高中的女友分了，虽然我知道王二乐得如此，但是我还是看到了王二的伪善的眼泪。\n我说：王二，丫装个什么劲啊，故意冷落别人让她先提出，好像自己很无辜啊。\n于是乎我看到了王二眼里闪过了杨亦凌眼中曾出现过的杀机。\n王二：丫的一边去，爷正伤感呢。闲了就写你的小说去。哪门子的网络写手，还整个什么兰陵小\n小生，你小个p,个子比李恒滨还大，年龄比王皓还老。\n人情冷暖啊，我决定养条狗，并且专门挑了一条凶狠的狗。我给他取了个名字叫路易十四，不过我更愿意简称它为小四。特此声明，那时候我还没看过蜡笔小新。否则，我会给它取名叫小白，因为后来我发现它很色。经我调教之后，它开始在宿舍里为祸一方。\n事实上，王二也很痛苦，不过他发泄痛苦的方法太没创意，他也养了只狗，不过无论个头还是性情都不能跟我的小四相提并论，真是狗如其主人啊。\n小四长的很快，行为也越来越出格，由以前的叼别人的牙刷发展到叼别人的脸盆。那天，小四就是因为叼走了王二的脸盆被王二从六楼追到一楼。\n我不知道杨亦凌是不是也在追另外一条狗，总之，她和王二撞到一块。\n那时，王二追累了，叉着腰简直就是个夜叉。路易十四也跑累了，停在王二脚边王二踢不着的地梳理皮毛。可能是因为它的夜生活太丰富，昨天晚上它同样因为叼走了对面宿舍小六的拖鞋被追的满宿舍楼跑。杨亦凌走近王二，像一个官僚看到了下级，其实就是一个官僚看到了下级，她也叉着腰，像个母夜叉，事实证明后来她就成了夜叉的对象——母夜叉。\n杨亦凌说:王二，你的狗真可爱，它咬人吗？\n一面夸路易十四可爱，一面担心被咬，可见她的夸奖并不真实。并不傻逼的读者，相信你们都能看得出来杨亦凌脑子并不少根筋，只是面对王二，她没有危机感，不想动脑子。\n王二想表现自己，拍着胸脯说：绝对不咬。\n于是，杨亦凌在得到肯定的回复之后想表现下自己的爱心。她弯腰要抱起小四，于是乎手上便留下了一圈并不浅的齿痕。血像三月的春花，从那些先花植物的枯干上涌现，异常绚丽。\n杨亦凌恶狠狠的看了王二一眼。\n王二心中一冷，说：这不是我的狗\u0026hellip;\u0026hellip;\n再给个镜头，我想我能猜出小四的想法，一个母夜叉和一个追了自己很久的夜叉对话后伸出双手靠近自己，这种行为怎么可能是善意的呢。咬，才是合乎理性的行为。但如果老是咬住不放，不管是咬的快感降低——因为边际效用递减，还是咬的行为成本增加——可能被夜叉和母夜叉抓住群殴，于是乎小四松口逃跑。由此可见，小四作为一个和农民、女人一样的弱势群体一样是最为理性的，完全符合我分析它的行为的理性狗的假设。\nchapter4 小六 这个世界如果还有真的话，那是因为存在着太多的假。小六就爱较真。王二就相反，也因此最更为可恶。例如，小六会因为脸盆被路易十四叼走追了它一夜。因为他发现小四的恶行后说：大爷今天逮不着你就不睡了。\n看着在楼道中踱步的小六，王二说：至于吗，跟个狗过不去。\n小六说：爷愿意。又不是你的狗？\n我看得出王二听了牙根发痒，他想打小六一顿，但王二还是有点顾忌的——那时候的小六壮得像头牛，又有一腔纯真的热情。\n两年后才实现这个夙愿。那天，王二、小六和楼管一起打牌、喝酒。那天，小六喝多了，回来发酒疯，把个酒瓶子摔碎在地上，王二说：小六，你丫的，要摔摔你们宿舍里去，别再爷宿舍里撒野。\n小六酒劲上来，怂人胆壮：王二，怎么着，我还打你那。\n王二立稳了，一个拳就把他打倒在地。\n小六从地上爬起来，一脚就踹过去，正中王二小腹，把王二踢到了走廊。王二喝的也不少，四仰八叉的躺在地上，嘴里还念念有词，“哪个孙子踢的？”\n小六闻声一脚又踢向王二，王二头一偏，小六踢中墙壁，站立不稳，再次摔倒。\n众人将他俩拉开。大学里的打架大抵如此，总不能尽兴。\n大一下，疯狂的玩了一学期的王二、我决定背水一战、绝地反击。王二是笨人，又迂（我们那管固执叫迂），他们决定看书。我是虽然不是个顽主，但是明白看一夜书到底不顶用，不如抄袭。大学考试不像高考那么严格，大家坐的近，我的视力好，一不小心就把前后左右的答案看了个遍。\n考高数的那天，我如愿以偿的抄地不亦乐乎。出来后当我给王二讲起高斯定理什么的时候听得他棒槌一愣一愣的。\n王二有点发木，他心里想着会不会挂科，“操行，大学刚开始就栽个跟头。”\n我想王二是真的受打击了吧。这帮人继承了优秀高中生的优良品质，把挂科看成了悬梁自尽，就像是女人被qj了一样，但挂过之后就是另一番境界了，如小六，自从挂了生化之后就再也不怕挂科了。\n当我擦亮眼镜准备考试（经常对着mp3看电子书弄的我视力下降并且有点斗鸡眼），王二提前两周复习生物统计时，小六仍然浑然不知，在大家都奔赴考场之际，他仍然在玩网游。\n当然小六也觉醒过，因为长时间打网游，小六开始营养不良，身体变得极差——这也是两年后我和王二敢打他的原因。\n那天，小六就觉醒了，早上起床后，冲进我们宿舍说，“兄弟们，我改了。”\n我们才知道他已经把电脑装好，打算再也不玩了，小六说：“兄弟我身体太差，你们帮我把电脑放上铺的墙上的箱子里。”\n我和王二见小六终于觉醒了，大为感动，就帮了他一把。\n下午回来却发现他又再玩，不知道他那孱弱的身体是怎样把沉重的tcl显示器搬下来的。 小六的另一次觉醒是在大病之后，因为营养不良，小六的身体不干了。那时候，小六他妈从遥远的东北赶来了，帮着小六把电脑卖了，在确信儿子不会再玩网游之后，六他妈才踏上火车。小六也的确出息了，改成看小说了，整天歪在床上。躺了几天之后，开始大病。小六开始借钱看病。\n王二犯了心太软的毛病，这个毛病他以前追杨亦凌的时候犯过，就是上次杨亦凌被路易十四咬了之后，王二陪着杨亦凌上兰州打狂犬疫苗。回来后，我们就发现杨亦凌看王二的眼神不对了，透着股含情脉脉。看得小六想吐，小六说：女人真装逼。\n如果说王二因为太有爱心勾搭上母夜叉是得偿所愿的话，这次王二滥用同情就损失了200元大币。小六拿到钱之后依然绝然的冲向了医院外的网吧。所以，后来杨亦凌每见小六总要瞪他几眼。\n王二眼中的小六，遍布校园。他们存在意义或许是让王二明白什么样的大学生活不是他想要的。\nchapter5女大学生 在英格兰，黄金在铸币后很久还不曾取得法币资格。\n———亚当-斯密\n如果说王二在加入彗星观察爱好者协会后，还没有取得作为杨亦凌男朋友的法定资格，那么，杨亦凌被狗咬过之后，王二显然是取得了这个资格。对此，杨亦凌的兴奋也许远没有王二那样厉害。因为，一个漂亮女人想在大学混好的一个重要的要件是做一个大众情人。这样，那些宅男们就只能停留在意淫并且不会疲倦的阶段。当然了，这个要求太难，除非这个女人拥有吴仪似的智慧。\n很显然杨亦凌没有这种智慧，所以她打算与王二先出双入对，至于王二卑劣的双宿双飞的想法杨亦凌则明确反对。这里再次彰显了我兰陵小小生的智慧，很多女人唯一的资本就是自己的美貌，而且在表面上开放实则高度保守的中国当代大学生眼里，女人的美貌又有贞操这一大敌，一但丧失贞操，美貌的边际效用就会出现暴跌而不是简单的递减。 对这个问题，王二则走得更远，这是我敬畏王二的地方之一。王二认为，女大学生即使是仅仅交个男朋友，也会使其吸引力大为降低。\n王二是以美国数学家小约翰-纳什的博弈理论开始的，如果想和舞会上漂亮的姑娘共舞一曲，所有参加舞会的男孩子最明智的策略是邀请那些不那么漂亮的姑娘跳舞。\n因为，如果大家都去邀请最漂亮的姑娘跳舞，那么只会有一个胜出者，而且剩下的姑娘由于你没有把她作为第一选择会感觉到恼怒，这么做的结果是很可能绝大部分男孩子连一个舞伴都请不到。而如果人人都不选择最漂亮的那位姑娘跳第一只舞，那么她就会被晾在那里。出于寂寞，可能会很容易接受你第二轮的邀请。而且，无论如何，在第一轮里你已经找到了个姑娘起舞。杨亦凌可能受够了第一轮不被邀请并因此只能做大众情人的痛苦。 我很怀疑这就是漂亮的杨亦凌被王二追到手的原因——她太漂亮，她身边的男生都是纳什的信徒，王二是个非理性的赌博者。\n这似乎已经成为一个社团的铁律了，所以有很多充满智慧的男生或者女生会选择作一个大众情人，因为现在是一个讲究个性的更为直白的表达自己的内心感受的时代，大家不可避免的会选择自己所心仪的男生或者女生，这样很明显会有很多的竞争者，因为虽然标榜着个性，但是大家对于美丽的认可却遵循着几千年来来的审美标准．很显然，大家成功的概率都极大的缩小了，这恐怕也是初恋往往失败的一个重要原因：我们骨子里的浪漫主义情结和现实巨大的竞争之间的矛盾之间的矛盾。\n于是大家在这个阶段为了规避被动或者失恋的痛苦而选择默言，似乎每个人都已经参透了这些人生的奥义（其实骨子里是因为深深明白主动求爱就会陷入被动之中），于是乎很多人选择做一个大众情人，因为他没有勇气接受或者主动追求，当然这种做法是符合经济学的原理的，这样做的机会成本太高了，理性人，即使是有限理性人也不会傻到这种程度，于是乎就出现了一种不追求，不拒绝，不负责的人生态度。\n但我们不能否认，用经济学来理解爱情不可避免的存在巨大地误差，这在更大程度上不是因为非理性的存在，而是失恋的痛苦在初恋时往往是饮鸩止渴的快乐了，大家在短期痛并快乐着，虔诚地皈依这种悲观。王二也曾体会过这种悲观，直到后来遇到小舟。\n但是时间当然会改变这一切，因为人生不仅仅只有爱情。\nchapter6教学楼 事实上我仍然想不通杨亦凌和王二的感情究竟是怎么回事，因为他俩勾搭到一块是05年春天，那时候王二大一，杨亦凌大三。而那时候的杨亦凌已经在准备考研了。如果我没有忘记暗示读者的话，那么你就应该才得出来杨亦凌是一个充满了远大理想的女性。而这正是王二的不幸。\n但那时的王二是体会不到这些的，为了追杨亦凌王二经常伪装成一个爱好学习者，每天在杨亦凌上自习的座位上晃来晃去。\n王二是更喜欢在教学楼上自习的人，因为教学楼里经常会有很多情侣，所以很多抵抗力差的人是不会在教学楼上自习的。另外，教学楼里的座位是连在一块的，通常是中间的一长排座位仅仅做两人，一边一个，中间空出好大空间，一般人看了是不可能有勇气夹在两个人中间坐的。\n但王二何许人也，爱招摇过市的他从来就有一个厚脸皮。王二的通常做法是这样的：很晚采去，那时候座位都被占完了。推开一个坐的满满的实则空了很多座位的教室，肆无忌惮、明目张胆的走进去。当满教室的眼睛都集中在他身上时，王二获得一种至高无上的满足。这个时候她通常会挑选几个对象肆无忌惮地看过去。由此我们可以看出王二身上所特有的演员的特质。如果王二是一个穿着新装的皇帝的话，王二其实经常这样想，他是不在乎自己身上是否真的披着几匹布的。\n在上管理学时都会讲到马斯洛，他提到了几种人类的基本需要，包括生理的需要、安全的需要、情感的需要、尊重的需要和自我实现的需要。王二在这种巡视中所获得的是什么呢？难道他能够从中获得一种得到注意的巅峰体验吗？或许物质生活堪称贫乏的王二依靠精神的意淫获得满足。\n在这种目光的对峙中总会有首先移开目光的一方，王二通常会坚持下来。但有一次，他没有。那一次，他遇到了小舟。\n坐在后排的小舟右手支颐，左手转着一只自动铅笔，看着王二走进，走过来。王二棋逢对手，但这次还是被小舟看毛了，走过小舟时，王二脚步略为加快，没提防教室后面的一级台阶，被绊了一下，王二忍不住转身却发现小舟以一贯的眼神瞅着他，王二的喜剧细胞一下子活跃起来，他看着小舟的线性代数的课本说：我身上有矩阵吗？\n小舟眼神移到王二的脚上，下巴配合着眼神做出一个示意的动作来。\n王二没反应过来：什么？\n小舟说：你的袜子。\n王二才注意到自己穿了两个不同的袜子，一个耐克，一个阿迪达斯。\n这是王二第一次见何小舟，我很庆幸我还记得这个名字。\nchapter7图书馆 一个美丽的女生应该是什么样子的？你所记忆中美丽的女生是怎样出现的。我们一直在思考什么样的女生最优秀，而不是什么样的女生最适合我们。这是我们最大的错误。王二不巧犯了这个错误。 王二本身当然是一个积极求进步的男人，但是王二的进步主要表现在宿舍里，例如王二喜欢在被窝里看《论美国的民主》，在教学楼、图书馆他是绝对不看的。\n因为何小舟，她的出现使王二再不敢肆无忌惮的闯入教学楼上自习。王二现在如惊弓之鸟，看到教学楼的女生就像看到了千千万万个何小舟们。当然更要的原因是因为杨亦凌，考研的杨亦凌像是一个两栖动物，白天栖息在图书馆里的自习室，深夜才回归宿舍。追随杨亦凌的脚步，王二也加入了图书馆占座的行列。\n郎咸平认为大学教育是一个培育精英的场所，以市场化的逻辑进行教育改革的本身就违背了教育的本意。中国大学的扩招与扩张稀释了有限的教育资源。当然，像王二这种有着自我批判意识的庸人应该感谢这种教育的扩张，因为如果没有扩招，或许王二高中毕业根本考不上大学。但是，市场总是会走向均衡的，扩招本身也稀释了大学毕业生本身的含金量。王二算与中国的教育制度打了个平手。倒霉的是那些精英，他们千辛万苦上了大学却发现身边的同学多是一些像王二一样的庸人。但这本身又存在悖论，这就是教育本质的问题，教育到底能否能够提高人的能力。很多人认为大学教育并不能提高人的能力，实际上我们毕业之后所面对的招聘者的核心衡量指标之一是大学的品牌，但我们应该明白考上不同的大学所体现的是高中教育的价值。王二要在大学实现一次质变，他想表明自己能够体现出大学教育的价值，但是在夏官营大学，王二找不到与仰慕的老师交流的机会，就只好与仰慕的书籍交流。\n所以王二对L大学图书馆的感情是很深的。之前图书馆委屈得窝在一个普通的两层的楼上。其气势便让人感到十分猥琐。所幸，不久新图书馆就建成了。虽然王二觉得翠英山如坟，山下的图书馆如墓碑，但是王二在墓碑里活动时候却无比的兴奋，这也成为了王二后来坚持留在夏官营校区的原因。后来很多人问王二，王二不好意思回答，但答案是他离不开书，确切的说他离不开那么多书。\n但是，杨亦凌在图书馆不是看那写有营养的经典，她不像王二一样喜欢呆在书库，她呆在一楼的自习室里。为了追杨亦凌王二之后委屈求爱情也呆在一楼，但是我知道王二是多么想上层楼、再上层楼到三楼看书。于是，王二就只能抱着柱子意淫一下。\nchapter8考研时期的爱情 转过身去，一切都变得遥远。写作的心境一下子乱了，离歌响起，我们很快会被赶出校园。与L大学四年的契约即将完结。一群人在群里悲吟，喝了这杯还有三杯。但我看着王二，仍然会清晰地想起两年前的往事。\n王二坐在考研者中间总有些不协调，或许在一群在考研者中间看《社会契约论》太奢侈了。王二困惑的是为什么这么多人选择考研，陪伴杨亦凌的日子里王二细致地观察了图书馆自习室，地下一层的南侧和东侧是连个巨大的自习室，也是所有考研人争夺的重点。暑假里第一次去排队占座的王二就被吓倒了，早晨六点刚过，图书馆门前就已经密密地站满了人，一直排到南北方向的道路边。而开门的瞬间，人潮如决堤的洪水泻入。在急促的奔跑中中会有人跌倒。丢掉鞋子什么的。因为从正门进要下楼梯才能到一楼的自习室，从楼梯上跌下去可不是闹着玩的，于是图书馆开始早上开放南门。开门的时间是六点五十左右。但通常六点十分王二就得甜蜜梦中惊坐起，背起包向图书馆跑去，因为宿舍楼管总是不愿意早起开门，王二们还要经常跟楼管进行间歇的斗争。\n走出宿舍的王二通常是要一路奔跑到图书馆南门的。\n在从八月到十一月里的六点十五到六点半，王二通常处于奔跑的状态，而他身边的景物却开始变化，芳草枯萎，风霜委地。有一天，王二感觉到第一场雪落下了。伤春悲秋的王二没有来得及多想就继续奔跑起来，因为晚了就没有位置了，杨亦凌就可能要发脾气了。 因为杨亦凌的原因王二提前经历了考研，但如果回想起来，我宁愿将王二和杨亦凌的爱情称之为考研时期的爱情。\n女人毕竟是女人，话说回来，男人到底是男人。如果你个女人在失落无助之时找不到一个肩膀依靠或许是一件很可怜的事情。这种观点到底是辩证的观点。女权主义的错误是把洗脚水和孩子一起泼掉，坚强过后才发现一身孑然。被主义引领着失去了世俗的智慧。杨亦凌是具有世俗智慧的女人，虽然我一直怀疑她对王二的感情。\n但那个时候的王二却经常与杨亦凌出双如对了，有时候两个人一起牵着手安静地走，有时候打闹着闪躲。杨亦凌拥有女人一切可爱之处。\n也正是这个时候王二开始晚上很晚回来。有时候王二会跟我和小六炫耀，才说到杨亦凌柔若无骨的小手时小六终于在吞了口唾沫后说：“不会吧，母夜叉个头比你都高，抱起一堆书疾走如脱兔，一只手可以握住篮球，手少说也有笊篱那么大。”\n时不时我和小六都要提醒王二：“王二，你已经接连三天晚归了，这样下去，楼管是不会放过你的。”\n我更愿意提醒王二：别没良心，上次买的qq恋省着点用。\n王二则厚颜无耻地说：怕什么，有毓婷。\n终于有一天，不对是有一夜，王二开始夜不归宿。气得小六说：丫的王二，真扎实干啊。 后来，王二说杨亦凌那天很失落，那天她放弃内保了。虽然是主动放弃，但是看着别人高高兴兴地内保，母夜叉的心灵还是很受伤。她像每一个有着远大理想的人一样开始自我感伤。\n那一夜，母夜叉和王二沿着南区的柏油路走出了校园。\nchapter9一切都如此重要 王二大二上买了令他后来为止后悔不已的电脑，05年班上买电脑的同学还不多。王二自称自己是一个“早”教徒，对张爱玲的“出名要趁早”的话王二笃信不移。\n对于买电脑的原因，王二很少对人讲。很多sb大学生可能一辈子都想不清楚自己为什么买电脑。消费社会里的人们把很多东西当作身份的标志。用消费品和他们相区分。王二还没无耻到用他的破电脑来和我们划明界限。\n困扰王二的问题是除了书他还能与谁交流？当和杨亦凌的谈话成为一种习惯性的行为之后，王二蓦然发现无论他热情地和杨亦凌说什么，杨亦凌的反应都是相反的漠然。\n直到有一天杨亦凌开始认真地问王二：你想过你以后做什么吗？\n王二无比谄媚地答：你做什么，我就做什么。\n于是，杨亦凌开始闪动长长的睫毛认真的注视着王二说：未来我们仍可能在一起吗？ 王二那时候就开始想杨亦凌是不是看复习考研时马哲看过头了，马哲里的一个重要的原理是“运动”，一切事物都在不断地变化发展。\n“明天的你还会在我身边吗？”杨亦凌问。\n王二搂住杨亦凌说：别傻了，我不会离开你，只要你不离开我。\n但从此之后王二对于爱情的坚守一下产生了一种莫名的不坚定。我们可能离开爱情生活吗？对于王二来说，以前他所唯一离不开的是书。王二曾不无得意的说：丫的，给老子书读，把老子扔到敦煌看佛经都没关系。现在的爱情呢？把王二和杨亦凌扔在荒原中，王二能安然地活着吗？\n当杨亦凌问王二:如果荒原上没有书，只有你我呢？\n王二眼神痛苦地变得晦暗，低下头没有回答。这证明王二对这个世界的所知仍然太少。 当杨亦凌在思考未来的时候，王二还停留在现在，这说明了王二和杨亦凌的思想还有很大的差距。这个世界上有太多的东西牵绕着王二，王二有太多的东西不忍舍弃。就是在对世间事物的价值产生怀疑的时候——不是怀疑事物的价值小，而是每个事物在王二心中都占有太大的价值，土鳖王二开始将目光转向电脑。花了两千块钱王二从一个大四的手里捧回了后来摆在王二书桌上的电脑。\n开始时，王二对电脑一无所知，他在买电脑前甚至妄想买了后写个程序什么的。事实证明后来的王二并没有成为什么黑客，倒是中了不少灰鸽子；并没有编出一行程序，虽然买了本c语言；并没有欣赏多少经典电影、音乐，倒是看了不少毛片；没有写出什么震铄古今的文章来，倒是在论坛里灌了不少水。\nchapter10毛片 我不知道王二是怎么思考他的电脑的，他叫它儿子。每天王二都会调教他的儿子。通常早上起床的时候王二会说：胖子，把老子的儿子叫醒。 于是，胖子就异常殷勤的把王二的电脑打开。\n对了还没有交代过我们的宿舍成员，虽然这并不太重要，但是为了不让大家觉得王二生活在空中楼阁里，我还是要透露点内幕：王二宿舍四人，我和王二大家都认识了，还有一个是胖子，湖北的，典型的奉行攘外必先安内哲学的湖北佬，我很喜欢丫。陈北，河南人，英文名是baby chen,如果他要有一个英文名的话.\n王二的这些行为都在可容忍的范围之内，最不能容忍的是王二通过他的儿子看毛片。这是王二的可鄙之处。我想如果未来王二有了儿子，如果以后他还会有老婆的话，那么王二肯定会教唆他的儿子帮他买黄片。\n对于看毛片王二这小子是有前科的。那时候，王二还没收养他的儿子。还没有儿子的王二经常拉着我去教学楼的机房上网。那时候上网需要一张贴有你的照片的纸。想要上网就需要去提前排队，被拦在门口的工作人员画押之后方可进入。并且机房通常是没有耳机之类的，为此上网的时候还必须戴上耳机。\n那天进门的时候，王二一心记挂着毛片，急不可耐的脚步绕过要给画押的值日生就往里走。值日生小女生一把抓住王二说：急什么，是你啊，拿来。\n王二像被从梦呓中叫醒，看了小女生一眼说：是你？\n小女生往下看了一眼，说：是啊，今天袜子没穿错。\n如果读者没有忘记的话，这个小女生正是何小舟。\n王二那天就窝在一个靠边的角落里看黄片，他让我坐在旁边。瞪着发光的眼睛等待着网络快车缓慢的下载进度。通过桌面的振动我能感觉到龌龊的王二正在处于一种兴奋的煎熬之中。王二看毛片的时候，同样显露着他的龌龊本性，通常王二看黄片时会将real player播放器拉小，把鼠标放在最小化的标志上，这可以看出王二的不专业。后来，王二进步了，他会将手指放在windows和D键上。但那时候的王二还嫩。当一个身影走近时我用脚碰了碰王二，没反应，快走近了，我只好用手拉了他一把，王二转头，看见何小舟走来，慌乱中王二的卑劣的右手食指无奈的按下去，却将屏幕最大化了。\n小舟看了一眼放在桌子上的王二的被划过押的上机证说:王二，你点错地方了。 王二张大了嘴没说话。\n我猜他想说：姑娘，丫的又是你。\nchapter11女人如衣服 王二和我今天马上就要毕业了，照学士服照片的时候，王二提前走了。王二在迷惑，在送走同学之后，留下的是什么，当大家都在抢着照相的时候，王二确发现自己所能抓住的仅此而已。为此，王二很悲观。由此，我们可以看到，四年之后，王二依然有一颗伤感的灵魂。\n衣服，并不简单的就是衣服。大二下的王二已经感受到这一点。那时候王二还迷惑于杨亦凌的美貌与智慧。每天陪着杨亦凌上自习的空档，王二已经感受到了的痛苦。\n有一天王二对杨亦凌说：咱弄套情侣装吧。我刚瞧过，商业一条街新开了一家。\n杨亦凌说：傻不傻啊，小孩子的游戏。\n也许，在杨亦凌的眼里王二一直很小孩。就像后来王二所感受到的一样。\n有时候王二很疲惫，也会看自习室外的美眉，杨亦凌就会靠近王二的耳朵说：好看么？ 王二会说：那不叫好看，那叫敢露。\n说话的时候，王二会故意认真的看着母夜叉。杨亦凌第二天就会换件衣服。对于这种游戏，王二和杨亦凌乐此不疲，直到有一天，王二发现杨亦凌疲惫了。\n对于榆中，四年后留给王二的是什么？除了图书馆和教学楼，王二想是对榆中女孩子的衣服的记忆了。像很多人说起榆中一样，王二后来也习惯于把榆中称之为“乡下”。而榆中女孩子的特点就是穿衣服特土。\n一年半后，王二从榆中校区搬到医学校区，望着满眼的女孩子，王二说，城市真好。\n榆中究竟怎么啦？当王二后来想起榆中的时候更多的是什么？大一时的王二有时会思考女孩子穿什么衣服才漂亮。\n春天的时候，王二说：“春天到了，女生都像花一样开了。”王二说“花”这个倒霉字眼的时候带着拖腔，每每独自品味良久。\n夏天的时候，王二说：“丫的，这么粗的大腿也拿出来凉。”\n秋天的时候王二说：“身高没我高呢，穿个靴子，快到膝盖了，怎么就没点自知之明呢？”\n冬天的时候王二说：“完了，以前不知道什么叫胖。”\n我和胖子很厌恶王二的虚伪，有的看，看就是了，还得瑟个什么劲。大四的王二还恋恋不舍地回了趟榆中，面对着人烟寥寥的空旷校园，王二沉静得连一点奋斗的欲望都没了。就像原来王二假装学佛时在宿舍播放《准提咒》的时候，王二的一个师弟所说的一样。人呢——对王二来说，确切的问题应该是女生呢？除了教学楼和图书馆自习室外，王二再也找不到了。人都闷在宿舍里，夏官营大学像一个囚笼，这里的囚徒连出来望风的欲望都没有。\n现在的王二说，在榆中，我除了谈恋爱和读书，什么都没干。\nchapter12 影吧 如果读者还记得，有一天失落的杨亦凌和王二沿着南区的柏油路走出了学校大门，那天杨亦凌的心里满是惆怅，王二的心里除了同情还有不轨。走出校园的杨亦凌和王二同时发现，他们做出了一个错误的选择，因为校园外一片荒芜，除了买衣服的地就是吃饭的地，当然还有上网的地和租房子的地。\n初次深夜双双外出的两个夜叉到底是没有勇气去租房，上网也不对劲，到底是母夜叉更机警。她说：王二，咱们去影吧。\n于是，王二就去了那个让他一辈子都不会忘怀的地方。\n付了15块钱后王二和杨亦凌进入了一个被薄薄的木板隔成的狭小空间。除了床和被子外，就仅仅放得下一台彩电和DVD了。王二搜索了半天才在一堆黄色影碟里找了部《色即是空2》，杨亦凌瞪了王二一眼，王二又费力的摸索了半天，居然找到一个《悲情城市》的碟片。台湾本地人对外省人的反抗是激烈的，不管是詹宏志和侯孝贤的这部影片，还有其他很多，例如《牯岭街少年杀人事件》。当夹杂着外省人、日本人、本省人的家族纷繁复杂的成员让王二不胜其扰，听着磨耳朵的闽南话，王二开始走神。\n随着隔壁音响开始变强，喘息的声音开始在空气中渗透。王二听得出神。\n杨亦凌说：王二，什么声音？\n王二没有回答，隔壁的声音开始变强，杨亦凌一下子明白了。\n之后王二和杨亦凌在十分的尴尬中继续看《悲情城市》，王二一下子理解了本我和超我的激烈斗争。我想那时的王二也许还没意识到这是因为他的本我过于丑陋，超我则还对人所具有的神的本性恋恋不舍。\n就在宽美和哑巴文清静静吃饭的时候，宽美夹菜放到文清碗里。静静地盯着屏幕的杨亦凌说：王二，梁朝伟每年都给刘嘉玲送花。\n如果是现在的王二他一定会说：关我什么鸟事。\n但那时的王二还比较较真，他说：为什么女生都喜欢送花呢？\n杨亦凌瞪了他一眼，但王二显然没有停下来的冲动，他望着杨亦凌说：花是植物的生殖器。人与花的不同是一个是隐秘而晦涩的，一个是开放且光鲜的。送花就是把植物的生殖器阉割下来然后送给喜欢的人。你为什么喜欢我把植物的生殖器送给你？\n据说，杨亦凌愤怒地说：王二，去死。\n我能想象杨亦凌面对王二这些弗洛伊德主义者的泛性主义的无奈。可怜的王二沉醉于思想，却搞不清楚母夜叉要王二送花这个简单的问题。\nchapter13毛片续 王二这个人总体上是悲观的，但他更重要的特征是理性的。原来的王二对理性的坚守到了无可附加的地步。没有经过思考的事情王二就不予理睬，这主要表现在王二的反应很慢。这是王二的一个悲剧。例如，上课的时候王二头顶的投影仪啪一声爆了，下面的王二毫无反应，倒是英语老师迅速地把王二拉了起来。英语老师说：王二，要死了，也不动下。 事后王二说：我看到了，但我还没想清楚。\n你很欣赏王二吗？然而这是和实践理性相违背的，很多事情是在我们实践之后才能有所感悟的。形如阿罗所说：learning by doing.干中学。但是王二却妄想靠着纯粹理性格物致知。对于这一点，我一向对王二充满了鄙夷。\n后来王二终于体悟到了这一点，大二下的一天夜里，王二被电了。傻逼王二拉线上网，原因大家都可以想象的来。卫生间里的王二把插头插好，拉着插座往宿舍走，却没发觉线的绝缘外皮开裂了，王二一下就被电的精神百倍。后来，王二说，那一刻他就意思到自己被电了。于是王二生出了一种恐惧，之后王二被电的不由自主地跳了起来。王二说他跳起的一瞬间突然感觉到很爽——废话，离开地面了啊。之后王二就像僵尸一样跳着往前走，并终于摆脱了黏在他手上的电线。\n我问：王二，你是思考清楚了才跳的吗？\n王二说：靠，丫的，大爷就要挂了，还思考个p?\n可见上帝是根据不同人的特点进行启蒙的。王二这样的就欠练。\nchapter13鬼的存在 大二下的我们经常夜里拉线上网，王二的看片品味也开始提升。原来的王二十分迷恋MAZE,北大的一群人搞的一个资料下载软件。有时候我们还真得佩服北大，北大的自由民主和兼容并包让王二在大二才进行了近乎全面却不太健康的性教育。围坐在王二的破显示器前，我们一个个故作镇静地说，“王二，开始吧。”\n最初大家只是静静地看，然后都似乎满怀心事的睡了。看的多了之后我们就开始讨论，整个宿舍存在着一种近乎完美的争鸣的气氛。\n胖子说：这样下去不行，非看出毛病来不行。\n王二说：我看到现在，才看出来自己的毛病。为什么咱们没有性教育课？\n我说：丫的，得了吧，你现在不也自学成才了嘛。\n后来王二品味提高开始看动画片，之后王二就开始评论别人，“丫的，看什么呢？日本AV，真没劲。”“呦，胖子，进步了，看动画了，什么鬼作，你有点出息成吗，那是老男人看的，你还很年轻，意淫个什么劲？”\n后来，《色戒》出来后，愣是没看懂，之后王二就开始猴急的寻找《色戒被删减部分》，黄天不负有心人，终于被王二找到了，还是高清晰版，看过之后的王二终于明白了。 王二说：丫的，必须禁，我党特务被敌特诱惑，情色高于政治，这怎么能行？汤唯就是一个没有理想的女人，禁，坚决要禁。\n厌倦了黄片之后的王二开始寻找新的视觉盛宴，在杨亦凌的帮助下王二找到了，因为杨亦凌喜欢看恐怖片，王二就开始努力想她靠拢。刚开始王二认为自己经过大风大浪，根本不怕什么恐怖片，于是就拉着杨亦凌的手去看《午夜凶铃》，出来的时候杨亦凌开始痛骂王二，因为王二把母夜叉的据说是“柔弱无骨”的手掐出了两个红印。\n王二回来就开始看《沉默的羔羊》，看到了剥去人面皮时候，王二使劲的咽了口唾沫。后来王二又看了《解剖学教室》，看了三遍把剧情看懂之后，王二一夜都没有睡着。那段时间的王二备受折磨，看人的眼神都变了，评价人的方式也变了，比如王二说：胖子，你丫的太纯洁了吧，连恐怖片都不看，你是不是害怕发现自己是多重人格啊。\n后来的王二实在坚持不住了，他决定看鬼片。这再次彰显了王二的与众不同。\n我说：王二，你丫连恐怖片都看不了，还看什么鬼片。\n王二说：你懂什么，鬼都是具有健全理性的，不像人，连自己是多重人格都不知道，寻找杀人犯，到最后发现是自己。除此之外，我对鬼有一种发自内心的亲近。唯物主义最大的问题就是让人的灵魂一下子没有了家园，如果我死后可以变成鬼多好啊，那样我就可以自由的去干很多事情，我可以自由的出国，看韩剧，不交门票看比赛\u0026hellip;\u0026hellip;如果真的有鬼那么我就找回了人类的精神家园，颠覆了唯物主义哲学的桎梏，在死后还可以进行我的不间断的思考。多么幸福啊。\n末了，王二仍恋恋不舍地说：“要是有鬼就好了。”\nchapter15失乐园 当王二回顾自己与杨亦凌的感情经历的时候，王二习惯于说自己从没有开始，这表现了王二的自欺欺人。王二的原话是：我没有得到任何东西，没有得到，就没有失去。\n这充分表明了王二的脆弱的逻辑和软弱的受害者心理，就像王二家被小偷偷了，王二还说我没有从小偷那得到任何的从西，没有得到，就没有失去。\n但小六和胖子等人居然信了。他们对王二表示同情。虽然我想说我对此很遗憾，但是我内心的想法是：太好了，早tmd该break了。王二怎么说也是个优秀青年，没必要吊死在杨亦凌手里。\n但是王二却不得不面对的一个现实是杨亦凌消失了，从王二的身边消失了，再也不会出现。这很残酷，但我不是琼瑶阿姨，我要再次声明夜叉夫妇掰了。也希望读者早点接受这一点。\n冬天过去了，春天就来了。杨亦凌走过了她的鬼魅般的考研生活，06年春天，杨亦凌去北京复试了，之后就回来进行了她的毕业旅行和形式主义的毕业。也就是在这个时候，王二开始走出了王二的视野。\n那天早晨杨亦凌和王二站在图书馆四楼的书库里，阳光很亮，透过大的落地窗照在杨亦凌脸上，宛若仙子，如果存在仙子的话。\n这让王二内心生出一种幸福感，但一会后这一切在瞬间瓦解,宛若一个玻璃的世界被王二不小心打破了。后来，王二这样想。\n杨亦凌说：王二，咱们分手吧。\n王二以为她开玩笑，因为也有一个无知的网友在校内上说‘女人习惯于提出分手，那是因为她们迷恋于被挽留’，王二伸出手戏谑道：好。\n杨亦凌以奇怪的眼神望着王二的眼睛和异常突兀的手。\n王二说：我和你在一起那么久了,怎么说也给点青春损失费吧！\n杨亦凌说：王二，去死。我说真的，我们家里也觉着我们在一起不合适。\n“为什么？”王二说。\n杨亦凌说：我已经有了新的男朋友。\n“谁？”王二说，“我杀了他。”\n杨亦凌冷笑道：“王二，你流氓，你要爱我就该祝福我。”\n王二：他才流氓，勾引别人女人，让我看见我就杀了他。\n杨亦凌：王二，我们不合适。\n王二沉默很久，杨亦凌注视着他的眼睛。王二说：好吧，我祝福你们。\n悬在王二眼中的泪莫名地流出来，王二转身往外走，没提防撞到一个人。被撞倒的女生站起来对着王二吼：王二，又是你，\u0026hellip;..\n“一边去。”王二看了一眼被撞倒的何小舟，回头对站立不动的杨亦凌说：我祝福你们一生一世，直到你们分手。\nchapter16失恋 王二是在被甩了之后才开始失恋的。所谓失恋不过是失去了可以爱的对象。如果一个人拒绝了你，你却还深爱着她，那么这就不是失恋。因为你还有爱慕的对象，只是你通过消除信息不对称的行为弄清楚了一件残酷的事情——那就是你爱的人并不爱你。王二则没有这么幸运，这是王二的卑劣所造成的，杨亦凌的移情别恋让王二一下子明白了杨亦凌的不可爱之处。如果说王二虽然龌龊但仍然不失赤子之心的话，杨亦凌就是一个完全世俗化的女人。\n但不管怎么说，作为一个符号，“甩”的能指当一个人离开另一个人的时候，其所指却是甩人者对于被甩者的作为恋爱对象价值的否定。这通常并不是一句简单的“我们不合适”所能掩盖的，它所传达的是甩人者在被甩者身上找不到她所必须的价值——容貌、才华、金钱、前程、性格、气质。\n而这些价值又可以分为短期价值和长期价值。有的人看重短期价值，如花容月貌、金钱、权势。有的人会看重长期价值，如前程、才华、性格、气质。\n王二身上究竟是少了哪种母夜叉所必须的价值？王二后来一直在想，自负的王二认为自己不缺乏容貌，虽然不是很帅；不缺乏才华，虽然略显平庸；不缺乏前程，虽然仍很遥远；不缺乏男人豪爽豁达的气质，虽然有很多时候略显龌龊。王二有着所有的长期价值。但是王二却缺乏杨亦凌所不能容忍其欠缺的短期价值，金钱和权势。杨亦凌会看重王二所欠缺的金钱和权势吗？对此，王二不敢肯定。他不愿意如此彻底的否定杨亦凌，虽然我常认为应该不怀好意的如此测度。\n王二转而求助于另外一个因素：因为寂寞所以恋爱。\n寂寞和孤独是一种难以避免的生活状态，作为社会人的我们都在选择逃避寂寞和孤独的路径，王二曾经选择了书本，庆幸的是王二直到现在都没有放弃这个选择。所以，王二对于爱情的宽容度就更高——我是指王二不会过多的苛责爱情，王二并不指望从爱情当中获得精神的解脱，王二没有给爱情太多的负担，虽然他坚持的是执子之手，与子偕老，终生相守，相濡以沫；在这一点上杨亦凌和王二存在根本的不同。\n规避寂寞同样是一种短期的价值，虽然杨亦凌认为规避寂寞是一种长期选择。这恐怕是杨亦凌接受王二并甩掉王二的根本原因。\n不管怎么说，王二突然没有喜欢的对象了。\nchapter17空档期 人的心理真的很奇怪，我们可以对得到的事物熟视无睹，却不能容忍一个原本属于自己的事物离开自己，这或许就是根源于人的占有欲望的劣根性。不幸的是王二也有这种劣根性。\n王二开始进入一种悲伤欲绝的状态。王二决心不再关注外部世界，他开始不在意自己的言行举止，迈着八字步低着头在校园里做无意识行走。\n上课的时候，老师让王二回答问题：王二，你来分析一下如何得到腺嘌呤的结晶体。\n王二说：嗯哪，对，好。\n我劝王二：王二，为了个女人没必要。\n王二回答：嗯哪，对。\n王二开始进入一种极度温顺的生活状态，大二下了，王二替我们整个宿舍签到。\n点名的时候给我们宿舍答到。答到第三次时，老师说：同学们都很失落啊。\n后来我逐渐明白王二进入了一种自我保护，就像李连杰版的《太极张三丰》一样。可怜的男人。\n但之后王二的行为就堪称犯贱，具体表现是他开始上自习。王二的自习过程通常是这样的：占个位置，趴在桌上大睡，眯眼假寐，开始看书，走廊散步，抽烟，回来再看书，走人。\n后来，王二说那是因为他处于空档期。\nchapter18 烟 写到这个时候我又开始看《苏丝黄的故事》，感到很沮丧。我不知道苏丝黄是怎么想的，如果她还有一个专栏的主题的话，那么我现在就处于思考这个短篇主题的时候。王二的在L大学的故事如果能够有一个主旨的话，那应该是对大学的反思。\n大二的王二也在思考自己的人生了，那天王二开始抽烟，王二不喜欢说吸烟。他觉得男人就应该有豪放不羁的气质。\n那时候王二所能接触到的兰州最便宜的香烟是海洋，三块钱的。王二笨拙地撕开软包的烟盒时，感到异常的亲切。烟放在嘴里的时候，王二突然有了一种耶稣被钉上十字架的感觉。\n后来，王二跟何小舟谈起烟的时候，王二说：抽烟的时刻，我有一种殉道的感觉。\n我无法理解王二的行为，对此，我只能说王二过于纯洁。可怜的王二坚持认为吸烟对于自己和他人都有很大的危害，虽然他不反对我们这些人在宿舍吸烟，但是后来王二也加入了在宿舍吸烟的行列。这个时候的王二更加沉默，我和小六都是习惯性抽烟者，对我们来说吸烟就像是呼吸一样自然。当我们摸遍身上的口袋都找不到烟时，我们习惯于蹭王二的烟。王二就会很小气的说：你们简直是暴殄天物，浪费香烟。\n在我和小六的启蒙下，王二开始玩弄抽烟的技巧，把一团污浊之气吸入嘴唇和齿间，王二把烟吹出，一股浓烈的烟柱就从王二的口中喷涌而出。这个时候他通常要说话，他看了一眼何小舟说：要不要来一支？\n何小舟说：我没失恋。\n王二说：草履虫不会失恋，我在宿舍培养的草履虫死了，就在昨天。\n何小舟悻悻道：王二，去死。\n王二抬头看了何小舟一眼就头也不回的站起来走回教室。王二习惯于在自习的间隙走到A区和B区之间的地方坐在巨大的落地窗前抽烟。\n王二喜欢等待下课，当很多人如潮水般涌出教学楼的时候，王二就会异常的孤单。王二喜欢这种感觉。恰如一个网友所说，王二的被甩的经过所展现的王二的被否定过程。但王二认为问题比这更严重，他认为自己爱杨亦凌。这一点让我和胖子、小六抓狂。\n让王二无法理解的是几乎每次都能遇到何小舟。以致后来王二开始怀疑何小舟在故意监视他，至于原因肯定是想看王二被戏弄的样子。卑劣的王二根据自己十九年的生命经验推断：何小舟是个虐待狂。除此，王二无法理解何小舟的动机。谈到监视王二所能想到的除了高中时班主任把眼睛贴在在教室后门的洞上观察的情景，王二讨厌被人观察，这充分说明了王二没有成为教师或者名人的希望，那时的王二经常想去在那个洞上涂上一层厚厚的清凉油。虽然后来这个计划一直因为王二的胆怯而被搁置。上了大学的王二开始有时间接触奥威尔，读了《1984》之后，王二开始理解为什么人在全方位的被监视之下会浑身不自在。因为监视者通常都是极权主义者，而王二厌恶被压迫，所以王二决定揭穿何小舟的阴谋。\nchapter19 自杀论 王二开始变得沉默，因为杨亦凌离开的日子快到了。有一天王二对我们说他要去自杀，对此我和胖子都嗤之以鼻，后来也证明我们的鄙夷是正确的。\n那天的王二可以拿了本海子诗集，对于海子王二以一种天然的皈依感，虽然靠近铁路，王二并没有选择卧轨。据说，曾经的L大学可以在黄河边建校，但是后来领导们考虑到大学里会有很多像王二这样的傻逼会因为失恋而自杀，否决了一个绝妙的idea。我们后来就难以理解把本科生新校区建在暴露的铁路边，难道不害怕那些激进的年轻人狂妄而浪漫地卧轨吗？\n但王二总算没有选择卧轨，他留恋西北的大山，王二幼稚地想死在这座荒凉的的山下。出乎大多数人都预料，王二决定去跳山。\n那天是周末，有闲阶级的典型代表王二在备受煎熬之后放弃了在尘世中挣扎的念头，王二在夕阳中向山上走去，他没有吃饭，这样腐烂的时候会好闻些，王二很细心地想。走过一幢幢女生楼的时候，王二莫名生出一种留恋，走过杨亦凌窗下的时候，王二心中的悲凉堵塞理智。之后，王二就悲壮地走向了白虎山，一座后来被改名萃英山的地方，一个王二选择的结束自我生命的对手。\n迈着缓慢的步子，王二感到有些头晕目眩，事实证明吃饭的确是人生中很重要的问题。可怜的王二却拒绝了。\n走上山顶的时候，王二真实地感觉到自己对这个世界的留恋，他沿着山顶平坦的曲线走动，却找不到任何改变的理由。前方有一群人，他们在烧烤。“垃圾。”王二骂道，他不能容忍这个世界对于一个即将离开者的漠视。王二走近他们，他想恶狠狠地瞪他们，事实上王二做到了这一点。在离开的时候，王二突然像海子一样，想尽情地和这个世界的骄傲的物质的无知的人们大打一架，王二捋起了袖子。\n一个女生显然是看见了王二，她丢掉烤肉向王二走来，“王二，是你。”\n王二很生气，他瞪大了眼睛看眼前的这个女人：“何小舟，是你，一直看我出丑很爽吧。” 何小舟能感觉到他的愤怒，但是她坚持说：“是啊。”\n王二转过身去，看着山下，风吹来，王二有庄子御风的感觉，一颗泪开始挤压王二的眼部神经，“活着的人，祝福你们。”\n何小舟很诧异，但王二已经转身跳下。\nchapter20 功利主义 功利主义的早期代表人物边沁认为：有助于产生快乐的行为和事物是善的，反之就是恶的。如果一个行为带来的快乐超过痛苦，那么它就是善。如果一个行为只带来快乐而没有痛苦，那么它就是至善。\n我必须承认，王二的跳山自杀的行为所带来的痛苦远少于快乐，那么以边沁的观点，王二跳山是善举。\n王二从山脚下爬起来，意识到自己没摔死。他脸被小灌木刮破了一道，衣服被撕破了几个地方，王二的头和腿在滚下来的时候撞在输水管道上，刚站起的王二头脑混乱意识模糊，一个趔趄又摔倒在地。\n除了感觉头痛之外，一股撕心裂肺的痛从脚跟传来，“该死，脚崴了。”经常打篮球的王二对此并不陌生。\n阳光的影子已经找不到了，六月的傍晚的风让王二感到很舒畅，回味着从山上滚下的情景，王二心中没有一丝害怕，他感到处于自杀想法中的自己太愚蠢，因为他还没听过从山上一路滚下来自杀成功的。王二苦涩地笑了笑，他感觉不到为愚蠢的自杀未遂感到内疚的必要。\n喘着粗气的王二躺在地上休息，他看了一眼白色衬衫下颤抖的身体，生出一种忽略世界的存在的冲动，王二后来说一个处于狂热和孤独的年轻人的愚蠢的想法是不能当成自杀的充要条件的，既然没有死去的理由，就应当好好生活。\n“我已经为爱情死过一次了。”王二想，“活着就要有所追求，除了爱情和死亡，我可以追求任何有价值的东西，哪怕是追求虚无。”\n但王二没法继续忽略这个世界并延续自己傻逼的想法，因为何小舟跑下山来了。那一刻的何小舟头脑变得虚空，一直以来她没法忽略王二的存在，虽然何小舟一直看着王二的近乎所有在公开场合所展露的傻逼行为，但她对王二的记忆却始终停留在大一开学的时候，与酷爱T恤的我们不同，那时的王二一袭白衬衫，手里握着一瓶纯净水静静地立在体育馆前的队列中，那是要上军训中的军事理论课。从何小舟的视角看过去，或许我们就能看到最为文质彬彬的王二，尤其是他那并不高挑但足够漂亮的鼻翼。之后的何小舟就看到了这个文静男孩近乎夸张地喝水，当她疑惑之际，王二已经离开队列，将手中的空瓶子递给了走过来的拣垃圾的大娘。老人看到了王二的举动，感激地点头。\n从此之后的何小舟就一直没有放弃走近看王二冲动，于是乎我们所有之前的猜测在此处得到近乎圆满的解答。王二这种烂人能有如此造化，必然不是王二优秀，而是看这个男人的何小舟太过特别。充分说明如果王二是属于足够执着的人都话，何小舟就是执着的超人；如果说王二是偏执的话，那何小舟就是偏执狂。\n躺在地上那个王二沉醉于幻想并耽于思想得到救赎的快乐，他显然没有注意到一个人正在注视着他，我必须强调这是一个偏执狂对于偏执者的注视。\n何小舟说：别动，我扶你起来。\n她上前去扶，王二用近乎愤怒的眼神看着她，他推开了她的手，自己站起来，但他才迈出一步就摔倒了。\n几个和她一起跑下的同学看着他俩叫：“盒饭，回去烧烤。”\n何小舟扶住身体前倾的王二，不理会同学的目光和王二的表情，何小舟贴着王二的耳朵说：“咱们走吧。”\nchapter21 挟持 你相信爱情吗？王二在滚下山后，领悟自己应该有新的追求，但他显然没有把爱情放在追求的目标中。\n当何小舟搀着他走下山的时候，王二感觉很不舒服。不过他并没有多想，王二或许只是认为何小舟良心发现而已，这样王二第一次对何小舟放松了警惕，也注定了王二第二次情感曲线出现了一个并不平滑的转折。看来傻逼王二太天真了，他怎么就愣是没看出何小舟眼神中所隐藏的蓄谋已久和永不言弃？\n走过山下的教学楼的时候，王二突然很不好意思，他要挣脱何小舟的手时才发现那丫头片子想熊瞎子抱住在水中逮住的鱼一样愣不撒手。\n在王二尝试几次未遂之后，何小舟突然转过身看着王二说：“别动，老实点。”\n不想继续意淫，但故事的发展是这样的，盒饭和王二去了校医院，王二经检查无碍，又被盒饭挟持着送回宿舍。\n出校医院门口的时候，一个熟悉的身影闪过，是母夜叉杨亦凌。王二迟疑一下就被盒饭拉着走了，这个丫头片子能量真大。\n但杨亦凌显然看到了王二，从外面买水果回来的杨亦凌几步赶上来对王二说：“她是谁？” 王二还没来得及开口，盒饭就说：“我是王二的女朋友。”\n杨亦凌恶狠狠地看了王二一眼，王二赶忙说：“你别误会，我摔倒了，恰巧她看到，她见义勇为呢。”\n苍白的独白换来的是两个女人的白眼，盒饭不等王二说完，就拉着王二走了。\n王二那一刻一定觉着自己方出狼穴又入虎口。\nchapter22 许三多和斯密 “许三多，你不是傻，你是太较真。”这是片中人物对许三多的评价。当许三多被分到红三连五班这个被称之为光荣在于平淡、艰巨在于漫长的荒野之中。本来一个强人却天生一副熊样的许三多，替所有的人整理内务，因为伍排长说过在内务方面要互相帮助。\n许三多显然不是一个我们传统上所说的好兵，队列不好，不够机警，所以他才被分到一个最差的班看守助训练场，五班被扰的鸡犬不宁，因为所有的人都甘于堕落，而许三多却一步一个脚印，从整理内务入手，玩空枪，在一个团结高于军容军纪的班里，许三多是个另类。但许三多的精神在于坚韧。或许，许三多最初不是优秀的，但他始终坚持下去，却成为最优秀的士兵，在这方面，许三多体现了不放弃的精神。许三多在雨中接受了第一个命令：修一条路。他冒着雨就去了，从此许三多就开始修路。\n许三多最让人惊讶的是他认为修路是有意义的。木讷的许三多是如何推论出这个结论的我很疑惑。从斯密的角度看许三多就是一个土鳖傻逼，斯密认为社会分工带来专业化和效率的提高，并能提高整个社会的生产效率。因此，如果让一个土工部队来修就会很快修完。 许三多所展现的是一个近乎哲学化的问题，或许根本不合乎经济的基本原则，但与庄子中所说的不追求技巧不同，许三多所坚守是人的价值，人必须有追求，哪怕追求虚无。许三多一起看守荒原的战友也有追求，如班长研究过桥牌，李梦想写小说。但唯有许三多才矢志不渝的坚持。\n后来毕业的时候王二才完整的看了《士兵突击》，王二突然很庆幸自己像在荒原上一样坚守了下来，更庆幸自己改变了自己的人生轨迹。\n欲死不得的王二回到宿舍，他开始思考人生，迫于生计的人们经常忽略的不是外部的世界，而是内心的想法。学了那么多年理科的王二有一种冲动，他想回到人文之中去，因为他怀念初中时第一次读庄子的感觉。与老子和孔子不同，庄子对于个人内心的皈依与追求达到了一个无以复加的高度。\n“我也应该如此汪洋恣肆地活着。”傻逼王二想，他再也不想对着实验室里的器皿和动植物奸尸了，天生具有幼稚的浪漫主义气息的王二厌恶标本，与之相反，王二更喜欢富有活力的自然、思考、历史文化。\nchapter24 理念的阳光 王二在欲死不成的第二天早晨的强烈的阳光中醒来，头有些痛。\n那闪耀的太阳曾经是八十年代的海子倾尽全力赞美的对象，权利意志的扩张让我们崇尚英雄，包括海子，都在贲张的气氛中挣扎，温润的外表下掩盖的火山在沉寂中酝酿爆发，在偏僻的政法大学外的小酒馆里海子与人大打出手，眼镜破了，但是海子确认为自己获得新生。耗尽生命赞美的太阳到底没有让海子看到现实的光明，他选择了卧轨。 然而却是同一个人却写下了“面朝大海，春暖花开”这样超然物外并充满了乐观的诗句。八十年代的诗人是一个矛盾的主体。后来，王二才明白这乃是存在主义遭遇虚无在中国的镜像。\n王二想到杨亦凌，曾经的美丽变的异常遥远，宛如一个虚假的影像，而王二却一直认为自己所面对的是一个散发着刺眼光芒的理念。\n“柏拉图的伟大之处在于对于理念论的发展。”曾经对柏拉图不屑一顾的王二想,“理念宛若太阳，它才是真实的存在。”\n在哲学导论的课上听到老师讲到天国的理念投射到人间，世间万物不过是对理念的不完美的模仿这句话的时候，王二也曾经报之以轻蔑的笑容。但此刻王二的笑意早已变形。对于现实中的杨亦凌才是完美的存在认识王二从来没有改变，但是曾经的美丽此刻却已经烟消云散。王二再也感觉不到杨亦凌的存在，心中甚至没有了痛的感觉，与杨亦凌分手后在自习室里突然袭来的深不可测的痛苦此刻宛若浮云，似乎永远地离开了。\n感情在时间里被消耗一空，王二想这显然是是不完美的，那么现实的杨亦凌就不是完美的存在，她只是对于完美理念的不完美的模仿。\n此刻的王二重新审视周围的世界顿感无味，如果连自己曾经如此深爱的女人也是虚假的不完美的模仿的话，这个世界还有什么是真实的完美的存在呢？过去的存在因为仅仅是不完美的模仿所以随着时间消逝了，有的仅仅留下躯壳，有的连躯壳也没有留下。那么还有什么真正的不被任何破坏的保存下来了呢？\n此刻王二一下子意识到一切个体，不管是人抑或是动物对外界的认识是千差万别的，而这正是作为不完美的影像在反映完美的理念时的局限性。所以，大象可以感受到次声波，蝙蝠可以感受到超声波，而人类却只能在更为狭窄的波段中感觉声音。同样，有的生物可以看到红外线，有的生物可以看到紫外线，而人却只能在更为狭窄的范围感受光的存在。同样人的味觉嗅觉触觉也都是对于外物的在一个狭窄的范围中的感觉。人类并不能在一个完整的范围中感受外物的存在，所以人的五感在更大程度上是虚假的。\n王二有一段时间沉浸在找不到真实的存在的痛苦中，直到这一天的早晨王二真实的感受到了刺眼的阳光。\n“理念，没错是理念。”王二想，“宛若太阳的理念。”\n一切历史都会随着时间推演，只有理念不灭，譬如人类所创造的散发光芒的文化可以完美地存留下来。\n“我要去追寻理念。”傻逼王二对着太阳说，“追求人文理念。”\nchapter 25 纠缠不清 我一直以为那是傻逼王二人生的转折点，大二下的时候王二说受够在实验室里作那些早就知道结果的实验，有机实验课上他同时打破了酸管和碱管，破了我们损坏实验仪器的记录，我要转到文科去。\n对于王二的想法我是嗤之以鼻的，虽然我们这些被高中生物课本上那句“21世纪最有前途的学科”所骗的人早就意识到自己是被骗了，学生物这专业就业不好，也不是每个人都有足够的天赋对它感兴趣并且喜欢做研究，但并不是所有的人有勇气离开这个专业，我们都习惯于现在的或许并不舒适但总算安稳的日子，我们害怕面临改变的时候的更为繁琐的细节。\n但是王二却恰恰在这里显示辅导员老师了他的纯真的激情，这是西方浪漫主义在中国的滥觞。王二开始草拟各种申请，去院办磨辅导员，到本部磨院长。当然结果是没门，因为王二想到转专业的时候已经是大二下了。于是乎官僚主义以一个冠冕堂皇的理由击败了浪漫主义。\n但王二的运气总算不坏，L大学还有第三条道路，也就是“2+2”，也就是说在大二下，如果对既有专业不满意，可以通过选拔，重新选择一个专业，但是06年的“2+2”已经濒临消亡，只有新闻院和生科开设了“2+2”专业，前者是网络新闻专业，后者是生物技术专业，因为王二本身是学生物的，当然不会选生科，那么就只剩下了网络新闻了。王二实际上仍然没的选择。\nchapter 26 旁观者 一个７５岁的老太婆自然不会损及这个年轻人的名誉，但要是一个陌生的老太太在他车内死去的话，他要如何向世界解释？　－－－德鲁克.《旁观者》\n王二没有想到过了06年的暑假，自己就离开原来的院了。虽然这正是他所想要的。但是，离开总不让人踏实。我不知道他这是否是他处于浪漫主义的虚伪的自恋情结——因为自恋，所以美化自己曾经坚守的事物。\n我说：丫的，王二，你就这样走了。\n王二说：我不想离开大家。\n事实是不久王二就离开了我们这个安乐窝，剩下的日子，我只有和我的小四一起度过，虽然还有胖子还有陈北，王二的这种冷酷让我倍感大学的漫长，我也该检点自己了。 但我恐怕王二在网络新闻班的生活也远没有他所预期的那么好，事实果然如此，因为他发现盒饭－－何小舟也在那里。她在跟几个女同学在前面窃窃私语。他知道自己是应该上前打个招呼的，但是这个时候的王二却不想做表演者，也不想做直接的聆听者，他希望做一个旁观者，从一个完全不同于他人的视角看问题。或许，他会有完全不同的发现，当然不一定是范式的改变，也许只是给别人留下一个性格腼腆的形象。但可怜的王二连这个也没有能够如愿。\n小小的鼻子，小小的嘴巴，明亮的眼眸，扎个马尾辫，较之杨亦凌的张扬，何小舟显然更为可爱。但王二是不会注意到这些的，他的视线在稍微迟疑之后就定格在何小舟身边的一个女生的身上，一个穿着一袭白裙的高个女生，她侧着身子，高高的鼻翼，坚毅的眼神，那一刻王二简直想要跳起来。\n“杨亦凌。”王二在心中大声的喊到。当然，已经日渐稳重的王二并没有叫出声。\n他定睛又看了一眼，才分辨出来她也许不是杨亦凌，因为她扎着耳环，长长的耳环分外招人，这个是杨亦凌所没有的；这个时候杨亦凌也应该在北京，而不是这里。\n当然了，王二并没有排除杨亦凌回心转意并且扎个耳孔戴上耳环来看自己的可能。所以傻逼王二走上前去，对着那帮女生招手。\n“早啊，我叫王二，也是网络班的。”\n何小舟转过身，“早，你的脸还真适合贴胶布。”\n王二摸着跳山给自己的额头留下的创可贴说：“为什么？”\n“因为你面目可憎。”何小舟说，但她已经注意到王二的略显游历的眼神了。以王二的两眼的视角做直线，沿着直线延伸的方向，何小舟一下明白了王二那罪恶的眼神在看什么。\n或许没有任何一个人注视另外一个人会像王二一样专注，他的眼神像麦芽糖粘住牙齿一样粘在了耳环女的脸上。忘了交代了，王二的审美比较其特，或许我们可以称之为看面相：他只关注女生的肩以上部分，他一般不会关注身高，因为需要他仰视的女生很少有比他矮的；他不必担心年龄，因为这些在脸孔的皱纹上显露无遗。\n“噢，忘记给你介绍了，这个是我的朋友，叫李琳。”\n“你\u0026hellip;\u0026hellip;是李琳？”\n“你好，我叫李琳，法学一班的，我是小舟的老乡，刚才正好看到盒饭也这。就过来聊会中秋老乡聚会的事。”李琳很镇定，她肯定经常遇到像王二这种处处对她留情的人。\n得到肯定回答的王二一下子没了精神，他想原来不是杨亦凌。\n“哦，很高兴认识你。”说着王二就走开了。\n李琳或者什么名字也好，此刻都没有了意义，她们全变成了理念的不完美的模仿。 chapter 27 不会经历的奇遇 萨特在《恶心》里叙述了一个孤独的灵魂奇遇，他没有能够幸免，不断的遭遇恶心，他把自己埋藏在世俗里，他为自学者的单纯叹息，为前女友的决绝叹息，为历史中的存在者叹息，但他却无法改变这一切，面对过去的场景，他感到恶心；面对他人，他感到恶心。他最终决定离开小城，去写书，一本关于不会发生的经历的书，他要描写一种美丽，让他人看到它感到羞愧。\n如果说存在必须找到一个对立面才能存在的话，那么空虚就不可或缺了。一个人只有在孤独的时候，才会认真地体悟存在。\n王二没有想到在自己19岁的人生会经历充满如此多的波折，在一年多的时间里他经历了恋爱、失恋、自杀。现在对人生的思考也是王二所意想不到的，大学总还是有很多精彩的地方的，但王二此次却不能从那些社团活动、班级活动、体育活动中得到任何乐趣。 在暑假里，王二读完了凯恩斯的《通论》，这本书王二是一页一页地翻过去，经历了杨亦凌之后，王二有很多问题想不清楚。\n但我更愿意认为他不愿意去想清楚。杨亦凌没有他所想的那么好，或许这就是答案。对于这个问题，我曾当面对王二说过，没理由为了一个把心系在天上的女人牺牲天下苍生。你跟着那个女人只会变成一个胸无大志的渣滓。\n王二反驳到：把对方看成恶的，很多问题都会迎刃而解。\n但在《通论》凯恩斯却开始从个体的人存在的时间来考察人的经济行为，毕竟个体的人也只是有限的存在，很多东西我们并不能找到一个有效的方式使其超越时间传承下去。而未来又有着太多的不确定性。天有不测风云，生命可能在意外中陨殁，金钱可能一夜之间失去，房子可能被付之一炬。反倒不如“有花堪折直须折，莫待无花空折枝。”黑格尔、迪尔凯姆、马克思都十分关注分工造成的极大风险，认为那样会撕裂社会的道德基础。罗尔斯的无知之幕也依赖于人生的不确定性。回避了不确定性，一切制度都是有效率的。很多人会选择活在当下，这样就可以解释很多看似不理性的行为。凯恩斯所开创的宏观经济学正是建立在这样的一个前提下，在此基础上，他引入了各种偏好，例如流动性偏好，为什么偏好流动性，为什么愿意持有货币呢?凯恩斯将人们的货币需求是出自于以下三种动机：交易动机、预防动机和投机动机。除了流动偏好外，还有时间偏好，当人们的收入增加时，即期消费也会增加。当然增加的幅度小于收入增加的幅度。\n杨亦凌的有限性在于她同样也生活在凯恩斯的场景之下，她没有能够超越它，她小心地回避不确定性。\n王二或许也感觉到了一种不得不去面对的绝望：生活已经如此残酷。\n面对这种生活，王二只感觉到悲凉，连恶心的决绝都没有，但他同样不想被它所束缚。历史，是我们很难去描述的，每当我们挖开故纸堆去翻阅揣测遥远的古人的时候，我们都堕入了文本的束缚和我们自身认知的束缚。过去的存在让我们无法鼓起足够的勇气去回顾，因为每次真诚地回顾所带来的都是被篡改的历史。\n与王二不同的是，杨亦凌除了拒斥过去之外，她同样拒斥未来。她只生活在当下。 但傻逼王二却决不允许自己从理想主义的迷梦中醒来，他拒斥过去，他热爱当下，但他对于未来之生活却有着更高的向往。\n我想，王二或许也想像萨特一样，对有德性的生活向往不已。不同的是萨特笔下的男主人公要写一个不会发生的有德性的生活的故事，而王二却要实现自己所热爱的崇高的生活。\n结尾 这是一个尾巴，难道围城就是这个样子吗？快乐如此短暂，仿佛才刚刚开始，却已经画上了圆点。再回头看的时候，已经是几年甚至几十年以后了。王二跳脱了短暂的爱情，在理念的阳光里寻找自我。或许，这才是不会发生的奇遇。\n幸运的是，对于爱情的向往是一个不死的魂灵，围城里的气氛若大雨将至时的紧张，耐人寻味却异常短暂。几年之后，王二开始快乐地跟何小舟生活在一起。现在的王二如那个恋爱的犀牛。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"f12a80e25a411de79a3f788acaa8c0c9","permalink":"https://chengjunwang.com/zh/post/cn/cn_archive/2008-05-01-happy-city/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/post/cn/cn_archive/2008-05-01-happy-city/","section":"post","summary":"","tags":null,"title":"围城里的快乐","type":"post"}]